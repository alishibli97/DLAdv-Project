{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_UCI(dset_name, splits=10, seed=0, separate_targets=True, save_dir='data/'):\n",
    "    mkdir(save_dir)\n",
    "\n",
    "    if dset_name == 'boston':\n",
    "        if not os.path.isfile(save_dir+'housing.data'):\n",
    "            urllib.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\",\n",
    "                               filename=save_dir+'housing.data')\n",
    "        data = pd.read_csv(save_dir + 'housing.data', header=0, delimiter=\"\\s+\").values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'concrete':\n",
    "        if not os.path.isfile(save_dir+'Concrete_Data.xls'):\n",
    "            urllib.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\",\n",
    "                               filename=save_dir+'Concrete_Data.xls')\n",
    "        data = pd.read_excel(save_dir+ 'Concrete_Data.xls', header=0, delimiter=\"\\s+\").values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'energy':\n",
    "        if not os.path.isfile(save_dir+'ENB2012_data.xlsx'):\n",
    "            urllib.urlretrieve(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\",\n",
    "                               filename=save_dir+'ENB2012_data.xlsx')\n",
    "        data = pd.read_excel(save_dir+'ENB2012_data.xlsx', header=0, delimiter=\"\\s+\").values\n",
    "        y_idx = [-2, -1]\n",
    "\n",
    "    elif dset_name == 'power':\n",
    "        if not os.path.isfile(save_dir+'CCPP.zip'):\n",
    "            urllib.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00294/CCPP.zip\",\n",
    "                               filename=save_dir+'CCPP.zip')\n",
    "        zipped = zipfile.ZipFile(save_dir+\"CCPP.zip\")\n",
    "        data = pd.read_excel(zipped.open('CCPP/Folds5x2_pp.xlsx'), header=0, delimiter=\"\\t\").values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'wine':\n",
    "        if not os.path.isfile(save_dir+'winequality-red.csv'):\n",
    "            urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "                               filename=save_dir+'winequality-red.csv')\n",
    "        data = pd.read_csv(save_dir+'winequality-red.csv', header=1, delimiter=';').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'yatch':\n",
    "        if not os.path.isfile(save_dir+'yacht_hydrodynamics.data'):\n",
    "            urllib.urlretrieve(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\",\n",
    "                               filename=save_dir+'yacht_hydrodynamics.data')\n",
    "        data = pd.read_csv(save_dir+'yacht_hydrodynamics.data', header=1, delimiter='\\s+').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'kin8nm':\n",
    "        if not os.path.isfile(save_dir+'dataset_2175_kin8nm.csv'):\n",
    "            urllib.urlretrieve(\"https://www.openml.org/data/get_csv/3626/dataset_2175_kin8nm.csv\",\n",
    "                               filename=save_dir+'dataset_2175_kin8nm.csv')\n",
    "        data = pd.read_csv(save_dir+'dataset_2175_kin8nm.csv', header=1, delimiter=',').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'kin8nm':\n",
    "        if not os.path.isfile(save_dir+'dataset_2175_kin8nm.csv'):\n",
    "            urllib.urlretrieve(\"https://www.openml.org/data/get_csv/3626/dataset_2175_kin8nm.csv\",\n",
    "                               filename=save_dir+'dataset_2175_kin8nm.csv')\n",
    "        data = pd.read_csv(save_dir+'dataset_2175_kin8nm.csv', header=1, delimiter=',').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'naval':\n",
    "        if not os.path.isfile(save_dir + 'UCI%20CBM%20Dataset.zip'):\n",
    "            urllib.urlretrieve(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00316/UCI%20CBM%20Dataset.zip\",\n",
    "                               filename=save_dir + 'UCI%20CBM%20Dataset.zip')\n",
    "        zipped = zipfile.ZipFile(save_dir + \"UCI%20CBM%20Dataset.zip\")\n",
    "        data = pd.read_csv(zipped.open('UCI CBM Dataset/data.txt'), header='infer', delimiter=\"\\s+\").values\n",
    "        y_idx = [-2, -1]\n",
    "\n",
    "    elif dset_name == 'protein':\n",
    "        if not os.path.isfile(save_dir+'CASP.csv'):\n",
    "            urllib.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00265/CASP.csv\",\n",
    "                               filename=save_dir+'CASP.csv')\n",
    "        data = pd.read_csv(save_dir+'CASP.csv', header=1, delimiter=',').values\n",
    "        y_idx = [0]\n",
    "\n",
    "    elif dset_name == 'default_credit':\n",
    "        if not os.path.isfile(save_dir + 'default of credit card clients.xls'):\n",
    "            urllib.request.urlretrieve(\n",
    "                \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\",\n",
    "                filename=save_dir + 'default of credit card clients.xls')\n",
    "        data = pd.read_excel(save_dir + 'default of credit card clients.xls', header=[0, 1], index_col=0, # delimiter=\"\\s+\"\n",
    "                             ).values\n",
    "        y_idx = [-1]  # OK\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('Dataset name doesnt match any known datasets.')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    data = data[np.random.permutation(np.arange(len(data)))]\n",
    "\n",
    "    kf = KFold(n_splits=splits)\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "\n",
    "        if separate_targets:\n",
    "            x_idx = list(range(data.shape[1]))\n",
    "            for e in y_idx:\n",
    "                x_idx.remove(x_idx[e])\n",
    "\n",
    "            x_idx = np.array(x_idx)\n",
    "            y_idx = np.array(y_idx)\n",
    "            x_train, y_train = data[train_index, :], data[train_index, :]\n",
    "            x_train, y_train = x_train[:, x_idx], y_train[:, y_idx]\n",
    "            x_test, y_test = data[test_index, :], data[test_index, :]\n",
    "            x_test, y_test = x_test[:, x_idx], y_test[:, y_idx]\n",
    "\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "            y_means, y_stds = y_train.mean(axis=0), y_train.std(axis=0)\n",
    "\n",
    "            y_stds[y_stds < 1e-10] = 1\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            y_train = ((y_train - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "            y_test = ((y_test - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds\n",
    "\n",
    "        else:\n",
    "            x_train, x_test = data[train_index, :], data[test_index, :]\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path, mode=0o777)\n",
    "            \n",
    "def unnormalise_cat_vars(x, x_means, x_stds, input_dim_vec):\n",
    "    input_dim_vec = np.array(input_dim_vec)\n",
    "    unnorm_x = np.multiply(x, x_stds) + x_means\n",
    "\n",
    "    fixed_unnorm = unnorm_x.round()\n",
    "    fixed_unnorm -= fixed_unnorm.min(axis=0).reshape([1, fixed_unnorm.shape[1]])  # this sets all mins to 0\n",
    "    for idx, dims in enumerate(input_dim_vec):\n",
    "        if dims > 1:\n",
    "            vec = fixed_unnorm[:, idx]\n",
    "            vec[vec > dims - 1] = dims - 1\n",
    "            fixed_unnorm[:, idx] = vec\n",
    "\n",
    "    x[:, input_dim_vec > 1] = fixed_unnorm[:, input_dim_vec > 1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wine', 'default_credit', 'compas', 'lsat']\n",
    "widths = [300, 300, 300, 300] # [200, 200, 200, 200]\n",
    "depths = [3, 3, 3, 3] # We go deeper because we are using residual models\n",
    "latent_dims = [6, 8, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine (1438, 11) (160, 11)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds = \\\n",
    "    load_UCI(dset_name='wine', splits=10, seed=42, separate_targets=True, save_dir='../data/')\n",
    "print('Wine', x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds = \\\n",
    "load_UCI(dset_name='default_credit', splits=10, seed=42, separate_targets=True, save_dir='../data/')\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = unnormalise_cat_vars(x_train, x_means, x_stds, input_dim_vec)\n",
    "x_test = unnormalise_cat_vars(x_test, x_means, x_stds, input_dim_vec)\n",
    "# target unnormalisation\n",
    "y_train = unnormalise_cat_vars(y_train, y_means, y_stds, [2])\n",
    "y_test = unnormalise_cat_vars(y_test, y_means, y_stds, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_credit\n"
     ]
    }
   ],
   "source": [
    "dname = 'default_credit'\n",
    "print(dname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1]\n",
    "len(input_dim_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(input_dim_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "cuda = torch.cuda.is_available()\n",
    "from torch.nn import MSELoss,CrossEntropyLoss\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import kl_divergence\n",
    "\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cprint(color, text, **kwargs):\n",
    "    if color[0] == '*':\n",
    "        pre_code = '1;'\n",
    "        color = color[1:]\n",
    "    else:\n",
    "        pre_code = ''\n",
    "    code = {\n",
    "        'a': '30',\n",
    "        'r': '31',\n",
    "        'g': '32',\n",
    "        'y': '33',\n",
    "        'b': '34',\n",
    "        'p': '35',\n",
    "        'c': '36',\n",
    "        'w': '37'\n",
    "    }\n",
    "    print(\"\\x1b[%s%sm%s\\x1b[0m\" % (pre_code, code[color], text), **kwargs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# (used in sub network)\n",
    "def normal_parse_params(params, min_sigma=1e-3):\n",
    "    \"\"\"\n",
    "    Take a Tensor (e. g. neural network output) and return\n",
    "    torch.distributions.Normal distribution.\n",
    "    This Normal distribution is component-wise independent,\n",
    "    and its dimensionality depends on the input shape.\n",
    "    First half of channels is mean of the distribution,\n",
    "    the softplus of the second half is std (sigma), so there is\n",
    "    no restrictions on the input tensor.\n",
    "    min_sigma is the minimal value of sigma. I. e. if the above\n",
    "    softplus is less than min_sigma, then sigma is clipped\n",
    "    from below with value min_sigma. This regularization\n",
    "    is required for the numerical stability and may be considered\n",
    "    as a neural network architecture choice without any change\n",
    "    to the probabilistic model.\n",
    "    \"\"\"\n",
    "    n = params.shape[0]\n",
    "    d = params.shape[1]\n",
    "    mu = params[:, :d // 2]\n",
    "    sigma_params = params[:, d // 2:]\n",
    "    sigma = softplus(sigma_params)\n",
    "    sigma = sigma.clamp(min=min_sigma)\n",
    "    distr = Normal(mu, sigma)\n",
    "    return distr\n",
    "\n",
    "## (used in the next function)\n",
    "def torch_onehot(y, Nclass):\n",
    "    if y.is_cuda:\n",
    "        y = y.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        y = y.type(torch.LongTensor)\n",
    "    y_onehot = torch.zeros((y.shape[0], Nclass)).type(y.type())\n",
    "    # In your for loop\n",
    "    y_onehot.scatter_(1, y.unsqueeze(1), 1)\n",
    "    return y_onehot\n",
    "\n",
    "## (used in the fit of the main network)\n",
    "def gauss_cat_to_flat(x, input_dim_vec):\n",
    "    output = []\n",
    "    for idx, dim in enumerate(input_dim_vec):\n",
    "        if dim == 1:\n",
    "            output.append(x[:, idx].unsqueeze(1))\n",
    "        elif dim > 1:\n",
    "            oh_vec = torch_onehot(x[:, idx], dim).type(x.type())\n",
    "            output.append(oh_vec)\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "    return torch.cat(output, dim=1)\n",
    "\n",
    "## (also used in the fit of the main network)\n",
    "def flat_to_gauss_cat(x, input_dim_vec):\n",
    "    output = []\n",
    "    cum_dims = 0\n",
    "    for idx, dims in enumerate(input_dim_vec):\n",
    "        if dims == 1:\n",
    "            output.append(x[:, cum_dims].unsqueeze(1))\n",
    "            cum_dims += 1\n",
    "\n",
    "        elif dims > 1:\n",
    "            output.append(x[:, cum_dims:cum_dims + dims].max(dim=1)[1].type(x.type()).unsqueeze(1))\n",
    "            cum_dims += dims\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "\n",
    "    return torch.cat(output, dim=1)\n",
    "\n",
    "## (also used in the fit of the main network)\n",
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "        out.append(v)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    Skip-connection over the sequence of layers in the constructor.\n",
    "    The module passes input data sequentially through these layers\n",
    "    and then adds original data to the result.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        super(SkipConnection, self).__init__()\n",
    "        self.inner_net = nn.Sequential(*args)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input + self.inner_net(input)\n",
    "\n",
    "def preact_leaky_MLPBlock(width):\n",
    "    return SkipConnection(\n",
    "        nn.LeakyReLU(),\n",
    "        nn.BatchNorm1d(num_features=width),\n",
    "        nn.Linear(width, width),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_preact_recognition_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_preact_recognition_net, self).__init__()\n",
    "        # input layer\n",
    "        proposal_layers = [nn.Linear(input_dim, width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            proposal_layers.append(\n",
    "                preact_leaky_MLPBlock(width)) ## *dependency\n",
    "        # output layer\n",
    "        proposal_layers.extend(\n",
    "            [nn.LeakyReLU(), nn.BatchNorm1d(num_features=width),\n",
    "            nn.Linear(width, latent_dim * 2)])\n",
    "\n",
    "        self.block = nn.Sequential(*proposal_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_preact_generator_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_preact_generator_net, self).__init__()\n",
    "        # input layer\n",
    "        generative_layers = [nn.Linear(latent_dim, width), nn.LeakyReLU(), nn.BatchNorm1d(num_features=width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            generative_layers.append(\n",
    "                    # skip-connection from prior network to generative network\n",
    "                    preact_leaky_MLPBlock(width))  ## *dependency\n",
    "        # output layer\n",
    "        generative_layers.extend([\n",
    "            nn.Linear(width,\n",
    "                      input_dim),\n",
    "        ])\n",
    "        self.block = nn.Sequential(*generative_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rms cat loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rms_cat_loglike(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim_vec, reduction='none'):\n",
    "        super(rms_cat_loglike, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        self.mse = MSELoss(reduction='none')  # takes(input, target)\n",
    "        self.ce = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        log_prob_vec = []\n",
    "        cum_dims = 0\n",
    "        for idx, dims in enumerate(self.input_dim_vec):\n",
    "            if dims == 1:\n",
    "                # Gaussian_case\n",
    "                log_prob_vec.append(-self.mse(x[:, cum_dims], y[:, idx]).unsqueeze(1))\n",
    "                cum_dims += 1\n",
    "\n",
    "            elif dims > 1:\n",
    "                if x.shape[1] == y.shape[1]:\n",
    "                    raise Exception('Input and target seem to be in flat format. Need integer cat targets.')\n",
    "                                \n",
    "                if y.is_cuda:\n",
    "                    tget = y[:, idx].type(torch.cuda.LongTensor)\n",
    "                else:\n",
    "                    tget = y[:, idx].type(torch.LongTensor)\n",
    "\n",
    "                log_prob_vec.append(-self.ce(x[:, cum_dims:cum_dims + dims], tget).unsqueeze(1))\n",
    "                cum_dims += dims\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Error, invalid dimension value')\n",
    "\n",
    "        log_prob_vec = torch.cat(log_prob_vec, dim=1)\n",
    "\n",
    "        if self.reduction == 'none':\n",
    "            return log_prob_vec\n",
    "        elif self.reduction == 'sum':\n",
    "            return log_prob_vec.sum()\n",
    "        elif self.reduction == 'average':\n",
    "            return log_prob_vec.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_gauss_cat(nn.Module):\n",
    "    def __init__(self, input_dim_vec, width, depth, latent_dim, pred_sig=False):\n",
    "        super(VAE_gauss_cat, self).__init__()\n",
    "\n",
    "        input_dim = 0\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        for e in input_dim_vec:\n",
    "            input_dim += e\n",
    "        \n",
    "        self.encoder = MLP_preact_recognition_net(input_dim, width, depth, latent_dim) ## *dependency\n",
    "        if pred_sig:\n",
    "            raise NotImplementedError()\n",
    "            # self.decoder = generator_net(2*input_dim, width, depth, latent_dim)\n",
    "            # self.rec_loglike = GaussianLoglike(min_sigma=1e-2)\n",
    "        else:\n",
    "            self.decoder = MLP_preact_generator_net(input_dim, width, depth, latent_dim)\n",
    "            self.rec_loglike = rms_cat_loglike(self.input_dim_vec, reduction='none') ## *dependency\n",
    "        self.pred_sig = pred_sig\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Works with flattened representATION\"\"\"\n",
    "        approx_post_params = self.encoder(x)\n",
    "        approx_post = normal_parse_params(approx_post_params, 1e-3)\n",
    "        return approx_post\n",
    "\n",
    "    def decode(self, z_sample):\n",
    "        \"\"\"Works with flattened representATION\"\"\"\n",
    "        rec_params = self.decoder(z_sample)\n",
    "        return rec_params\n",
    "\n",
    "    def vlb(self, prior, approx_post, x, rec_params):\n",
    "        \"\"\"Works with flattened representATION\"\"\"\n",
    "        if self.pred_sig:\n",
    "            pass\n",
    "        else:\n",
    "            rec = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "        return rec - kl\n",
    "\n",
    "    def iwlb(self, prior, approx_post, x, K=50):\n",
    "        estimates = []\n",
    "        for i in range(K):\n",
    "            latent = approx_post.rsample()\n",
    "            rec_params = self.decode(latent)\n",
    "            if self.pred_sig:\n",
    "                pass\n",
    "            else:\n",
    "                rec_loglike = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "\n",
    "            prior_log_prob = prior.log_prob(latent)\n",
    "            prior_log_prob = prior_log_prob.view(x.shape[0], -1)\n",
    "            prior_log_prob = prior_log_prob.sum(-1)\n",
    "\n",
    "            proposal_log_prob = approx_post.log_prob(latent)\n",
    "            proposal_log_prob = proposal_log_prob.view(x.shape[0], -1)\n",
    "            proposal_log_prob = proposal_log_prob.sum(-1)\n",
    "\n",
    "            estimate = rec_loglike + prior_log_prob - proposal_log_prob\n",
    "            estimates.append(estimate[:, None])\n",
    "\n",
    "        return torch.logsumexp(torch.cat(estimates, 1), 1) - np.log(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(object):\n",
    "    def __init__(self):\n",
    "        cprint('c', '\\nNet:')\n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return np.sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "    def set_mode_train(self, train=True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "    def update_lr(self, epoch, gamma=0.99):\n",
    "        self.epoch += 1\n",
    "        if self.schedule is not None:\n",
    "            if len(self.schedule) == 0 or epoch in self.schedule:\n",
    "                self.lr *= gamma\n",
    "                print('learning rate: %f  (%d)\\n' % (self.lr, epoch))\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.lr\n",
    "\n",
    "    def save(self, filename):\n",
    "        cprint('c', 'Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer}, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        cprint('c', 'Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactified Adam (RAdam) Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt(\n",
    "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_gauss_cat_net(BaseNet):\n",
    "    def __init__(self, input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=1e-3, cuda=True, flatten=True):\n",
    "        super(VAE_gauss_cat_net, self).__init__()\n",
    "        cprint('y', 'VAE_gauss_net')\n",
    "\n",
    "        self.cuda = cuda\n",
    "        self.input_dim = 0\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        for e in self.input_dim_vec:\n",
    "            self.input_dim += e\n",
    "        self.flatten = flatten\n",
    "        if not self.flatten:\n",
    "            pass\n",
    "            # raise Exception('Error calculation not supported without flattening')\n",
    "\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.pred_sig = pred_sig\n",
    "        \n",
    "        # Here create the network\n",
    "        self.create_net()\n",
    "        \n",
    "        # Here create the optimizer\n",
    "        self.create_opt()\n",
    "        \n",
    "        self.epoch = 0\n",
    "        self.schedule = None\n",
    "\n",
    "        if self.cuda:\n",
    "            self.prior = self.prior = Normal(loc=torch.zeros(latent_dim).cuda(), scale=torch.ones(latent_dim).cuda())\n",
    "        else:\n",
    "            self.prior = Normal(loc=torch.zeros(latent_dim), scale=torch.ones(latent_dim))\n",
    "        self.vlb_scale = 1 / len(self.input_dim_vec)  # scale for dimensions of input so we can use same LR always\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        self.model = VAE_gauss_cat(self.input_dim_vec, self.width, self.depth, self.latent_dim, self.pred_sig)\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = RAdam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def fit(self, x):\n",
    "        self.set_mode_train(train=True)\n",
    "\n",
    "        if self.flatten:\n",
    "            x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        else:\n",
    "            x_flat = x\n",
    "            x = flat_to_gauss_cat(x, self.input_dim_vec)\n",
    "\n",
    "        x, x_flat = to_variable(var=(x, x_flat), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        approx_post = self.model.encode(x_flat)\n",
    "        z_sample = approx_post.rsample()\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(self.prior, approx_post, x, rec_params)\n",
    "        loss = (- vlb * self.vlb_scale).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return vlb.mean().item(), rec_params\n",
    "\n",
    "    def eval(self, x, sample=False):\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        if self.flatten:\n",
    "            x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        else:\n",
    "            x_flat = x\n",
    "            x = flat_to_gauss_cat(x, self.input_dim_vec)\n",
    "\n",
    "        x, x_flat = to_variable(var=(x, x_flat), cuda=self.cuda)\n",
    "        approx_post = self.model.encode(x_flat)\n",
    "        if sample:\n",
    "            z_sample = approx_post.sample()\n",
    "        else:\n",
    "            z_sample = approx_post.loc\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(self.prior, approx_post, x, rec_params)\n",
    "\n",
    "        return vlb.mean().item(), rec_params\n",
    "\n",
    "    def eval_iw(self, x, k=50):\n",
    "        self.set_mode_train(train=False)\n",
    "        if self.flatten:\n",
    "            x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        else:\n",
    "            x_flat = x\n",
    "            x = flat_to_gauss_cat(x, self.input_dim_vec)\n",
    "\n",
    "        x, x_flat = to_variable(var=(x, x_flat), cuda=self.cuda)\n",
    "\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "\n",
    "        iw_lb = self.model.iwlb(self.prior, approx_post, x, k)\n",
    "        return iw_lb.mean().item()\n",
    "\n",
    "    def recongnition(self, x, grad=False, flatten=None):\n",
    "        if flatten is None:\n",
    "            flatten = self.flatten\n",
    "        if flatten and grad:\n",
    "            raise Exception('flatten and grad options are not compatible')\n",
    "        self.set_mode_train(train=False)\n",
    "        if flatten:\n",
    "            x = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        if grad:\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "        else:\n",
    "            x, = to_variable(var=(x,), volatile=True, cuda=self.cuda)\n",
    "        approx_post = self.model.encode(x)\n",
    "        return approx_post\n",
    "\n",
    "    def regenerate(self, z, grad=False, unflatten=False):\n",
    "        if unflatten and grad:\n",
    "            raise Exception('flatten and grad options are not compatible')\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not z.requires_grad:\n",
    "                z.requires_grad = True\n",
    "        else:\n",
    "            z, = to_variable(var=(z,), volatile=True, cuda=self.cuda)\n",
    "        out = self.model.decode(z)\n",
    "\n",
    "        if unflatten:\n",
    "            out = flat_to_gauss_cat(out, self.input_dim_vec)\n",
    "        else:\n",
    "            out = selective_softmax(out, self.input_dim_vec, grad=grad)\n",
    "\n",
    "        if self.pred_sig:\n",
    "            raise Exception('Not implemented')\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = widths[names.index(dname)]\n",
    "depth = depths[names.index(dname)] # number of hidden layers\n",
    "latent_dim = latent_dims[names.index(dname)]\n",
    "\n",
    "batch_size = 128\n",
    "nb_epochs = 2500\n",
    "lr = 1e-4\n",
    "early_stop = 200\n",
    "\n",
    "# cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mVAE_gauss_net\u001b[0m\n",
      "    Total params: 0.39M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-03b0ab969b31>:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    }
   ],
   "source": [
    "net = VAE_gauss_cat_net(input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=lr, cuda=cuda, flatten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Datafeed(data.Dataset):\n",
    "\n",
    "    def __init__(self, x_train, y_train=None, transform=None):\n",
    "        self.data = x_train\n",
    "        self.targets = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.targets is not None:\n",
    "            return img, self.targets[index]\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Datafeed(x_train, x_train, transform=None)\n",
    "valset = Datafeed(x_test, x_test, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(net, name, batch_size, nb_epochs, trainset, valset, cuda, flat_ims=False,\n",
    "              train_plot=False, Nclass=None, early_stop=None, script_mode=False):\n",
    "\n",
    "    models_dir = name + '_models'\n",
    "    results_dir = name + '_results'\n",
    "    mkdir(models_dir)\n",
    "    mkdir(results_dir)\n",
    "\n",
    "    if cuda:\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                                  num_workers=3)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                                num_workers=3)\n",
    "\n",
    "    else:\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                                  num_workers=3)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                                num_workers=3)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "    cprint('c', '\\nNetwork:')\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # train\n",
    "    cprint('c', '\\nTrain:')\n",
    "\n",
    "    print('  init cost variables:')\n",
    "    vlb_train = np.zeros(nb_epochs)\n",
    "    vlb_dev = np.zeros(nb_epochs)\n",
    "    best_vlb = -np.inf\n",
    "    best_vlb_train = -np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    nb_its_dev = 1\n",
    "\n",
    "    tic0 = time.time()\n",
    "    for i in range(epoch, nb_epochs):\n",
    "        net.set_mode_train(True)\n",
    "\n",
    "        tic = time.time()\n",
    "        nb_samples = 0\n",
    "        for x, y in trainloader:\n",
    "\n",
    "            if flat_ims:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "            if Nclass is not None:\n",
    "                y_oh = torch_onehot(y, Nclass).type(x.type())\n",
    "                x = torch.cat([x, y_oh], 1)\n",
    "\n",
    "            cost, _ = net.fit(x)\n",
    "\n",
    "            vlb_train[i] += cost * len(x)\n",
    "            nb_samples += len(x)\n",
    "\n",
    "        vlb_train[i] /= nb_samples\n",
    "\n",
    "        toc = time.time()\n",
    "\n",
    "        # ---- print\n",
    "        print(\"it %d/%d, vlb %f, \" % (i, nb_epochs, vlb_train[i]), end=\"\")\n",
    "        cprint('r', '   time: %f seconds\\n' % (toc - tic))\n",
    "        net.update_lr(i)\n",
    "\n",
    "        if vlb_train[i] > best_vlb_train:\n",
    "            best_vlb_train = vlb_train[i]\n",
    "\n",
    "        # ---- dev\n",
    "        if i % nb_its_dev == 0:\n",
    "            nb_samples = 0\n",
    "            for j, (x, y) in enumerate(valloader):\n",
    "\n",
    "                if flat_ims:\n",
    "                    x = x.view(x.shape[0], -1)\n",
    "                if Nclass is not None:\n",
    "                    y_oh = torch_onehot(y, Nclass).type(x.type())\n",
    "                    x = torch.cat([x, y_oh], 1)\n",
    "\n",
    "                cost, _ = net.eval(x)\n",
    "\n",
    "                vlb_dev[i] += cost * len(x)\n",
    "                nb_samples += len(x)\n",
    "\n",
    "            vlb_dev[i] /= nb_samples\n",
    "\n",
    "            cprint('g', '    vlb %f (%f)\\n' % (vlb_dev[i], best_vlb))\n",
    "\n",
    "            if train_plot:\n",
    "                zz = net.recongnition(x).sample()\n",
    "                o = net.regenerate(zz)\n",
    "                try:\n",
    "                    o = o.cpu()\n",
    "                except:\n",
    "                    o = o.loc.cpu()\n",
    "                if len(x.shape) == 2:\n",
    "                    side = int(np.sqrt(x.shape[1]))\n",
    "                    x = x.view(-1, 1, side, side).data\n",
    "                    o = o.view(-1, 1, side, side).data\n",
    "\n",
    "                # save_image(torch.cat([x[:8], o[:8]]), results_dir + '/rec_%d.png' % i, nrow=8)\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                dd = make_grid(torch.cat([x[:10], o[:10]]), nrow=10).numpy()\n",
    "                plt.imshow(np.transpose(dd, (1, 2, 0)), interpolation='nearest')\n",
    "                if script_mode:\n",
    "                    plt.savefig(results_dir + '/rec%d.png' % i)\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "                z_sample = normal(loc=0.0, scale=1.0, size=(36, net.latent_dim))\n",
    "                x_rec = net.regenerate(z_sample)\n",
    "                try:\n",
    "                    x_rec = x_rec.cpu()\n",
    "                except:\n",
    "                    x_rec = x_rec.loc.cpu()\n",
    "                if len(x_rec.shape) == 2:\n",
    "                    side = int(np.sqrt(x_rec.shape[1]))\n",
    "                    x_rec = x_rec.view(-1, 1, side, side)\n",
    "                plt.figure()\n",
    "                dd = make_grid(x_rec, nrow=6).numpy()\n",
    "                plt.imshow(np.transpose(dd, (1, 2, 0)), interpolation='nearest')\n",
    "                if script_mode:\n",
    "                    plt.savefig(results_dir + '/sample%d.png' % i)\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "        if vlb_dev[i] > best_vlb:\n",
    "            best_vlb = vlb_dev[i]\n",
    "            best_epoch = i\n",
    "            net.save(models_dir + '/theta_best.dat')\n",
    "\n",
    "        if early_stop is not None and (i - best_epoch) > early_stop:\n",
    "            break\n",
    "\n",
    "\n",
    "    net.save(models_dir + '/theta_last.dat')\n",
    "    toc0 = time.time()\n",
    "    runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n",
    "    cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # results\n",
    "    cprint('c', '\\nRESULTS:')\n",
    "    nb_parameters = net.get_nb_parameters()\n",
    "    best_cost_dev = best_vlb\n",
    "    best_cost_train = best_vlb_train\n",
    "\n",
    "    print('  best_vlb_dev: %f' % best_cost_dev)\n",
    "    print('  best_vlb_train: %f' % best_cost_train)\n",
    "    print('  nb_parameters: %d (%s)\\n' % (nb_parameters, humansize(nb_parameters)))\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # fig cost vs its\n",
    "    if not train_plot:\n",
    "        import matplotlib\n",
    "        matplotlib.use('agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    if train_plot:\n",
    "        plt.figure()\n",
    "        plt.plot(np.clip(vlb_train, -1000, 1000), 'r')\n",
    "        plt.plot(np.clip(vlb_dev[::nb_its_dev], -1000, 1000), 'b')\n",
    "        plt.legend(['cost_train', 'cost_dev'])\n",
    "        plt.ylabel('vlb')\n",
    "        plt.xlabel('it')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(results_dir+'/train_cost.png')\n",
    "        if train_plot:\n",
    "            plt.show()\n",
    "    return vlb_train, vlb_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../saves/fc_preact_VAE_NEW(300)_' + dname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n",
      "  init cost variables:\n",
      "it 0/2500, vlb -16.290074, \u001b[31m   time: 2.343825 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -11.441558 (-inf)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/2500, vlb -14.814891, \u001b[31m   time: 2.291842 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -10.454740 (-11.441558)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 2/2500, vlb -14.097355, \u001b[31m   time: 2.231448 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -10.100600 (-10.454740)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 3/2500, vlb -13.544256, \u001b[31m   time: 2.344557 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.498764 (-10.100600)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 4/2500, vlb -13.129443, \u001b[31m   time: 2.267055 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.556649 (-9.498764)\n",
      "\u001b[0m\n",
      "it 5/2500, vlb -12.812818, \u001b[31m   time: 2.539868 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.101098 (-9.498764)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 6/2500, vlb -12.606448, \u001b[31m   time: 2.481671 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.013099 (-9.101098)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 7/2500, vlb -12.342396, \u001b[31m   time: 2.624982 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.909029 (-9.013099)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 8/2500, vlb -12.141780, \u001b[31m   time: 2.771671 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.834703 (-8.909029)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 9/2500, vlb -11.981083, \u001b[31m   time: 2.560663 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.771822 (-8.834703)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 10/2500, vlb -11.753486, \u001b[31m   time: 2.566626 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.579128 (-8.771822)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 11/2500, vlb -11.668204, \u001b[31m   time: 2.264448 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.640714 (-8.579128)\n",
      "\u001b[0m\n",
      "it 12/2500, vlb -11.554207, \u001b[31m   time: 2.280070 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.595252 (-8.579128)\n",
      "\u001b[0m\n",
      "it 13/2500, vlb -11.391241, \u001b[31m   time: 2.277846 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.517128 (-8.579128)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 14/2500, vlb -11.301732, \u001b[31m   time: 2.282375 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.481410 (-8.517128)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 15/2500, vlb -11.210020, \u001b[31m   time: 2.357867 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.360753 (-8.481410)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 16/2500, vlb -11.122567, \u001b[31m   time: 2.385147 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.351461 (-8.360753)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 17/2500, vlb -11.044863, \u001b[31m   time: 2.497379 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.370161 (-8.351461)\n",
      "\u001b[0m\n",
      "it 18/2500, vlb -10.966908, \u001b[31m   time: 2.358974 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.329381 (-8.351461)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 19/2500, vlb -10.942292, \u001b[31m   time: 2.413961 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.264527 (-8.329381)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 20/2500, vlb -10.865368, \u001b[31m   time: 2.444369 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.232388 (-8.264527)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 21/2500, vlb -10.855445, \u001b[31m   time: 2.572135 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.260729 (-8.232388)\n",
      "\u001b[0m\n",
      "it 22/2500, vlb -10.844526, \u001b[31m   time: 2.347599 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.267958 (-8.232388)\n",
      "\u001b[0m\n",
      "it 23/2500, vlb -10.761832, \u001b[31m   time: 2.443555 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.290420 (-8.232388)\n",
      "\u001b[0m\n",
      "it 24/2500, vlb -10.696391, \u001b[31m   time: 2.393729 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.279800 (-8.232388)\n",
      "\u001b[0m\n",
      "it 25/2500, vlb -10.690333, \u001b[31m   time: 2.442498 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.187951 (-8.232388)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 26/2500, vlb -10.681901, \u001b[31m   time: 2.531088 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.093408 (-8.187951)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 27/2500, vlb -10.622975, \u001b[31m   time: 2.800425 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.157331 (-8.093408)\n",
      "\u001b[0m\n",
      "it 28/2500, vlb -10.552507, \u001b[31m   time: 2.520961 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.220952 (-8.093408)\n",
      "\u001b[0m\n",
      "it 29/2500, vlb -10.590360, \u001b[31m   time: 2.424788 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.133286 (-8.093408)\n",
      "\u001b[0m\n",
      "it 30/2500, vlb -10.524916, \u001b[31m   time: 2.557179 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.033274 (-8.093408)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 31/2500, vlb -10.530467, \u001b[31m   time: 2.411249 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.109143 (-8.033274)\n",
      "\u001b[0m\n",
      "it 32/2500, vlb -10.471777, \u001b[31m   time: 2.486400 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.023582 (-8.033274)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 33/2500, vlb -10.502127, \u001b[31m   time: 2.552063 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.092005 (-8.023582)\n",
      "\u001b[0m\n",
      "it 34/2500, vlb -10.468541, \u001b[31m   time: 2.640250 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.017210 (-8.023582)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 35/2500, vlb -10.483814, \u001b[31m   time: 2.459328 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.028010 (-8.017210)\n",
      "\u001b[0m\n",
      "it 36/2500, vlb -10.431358, \u001b[31m   time: 2.519193 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.042648 (-8.017210)\n",
      "\u001b[0m\n",
      "it 37/2500, vlb -10.439697, \u001b[31m   time: 2.533715 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.037225 (-8.017210)\n",
      "\u001b[0m\n",
      "it 38/2500, vlb -10.377056, \u001b[31m   time: 2.386995 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.981210 (-8.017210)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 39/2500, vlb -10.363830, \u001b[31m   time: 2.450847 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.955180 (-7.981210)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 40/2500, vlb -10.362526, \u001b[31m   time: 2.546993 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.968578 (-7.955180)\n",
      "\u001b[0m\n",
      "it 41/2500, vlb -10.334672, \u001b[31m   time: 2.538266 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.031477 (-7.955180)\n",
      "\u001b[0m\n",
      "it 42/2500, vlb -10.345121, \u001b[31m   time: 2.627566 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.935829 (-7.955180)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 43/2500, vlb -10.307108, \u001b[31m   time: 2.559281 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.962170 (-7.935829)\n",
      "\u001b[0m\n",
      "it 44/2500, vlb -10.310872, \u001b[31m   time: 2.596256 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.879782 (-7.935829)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 45/2500, vlb -10.264880, \u001b[31m   time: 2.567147 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.977906 (-7.879782)\n",
      "\u001b[0m\n",
      "it 46/2500, vlb -10.291956, \u001b[31m   time: 2.445687 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.065370 (-7.879782)\n",
      "\u001b[0m\n",
      "it 47/2500, vlb -10.283299, \u001b[31m   time: 2.560583 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.916870 (-7.879782)\n",
      "\u001b[0m\n",
      "it 48/2500, vlb -10.267509, \u001b[31m   time: 2.516195 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.010155 (-7.879782)\n",
      "\u001b[0m\n",
      "it 49/2500, vlb -10.235857, \u001b[31m   time: 2.472879 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.891722 (-7.879782)\n",
      "\u001b[0m\n",
      "it 50/2500, vlb -10.216478, \u001b[31m   time: 2.645962 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.002574 (-7.879782)\n",
      "\u001b[0m\n",
      "it 51/2500, vlb -10.196035, \u001b[31m   time: 2.469810 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.932511 (-7.879782)\n",
      "\u001b[0m\n",
      "it 52/2500, vlb -10.189023, \u001b[31m   time: 2.554837 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.895248 (-7.879782)\n",
      "\u001b[0m\n",
      "it 53/2500, vlb -10.192932, \u001b[31m   time: 2.459752 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.898193 (-7.879782)\n",
      "\u001b[0m\n",
      "it 54/2500, vlb -10.207169, \u001b[31m   time: 2.514361 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.954171 (-7.879782)\n",
      "\u001b[0m\n",
      "it 55/2500, vlb -10.154208, \u001b[31m   time: 2.525043 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.908042 (-7.879782)\n",
      "\u001b[0m\n",
      "it 56/2500, vlb -10.183709, \u001b[31m   time: 2.519599 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -7.879159 (-7.879782)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 57/2500, vlb -10.152980, \u001b[31m   time: 2.482724 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.956826 (-7.879159)\n",
      "\u001b[0m\n",
      "it 58/2500, vlb -10.162180, \u001b[31m   time: 2.617347 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.926289 (-7.879159)\n",
      "\u001b[0m\n",
      "it 59/2500, vlb -10.143148, \u001b[31m   time: 2.491330 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.918534 (-7.879159)\n",
      "\u001b[0m\n",
      "it 60/2500, vlb -10.141480, \u001b[31m   time: 2.712121 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.917398 (-7.879159)\n",
      "\u001b[0m\n",
      "it 61/2500, vlb -10.100748, \u001b[31m   time: 2.459818 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.854641 (-7.879159)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAE_NEW(300)_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 62/2500, vlb -10.107993, \u001b[31m   time: 2.572758 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.880467 (-7.854641)\n",
      "\u001b[0m\n",
      "it 63/2500, vlb -10.106003, \u001b[31m   time: 2.512296 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.863739 (-7.854641)\n",
      "\u001b[0m\n",
      "it 64/2500, vlb -10.102460, \u001b[31m   time: 2.536662 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.892385 (-7.854641)\n",
      "\u001b[0m\n",
      "it 65/2500, vlb -10.092575, \u001b[31m   time: 2.522833 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.882633 (-7.854641)\n",
      "\u001b[0m\n",
      "it 66/2500, vlb -10.093885, \u001b[31m   time: 2.517159 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.885539 (-7.854641)\n",
      "\u001b[0m\n",
      "it 67/2500, vlb -10.071789, \u001b[31m   time: 2.472955 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.885369 (-7.854641)\n",
      "\u001b[0m\n",
      "it 68/2500, vlb -10.081558, \u001b[31m   time: 2.487719 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.897463 (-7.854641)\n",
      "\u001b[0m\n",
      "it 69/2500, vlb -10.065825, \u001b[31m   time: 2.439138 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.885619 (-7.854641)\n",
      "\u001b[0m\n",
      "it 70/2500, vlb -10.069697, \u001b[31m   time: 2.534292 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.915450 (-7.854641)\n",
      "\u001b[0m\n",
      "it 71/2500, vlb -10.033885, \u001b[31m   time: 2.615398 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.896299 (-7.854641)\n",
      "\u001b[0m\n",
      "it 72/2500, vlb -10.044313, \u001b[31m   time: 2.580477 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.892250 (-7.854641)\n",
      "\u001b[0m\n",
      "it 73/2500, vlb -10.036574, \u001b[31m   time: 3.092170 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.900278 (-7.854641)\n",
      "\u001b[0m\n",
      "it 74/2500, vlb -10.047751, \u001b[31m   time: 2.694768 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.942364 (-7.854641)\n",
      "\u001b[0m\n",
      "it 75/2500, vlb -10.062931, \u001b[31m   time: 2.661241 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.927680 (-7.854641)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-168:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ali/anaconda3/envs/py38/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-cd0d350a6071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vlb_train, vlb_dev = train_VAE(net, save_dir, batch_size, nb_epochs, trainset, valset,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                cuda=cuda, flat_ims=False, train_plot=False, early_stop=early_stop)\n",
      "\u001b[0;32m<ipython-input-52-504e1913e773>\u001b[0m in \u001b[0;36mtrain_VAE\u001b[0;34m(net, name, batch_size, nb_epochs, trainset, valset, cuda, flat_ims, train_plot, Nclass, early_stop, script_mode)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_oh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mvlb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-94c50629fb3f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mapprox_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapprox_post\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mrec_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mvlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-4801359e66c3>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z_sample)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m\"\"\"Works with flattened representATION\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mrec_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrec_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c9d16fd3dc47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vlb_train, vlb_dev = train_VAE(net, save_dir, batch_size, nb_epochs, trainset, valset,\n",
    "                               cuda=cuda, flat_ims=False, train_plot=False, early_stop=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "282.986px",
    "width": "217.986px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
