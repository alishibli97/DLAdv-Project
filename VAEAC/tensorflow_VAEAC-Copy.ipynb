{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310825f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import uniform, binomial\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# To remove WARNINGS from saving the models without compiling them first\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "#print(tf.__version__)\n",
    "#print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e185160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "#Working with CPU for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7336c",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59efb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_credit\n"
     ]
    }
   ],
   "source": [
    "# For Default credit\n",
    "\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2]\n",
    "width = 350\n",
    "depth = 3\n",
    "latent_dim = 8\n",
    "\n",
    "\n",
    "# For all tabular data sets\n",
    "\"\"\"\n",
    "names = ['wine', 'default_credit', 'compas', 'lsat']\n",
    "widths = [350, 350, 350, 350] # Bigger than VAE because the task of modelling all conditionals is more complex\n",
    "depths = [3, 3, 3, 3] # We go deeper because we are using residual models\n",
    "latent_dims = [6, 8, 4, 4]\n",
    "under_latent_dims = [6, 8, 4, 4] # following the original paper we set dim(u) = dim(z) with d>r [r is true manifold dim]\n",
    "under_latent_dims2 = [4, 6, 3, 3] # following the original paper we set dim(u) = dim(z) with d>r [r is true manifold dim]\n",
    "\"\"\"\n",
    "dname = 'default_credit'\n",
    "print(dname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33809880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets in UCI\n",
    "def load_UCI(dset_name, splits=10, seed=0, separate_targets=True, save_dir='data/'):\n",
    "    mkdir(save_dir)\n",
    "\n",
    "    if dset_name == 'wine':\n",
    "        if not os.path.isfile(save_dir+'winequality-red.csv'):\n",
    "            urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "                               filename=save_dir+'winequality-red.csv')\n",
    "        data = pd.read_csv(save_dir+'winequality-red.csv', header=1, delimiter=';').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'default_credit':\n",
    "        if not os.path.isfile(save_dir + 'default of credit card clients.xls'):\n",
    "            urllib.request.urlretrieve(\n",
    "                \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\",\n",
    "                filename=save_dir + 'default of credit card clients.xls')\n",
    "        data = pd.read_excel(save_dir + 'default of credit card clients.xls', header=[0, 1], index_col=0, # delimiter=\"\\s+\"\n",
    "                             ).values\n",
    "        y_idx = [-1]  # OK\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('Dataset name doesnt match any known datasets.')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    data = data[np.random.permutation(np.arange(len(data)))] #Shuffle the data\n",
    "    \n",
    "    kf = KFold(n_splits=splits)\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "\n",
    "        # Not sure what separate targets is\n",
    "        if separate_targets:\n",
    "            x_idx = list(range(data.shape[1]))\n",
    "            for e in y_idx:\n",
    "                x_idx.remove(x_idx[e])\n",
    "\n",
    "            x_idx = np.array(x_idx)\n",
    "            y_idx = np.array(y_idx)\n",
    "            x_train, y_train = data[train_index, :], data[train_index, :]\n",
    "            x_train, y_train = x_train[:, x_idx], y_train[:, y_idx]\n",
    "            x_test, y_test = data[test_index, :], data[test_index, :]\n",
    "            x_test, y_test = x_test[:, x_idx], y_test[:, y_idx]\n",
    "\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "            y_means, y_stds = y_train.mean(axis=0), y_train.std(axis=0)\n",
    "\n",
    "            y_stds[y_stds < 1e-10] = 1\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            y_train = ((y_train - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "            y_test = ((y_test - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds\n",
    "\n",
    "        else:\n",
    "            x_train, x_test = data[train_index, :], data[test_index, :]\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path, mode=0o777)\n",
    "\n",
    "# Not sure why this is needed\n",
    "def unnormalise_cat_vars(x, x_means, x_stds, input_dim_vec):\n",
    "    input_dim_vec = np.array(input_dim_vec)\n",
    "    unnorm_x = np.multiply(x, x_stds) + x_means\n",
    "\n",
    "    fixed_unnorm = unnorm_x.round()\n",
    "    fixed_unnorm -= fixed_unnorm.min(axis=0).reshape([1, fixed_unnorm.shape[1]])  # this sets all mins to 0\n",
    "    for idx, dims in enumerate(input_dim_vec):\n",
    "        if dims > 1:\n",
    "            vec = fixed_unnorm[:, idx]\n",
    "            vec[vec > dims - 1] = dims - 1\n",
    "            fixed_unnorm[:, idx] = vec\n",
    "\n",
    "    x[:, input_dim_vec > 1] = fixed_unnorm[:, input_dim_vec > 1]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c633c97",
   "metadata": {},
   "source": [
    "## Recognition (Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5836060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The arguments sent to the different keras layers are there to mimic the Torch layers in CLUE.\n",
    "\"\"\"\n",
    "\n",
    "def create_recognition_encoder(width, depth, latent_dim, input_dim_vec):\n",
    "    # Tensorflow network as one big Russian doll\n",
    "    nb_inputs = sum(input_dim_vec)\n",
    "    inputs = keras.Input(shape=(nb_inputs,))\n",
    "    #inputs = keras.Input(shape=(None,nb_inputs))\n",
    "    input = layers.Dense(width, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/nb_inputs), math.sqrt(1/nb_inputs)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/nb_inputs), math.sqrt(1/nb_inputs))) \\\n",
    "                         (inputs)\n",
    "\n",
    "    for i in range(depth-1):\n",
    "\n",
    "        x = layers.LeakyReLU(alpha=0.01)(input)\n",
    "        x = layers.BatchNormalization(momentum=0.1, epsilon=1e-5)(x)\n",
    "        x = layers.Dense(width, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width))) \\\n",
    "                         (x)\n",
    "\n",
    "        # Skip connection \n",
    "        x = x + input\n",
    "\n",
    "        input = x\n",
    "\n",
    "    # Final layers\n",
    "    x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1, epsilon=1e-5)(x)\n",
    "    outputs = layers.Dense(latent_dim*2, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width))) \\\n",
    "                         (x)\n",
    "\n",
    "    recognition_encoder = keras.Model(inputs=inputs, outputs=outputs, name=\"recognition_encoder_model\")\n",
    "    return recognition_encoder\n",
    "#recognition_encoder.summary()\n",
    "\n",
    "# keras.utils.plot_model(encoder, \"encoder.png\")\n",
    "#keras.utils.plot_model(recognition_encoder, \"recognition.png\", show_shapes=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06253187",
   "metadata": {},
   "source": [
    "## Prior network (Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd58a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The arguments sent to the different keras layers are there to mimic the Torch layers in CLUE.\n",
    "\"\"\"\n",
    "def create_prior_encoder(width, depth, latent_dim, input_dim_vec):\n",
    "    nb_inputs = sum(input_dim_vec)*2\n",
    "    inputs = keras.Input(shape=(nb_inputs,))\n",
    "    #inputs = keras.Input(shape=(None,nb_inputs))\n",
    "    input = layers.Dense(width, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/nb_inputs), math.sqrt(1/nb_inputs)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/nb_inputs), math.sqrt(1/nb_inputs))) \\\n",
    "                         (inputs)\n",
    "\n",
    "    for i in range(depth-1):\n",
    "\n",
    "        x = layers.LeakyReLU(alpha=0.01)(input)\n",
    "        x = layers.BatchNormalization(momentum=0.1, epsilon=1e-5)(x)\n",
    "        x = layers.Dense(width, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width))) \\\n",
    "                         (x)\n",
    "\n",
    "        x = x + input\n",
    "\n",
    "        input = x\n",
    "\n",
    "    x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1, epsilon=1e-5)(x)\n",
    "    outputs = layers.Dense(latent_dim*2, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width))) \\\n",
    "                         (x)\n",
    "\n",
    "    prior_encoder = keras.Model(inputs=inputs, outputs=outputs, name=\"prior_encoder_model\")\n",
    "    return prior_encoder\n",
    "#prior_encoder.summary()\n",
    "\n",
    "# keras.utils.plot_model(encoder, \"encoder.png\")\n",
    "#keras.utils.plot_model(prior_encoder, \"prior.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761740b",
   "metadata": {},
   "source": [
    "## Generator (Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57db3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The arguments sent to the different keras layers are there to mimic the Torch layers in CLUE.\n",
    "\"\"\"\n",
    "def create_decoder(width, depth, latent_dim, input_dim_vec):\n",
    "    nb_inputs = latent_dim\n",
    "    inputs = keras.Input(shape=(nb_inputs,))\n",
    "    input = layers.Dense(width, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/nb_inputs), math.sqrt(1/nb_inputs)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/nb_inputs), math.sqrt(1/nb_inputs))) \\\n",
    "                         (inputs)\n",
    "\n",
    "    for i in range(depth-1):\n",
    "\n",
    "        x = layers.LeakyReLU(alpha=0.01)(input)\n",
    "        x = layers.BatchNormalization(momentum=0.1, epsilon=1e-5)(x)\n",
    "        x = layers.Dense(width, use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width))) \\\n",
    "                         (x)\n",
    "        x = x + input\n",
    "\n",
    "        input = x\n",
    "\n",
    "    x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1, epsilon=1e-5)(x)\n",
    "    outputs = layers.Dense(sum(input_dim_vec), use_bias=True, \\\n",
    "                         kernel_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width)), \\\n",
    "                         bias_initializer = tf.keras.initializers.RandomUniform(-math.sqrt(1/width), math.sqrt(1/width))) \\\n",
    "                         (x)\n",
    "\n",
    "    decoder = keras.Model(inputs=inputs, outputs=outputs, name=\"decoder_model\")\n",
    "    return decoder\n",
    "\n",
    "#decoder.summary()\n",
    "\n",
    "# keras.utils.plot_model(model, \"decoder_model.png\")\n",
    "#keras.utils.plot_model(decoder, \"generator.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f25722",
   "metadata": {},
   "source": [
    "## Masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddccccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_masker_tensorflow:\n",
    "    \"\"\"\n",
    "    Returned mask is sampled from component-wise independent Bernoulli\n",
    "    distribution with probability of component to be unobserved p.\n",
    "    Such mask induces the type of missingness which is called\n",
    "    in literature \"missing completely at random\" (MCAR).\n",
    "    If some value in batch is missed, it automatically becomes unobserved.\n",
    "    \"\"\"\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            - batch is a numpy array with as many rows as batch_size and as many columns as features\n",
    "        \n",
    "        Returned:\n",
    "       \n",
    "            - mask is a float32 tensor\n",
    "        \n",
    "        The mask seems to be random\n",
    "        \"\"\"\n",
    "        # Generate one uniform number for each row (1xrow numpy matrix)\n",
    "        pp = uniform(low=0.0, high=self.p, size=batch.shape[0]) \n",
    "        pp = np.expand_dims(pp, axis=1) # Put the number in 1x1 matrices in a 1x#row matrix\n",
    "        pp = np.repeat(pp, batch.shape[1], axis=1) # Repeat the number across each row\n",
    "        nan_mask = tf.math.is_nan(batch) # If nan => should be unobserved i.e. boolean True\n",
    "        \n",
    "        # Generate Bernoulli samples (0 or 1) from pp i.e. for each sample in batch determine if a feature is\n",
    "        # observed or hidden.\n",
    "        bernoulli_mask_numpy = binomial(1, pp, size=None) \n",
    "        bernoulli_mask = tf.convert_to_tensor(tf.cast(bernoulli_mask_numpy, tf.bool))\n",
    "        mask = tf.math.logical_or(bernoulli_mask, nan_mask) # Logical or between bernoulli and nan mask\n",
    "        \n",
    "        # Logical not to invert the mask (This is done in CLUE)\n",
    "        # Mask is converted to a boolean tensor with floats for element wise multiplication with the batch\n",
    "        # which is done in apply mask\n",
    "        # (True => 0, False => 1)\n",
    "        \n",
    "        #TODO: The logical_not might be unnecessary as the probability of getting a true or false is equal.\n",
    "        #      perhaps this can be removed later...\n",
    "        return tf.cast(tf.math.logical_not(mask), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e8c65",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f82868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_cat_to_flat_mask(mask, input_dim_vec):\n",
    "    output = []\n",
    "    for idx, dim in enumerate(input_dim_vec):\n",
    "        if dim == 1:\n",
    "            \"\"\"\n",
    "            tf.expand_dims (axis=1) takes mask[:, idx] (batch_size,) and converts it into (64,1) e.g. [1,2,3] => [[1];[2];[3]] same as torch unsqueeze(1)\n",
    "            \"\"\"\n",
    "            output.append(tf.expand_dims(mask[:, idx], axis=1))\n",
    "\n",
    "        elif dim > 1: \n",
    "            \"\"\"\n",
    "            oh_vec = mask.new_ones(mask.shape[0], dim) * mask[:, idx].unsqueeze(1) # TODO remove\n",
    "            print(\"mask.new_ones: \", tf.ones([mask.shape[0], dim]))\n",
    "            print(\"Right side: \", tf.expand_dims(mask[:, idx], axis=1)) \n",
    "            \n",
    "            tf.expand_dims (read comment above)\n",
    "            tf.ones([mask.shape[0], dim]) creates an array of batch_size x dim with ones\n",
    "            oh_vec will be mask.shape[0] x dim and contain 0 or 1 on rows depending on if mask is 0 or 1.\n",
    "            \"\"\"\n",
    "            oh_vec = tf.ones([mask.shape[0], dim]) * tf.expand_dims(mask[:, idx], axis=1) # TODO remove\n",
    "            \n",
    "            #print(\"After oh_vec: \", oh_vec)\n",
    "\n",
    "            output.append(oh_vec)\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "    return tf.concat(output, axis=1)\n",
    "\n",
    "\n",
    "def gauss_cat_to_flat(x, input_dim_vec):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - x: numpy array\n",
    "        - input_dim_vec: list e.g. [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2] credit\n",
    "    Returns:\n",
    "        - numpy array \n",
    "        \n",
    "    Example:\n",
    "        \n",
    "        x:\n",
    "             [-0.52121574  0.          2.          1.          1.2496392   0.01383046\n",
    "              0.1105278   1.8173771   0.18815508  0.2341654   1.9953084   0.2038664\n",
    "              0.31341553  0.31455126  0.32473356  0.4501966   0.45570025  0.0774322\n",
    "             -0.2517514  -0.1535475   0.03951775 -0.31174627 -0.12532774  0.        ]\n",
    "        \n",
    "        input_dim_vec:\n",
    "            [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2]\n",
    "        \n",
    "        return:\n",
    "             [-0.52121574  1.          0.          0.          0.          1.\n",
    "              0.          0.          1.          0.          1.2496392   0.01383046\n",
    "              0.1105278   1.8173771   0.18815508  0.2341654   1.9953084   0.2038664\n",
    "              0.31341553  0.31455126  0.32473356  0.4501966   0.45570025  0.0774322\n",
    "             -0.2517514  -0.1535475   0.03951775 -0.31174627 -0.12532774  1.\n",
    "              0.        ]\n",
    "    \n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for idx, dim in enumerate(input_dim_vec):\n",
    "        if dim == 1:\n",
    "            output.append(tf.expand_dims(x[:, idx], axis=1))\n",
    "        elif dim > 1:\n",
    "            oh_vec = tf.one_hot(x[:, idx], dim) # Returns one hot encoding 0 with dim 2 -> 1 0, 1 -> 0 1\n",
    "            output.append(oh_vec)\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "    return tf.concat(output, axis=1).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe98e6",
   "metadata": {},
   "source": [
    "## CLASS VAEAC and loss and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc4120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEAC_gauss_cat(tf.keras.Model):\n",
    "    def __init__(self, width, depth, latent_dim, input_dim_vec, batch_size, lr, optimizer, save_model):\n",
    "        super(VAEAC_gauss_cat, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        self.recognition_encoder = create_recognition_encoder(width, depth, latent_dim, input_dim_vec)\n",
    "        self.prior_encoder = create_prior_encoder(width, depth, latent_dim, input_dim_vec)\n",
    "        self.decoder = create_decoder(width, depth, latent_dim, input_dim_vec)\n",
    "        self.sigma_mu = 1e4\n",
    "        self.sigma_sigma = 1e-4\n",
    "        self.vlb_scale = 1 / len(self.input_dim_vec)\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.save_model = save_model\n",
    "        self.lr = lr\n",
    "        \n",
    "\n",
    "    # Inspiration taken from \n",
    "    # https://github.com/joocxi/tf2-VAEAC/blob/d2b1bbc258ec77ee0975ea7eb68e63c4efcda6f0/model/vaeac.py\n",
    "    def prior_regularizer(self, prior):\n",
    "\n",
    "        mu = tf.reshape(prior.mean(), (self.batch_size, -1))\n",
    "        sigma = tf.reshape(prior.scale, (self.batch_size, -1))\n",
    "\n",
    "        mu_regularizer = -tf.reduce_sum(tf.square(mu), -1) / (2 * self.sigma_mu ** 2)\n",
    "        sigma_regularizer = tf.reduce_sum((tf.math.log(sigma) - sigma), -1) * self.sigma_sigma\n",
    "        return mu_regularizer + sigma_regularizer\n",
    "\n",
    "    def apply_mask(self, x, mask):\n",
    "        return x * mask\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            - mean: tensor of size number of samples in x times half of the number of outputs in encoder\n",
    "            - logvar: tensor -//-\n",
    "            \n",
    "        Returns:\n",
    "            - The values from the encoder as a normal distribution. Multiply eps (samples from N(0,1)) \n",
    "              with std deviation tf.exp(logvar * 0.5) and add mean.\n",
    "        \n",
    "        \"\"\"  \n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def reconstruction_loss(self, x, y):\n",
    "        log_prob_vec = []\n",
    "        cum_dims = 0\n",
    "        reshape_dim = self.batch_size\n",
    "        for idx, dims in enumerate(self.input_dim_vec):\n",
    "            if dims == 1:\n",
    "                # Gaussian_case\n",
    "                log_prob_vec.append(tf.expand_dims(-(x[:, cum_dims] - y[:, cum_dims])**2, 1))\n",
    "                \n",
    "                cum_dims += 1\n",
    "\n",
    "            elif dims > 1:\n",
    "                # if x.shape[1] == y.shape[1]:\n",
    "                #    raise Exception('Input and target seem to be in flat format. Need integer cat targets.'\n",
    "\n",
    "                cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits = True)\n",
    "                cat_cross_entropy = -cce(tf.cast(y[:, cum_dims:cum_dims + dims], dtype=tf.int64), x[:, cum_dims:cum_dims + dims])\n",
    "                \n",
    "                log_prob_vec.append(tf.expand_dims(cat_cross_entropy, 1))\n",
    "                cum_dims += dims\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Error, invalid dimension value')\n",
    "\n",
    "        log_prob_vec = tf.reshape(log_prob_vec, [reshape_dim, len(self.input_dim_vec)])\n",
    "        log_prob_vec = tf.reduce_sum(log_prob_vec, axis= -1) # Do I want this? \n",
    "                                                                 # Yes vlb in original code does this when return\n",
    "        return log_prob_vec\n",
    "\n",
    "    \"\"\"\n",
    "    def generate_samples_params(self, inputs, masks, sample=1):\n",
    "\n",
    "        #Takes a model and \n",
    "\n",
    "        # (batch_size, width, height, channels)\n",
    "        observed_inputs = self.make_observed_inputs(inputs, masks)\n",
    "        # (batch_size, width, height, 2*channels)\n",
    "        observed_inputs_with_masks = tf.concat([observed_inputs, masks], axis=-1)\n",
    "\n",
    "        prior_params = self.prior_net(observed_inputs_with_masks)\n",
    "\n",
    "        prior_distribution = tfd.Normal(\n",
    "          loc=prior_params[..., :256],\n",
    "          scale=tf.clip_by_value(\n",
    "            tf.nn.softplus(prior_params[..., 256:]),\n",
    "            1e-3,\n",
    "            tf.float32.max),\n",
    "          name=\"priors\")\n",
    "\n",
    "        samples_params = []\n",
    "        for i in range(sample):\n",
    "          latent = prior_distribution.sample()\n",
    "          sample_params = self.generative_net(latent)\n",
    "          samples_params.append(sample_params)\n",
    "        return tf.stack(samples_params, axis=1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO Implement correctly\n",
    "    \"\"\"\n",
    "    def generate_sample(self, sample=1):\n",
    "        if(self.proposal_distribution == None):\n",
    "            raise Exception('Network has no proposal distribution. Train it first')\n",
    "        else:\n",
    "            latent = proposal_distribution.sample()\n",
    "\n",
    "            generative_params = self.decoder(latent)\n",
    "        \n",
    "            return generative_params\n",
    "    \"\"\"\n",
    "\n",
    "def eval(model, x_batch, x_flat, x_masked, mask):\n",
    "    \"\"\"\n",
    "    self.set_mode_train(train=False)\n",
    "\n",
    "    if self.flatten:\n",
    "        mask = gauss_cat_to_flat_mask(mask, self.input_dim_vec)\n",
    "        x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "    else:\n",
    "        x_flat = x\n",
    "        x = flat_to_gauss_cat(x, self.input_dim_vec)\n",
    "\n",
    "    x_flat, x, mask = to_variable(var=(x_flat, x, mask), cuda=self.cuda)\n",
    "\n",
    "    prior = self.model.prior_encode(x_flat, mask)\n",
    "\n",
    "    approx_post = self.model.recognition_encode(x_flat)\n",
    "\n",
    "    if sample:\n",
    "        z_sample = approx_post.sample()\n",
    "    else:\n",
    "        z_sample = approx_post.loc\n",
    "\n",
    "    rec_params = self.model.decode(z_sample)\n",
    "\n",
    "    vlb = self.model.vlb(prior, approx_post, x, rec_params)\n",
    "\n",
    "    if self.pred_sig:\n",
    "        rec_return = normal_parse_params(rec_params, 1e-3)\n",
    "    else:\n",
    "        rec_return = rec_params\n",
    "    return vlb.mean().item(), rec_return\n",
    "    \"\"\"\n",
    "\n",
    "    #print(\"Validation, x_masked: \", x_masked)\n",
    "    #print(\"Validation, x_flat: \", x_flat)\n",
    "    #print(\"-----\")\n",
    "    #time.sleep(3)\n",
    "\n",
    "    x_flat = tf.convert_to_tensor(x_flat)\n",
    "\n",
    "\n",
    "    prior_params = model.prior_encoder(x_masked, training = True)\n",
    "    #prior_params = model.prior_encoder(x_masked, training = False)\n",
    "\n",
    "    proposal_params = model.recognition_encoder(x_flat, training = True)\n",
    "    #proposal_params = model.recognition_encoder(x_flat, training = False)\n",
    "\n",
    "    # Essentially CLUEs normal_parse_params\n",
    "    prior_distribution = tfd.Normal(\n",
    "      loc=prior_params[..., :model.latent_dim],\n",
    "      scale=tf.clip_by_value(\n",
    "        tf.nn.softplus(prior_params[..., model.latent_dim:]),\n",
    "        1e-3,\n",
    "        tf.float32.max),\n",
    "      name=\"priors\")\n",
    "\n",
    "    proposal_distribution = tfd.Normal(\n",
    "      loc=proposal_params[..., :model.latent_dim],\n",
    "      scale=tf.clip_by_value(\n",
    "        tf.nn.softplus(proposal_params[..., model.latent_dim:]),\n",
    "        1e-3,\n",
    "        tf.float32.max),\n",
    "      name=\"proposal\")\n",
    "\n",
    "    z_sample = proposal_distribution.loc # TODO, check if this works\n",
    "\n",
    "    #vlb = self.model.vlb(prior, approx_post, x, rec_params)\n",
    "    \"\"\"\n",
    "    def vlb(self, prior, approx_post, x, rec_params):\n",
    "        rec = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        prior_regularization = self.reg_cost(prior).view(x.shape[0], -1).sum(-1)\n",
    "        kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "\n",
    "        return rec - kl + prior_regularization\n",
    "    \"\"\"\n",
    "\n",
    "    #rec_params = model.decoder(z_sample, training = False)\n",
    "    rec_params = model.decoder(z_sample, training = True)\n",
    "\n",
    "    regularizer = model.prior_regularizer(prior_distribution)\n",
    "\n",
    "    rec_loss = model.reconstruction_loss(rec_params, x_flat) # TODO Maybe this should be x_batch (not flattened)\n",
    "\n",
    "    # True distribution, Estimated distribution in this order\n",
    "    kl_divergence = tf.reduce_sum(\n",
    "      tf.reshape(\n",
    "        tfd.kl_divergence(proposal_distribution, prior_distribution),\n",
    "        (model.batch_size, -1)), -1)\n",
    "\n",
    "    vlb = tf.reduce_mean(-kl_divergence + rec_loss + regularizer) # For comparing\n",
    "    return vlb, kl_divergence, rec_loss, regularizer\n",
    "\n",
    "def compute_loss_VAEAC(model, x_batch, x_flat, x_masked, mask):\n",
    "\n",
    "    #print(\"Training, x_masked: \", x_masked)\n",
    "    #print(\"Training, x_flat: \", x_flat)\n",
    "    \n",
    "    #time.sleep(3)\n",
    "    prior_params = model.prior_encoder(x_masked, training = True) \n",
    "    proposal_params = model.recognition_encoder(x_flat, training = True)\n",
    "\n",
    "    # Essentially CLUEs normal_parse_params\n",
    "    proposal_distribution = tfd.Normal(\n",
    "      loc=proposal_params[..., :model.latent_dim],\n",
    "      scale=tf.clip_by_value(\n",
    "        tf.nn.softplus(proposal_params[..., model.latent_dim:]),\n",
    "        1e-3,\n",
    "        tf.float32.max),\n",
    "      name=\"proposal\")\n",
    "\n",
    "    prior_distribution = tfd.Normal(\n",
    "      loc=prior_params[..., :model.latent_dim],\n",
    "      scale=tf.clip_by_value(\n",
    "        tf.nn.softplus(prior_params[..., model.latent_dim:]),\n",
    "        1e-3,\n",
    "        tf.float32.max),\n",
    "      name=\"priors\")\n",
    "\n",
    "    regularizer = model.prior_regularizer(prior_distribution)\n",
    "\n",
    "    #print(\"regularizer: \", regularizer)\n",
    "\n",
    "    latent = proposal_distribution.sample()\n",
    "\n",
    "    generative_params = model.decoder(latent, training = True)\n",
    "\n",
    "    rec_loss = model.reconstruction_loss(generative_params, x_flat) # TODO Maybe this should be x_batch (not flattened)\n",
    "    \n",
    "    #print(\"Prior distr: \", prior_distribution)\n",
    "    #print(\"Proposal distr: \", proposal_distribution)\n",
    "    \n",
    "    # True distribution, Estimated distribution in this order\n",
    "    kl_divergence = tf.reduce_sum(\n",
    "      tf.reshape(\n",
    "        tfd.kl_divergence(proposal_distribution, prior_distribution),\n",
    "        (model.batch_size, -1)), -1)\n",
    "\n",
    "    vlb = tf.reduce_mean(-kl_divergence + rec_loss + regularizer) # For comparing\n",
    "    loss = tf.reduce_mean((kl_divergence - rec_loss - regularizer) * model.vlb_scale) \n",
    "    return loss, vlb, kl_divergence, rec_loss, regularizer\n",
    "\n",
    "@tf.function # Converts all numpy arrays to tensors\n",
    "def train_step_VAEAC(model, x_batch, x_flat, x_masked, mask):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, vlb, kl_divergence, rec_loss, regularizer = compute_loss_VAEAC(model, x_batch, x_flat, x_masked, mask)\n",
    "    \n",
    "    # TODO train_loss(loss)???\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, vlb, kl_divergence, rec_loss, regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6d5c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "def train_VAEAC(model, x_train, x_test, masker, nb_epochs, early_stop = None):\n",
    "    \n",
    "    vlb_train = np.zeros(nb_epochs)\n",
    "    vlb_dev = np.zeros(nb_epochs)\n",
    "    best_vlb = -np.inf\n",
    "    best_epoch = 0\n",
    "    \n",
    "    test_data = []\n",
    "    for x in batch(x_test, n = model.batch_size):\n",
    "        test_data.append(x)\n",
    "    \n",
    "    for epoch in range(0, nb_epochs):\n",
    "        \n",
    "        \n",
    "        # Shuffle the training data and sort it into batches every epoch\n",
    "        train_data = []\n",
    "        np.random.shuffle(x_train)\n",
    "        for x in batch(x_train, n = model.batch_size):\n",
    "            train_data.append(x)\n",
    "        \n",
    "        tic = time.time()\n",
    "        ## Training\n",
    "        nb_samples = 0\n",
    "        for x_batch in train_data:\n",
    "\n",
    "            model.batch_size = x_batch.shape[0] # TODO: FIX THIS: Very ugly solution now to make sure batches \n",
    "                                                # that do not have the full size\n",
    "            \n",
    "            mask = masker(x_batch) #tensor with floats\n",
    "            \n",
    "            # Flatten the batch\n",
    "            x_batch_flat = gauss_cat_to_flat(x_batch, model.input_dim_vec) # numpy\n",
    "            \n",
    "            # Flatten the mask\n",
    "            mask_flat = gauss_cat_to_flat_mask(mask, model.input_dim_vec)\n",
    "            \n",
    "            # Mask flattened batch\n",
    "            x_batch_flat_masked = model.apply_mask(tf.convert_to_tensor(x_batch_flat), mask_flat)\n",
    "            \n",
    "            # Concat the mask flattened batch with the flattened mask\n",
    "            x_batch_flat_masked_concat = tf.concat([x_batch_flat_masked, mask_flat], axis=1)\n",
    "            \n",
    "            loss, vlb, kl_divergence, rec_loss, regularizer = train_step_VAEAC(model, x_batch, x_batch_flat, x_batch_flat_masked_concat, mask_flat)\n",
    "\n",
    "            #print(\"kl_div: \", kl_divergence.numpy())\n",
    "            #print(\"reg: \", regularizer.numpy())\n",
    "            #print(\"rec_loss: \", rec_loss.numpy())\n",
    "            vlb_train[epoch] += vlb.numpy() * x_batch.shape[0]\n",
    "            nb_samples += x_batch.shape[0]\n",
    "\n",
    "        vlb_train[epoch] /= nb_samples\n",
    "        toc = time.time()\n",
    "        print(\"Epoch_\" + str(epoch) + \", vlb: \" + str(vlb_train[epoch]) + \", took: \" + str(toc-tic))\n",
    "        \n",
    "        ## Validation\n",
    "        nb_samples = 0\n",
    "        for x_batch in test_data:\n",
    "            model.batch_size = x_batch.shape[0] # TODO: FIX THIS: Very ugly solution now to make sure batches \n",
    "                                                # that do not have the full size\n",
    "            mask = masker(x_batch) #tensor with floats\n",
    "            \n",
    "            # Flatten the batch\n",
    "            x_batch_flat = gauss_cat_to_flat(x_batch, model.input_dim_vec) # numpy\n",
    "            \n",
    "            # Flatten the mask\n",
    "            mask_flat = gauss_cat_to_flat_mask(mask, model.input_dim_vec)\n",
    "            \n",
    "            # Mask flattened batch\n",
    "            x_batch_flat_masked = model.apply_mask(tf.convert_to_tensor(x_batch_flat), mask_flat)\n",
    "            \n",
    "            # Concat the mask flattened batch with the flattened mask\n",
    "            x_batch_flat_masked_concat = tf.concat([x_batch_flat_masked, mask_flat], axis=1)\n",
    "            \n",
    "            vlb, kl_divergence, rec_loss, regularizer = eval(model, x_batch, x_batch_flat, x_batch_flat_masked_concat, mask_flat)\n",
    "            #if(epoch > 0):\n",
    "            #    print(\"kl_div: \", kl_divergence.numpy())\n",
    "            #    print(\"reg: \", regularizer.numpy())\n",
    "            #    print(\"rec_loss: \", rec_loss.numpy())\n",
    "            vlb_dev[epoch] += vlb.numpy() * x_batch.shape[0]\n",
    "            nb_samples += x_batch.shape[0]\n",
    "\n",
    "        vlb_dev[epoch] /= nb_samples\n",
    "        \n",
    "        if vlb_dev[epoch] > best_vlb:\n",
    "            best_vlb = vlb_dev[epoch]\n",
    "            best_epoch = epoch\n",
    "            if(model.save_model):\n",
    "                #open text file\n",
    "                text_file = open(\"best_epoch_VAEAC_lr_\" + str(model.lr) + \".txt\", \"w\")\n",
    "\n",
    "                #write string to file\n",
    "                text_file.write(str(epoch))\n",
    "\n",
    "                #close file\n",
    "                text_file.close()\n",
    "\n",
    "                model.recognition_encoder.save(\"recog_encoder_7e-4\")\n",
    "                model.prior_encoder.save(\"prior_encoder_7e-4\")\n",
    "                model.decoder.save(\"decoder_7e-4\")\n",
    "\n",
    "        print(\"Validation vlb: \" + str(vlb_dev[epoch]) + \", Best vlb: \" + str(best_vlb) + \"\\n\")\n",
    "\n",
    "        if early_stop is not None and (epoch - best_epoch) > early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    return vlb_train, vlb_dev\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ac60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f8e2b58",
   "metadata": {},
   "source": [
    "## Train VAEAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa76c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:28:36.446449: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_0, vlb: -18.364715020073785, took: 27.10701584815979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:29:07.816439: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation vlb: -10.006155448913574, Best vlb: -10.006155448913574\n",
      "\n",
      "Epoch_1, vlb: -11.508864373101128, took: 20.368751764297485\n",
      "Validation vlb: -8.113049713134766, Best vlb: -8.113049713134766\n",
      "\n",
      "Epoch_2, vlb: -10.290587674741392, took: 16.262703895568848\n",
      "Validation vlb: -7.540027280171712, Best vlb: -7.540027280171712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # TODO get batch size to work\n",
    "nb_epochs = 2000 # 2000\n",
    "early_stop = 200 # TODO get early stop to work\n",
    "lr = 7e-4        # Maybe this should be 1e-4, but it makes the performance terrible...\n",
    "\n",
    "optimizer = tfa.optimizers.RectifiedAdam(lr)\n",
    "\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "\n",
    "width = 350\n",
    "depth = 3\n",
    "latent_dim = 8\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "masker = top_masker_tensorflow(p=1)\n",
    "\n",
    "x_train, x_test, x_means, x_stds = \\\n",
    "load_UCI(dset_name=dname, splits=10, seed=42, separate_targets=False, save_dir='../data/') # np.arrays\n",
    "\n",
    "model = VAEAC_gauss_cat(width, depth, latent_dim, input_dim_vec, batch_size, lr, optimizer, save_model = True)\n",
    "\n",
    "x_train = unnormalise_cat_vars(x_train, x_means, x_stds, input_dim_vec) # np.array\n",
    "x_test = unnormalise_cat_vars(x_test, x_means, x_stds, input_dim_vec) \n",
    "\n",
    "vlb_train, vlb_dev = train_VAEAC(model, x_train, x_test, masker, nb_epochs, early_stop=early_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad555fe9",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b8ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the total number of trainable variables \n",
    "\"\"\"\n",
    "total_parameters = 0\n",
    "for variable in model.trainable_variables:\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    #print(shape)\n",
    "    #print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        #print(dim)\n",
    "        variable_parameters *= dim\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)\n",
    "\n",
    "time.sleep(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0e8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f0d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20896d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae708749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b7c650e",
   "metadata": {},
   "source": [
    "## Generate sample parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71b276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55cd3a92",
   "metadata": {},
   "source": [
    "## UNDER VAEAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107d2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af920dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class under_VAEAC(tf.keras.Model):\n",
    "    def __init__(self, base_VAE, width, depth, latent_dim, batch_size, lr, optimizer, save_model = True):\n",
    "        super(under_VAEAC, self).__init__()\n",
    "        \n",
    "        self.base_VAEAC = base_VAE\n",
    "        self.input_dim = self.base_VAEAC.latent_dim # 8 for default credit\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.latent_dim = latent_dim # 6 for default credit\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.prior_encoder = tfd.Normal(loc=tf.zeros(latent_dim), scale=tf.ones(latent_dim))\n",
    "        \n",
    "        # self.input_dim is put in a list to make sum(input_dim_vec in recognition_encoder work)\n",
    "        self.recognition_encoder = create_recognition_encoder(width, depth, latent_dim, [self.input_dim])\n",
    "        self.decoder = create_decoder(width, depth, latent_dim, [self.input_dim])\n",
    "        \n",
    "        self.sigma_mu = 1e4\n",
    "        self.sigma_sigma = 1e-4\n",
    "        \n",
    "        self.vlb_scale = 1 / self.input_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.save_model = save_model\n",
    "\n",
    "    # Inspiration taken from \n",
    "    # https://github.com/joocxi/tf2-VAEAC/blob/d2b1bbc258ec77ee0975ea7eb68e63c4efcda6f0/model/vaeac.py\n",
    " \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            - mean: tensor of size number of samples in x times half of the number of outputs in encoder\n",
    "            - logvar: tensor -//-\n",
    "            \n",
    "        Returns:\n",
    "            - The values from the encoder as a normal distribution. Multiply eps (samples frm N(0,1)) \n",
    "              with std deviation tf.exp(logvar * 0.5) and add mean.\n",
    "        \n",
    "        \"\"\"  \n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def reconstruction_loss(self, x, y):\n",
    "        log_prob_vec = []\n",
    "        reshape_dim = self.batch_size\n",
    "        for idx in range(self.input_dim):\n",
    "            # Gaussian_case\n",
    "            log_prob_vec.append(tf.expand_dims(-(x[:, idx] - y[:, idx])**2, 1))\n",
    "\n",
    "        log_prob_vec = tf.reshape(log_prob_vec, [reshape_dim, self.input_dim])\n",
    "        log_prob_vec = tf.math.reduce_sum(log_prob_vec, axis= -1)\n",
    "        \n",
    "        return log_prob_vec\n",
    "    \n",
    "    \n",
    "def compute_loss_under_VAEAC(net, x_flat):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    z_sample = self.base_VAEAC.recognition_encode(x).sample()\n",
    "    approx_post = self.model.encode(z_sample)\n",
    "    u_sample = approx_post.rsample()\n",
    "    rec_params = self.model.decode(u_sample)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    z_sample = self.base_VAEAC.recognition_encode(x).sample()\n",
    "    \n",
    "    Have the base_VAEAC encode the data and generate a sample from the latent representation\n",
    "    \"\"\"\n",
    "    proposal_params_VAEAC = net.base_VAEAC.recognition_encoder(x_flat) # tensor with dim (16,)\n",
    "    \n",
    "    # net.input_dim = base_VAEAC latent dim (8)\n",
    "    # net.latent_dim = VAE latent dim (6)\n",
    "    \n",
    "    # Essentially CLUEs normal_parse_params\n",
    "    proposal_distribution_VAEAC = tfd.Normal(\n",
    "      loc=proposal_params_VAEAC[..., :net.input_dim],\n",
    "      scale=tf.clip_by_value(\n",
    "        tf.nn.softplus(proposal_params_VAEAC[..., net.input_dim:]),\n",
    "        1e-3,\n",
    "        tf.float32.max),\n",
    "      name=\"proposal\")\n",
    "    \n",
    "    z_sample = proposal_distribution_VAEAC.sample() # tensor with dim (8,)\n",
    "    \n",
    "    \"\"\"\n",
    "    approx_post = self.model.encode(z_sample)\n",
    "    \n",
    "    Have the VAE encode the sample\n",
    "    \"\"\"\n",
    "    \n",
    "    proposal_params_VAE = net.recognition_encoder(z_sample) # tensor with dim (12,)\n",
    "\n",
    "    proposal_distribution_VAE = tfd.Normal(\n",
    "      loc=proposal_params_VAE[..., :net.latent_dim],\n",
    "      scale=tf.clip_by_value(\n",
    "        tf.nn.softplus(proposal_params_VAE[..., net.latent_dim:]),\n",
    "        1e-3,\n",
    "        tf.float32.max),\n",
    "      name=\"priors\")\n",
    "\n",
    "    u_sample = proposal_distribution_VAE.sample() # tensor with dim (6,)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    rec_params = self.model.decode(u_sample)\n",
    "    \n",
    "    Have the VAE decode the sample\n",
    "    \"\"\"\n",
    "    \n",
    "    rec_params = net.decoder(u_sample) # tensor with dim (8,)\n",
    "    \n",
    "    \"\"\"\n",
    "    def vlb(self, prior, approx_post, x, rec_params):\n",
    "        if self.pred_sig:\n",
    "            rec = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        else:\n",
    "            rec = -self.m_rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "        return rec - kl\n",
    "    \n",
    "    vlb = self.model.vlb(self.prior, approx_post, z_sample, rec_params)\n",
    "    loss = (- vlb * self.vlb_scale).mean()\n",
    "    \"\"\"\n",
    "    \n",
    "    #rec = -self.m_rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "    #kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "    \n",
    "    # True distribution, Estimated distribution in this order\n",
    "    kl_divergence = tf.reduce_sum(\n",
    "      tf.reshape(\n",
    "        tfd.kl_divergence(proposal_distribution_VAE, net.prior_encoder),\n",
    "        (net.batch_size, -1)), -1)\n",
    "    \n",
    "    rec_loss = net.reconstruction_loss(rec_params, z_sample) # TODO Maybe this should be x_batch (not flattened)\n",
    "    \n",
    "    vlb = tf.reduce_mean(-kl_divergence + rec_loss) # For comparing\n",
    "    loss = tf.reduce_mean((kl_divergence - rec_loss) * net.vlb_scale) \n",
    "    return loss, vlb, kl_divergence, rec_loss\n",
    "\n",
    "@tf.function # Converts all numpy arrays to tensors\n",
    "def train_step_under_VAEAC(model, x_flat):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, vlb, kl_divergence, rec_loss = compute_loss_under_VAEAC(model, x_flat)\n",
    "    \n",
    "    # TODO train_loss(loss)???\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, vlb, kl_divergence, rec_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e843dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "def train_VAE(model, x_train, x_test, nb_epochs, early_stop = None):\n",
    "    \n",
    "    vlb_train = np.zeros(nb_epochs)\n",
    "    vlb_dev = np.zeros(nb_epochs)\n",
    "    best_vlb = -np.inf\n",
    "    best_epoch = 0\n",
    "    \n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for x in batch(x_train, n = model.batch_size):\n",
    "        train_data.append(x)\n",
    "    \n",
    "    for x in batch(x_test, n = model.batch_size):\n",
    "        test_data.append(x)\n",
    "\n",
    "    for epoch in range(0, nb_epochs):\n",
    "        tic = time.time()\n",
    "        \n",
    "        ## Training\n",
    "        nb_samples = 0\n",
    "        for _, x_batch in enumerate(train_data):\n",
    "\n",
    "            model.batch_size = x_batch.shape[0] # TODO: FIX THIS: Very ugly solution now to make sure batches \n",
    "                                                # that do not have the full size\n",
    "            \n",
    "            # Flatten the batch\n",
    "            x_batch_flat = gauss_cat_to_flat(x_batch, model.base_VAEAC.input_dim_vec) # numpy\n",
    "            \n",
    "            loss, vlb, kl_divergence, rec_loss = train_step_under_VAEAC(model, x_batch_flat)\n",
    "\n",
    "            #print(\"kl_div: \", kl_divergence.numpy())\n",
    "            #print(\"rec_loss: \", rec_loss.numpy())\n",
    "            vlb_train[epoch] += vlb.numpy() * x_batch.shape[0]\n",
    "            nb_samples += x_batch.shape[0]\n",
    "\n",
    "        vlb_train[epoch] /= nb_samples\n",
    "        toc = time.time()\n",
    "        print(\"Epoch\" + str(epoch) + \", vlb: \" + str(vlb_train[epoch]) + \", took: \" + str(toc-tic))\n",
    "        \n",
    "        ## Validation\n",
    "        nb_samples = 0\n",
    "        for _, x_batch in enumerate(test_data):\n",
    "            model.batch_size = x_batch.shape[0] # TODO: FIX THIS: Very ugly solution now to make sure batches \n",
    "                                                # that do not have the full size\n",
    "            \n",
    "            # Flatten the batch\n",
    "            x_batch_flat = gauss_cat_to_flat(x_batch, model.base_VAEAC.input_dim_vec) # numpy\n",
    "            \n",
    "            loss, vlb, kl_divergence, rec_loss = train_step_under_VAEAC(model, x_batch_flat)\n",
    "\n",
    "            vlb_dev[epoch] += vlb.numpy() * x_batch.shape[0]\n",
    "            nb_samples += x_batch.shape[0]\n",
    "\n",
    "        vlb_dev[epoch] /= nb_samples\n",
    "        \n",
    "        if vlb_dev[epoch] > best_vlb:\n",
    "            best_vlb = vlb_dev[epoch]\n",
    "            best_epoch = epoch\n",
    "            if(model.save_model):\n",
    "                #open text file\n",
    "                text_file = open(\"best_epoch_2nd_VAE_lr_\" + str(model.lr) + \".txt\", \"w\")\n",
    "\n",
    "                #write string to file\n",
    "                text_file.write(str(epoch))\n",
    "\n",
    "                #close file\n",
    "                text_file.close()\n",
    "\n",
    "                model.recognition_encoder.save(\"recog_encoder_2nd_VAE\")\n",
    "                model.prior_encoder.save(\"prior_encoder_2nd_VAE\")\n",
    "                model.decoder.save(\"decoder_2nd_VAE\")\n",
    "\n",
    "        print(\"Validation vlb: \" + str(vlb_dev[epoch]) + \", Best vlb: \" + str(best_vlb) + \"\\n\")\n",
    "\n",
    "        if early_stop is not None and (epoch - best_epoch) > early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    return vlb_train, vlb_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf0a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 15:16:52.361979: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_91101/1694607955.py\", line 146, in train_step_under_VAEAC  *\n        loss, vlb, kl_divergence, rec_loss = compute_loss_under_VAEAC(model, x_flat)\n    File \"/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_91101/1694607955.py\", line 131, in compute_loss_under_VAEAC  *\n        kl_divergence = tf.reduce_sum(\n    File \"/opt/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow_probability/python/distributions/kullback_leibler.py\", line 100, in kl_divergence  **\n        kl_t = kl_fn(distribution_a, distribution_b, name=name)\n    File \"/opt/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow_probability/python/distributions/normal.py\", line 273, in _kl_normal_normal\n        diff_log_scale = tf.math.log(a.scale) - tf.math.log(b_scale)\n\n    ValueError: Dimensions must be equal, but are 8 and 6 for '{{node KullbackLeibler/proposal_CONSTRUCTED_AT_top_level/KullbackLeibler_a/Normal/KullbackLeibler_b/KullbackLeibler/sub}} = Sub[T=DT_FLOAT](KullbackLeibler/proposal_CONSTRUCTED_AT_top_level/KullbackLeibler_a/Normal/KullbackLeibler_b/KullbackLeibler/Log, KullbackLeibler/proposal_CONSTRUCTED_AT_top_level/KullbackLeibler_a/Normal/KullbackLeibler_b/KullbackLeibler/Log_1)' with input shapes: [128,8], [6].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_91101/4263377014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0munder_VAEAC_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munder_VAEAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_under_VAEAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mvlb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlb_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munder_VAEAC_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_91101/768997951.py\u001b[0m in \u001b[0;36mtrain_VAE\u001b[0;34m(model, x_train, x_test, nb_epochs, early_stop)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mx_batch_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgauss_cat_to_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_VAEAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim_vec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_under_VAEAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#print(\"kl_div: \", kl_divergence.numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_91101/1694607955.py\", line 146, in train_step_under_VAEAC  *\n        loss, vlb, kl_divergence, rec_loss = compute_loss_under_VAEAC(model, x_flat)\n    File \"/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_91101/1694607955.py\", line 131, in compute_loss_under_VAEAC  *\n        kl_divergence = tf.reduce_sum(\n    File \"/opt/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow_probability/python/distributions/kullback_leibler.py\", line 100, in kl_divergence  **\n        kl_t = kl_fn(distribution_a, distribution_b, name=name)\n    File \"/opt/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow_probability/python/distributions/normal.py\", line 273, in _kl_normal_normal\n        diff_log_scale = tf.math.log(a.scale) - tf.math.log(b_scale)\n\n    ValueError: Dimensions must be equal, but are 8 and 6 for '{{node KullbackLeibler/proposal_CONSTRUCTED_AT_top_level/KullbackLeibler_a/Normal/KullbackLeibler_b/KullbackLeibler/sub}} = Sub[T=DT_FLOAT](KullbackLeibler/proposal_CONSTRUCTED_AT_top_level/KullbackLeibler_a/Normal/KullbackLeibler_b/KullbackLeibler/Log, KullbackLeibler/proposal_CONSTRUCTED_AT_top_level/KullbackLeibler_a/Normal/KullbackLeibler_b/KullbackLeibler/Log_1)' with input shapes: [128,8], [6].\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # TODO get batch size to work\n",
    "nb_epochs = 2000 # 2000\n",
    "early_stop = 200 # TODO get early stop to work\n",
    "lr = 1e-4        # Maybe this should be 1e-4, but it makes the performance terrible...\n",
    "\n",
    "optimizer_VAEAC = tfa.optimizers.RectifiedAdam(lr)\n",
    "\n",
    "# For Default credit\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2]\n",
    "width = 350\n",
    "depth = 3\n",
    "latent_dim = 8\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# Create new model to load in weightsinto that can then continued to be trained\n",
    "model2 = VAEAC_gauss_cat(width, depth, latent_dim, input_dim_vec, batch_size, optimizer_VAEAC, save_model = False)\n",
    "\n",
    "model2.recognition_encoder = keras.models.load_model(\"recog_encoder\")\n",
    "model2.prior_encoder = keras.models.load_model(\"prior_encoder\")\n",
    "model2.decoder = keras.models.load_model(\"decoder\")\n",
    "\n",
    "\n",
    "# No mask is used to train the 2nd lvl VAE\n",
    "#masker = top_masker_tensorflow(p=1)\n",
    "\n",
    "x_train, x_test, x_means, x_stds = \\\n",
    "load_UCI(dset_name=dname, splits=10, seed=42, separate_targets=False, save_dir='../data/') # np.arrays\n",
    "\n",
    "x_train = unnormalise_cat_vars(x_train, x_means, x_stds, input_dim_vec) # np.array\n",
    "x_test = unnormalise_cat_vars(x_test, x_means, x_stds, input_dim_vec) \n",
    "\n",
    "base_network = model2\n",
    "width = 150\n",
    "depth = 2\n",
    "latent_dim = 6 # under_latent_dims2 = [4, 6, 3, 3], 6 for default_credit\n",
    "\n",
    "batch_size = 128\n",
    "nb_epochs = 2000\n",
    "early_stop = 200\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer_under_VAEAC = tfa.optimizers.RectifiedAdam(lr)\n",
    "\n",
    "under_VAEAC_net = under_VAEAC(base_network, width, depth, latent_dim, batch_size, lr, optimizer_under_VAEAC, save_model = False)\n",
    "\n",
    "vlb_train, vlb_dev = train_VAE(under_VAEAC_net, x_train, x_test, nb_epochs, early_stop=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813be207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(under_VAEAC_net.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e0896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 150)          1050        ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_46 (LeakyReLU)     (None, 150)          0           ['dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 150)         600         ['leaky_re_lu_46[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 150)          22650       ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 150)         0           ['dense_64[0][0]',               \n",
      " ambda)                                                           'dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_47 (LeakyReLU)     (None, 150)          0           ['tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 150)         600         ['leaky_re_lu_47[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 8)            1208        ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,108\n",
      "Trainable params: 25,508\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(under_VAEAC_net.decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78fb90c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"recognition_encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 150)          1350        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 150)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 150)         600         ['leaky_re_lu_9[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 150)          22650       ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 150)         0           ['dense_13[0][0]',               \n",
      " mbda)                                                            'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 150)          0           ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 150)         600         ['leaky_re_lu_10[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 12)           1812        ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,012\n",
      "Trainable params: 26,412\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(under_VAEAC_net.recognition_encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ef766",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Currently Working on ###\n",
    "\n",
    "# Need to set the models to eval mode and not training during validation data \n",
    "    # Apparently batchnorm layers do different things during training/evaluation\n",
    "\n",
    "# Something might be wrong with how the training is done with batches...\n",
    "\n",
    "# Have I forgotten to do a tf.reduce_sum over regularisation? Don't think so... their sum(-1) on reg_cost does nothing\n",
    "\n",
    "# Something wrong with the validation vlb results during training of the VAEAC?\n",
    "\n",
    "# Is something wrong with the trainable variables? Should I before training use tf.Variable to make them trainable?\n",
    "# https://www.tensorflow.org/api_docs/python/tf/Variable\n",
    "\n",
    "### TODO ###\n",
    "\n",
    "# Generator function that is used in 2nd lvl VAE \n",
    "    # do we generate sample from the 2nd lvl VAE after 2 encodes and 1 decode? After VAE_decode we get params with \n",
    "    # dimension 8 which is the latent dimension for VAEAC? Maybe we can generates samples from that afterwards...\n",
    "\n",
    "# Compare sizes between CLUE under and TF under in under_VAEAC\n",
    "\n",
    "# Save the vlb_train & vlb_dev after training\n",
    "\n",
    "# Add lr to print epoch in VAEAC training\n",
    "\n",
    "# Remove reparametrize?\n",
    "\n",
    "# Should I have 7e-4 or 1e-4 learning rate?\n",
    "\n",
    "# Plot the loss graph over train and validation set\n",
    "\n",
    "# Clean up the code\n",
    "\n",
    "# Push to github\n",
    "\n",
    "## Ask Ali if \n",
    "    # His network has the correct structure (The decoder was wrong for VAEAC)\n",
    "    # He has thought of initlialisations\n",
    "    # hyperparameters, bias, epsilon, momentum etc.\n",
    "\n",
    "# rec_los: Should the target not be flattened but instead just x_batch?\n",
    "    # Don't think so, the final values look fairly similar.\n",
    "\n",
    "# Skip connections from prior to decoder? I don't think CLUE got this to work properly...\n",
    "    # Memory layer is used in Tf2 github\n",
    "\n",
    "# How do the batches work in the network? How can we send a 64x31 batch to encoder? It should only take 31 as input\n",
    "\n",
    "# Not sure what the TF equivalence of affine and track_running_stats is in Torch BatchNorm1D \n",
    "    \n",
    "# Why does train_step only print things inside it twice for the first batch and then never for any other batch?\n",
    "    \n",
    "### TO IMPLEMENT ###\n",
    "\n",
    "# Evaluation with tensorflow\n",
    "\n",
    "# Make VAEAC work for other datasets (COMPAS)\n",
    "\n",
    "### DONE ###\n",
    "\"\"\"\n",
    "\n",
    "√ vlb_dev is calculated using eval not fit\n",
    "\n",
    "√ Add shuffling of the training data \n",
    "\n",
    "√ Train VAEAC using 7e-4 lr and save the model (with lr in its name)\n",
    "\n",
    "√ Verify the number of trainable parameters in CLUE vs TF \n",
    "    # Exact same amount for under_VAEAC and VAEAC\n",
    "\n",
    "√ implement under_VAEAC vlb (MSELoss and KL-divergence)\n",
    "\n",
    "√ rsample instead of sample? (rsample for derivatives in torch, tf does not care)\n",
    "\n",
    "√ Save the model during training (best vlb)\n",
    "\n",
    "√ Fix so that training with 2nd lvl VAE is done without the mask\n",
    "\n",
    "√ 1e-4 can at times get very poor vlb at the start but then recover. Why is this?   \n",
    "    # Seems to have been solved by initialising the dense weights and bias weights the same way as Torch\n",
    "    # I get like -19 or -20, -22 every single first epoch now\n",
    "\n",
    "√ Validation vlb not low enough? \n",
    "    # Not terrible but indeed not as low, seems to go towards the right values at least but it happens slowly\n",
    "\n",
    "√ Need to initialise the weights in keras dense for the neurons and bias the same way as nn.linear\n",
    "\n",
    "√ Need to make the layers in a skip connection sequential? nn.sequential in torch\n",
    "    # The russian doll effect does exactly this!\n",
    "    \n",
    "√ What activation is used in dense/nn.linear?\n",
    "    # None\n",
    "    \n",
    "√ Is keras dense and torch nn.linear the same thing?\n",
    "    # How are the weights inited in each? (Different ways by default but I made them init the same way)\n",
    "    # They are basically the same, input to neural network nodes (bias = True add a bias node)\n",
    "    # Google images for keras dense and nn.linear and you see that it is just a normal feed forward process.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
