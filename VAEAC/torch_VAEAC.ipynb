{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df6fa2c",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500cba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from numpy.random import uniform, binomial, normal\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import kl_divergence\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.distributions import kl_divergence\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.utils.data\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.nn import Module\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e311a",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ea67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cprint(color, text, **kwargs):\n",
    "    if color[0] == '*':\n",
    "        pre_code = '1;'\n",
    "        color = color[1:]\n",
    "    else:\n",
    "        pre_code = ''\n",
    "    code = {\n",
    "        'a': '30',\n",
    "        'r': '31',\n",
    "        'g': '32',\n",
    "        'y': '33',\n",
    "        'b': '34',\n",
    "        'p': '35',\n",
    "        'c': '36',\n",
    "        'w': '37'\n",
    "    }\n",
    "    print(\"\\x1b[%s%sm%s\\x1b[0m\" % (pre_code, code[color], text), **kwargs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# (used in sub network)\n",
    "def normal_parse_params(params, min_sigma=1e-3):\n",
    "    \"\"\"\n",
    "    Take a Tensor (e. g. neural network output) and return\n",
    "    torch.distributions.Normal distribution.\n",
    "    This Normal distribution is component-wise independent,\n",
    "    and its dimensionality depends on the input shape.\n",
    "    First half of channels is mean of the distribution,\n",
    "    the softplus of the second half is std (sigma), so there is\n",
    "    no restrictions on the input tensor.\n",
    "    min_sigma is the minimal value of sigma. I. e. if the above\n",
    "    softplus is less than min_sigma, then sigma is clipped\n",
    "    from below with value min_sigma. This regularization\n",
    "    is required for the numerical stability and may be considered\n",
    "    as a neural network architecture choice without any change\n",
    "    to the probabilistic model.\n",
    "    \"\"\"\n",
    "    n = params.shape[0]\n",
    "    d = params.shape[1]\n",
    "    mu = params[:, :d // 2]\n",
    "    sigma_params = params[:, d // 2:]\n",
    "    sigma = softplus(sigma_params)\n",
    "    sigma = sigma.clamp(min=min_sigma)\n",
    "    distr = Normal(mu, sigma)\n",
    "    return distr\n",
    "\n",
    "## (used in the next function)\n",
    "def torch_onehot(y, Nclass):\n",
    "    if y.is_cuda:\n",
    "        y = y.type(torch.cuda.LongTensor)\n",
    "    else:\n",
    "        y = y.type(torch.LongTensor)\n",
    "    y_onehot = torch.zeros((y.shape[0], Nclass)).type(y.type())\n",
    "    # In your for loop\n",
    "    y_onehot.scatter_(1, y.unsqueeze(1), 1)\n",
    "    return y_onehot\n",
    "\n",
    "## (used in the fit of the main network)\n",
    "def gauss_cat_to_flat(x, input_dim_vec):\n",
    "    output = []\n",
    "    for idx, dim in enumerate(input_dim_vec):\n",
    "        if dim == 1:\n",
    "            output.append(x[:, idx].unsqueeze(1))\n",
    "        elif dim > 1:\n",
    "            oh_vec = torch_onehot(x[:, idx], dim).type(x.type())\n",
    "            output.append(oh_vec)\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "    return torch.cat(output, dim=1)\n",
    "\n",
    "## (also used in the fit of the main network)\n",
    "def flat_to_gauss_cat(x, input_dim_vec):\n",
    "    output = []\n",
    "    cum_dims = 0\n",
    "    for idx, dims in enumerate(input_dim_vec):\n",
    "        if dims == 1:\n",
    "            output.append(x[:, cum_dims].unsqueeze(1))\n",
    "            cum_dims += 1\n",
    "\n",
    "        elif dims > 1:\n",
    "            output.append(x[:, cum_dims:cum_dims + dims].max(dim=1)[1].type(x.type()).unsqueeze(1))\n",
    "            cum_dims += dims\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "\n",
    "    return torch.cat(output, dim=1)\n",
    "\n",
    "def gauss_cat_to_flat_mask(x, input_dim_vec):\n",
    "    output = []\n",
    "    for idx, dim in enumerate(input_dim_vec):\n",
    "        if dim == 1:\n",
    "            output.append(x[:, idx].unsqueeze(1))\n",
    "        elif dim > 1:\n",
    "            oh_vec = x.new_ones(x.shape[0], dim) * x[:, idx].unsqueeze(1)\n",
    "            output.append(oh_vec)\n",
    "        else:\n",
    "            raise ValueError('Error, invalid dimension value')\n",
    "    return torch.cat(output, dim=1)\n",
    "\n",
    "## (also used in the fit of the main network)\n",
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Datafeed function which does something, seems to just be a class for the data?\n",
    "class Datafeed(data.Dataset):\n",
    "\n",
    "    def __init__(self, x_train, y_train=None, transform=None):\n",
    "        self.data = x_train\n",
    "        self.targets = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.targets is not None:\n",
    "            return img, self.targets[index]\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009aebcb",
   "metadata": {},
   "source": [
    "## Skip Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c980a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\"\"\"\n",
    "class SkipConnection(nn.Module):\n",
    "\n",
    "    #Skip-connection over the sequence of layers in the constructor.\n",
    "    #The module passes input data sequentially through these layers\n",
    "    #and then adds original data to the result.\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        super(SkipConnection, self).__init__()\n",
    "        self.inner_net = nn.Sequential(*args)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input + self.inner_net(input)\n",
    "#\"\"\"\n",
    "def preact_leaky_MLPBlock(width):\n",
    "    return SkipConnection(\n",
    "        nn.LeakyReLU(),\n",
    "        nn.BatchNorm1d(num_features=width),\n",
    "        nn.Linear(width, width),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b6cb5",
   "metadata": {},
   "source": [
    "## Fully connected neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52148503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC Networks\n",
    "\n",
    "#Non-leaky (not used)\n",
    "\"\"\"\n",
    "class MLP_prior_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_prior_net, self).__init__()\n",
    "        # input layer\n",
    "        proposal_layers = [nn.Linear(input_dim*2, width), nn.ReLU(), nn.BatchNorm1d(num_features=width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            proposal_layers.append(MLPBlock(width))\n",
    "        # output layer\n",
    "        proposal_layers.append(\n",
    "            nn.Linear(width, latent_dim * 2)\n",
    "        )\n",
    "\n",
    "        self.block = nn.Sequential(*proposal_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class MLP_recognition_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_recognition_net, self).__init__()\n",
    "        # input layer\n",
    "        proposal_layers = [nn.Linear(input_dim, width), nn.ReLU(), nn.BatchNorm1d(num_features=width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            proposal_layers.append(MLPBlock(width))\n",
    "        # output layer\n",
    "        proposal_layers.append(\n",
    "            nn.Linear(width, latent_dim * 2)\n",
    "        )\n",
    "\n",
    "        self.block = nn.Sequential(*proposal_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class MLP_generator_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_generator_net, self).__init__()\n",
    "        # input layer\n",
    "        generative_layers = [nn.Linear(latent_dim, width), nn.LeakyReLU(), nn.BatchNorm1d(num_features=width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            generative_layers.append(\n",
    "                # skip-connection from prior network to generative network\n",
    "                leaky_MLPBlock(width))\n",
    "        # output layer\n",
    "        generative_layers.extend([\n",
    "            nn.Linear(width,\n",
    "                      input_dim),\n",
    "        ])\n",
    "        self.block = nn.Sequential(*generative_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\"\"\"\n",
    "## Fully linear residual path preact models\n",
    "\n",
    "#Prior net\n",
    "class MLP_preact_prior_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_preact_prior_net, self).__init__()\n",
    "        # input layer\n",
    "        proposal_layers = [nn.Linear(input_dim*2, width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            proposal_layers.append(preact_leaky_MLPBlock(width))\n",
    "        # output layer\n",
    "        proposal_layers.extend([nn.LeakyReLU(), nn.BatchNorm1d(num_features=width), nn.Linear(width, latent_dim * 2)])\n",
    "\n",
    "\n",
    "        self.block = nn.Sequential(*proposal_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "#Encoder\n",
    "class MLP_preact_recognition_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_preact_recognition_net, self).__init__()\n",
    "        # input layer\n",
    "        proposal_layers = [nn.Linear(input_dim, width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            proposal_layers.append(preact_leaky_MLPBlock(width))\n",
    "        # output layer\n",
    "        proposal_layers.extend([nn.LeakyReLU(), nn.BatchNorm1d(num_features=width), nn.Linear(width, latent_dim * 2)])\n",
    "\n",
    "        self.block = nn.Sequential(*proposal_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "#Decoder\n",
    "class MLP_preact_generator_net(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim):\n",
    "        super(MLP_preact_generator_net, self).__init__()\n",
    "        # input layer\n",
    "        generative_layers = [nn.Linear(latent_dim, width)]\n",
    "        # body\n",
    "        for i in range(depth-1):\n",
    "            generative_layers.append(\n",
    "                # skip-connection from prior network to generative network\n",
    "                preact_leaky_MLPBlock(width))\n",
    "        # output layer\n",
    "        generative_layers.extend([\n",
    "            nn.LeakyReLU(), nn.BatchNorm1d(num_features=width), nn.Linear(width, input_dim),\n",
    "        ])\n",
    "        self.block = nn.Sequential(*generative_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037739c1",
   "metadata": {},
   "source": [
    "## Functions for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5a11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datasets in UCI\n",
    "def load_UCI(dset_name, splits=10, seed=0, separate_targets=True, save_dir='data/'):\n",
    "    mkdir(save_dir)\n",
    "\n",
    "    if dset_name == 'wine':\n",
    "        if not os.path.isfile(save_dir+'winequality-red.csv'):\n",
    "            urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "                               filename=save_dir+'winequality-red.csv')\n",
    "        data = pd.read_csv(save_dir+'winequality-red.csv', header=1, delimiter=';').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'default_credit':\n",
    "        if not os.path.isfile(save_dir + 'default of credit card clients.xls'):\n",
    "            urllib.request.urlretrieve(\n",
    "                \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\",\n",
    "                filename=save_dir + 'default of credit card clients.xls')\n",
    "        data = pd.read_excel(save_dir + 'default of credit card clients.xls', header=[0, 1], index_col=0, # delimiter=\"\\s+\"\n",
    "                             ).values\n",
    "        y_idx = [-1]  # OK\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('Dataset name doesnt match any known datasets.')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    data = data[np.random.permutation(np.arange(len(data)))]\n",
    "\n",
    "    kf = KFold(n_splits=splits)\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "\n",
    "        # Not sure what separate targets is\n",
    "        if separate_targets:\n",
    "            x_idx = list(range(data.shape[1]))\n",
    "            for e in y_idx:\n",
    "                x_idx.remove(x_idx[e])\n",
    "\n",
    "            x_idx = np.array(x_idx)\n",
    "            y_idx = np.array(y_idx)\n",
    "            x_train, y_train = data[train_index, :], data[train_index, :]\n",
    "            x_train, y_train = x_train[:, x_idx], y_train[:, y_idx]\n",
    "            x_test, y_test = data[test_index, :], data[test_index, :]\n",
    "            x_test, y_test = x_test[:, x_idx], y_test[:, y_idx]\n",
    "\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "            y_means, y_stds = y_train.mean(axis=0), y_train.std(axis=0)\n",
    "\n",
    "            y_stds[y_stds < 1e-10] = 1\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            y_train = ((y_train - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "            y_test = ((y_test - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds\n",
    "\n",
    "        else:\n",
    "            x_train, x_test = data[train_index, :], data[test_index, :]\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path, mode=0o777)\n",
    "\n",
    "# Not sure why this is needed\n",
    "def unnormalise_cat_vars(x, x_means, x_stds, input_dim_vec):\n",
    "    input_dim_vec = np.array(input_dim_vec)\n",
    "    unnorm_x = np.multiply(x, x_stds) + x_means\n",
    "\n",
    "    fixed_unnorm = unnorm_x.round()\n",
    "    fixed_unnorm -= fixed_unnorm.min(axis=0).reshape([1, fixed_unnorm.shape[1]])  # this sets all mins to 0\n",
    "    for idx, dims in enumerate(input_dim_vec):\n",
    "        if dims > 1:\n",
    "            vec = fixed_unnorm[:, idx]\n",
    "            vec[vec > dims - 1] = dims - 1\n",
    "            fixed_unnorm[:, idx] = vec\n",
    "\n",
    "    x[:, input_dim_vec > 1] = fixed_unnorm[:, input_dim_vec > 1]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b56a00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_credit\n"
     ]
    }
   ],
   "source": [
    "names = ['wine', 'default_credit', 'compas', 'lsat']\n",
    "widths = [350, 350, 350, 350] # Bigger than VAE because the task of modelling all conditionals is more complex\n",
    "depths = [3, 3, 3, 3] # We go deeper because we are using residual models\n",
    "latent_dims = [6, 8, 4, 4]\n",
    "under_latent_dims = [6, 8, 4, 4] # following the original paper we set dim(u) = dim(z) with d>r [r is true manifold dim]\n",
    "under_latent_dims2 = [4, 6, 3, 3] # following the original paper we set dim(u) = dim(z) with d>r [r is true manifold dim]\n",
    "\n",
    "dname = 'default_credit'\n",
    "print(dname)\n",
    "\n",
    "x_train, x_test, x_means, x_stds = \\\n",
    "load_UCI(dset_name=dname, splits=10, seed=42, separate_targets=False, save_dir='../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fd341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed\n",
    "#from .UCI_loader import unnormalise_cat_vars\n",
    "\n",
    "\n",
    "# TODO return mean and std for variables + train test split\n",
    "\n",
    "\"\"\"\n",
    "def check_data_file(fname):\n",
    "    files = os.listdir(\".\")  # get the current directory listing\n",
    "    print\n",
    "    \"Looking for file '%s' in the current directory...\" % fname\n",
    "\n",
    "    if fname not in files:\n",
    "        print\n",
    "        \"'%s' not found! Downloading from GitHub...\" % fname\n",
    "        addr = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        try:\n",
    "            response = urllib2.urlopen(addr)\n",
    "        except:\n",
    "            response = urllib3.urlopen(addr)\n",
    "        data = response.read()\n",
    "        fileOut = open(fname, \"w\")\n",
    "        fileOut.write(data)\n",
    "        fileOut.close()\n",
    "        print\n",
    "        \"'%s' download and saved locally..\" % fname\n",
    "    else:\n",
    "        print\n",
    "        \"File found in current directory..\"\n",
    "\"\"\"\n",
    "\n",
    "def check_data_file(fname):\n",
    "    files = os.listdir(\".\")  # get the current directory listing\n",
    "    print\n",
    "    \"Looking for file '%s' in the current directory...\" % fname\n",
    "\n",
    "    if fname not in files:\n",
    "        print\n",
    "        \"'%s' not found! Downloading from GitHub...\" % fname\n",
    "        addr = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        \n",
    "        response = urllib.request.urlopen(addr)\n",
    "\n",
    "        data = response.read()\n",
    "        fileOut = open(fname, \"wb\")\n",
    "        fileOut.write(data)\n",
    "        fileOut.close()\n",
    "        print\n",
    "        \"'%s' download and saved locally..\" % fname\n",
    "    else:\n",
    "        print\n",
    "        \"File found in current directory..\"\n",
    "\n",
    "def get_my_COMPAS(rseed=0, separate_test=True, test_ratio=0.2, save_dir='../data/'):\n",
    "    \"\"\"\n",
    "        The adult dataset can be obtained from: https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
    "        The code will look for the data file in the present directory, if it is not found, it will download them from GitHub.\n",
    "    \"\"\"\n",
    "\n",
    "    SEED = rseed\n",
    "    seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    their_FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"]\n",
    "    FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"c_charge_degree\", \"is_recid\", \"priors_count\",\n",
    "                               \"time_served\"]  # features to be used for classification\n",
    "    CONT_VARIABLES = [\"priors_count\",\n",
    "                      \"time_served\"]  # continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot\n",
    "    CLASS_FEATURE = \"two_year_recid\"  # the decision variable\n",
    "\n",
    "\n",
    "    COMPAS_INPUT_FILE = save_dir + \"compas-scores-two-years.csv\"\n",
    "    check_data_file(COMPAS_INPUT_FILE)\n",
    "\n",
    "    # load the data and get some stats\n",
    "    df = pd.read_csv(COMPAS_INPUT_FILE)\n",
    "    df = df.dropna(subset=[\"days_b_screening_arrest\"])  # dropping missing vals\n",
    "\n",
    "    # convert to np array\n",
    "    data = df.to_dict('list')\n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "\n",
    "    dates_in = data['c_jail_in']\n",
    "    dates_out = data['c_jail_out']\n",
    "    # this measures time in Jail\n",
    "    time_served = []\n",
    "    for i in range(len(dates_in)):\n",
    "        di = datetime.datetime.strptime(dates_in[i], '%Y-%m-%d %H:%M:%S')\n",
    "        do = datetime.datetime.strptime(dates_out[i], '%Y-%m-%d %H:%M:%S')\n",
    "        time_served.append((do - di).days)\n",
    "    time_served = np.array(time_served)\n",
    "    time_served[time_served < 0] = 0\n",
    "    data[\"time_served\"] = time_served\n",
    "\n",
    "    \"\"\" Filtering the data \"\"\"\n",
    "\n",
    "    # These filters are the same as propublica (refer to https://github.com/propublica/compas-analysis)\n",
    "    # If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "    idx = np.logical_and(data[\"days_b_screening_arrest\"] <= 30, data[\"days_b_screening_arrest\"] >= -30)\n",
    "\n",
    "    # We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "    idx = np.logical_and(idx, data[\"is_recid\"] != -1)\n",
    "\n",
    "    # In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "    idx = np.logical_and(idx, data[\"c_charge_degree\"] != \"O\")  # F: felony, M: misconduct\n",
    "\n",
    "    # We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
    "    idx = np.logical_and(idx, data[\"score_text\"] != \"NA\")\n",
    "\n",
    "    # select the examples that satisfy this criteria\n",
    "    for k in data.keys():\n",
    "        data[k] = data[k][idx]\n",
    "\n",
    "    y = data[CLASS_FEATURE]\n",
    "    \"\"\" Feature normalization and one hot encoding \"\"\"\n",
    "\n",
    "    print\n",
    "    \"\\nNumber of people recidivating within two years\"\n",
    "    print\n",
    "    pd.Series(y).value_counts()\n",
    "    print\n",
    "    \"\\n\"\n",
    "\n",
    "    X = []  # empty array with num rows same as num examples, will hstack the features to it\n",
    "    X_dims = []\n",
    "\n",
    "    feature_names = []\n",
    "    for attr in FEATURES_CLASSIFICATION:\n",
    "        vals = data[attr]\n",
    "        if attr in CONT_VARIABLES:\n",
    "            vals = [float(v) for v in vals]\n",
    "            # vals = preprocessing.scale(vals, axis=0, with_mean=True, with_std=True)  # 0 mean and 1 variance\n",
    "            vals = np.reshape(vals, (len(y), -1))  # convert from 1-d arr to a 2-d arr with one col\n",
    "            X_dims.append(1)\n",
    "\n",
    "        else:  # for binary categorical variables, the label binarizer uses just one var instead of two\n",
    "            enc = preprocessing.OneHotEncoder(categories='auto', handle_unknown='error')\n",
    "            enc.fit(vals.reshape(-1, 1))\n",
    "            vals = enc.transform(vals.reshape(-1, 1)).todense()\n",
    "            X_dims += [vals.shape[1]]*vals.shape[1]\n",
    "\n",
    "        # add to learnable features\n",
    "        X.append(vals)\n",
    "\n",
    "        if attr in CONT_VARIABLES:  # continuous feature, just append the name\n",
    "            feature_names.append(attr)\n",
    "        else:  # categorical features\n",
    "            if vals.shape[1] == 1:  # binary features that passed through lib binarizer\n",
    "                feature_names.append(attr)\n",
    "            else:\n",
    "                for k in enc.categories_:  # non-binary categorical features, need to add the names for each cat\n",
    "                    feature_names.append(attr + \"_\" + str(k))\n",
    "\n",
    "    X = np.array(np.concatenate(list(X), axis=1))\n",
    "    X_dims = np.array(X_dims)\n",
    "\n",
    "    if separate_test:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=rseed, shuffle=True)\n",
    "\n",
    "        x_means, x_stds = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "        x_means[X_dims>1] = 0\n",
    "        x_stds[X_dims>1] = 1\n",
    "        x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "        x_train = ((X_train - x_means) / x_stds).astype(np.float32)\n",
    "        x_test = ((X_test - x_means) / x_stds).astype(np.float32)\n",
    "\n",
    "        return x_train, x_test, x_means, x_stds, y_train, y_test, feature_names, X_dims\n",
    "    else:\n",
    "        x_means, x_stds = X.mean(axis=0), X.std(axis=0)\n",
    "        print(X_dims.shape, x_means.shape)\n",
    "        x_means[:,X_dims>1] = 0\n",
    "        x_stds[:,X_dims>1] = 1\n",
    "        x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "        x_train = ((X - x_means) / x_stds).astype(np.float32)\n",
    "\n",
    "        return x_train, x_means, x_stds, y, feature_names, X_dims\n",
    "\n",
    "\n",
    "def join_compas_targets(x_train, x_test, y_train, y_test, X_dims):\n",
    "    # output from get method is onehot so we need to flatten and append 2\n",
    "    input_dim_vec = X_dims_to_input_dim_vec(X_dims)\n",
    "    input_dim_vec = np.append(input_dim_vec, 2)\n",
    "    enc = preprocessing.OneHotEncoder(categories='auto', handle_unknown='error')\n",
    "    enc.fit(y_train.reshape(-1, 1))\n",
    "\n",
    "    vals_train = np.array(enc.transform(y_train.reshape(-1, 1)).todense()).astype(np.float32)\n",
    "    vals_test = np.array(enc.transform(y_test.reshape(-1, 1)).todense()).astype(np.float32)\n",
    "\n",
    "    x_train = np.concatenate([x_train, vals_train], axis=1)\n",
    "    x_test = np.concatenate([x_test, vals_test], axis=1)\n",
    "    return x_train, x_test, input_dim_vec\n",
    "\n",
    "\n",
    "def X_dims_to_input_dim_vec(X_dims):\n",
    "    \"\"\"This is for our cat_Gauss VAE model\"\"\"\n",
    "    input_dim_vec = []\n",
    "    i = 0\n",
    "    while i < len(X_dims):\n",
    "        input_dim_vec.append(X_dims[i])\n",
    "        i += X_dims[i]\n",
    "    return np.array(input_dim_vec)\n",
    "\n",
    "#\"\"\"\n",
    "def input_dim_vec_to_X_dims(input_dim_vec):\n",
    "    # This is for our cat_Gauss VAE model\n",
    "    X_dims = []\n",
    "    for i in input_dim_vec:\n",
    "        for ii in range(i):\n",
    "            X_dims.append(i)\n",
    "    return np.array(X_dims)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93410b7d",
   "metadata": {},
   "source": [
    "# Create datafeed for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfb4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Datafeed(x_train, x_train, transform=None) \n",
    "valset = Datafeed(x_test, x_train, transform=None)\n",
    "\n",
    "save_dir = '../saves/fc_preact_VAEAC_NEW_' + dname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f024653",
   "metadata": {},
   "source": [
    "# Masker for the VAEAC training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68649573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_masker:\n",
    "    \"\"\"\n",
    "    Returned mask is sampled from component-wise independent Bernoulli\n",
    "    distribution with probability of component to be unobserved p.\n",
    "    Such mask induces the type of missingness which is called\n",
    "    in literature \"missing completely at random\" (MCAR).\n",
    "    If some value in batch is missed, it automatically becomes unobserved.\n",
    "    \"\"\"\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        pp = uniform(low=0.0, high=self.p, size=batch.shape[0])\n",
    "        pp = np.expand_dims(pp, axis=1)\n",
    "        pp = np.repeat(pp, batch.shape[1], axis=1)\n",
    "        nan_mask = torch.isnan(batch).float()  # missed values\n",
    "#         bernoulli_mask_numpy = np.random.choice(2, size=batch.shape,\n",
    "#                                                 p=[1 - pp, pp])\n",
    "        bernoulli_mask_numpy = binomial(1, pp, size=None)\n",
    "#         print(bernoulli_mask_numpy.shape)\n",
    "        bernoulli_mask = torch.from_numpy(bernoulli_mask_numpy).float()\n",
    "        mask = torch.max(bernoulli_mask, nan_mask)  # logical or\n",
    "        return mask\n",
    "    \n",
    "masker = top_masker(p=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d145c7",
   "metadata": {},
   "source": [
    "# rms cat loglike (only for categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15df99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rms_cat_loglike(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim_vec, reduction='none'):\n",
    "        super(rms_cat_loglike, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        self.mse = MSELoss(reduction='none')  # takes(input, target)\n",
    "        self.ce = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        log_prob_vec = []\n",
    "        cum_dims = 0\n",
    "        for idx, dims in enumerate(self.input_dim_vec):\n",
    "            if dims == 1:\n",
    "                # Gaussian_case\n",
    "                log_prob_vec.append(-self.mse(x[:, cum_dims], y[:, idx]).unsqueeze(1))\n",
    "                cum_dims += 1\n",
    "\n",
    "            elif dims > 1:\n",
    "                if x.shape[1] == y.shape[1]:\n",
    "                    raise Exception('Input and target seem to be in flat format. Need integer cat targets.')\n",
    "                                \n",
    "                if y.is_cuda:\n",
    "                    tget = y[:, idx].type(torch.cuda.LongTensor)\n",
    "                else:\n",
    "                    tget = y[:, idx].type(torch.LongTensor)\n",
    "\n",
    "                log_prob_vec.append(-self.ce(x[:, cum_dims:cum_dims + dims], tget).unsqueeze(1))\n",
    "                cum_dims += dims\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Error, invalid dimension value')\n",
    "\n",
    "        log_prob_vec = torch.cat(log_prob_vec, dim=1)\n",
    "\n",
    "        if self.reduction == 'none':\n",
    "            return log_prob_vec\n",
    "        elif self.reduction == 'sum':\n",
    "            return log_prob_vec.sum()\n",
    "        elif self.reduction == 'average':\n",
    "            return log_prob_vec.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d94fdf",
   "metadata": {},
   "source": [
    "# Gaussian log likelihood (For datasets with continous with or without categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0eb2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GaussianLoglike(Module):\n",
    "    \"\"\"\n",
    "    Compute reconstruction log probability of groundtruth given\n",
    "    a tensor of Gaussian distribution parameters and a mask.\n",
    "    Gaussian distribution parameters are output of a neural network\n",
    "    without any restrictions, the minimal sigma value is clipped\n",
    "    from below to min_sigma (default: 1e-2) in order not to overfit\n",
    "    network on some exact pixels.\n",
    "    The first half of channels corresponds to mean, the second half\n",
    "    corresponds to std. See normal_parse_parameters for more info.\n",
    "    This layer doesn't work with NaNs in the data, it is used for\n",
    "    inpainting. Roughly speaking, this loss is similar to L2 loss.\n",
    "    Returns a vector of log probabilities for each object of the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_sigma=1e-2):\n",
    "        super(GaussianLoglike, self).__init__()\n",
    "        self.min_sigma = min_sigma\n",
    "\n",
    "    def forward(self, distr_params, groundtruth, mask=None):\n",
    "        distr = normal_parse_params(distr_params, self.min_sigma)\n",
    "        if mask is not None:\n",
    "            log_probs = distr.log_prob(groundtruth) * mask\n",
    "        else:\n",
    "            log_probs = distr.log_prob(groundtruth)\n",
    "        return log_probs.view(groundtruth.shape[0], -1).sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcc971",
   "metadata": {},
   "source": [
    "# Rectified Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7401578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt(\n",
    "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e954f83",
   "metadata": {},
   "source": [
    "# Base Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46357ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(object):\n",
    "    def __init__(self):\n",
    "        cprint('c', '\\nNet:')\n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return np.sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "    def set_mode_train(self, train=True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "    def update_lr(self, epoch, gamma=0.99):\n",
    "        self.epoch += 1\n",
    "        if self.schedule is not None:\n",
    "            if len(self.schedule) == 0 or epoch in self.schedule:\n",
    "                self.lr *= gamma\n",
    "                print('learning rate: %f  (%d)\\n' % (self.lr, epoch))\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.lr\n",
    "\n",
    "    def save(self, filename):\n",
    "        cprint('c', 'Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer}, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        cprint('c', 'Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfaacd1",
   "metadata": {},
   "source": [
    "# Sub network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6654f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEAC_gauss(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim, pred_sig=True):\n",
    "        super(VAEAC_gauss, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.recognition_net = MLP_preact_recognition_net(input_dim, width, depth, latent_dim)\n",
    "        self.prior_net = MLP_preact_prior_net(input_dim, width, depth, latent_dim)\n",
    "        if pred_sig:\n",
    "            self.generator_net = MLP_preact_generator_net(2*input_dim, width, depth, latent_dim)\n",
    "            self.rec_loglike = GaussianLoglike(min_sigma=1e-2)\n",
    "        else:\n",
    "            self.generator_net = MLP_preact_generator_net(input_dim, width, depth, latent_dim)\n",
    "            self.m_rec_loglike = MSELoss(reduction='none')\n",
    "        self.pred_sig = pred_sig\n",
    "        self.sigma_mu = 1e4\n",
    "        self.sigma_sigma = 1e-4\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mask(x, mask):\n",
    "        \"\"\"Positive bits in mask are set to 0 in x (observed)\"\"\"\n",
    "        observed = x.clone()  # torch.tensor(x)\n",
    "        observed[mask.bool()] = 0\n",
    "        return observed\n",
    "\n",
    "    def recognition_encode(self, x):\n",
    "        approx_post_params = self.recognition_net(x)\n",
    "        approx_post = normal_parse_params(approx_post_params, 1e-3)\n",
    "        return approx_post\n",
    "\n",
    "    def prior_encode(self, x, mask):\n",
    "        x = self.apply_mask(x, mask)\n",
    "        x = torch.cat([x, mask], 1)\n",
    "        prior_params = self.prior_net(x)\n",
    "        prior = normal_parse_params(prior_params, 1e-3)\n",
    "        return prior\n",
    "\n",
    "    def decode(self, z_sample):\n",
    "        rec_params = self.generator_net(z_sample)\n",
    "        return rec_params\n",
    "\n",
    "    def reg_cost(self, prior):\n",
    "        num_objects = prior.mean.shape[0]\n",
    "        mu = prior.mean.view(num_objects, -1)\n",
    "        sigma = prior.scale.view(num_objects, -1)\n",
    "        mu_regularizer = -(mu ** 2).sum(-1) / 2 / (self.sigma_mu ** 2)\n",
    "        sigma_regularizer = (sigma.log() - sigma).sum(-1) * self.sigma_sigma\n",
    "        return mu_regularizer + sigma_regularizer\n",
    "\n",
    "    def vlb(self, prior, approx_post, x, rec_params):\n",
    "        if self.pred_sig:\n",
    "            rec = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        else:\n",
    "            rec = -self.m_rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        prior_regularization = self.reg_cost(prior).view(x.shape[0], -1).sum(-1)\n",
    "        kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "        return rec - kl + prior_regularization\n",
    "\n",
    "    def iwlb(self, prior, approx_post, x, K=50):\n",
    "        estimates = []\n",
    "        for i in range(K):\n",
    "            latent = approx_post.rsample()\n",
    "            rec_params = self.decode(latent)\n",
    "            if self.pred_sig:\n",
    "                rec_loglike = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "            else:\n",
    "                rec_loglike = -self.m_rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "\n",
    "            prior_log_prob = prior.log_prob(latent)\n",
    "            prior_log_prob = prior_log_prob.view(x.shape[0], -1)\n",
    "            prior_log_prob = prior_log_prob.sum(-1)\n",
    "\n",
    "            proposal_log_prob = approx_post.log_prob(latent)\n",
    "            proposal_log_prob = proposal_log_prob.view(x.shape[0], -1)\n",
    "            proposal_log_prob = proposal_log_prob.sum(-1)\n",
    "\n",
    "            estimate = rec_loglike + prior_log_prob - proposal_log_prob\n",
    "            estimates.append(estimate[:, None])\n",
    "\n",
    "        return torch.logsumexp(torch.cat(estimates, 1), 1) - np.log(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f89180",
   "metadata": {},
   "source": [
    "# Main Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb03688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Network\n",
    "class VAEAC_gauss_net(BaseNet):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim, pred_sig=True, lr=1e-3, cuda=True):\n",
    "        super(VAEAC_gauss_net, self).__init__()\n",
    "        cprint('y', 'VAE_gauss_net')\n",
    "\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.pred_sig = pred_sig\n",
    "\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "        self.schedule = None\n",
    "\n",
    "        self.vlb_scale = 1 / input_dim  # scale for dimensions of input so we can use same LR always\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        self.model = VAEAC_gauss(self.input_dim, self.width, self.depth, self.latent_dim, self.pred_sig)\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = RAdam(self.model.parameters(), lr=self.lr) # torch.optim.Adam\n",
    "\n",
    "    def fit(self, x, mask):\n",
    "        self.set_mode_train(train=True)\n",
    "\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "        z_sample = approx_post.rsample()\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(prior, approx_post, x, rec_params)\n",
    "        loss = (- vlb * self.vlb_scale).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.pred_sig:\n",
    "            rec_return = normal_parse_params(rec_params, 1e-3)\n",
    "        else:\n",
    "            rec_return = rec_params\n",
    "        return vlb.mean().item(), rec_return\n",
    "\n",
    "    def eval(self, x, mask, sample=False):\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "        if sample:\n",
    "            z_sample = approx_post.sample()\n",
    "        else:\n",
    "            z_sample = approx_post.loc\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(prior, approx_post, x, rec_params)\n",
    "\n",
    "        if self.pred_sig:\n",
    "            rec_return = normal_parse_params(rec_params, 1e-3)\n",
    "        else:\n",
    "            rec_return = rec_params\n",
    "        return vlb.mean().item(), rec_return\n",
    "\n",
    "    def eval_iw(self, x, mask, k=50):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "\n",
    "        iw_lb = self.model.iwlb(prior, approx_post, x, k)\n",
    "        return iw_lb.mean().item()\n",
    "\n",
    "    def get_prior(self, x, mask):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        return prior\n",
    "\n",
    "    def get_post(self, x):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, = to_variable(var=(x,), cuda=self.cuda)\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "        return approx_post\n",
    "\n",
    "    def inpaint(self, x, mask, Nsample=1, z_mean=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        out = []\n",
    "        for i in range(Nsample):\n",
    "            if z_mean:\n",
    "                z_sample = prior.loc.data\n",
    "            else:\n",
    "                z_sample = prior.sample()\n",
    "            rec_params = self.model.decode(z_sample)\n",
    "            out.append(rec_params.data)\n",
    "        out = torch.stack(out, dim=0)\n",
    "\n",
    "        if self.pred_sig:\n",
    "            return [normal_parse_params(out[i], 1e-2) for i in range(Nsample)]\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def regenerate(self, z, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not z.requires_grad:\n",
    "                z.requires_grad = True\n",
    "        else:\n",
    "            z, = to_variable(var=(z,), volatile=True, cuda=self.cuda)\n",
    "        out = self.model.decode(z)\n",
    "        if self.pred_sig:\n",
    "            return normal_parse_params(out, 1e-2)\n",
    "        else:\n",
    "            return out.data\n",
    "class VAEAC_gauss_cat(nn.Module):\n",
    "    def __init__(self, input_dim_vec, width, depth, latent_dim, pred_sig=True):\n",
    "        super(VAEAC_gauss_cat, self).__init__()\n",
    "\n",
    "        self.input_dim = 0\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        for e in self.input_dim_vec:\n",
    "            self.input_dim += e\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.recognition_net = MLP_preact_recognition_net(self.input_dim, width, depth, latent_dim)\n",
    "        self.prior_net = MLP_preact_prior_net(self.input_dim, width, depth, latent_dim)\n",
    "        if pred_sig:\n",
    "            raise Exception('Not yet implemented')\n",
    "        else:\n",
    "            self.generator_net = MLP_preact_generator_net(self.input_dim, width, depth, latent_dim)\n",
    "            self.rec_loglike = rms_cat_loglike(self.input_dim_vec, reduction='none')\n",
    "        self.pred_sig = pred_sig\n",
    "        self.sigma_mu = 1e4\n",
    "        self.sigma_sigma = 1e-4\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mask(x, mask):\n",
    "        \"\"\"Positive bits in mask are set to 0 in x (observed)\"\"\"\n",
    "        observed = x.clone()  # torch.tensor(x)\n",
    "        observed[mask.bool()] = 0\n",
    "        return observed\n",
    "\n",
    "    def recognition_encode(self, x):\n",
    "        \"\"\"Works with flattened representATION\"\"\"\n",
    "        approx_post_params = self.recognition_net(x)\n",
    "        approx_post = normal_parse_params(approx_post_params, 1e-3)\n",
    "        return approx_post\n",
    "\n",
    "    def prior_encode(self, x, mask):\n",
    "        \"\"\"Works with flattened representATION\"\"\"\n",
    "        x = self.apply_mask(x, mask)\n",
    "        x = torch.cat([x, mask], 1)\n",
    "        prior_params = self.prior_net(x)\n",
    "        prior = normal_parse_params(prior_params, 1e-3)\n",
    "        return prior\n",
    "\n",
    "    def decode(self, z_sample):\n",
    "        rec_params = self.generator_net(z_sample)\n",
    "        return rec_params\n",
    "\n",
    "    def reg_cost(self, prior):\n",
    "        num_objects = prior.mean.shape[0]\n",
    "        mu = prior.mean.view(num_objects, -1)\n",
    "        sigma = prior.scale.view(num_objects, -1)\n",
    "        mu_regularizer = -(mu ** 2).sum(-1) / 2 / (self.sigma_mu ** 2)\n",
    "        sigma_regularizer = (sigma.log() - sigma).sum(-1) * self.sigma_sigma\n",
    "        return mu_regularizer + sigma_regularizer\n",
    "\n",
    "    def vlb(self, prior, approx_post, x, rec_params):\n",
    "        if self.pred_sig:\n",
    "            raise Exception('Not yet imeplemented')\n",
    "        else:\n",
    "            rec = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        prior_regularization = self.reg_cost(prior).view(x.shape[0], -1).sum(-1)\n",
    "        kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "        return rec - kl + prior_regularization\n",
    "\n",
    "    def iwlb(self, prior, approx_post, x, K=50):\n",
    "        estimates = []\n",
    "        for i in range(K):\n",
    "            latent = approx_post.rsample()\n",
    "            rec_params = self.decode(latent)\n",
    "            if self.pred_sig:\n",
    "                raise Exception('Not yet imeplemented')\n",
    "            else:\n",
    "                rec_loglike = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "\n",
    "            prior_log_prob = prior.log_prob(latent)\n",
    "            prior_log_prob = prior_log_prob.view(x.shape[0], -1)\n",
    "            prior_log_prob = prior_log_prob.sum(-1)\n",
    "\n",
    "            proposal_log_prob = approx_post.log_prob(latent)\n",
    "            proposal_log_prob = proposal_log_prob.view(x.shape[0], -1)\n",
    "            proposal_log_prob = proposal_log_prob.sum(-1)\n",
    "\n",
    "            estimate = rec_loglike + prior_log_prob - proposal_log_prob\n",
    "            estimates.append(estimate[:, None])\n",
    "\n",
    "        return torch.logsumexp(torch.cat(estimates, 1), 1) - np.log(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75a7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VAEAC_gauss_cat_net(BaseNet):\n",
    "    def __init__(self, input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=1e-3, cuda=True, flatten=True):\n",
    "        super(VAEAC_gauss_cat_net, self).__init__()\n",
    "        cprint('y', 'VAE_gauss_net')\n",
    "\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.input_dim = 0\n",
    "        self.input_dim_vec = input_dim_vec\n",
    "        for e in self.input_dim_vec:\n",
    "            self.input_dim += e\n",
    "        self.flatten = flatten\n",
    "        if not self.flatten:\n",
    "            pass\n",
    "            # raise Exception('Error calculation not supported without flattening')\n",
    "\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.pred_sig = pred_sig\n",
    "\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "        self.schedule = None\n",
    "\n",
    "        self.vlb_scale = 1 / len(self.input_dim_vec)  # scale for dimensions of input so we can use same LR always\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        self.model = VAEAC_gauss_cat(self.input_dim_vec, self.width, self.depth, self.latent_dim, self.pred_sig)\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = RAdam(self.model.parameters(), lr=self.lr)  # torch.optim.Adam\n",
    "\n",
    "    def fit(self, x, mask):\n",
    "        self.set_mode_train(train=True)\n",
    "        \n",
    "        #print(\"bef x: \", x.shape)\n",
    "        if self.flatten:\n",
    "            mask = gauss_cat_to_flat_mask(mask, self.input_dim_vec)\n",
    "            x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        \n",
    "        else:\n",
    "            x_flat = x # X already flattened\n",
    "            x = flat_to_gauss_cat(x, self.input_dim_vec) # unflattened x (used for loss computation)\n",
    "        #print(\"aft x: \", x.shape)\n",
    "        x_flat, x, mask = to_variable(var=(x_flat, x, mask), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        prior = self.model.prior_encode(x_flat, mask)\n",
    "        approx_post = self.model.recognition_encode(x_flat)\n",
    "        z_sample = approx_post.rsample()\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(prior, approx_post, x, rec_params)\n",
    "        loss = (- vlb * self.vlb_scale).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.pred_sig:\n",
    "            rec_return = normal_parse_params(rec_params, 1e-3)\n",
    "        else:\n",
    "            rec_return = rec_params\n",
    "        return vlb.mean().item(), rec_return\n",
    "\n",
    "    def eval(self, x, mask, sample=False):\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        if self.flatten:\n",
    "            mask = gauss_cat_to_flat_mask(mask, self.input_dim_vec)\n",
    "            x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        else:\n",
    "            x_flat = x\n",
    "            x = flat_to_gauss_cat(x, self.input_dim_vec)\n",
    "\n",
    "        x_flat, x, mask = to_variable(var=(x_flat, x, mask), cuda=self.cuda)\n",
    "        prior = self.model.prior_encode(x_flat, mask)\n",
    "\n",
    "        approx_post = self.model.recognition_encode(x_flat)\n",
    "        if sample:\n",
    "            z_sample = approx_post.sample()\n",
    "        else:\n",
    "            z_sample = approx_post.loc\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(prior, approx_post, x, rec_params)\n",
    "\n",
    "        if self.pred_sig:\n",
    "            rec_return = normal_parse_params(rec_params, 1e-3)\n",
    "        else:\n",
    "            rec_return = rec_params\n",
    "        return vlb.mean().item(), rec_return\n",
    "\n",
    "    def eval_iw(self, x, mask, k=50):\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        if self.flatten:\n",
    "            mask = gauss_cat_to_flat_mask(mask, self.input_dim_vec)\n",
    "            x_flat = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "        else:\n",
    "            x_flat = x\n",
    "            x = flat_to_gauss_cat(x, self.input_dim_vec)\n",
    "\n",
    "\n",
    "        x_flat, x, mask = to_variable(var=(x_flat, x, mask), cuda=self.cuda)\n",
    "\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        approx_post = self.model.recognition_encode(x_flat)\n",
    "\n",
    "        iw_lb = self.model.iwlb(prior, approx_post, x, k)\n",
    "        return iw_lb.mean().item()\n",
    "\n",
    "    def get_prior(self, x, mask, flatten=None):\n",
    "        self.set_mode_train(train=False)\n",
    "        if flatten is None:\n",
    "            flatten = self.flatten\n",
    "        if flatten:\n",
    "            mask = gauss_cat_to_flat_mask(mask, self.input_dim_vec)\n",
    "            x = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        return prior\n",
    "\n",
    "    def get_post(self, x, flatten=None):\n",
    "        self.set_mode_train(train=False)\n",
    "        if flatten is None:\n",
    "            flatten = self.flatten\n",
    "        if flatten:\n",
    "            x = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "\n",
    "        x, = to_variable(var=(x,), cuda=self.cuda)\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "        return approx_post\n",
    "\n",
    "    def inpaint(self, x, mask, Nsample=1, z_mean=False, flatten=False, unflatten=False, cat_probs=False):\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        if flatten:\n",
    "            mask = gauss_cat_to_flat_mask(mask, self.input_dim_vec)\n",
    "            x = gauss_cat_to_flat(x, self.input_dim_vec)\n",
    "\n",
    "        x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "        prior = self.model.prior_encode(x, mask)\n",
    "        out = []\n",
    "        for i in range(Nsample):\n",
    "            if z_mean:\n",
    "                z_sample = prior.loc.data\n",
    "            else:\n",
    "                z_sample = prior.sample()\n",
    "            rec_params = self.model.decode(z_sample)\n",
    "            out.append(rec_params.data)\n",
    "        out = torch.stack(out, dim=0)\n",
    "\n",
    "        if self.pred_sig:\n",
    "            raise Exception('Not yet implemented')\n",
    "        else:\n",
    "            dim0 = out.shape[0]\n",
    "            dim1 = out.shape[1]\n",
    "            out = out.view(dim0*dim1, -1)\n",
    "            if unflatten:\n",
    "                out = flat_to_gauss_cat(out, self.input_dim_vec)\n",
    "            else:\n",
    "                out = selective_softmax(out, self.input_dim_vec, grad=False, cat_probs=cat_probs)\n",
    "            out = out.view(dim0, dim1, -1)\n",
    "            return out.data\n",
    "\n",
    "    def regenerate(self, z, grad=False, unflatten=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if unflatten and grad:\n",
    "            raise Exception('flatten and grad options are not compatible')\n",
    "        if grad:\n",
    "            if not z.requires_grad:\n",
    "                z.requires_grad = True\n",
    "        else:\n",
    "            z, = to_variable(var=(z,), volatile=True, cuda=self.cuda)\n",
    "        out = self.model.decode(z)\n",
    "        if self.pred_sig:\n",
    "            raise Exception('Not yet implemented')\n",
    "        else:\n",
    "            if unflatten:\n",
    "                out = flat_to_gauss_cat(out, self.input_dim_vec)\n",
    "            else:\n",
    "                out = selective_softmax(out, self.input_dim_vec, grad=grad)\n",
    "            return out.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b166b7",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0642f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAEAC(net, masker, name, batch_size, nb_epochs, trainset, valset, cuda,\n",
    "                flat_ims=False, train_plot=False, Nclass=None, early_stop=None, script_mode=False):\n",
    "\n",
    "    models_dir = name + '_models'\n",
    "    results_dir = name + '_results'\n",
    "    mkdir(models_dir)\n",
    "    mkdir(results_dir)\n",
    "\n",
    "    if cuda:\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                                  num_workers=0)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "    else:\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                                  num_workers=0)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                                num_workers=0)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "    cprint('c', '\\nNetwork:')\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # train\n",
    "    cprint('c', '\\nTrain:')\n",
    "\n",
    "    print('  init cost variables:')\n",
    "    vlb_train = np.zeros(nb_epochs)\n",
    "    vlb_dev = np.zeros(nb_epochs)\n",
    "    iwlb_dev = np.zeros(nb_epochs)\n",
    "    best_vlb = -np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    nb_its_dev = 1\n",
    "\n",
    "    tic0 = time.time()\n",
    "    for i in range(epoch, nb_epochs):\n",
    "        net.set_mode_train(True)\n",
    "\n",
    "        tic = time.time()\n",
    "        nb_samples = 0\n",
    "        for x, y in trainloader:\n",
    "\n",
    "            if flat_ims:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "            if Nclass is not None:\n",
    "                y_oh = torch_onehot(y, Nclass).type(x.type())\n",
    "                x = torch.cat([x, y_oh], 1)\n",
    "\n",
    "            mask = masker(x)\n",
    "            cost, _ = net.fit(x, mask)\n",
    "\n",
    "            vlb_train[i] += cost * len(x)\n",
    "            nb_samples += len(x)\n",
    "\n",
    "        vlb_train[i] /= nb_samples\n",
    "\n",
    "        toc = time.time()\n",
    "\n",
    "        # ---- print\n",
    "        print(\"it %d/%d, vlb %f, \" % (i, nb_epochs, vlb_train[i]), end=\"\")\n",
    "        cprint('r', '   time: %f seconds\\n' % (toc - tic))\n",
    "        net.update_lr(i)\n",
    "\n",
    "        # ---- dev\n",
    "        if i % nb_its_dev == 0:\n",
    "            nb_samples = 0\n",
    "            for j, (x, y) in enumerate(valloader):\n",
    "\n",
    "                if flat_ims:\n",
    "                    x = x.view(x.shape[0], -1)\n",
    "                if Nclass is not None:\n",
    "                    y_oh = torch_onehot(y, Nclass).type(x.type())\n",
    "                    x = torch.cat([x, y_oh], 1)\n",
    "\n",
    "                mask = masker(x)\n",
    "                cost, rec_mean = net.eval(x, mask)\n",
    "                # iwlb = net.eval_iw(x, mask, 25)\n",
    "\n",
    "                vlb_dev[i] += cost * len(x)\n",
    "                # iwlb_dev[i] += iwlb\n",
    "                nb_samples += len(x)\n",
    "\n",
    "            vlb_dev[i] /= nb_samples\n",
    "            # iwlb_dev[i] /= nb_samples\n",
    "\n",
    "            cprint('g', '    vlb %f (%f)\\n' % (vlb_dev[i], best_vlb))\n",
    "\n",
    "            if train_plot:\n",
    "                xm = net.model.apply_mask(x, mask)\n",
    "                \n",
    "                xr = x.cpu()\n",
    "                rec_inpaint = net.inpaint(xm, mask)\n",
    "                try:\n",
    "                    o = rec_mean.cpu()\n",
    "                    rec_inpaint = rec_inpaint[0].cpu()\n",
    "                except:\n",
    "                    o = rec_mean.loc.cpu()\n",
    "                    rec_inpaint = rec_inpaint[0].loc.cpu()\n",
    "\n",
    "                if Nclass is not None:\n",
    "                    xm = xm[:, :-Nclass]\n",
    "                    rec_inpaint = rec_inpaint[:, :-Nclass]\n",
    "                    xr = xr[:, :-Nclass]\n",
    "                    o = o[:, :-Nclass]\n",
    "\n",
    "                if len(x.shape) == 2:\n",
    "                    side = int(np.sqrt(xm.shape[1]))\n",
    "                    xm = xm.view(-1, 1, side, side).data\n",
    "                    rec_inpaint = rec_inpaint.view(-1, 1, side, side).data\n",
    "                    xr = xr.view(-1, 1, side, side).data\n",
    "                    o = o.view(-1, 1, side, side).data\n",
    "\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                dd = make_grid(torch.cat([xr[:10], o[:10]]), nrow=10).numpy()\n",
    "                plt.imshow(np.transpose(dd, (1, 2, 0)), interpolation='nearest')\n",
    "                plt.title('reconstruct')\n",
    "                if script_mode:\n",
    "                    plt.savefig(results_dir + '/rec%d.png' % i)\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                dd = make_grid(torch.cat([xm[:10], rec_inpaint[:10]]), nrow=10).numpy()\n",
    "                plt.imshow(np.transpose(dd, (1, 2, 0)), interpolation='nearest')\n",
    "                plt.title('inpaint')\n",
    "                if script_mode:\n",
    "                    plt.savefig(results_dir + '/inp%d.png' % i)\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "        if vlb_dev[i] > best_vlb:\n",
    "            best_vlb = vlb_dev[i]\n",
    "            best_epoch = i\n",
    "            net.save(models_dir + '/theta_best.dat')\n",
    "\n",
    "        if early_stop is not None and (i - best_epoch) > early_stop:\n",
    "            break\n",
    "\n",
    "\n",
    "    net.save(models_dir + '/theta_last.dat')\n",
    "    toc0 = time.time()\n",
    "    runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n",
    "    cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # results\n",
    "    cprint('c', '\\nRESULTS:')\n",
    "    nb_parameters = net.get_nb_parameters()\n",
    "    best_cost_dev = np.max(vlb_dev)\n",
    "    # best_iw_dev = np.max(iwlb_dev)\n",
    "    best_cost_train = np.max(vlb_train)\n",
    "\n",
    "    print('  best_vlb_dev: %f' % best_cost_dev)\n",
    "    # print('  best_iwlb_dev: %f' % best_iw_dev)\n",
    "    print('  best_vlb_train: %f' % best_cost_train)\n",
    "    print('  nb_parameters: %d (%s)\\n' % (nb_parameters, humansize(nb_parameters)))\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # fig cost vs its\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.clip(vlb_train, -1000, 1000), 'r')\n",
    "    plt.plot(np.clip(vlb_dev[::nb_its_dev], -1000, 1000), 'b')\n",
    "    plt.legend(['cost_train', 'cost_dev'])\n",
    "    plt.ylabel('vlb')\n",
    "    plt.xlabel('it')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(results_dir+'/train_cost.png')\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.plot(np.clip(iwlb_dev[::nb_its_dev], -1000, 1000), 'b')\n",
    "    # plt.ylabel('dev iwlb')\n",
    "    # plt.xlabel('it')\n",
    "    # plt.grid(True)\n",
    "    # plt.savefig(results_dir + '/train_iwlb.png')\n",
    "    if train_plot:\n",
    "        plt.show()\n",
    "    return vlb_train, vlb_dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046f0e6",
   "metadata": {},
   "source": [
    "## COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b188c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compas (5554, 19) (618, 19)\n",
      "[3 6 2 2 2 1 1 2]\n",
      "compas\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mVAE_gauss_net\u001b[0m\n",
      "    Total params: 0.78M\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n",
      "  init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/1070947545.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/2000, vlb -18.383537, \u001b[31m   time: 1.619305 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -10.621977 (-inf)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/2000, vlb -12.485022, \u001b[31m   time: 1.502898 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -11.428103 (-10.621977)\n",
      "\u001b[0m\n",
      "it 2/2000, vlb -11.150703, \u001b[31m   time: 1.491699 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -10.307267 (-10.621977)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 3/2000, vlb -10.111939, \u001b[31m   time: 1.530016 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.356564 (-10.307267)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 4/2000, vlb -9.358087, \u001b[31m   time: 1.516967 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -8.211029 (-9.356564)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 5/2000, vlb -8.774173, \u001b[31m   time: 1.523422 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.624780 (-8.211029)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 6/2000, vlb -8.383996, \u001b[31m   time: 1.521481 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.104462 (-7.624780)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 7/2000, vlb -7.931534, \u001b[31m   time: 1.524011 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.953472 (-7.104462)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 8/2000, vlb -7.641358, \u001b[31m   time: 1.549215 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.272264 (-6.953472)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 9/2000, vlb -7.339769, \u001b[31m   time: 1.519224 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.917879 (-6.272264)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 10/2000, vlb -7.118479, \u001b[31m   time: 1.743794 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.705848 (-5.917879)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 11/2000, vlb -6.870361, \u001b[31m   time: 2.081666 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.671996 (-5.705848)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 12/2000, vlb -6.633090, \u001b[31m   time: 2.476295 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.307327 (-5.671996)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 13/2000, vlb -6.462764, \u001b[31m   time: 2.050441 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.027849 (-5.307327)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 14/2000, vlb -6.308567, \u001b[31m   time: 2.274200 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.921386 (-5.027849)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 15/2000, vlb -6.158511, \u001b[31m   time: 1.846914 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.864207 (-4.921386)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 16/2000, vlb -5.953819, \u001b[31m   time: 2.000225 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.745217 (-4.864207)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 17/2000, vlb -5.834157, \u001b[31m   time: 1.897948 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.583434 (-4.745217)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 18/2000, vlb -5.818384, \u001b[31m   time: 1.978877 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.588758 (-4.583434)\n",
      "\u001b[0m\n",
      "it 19/2000, vlb -5.622499, \u001b[31m   time: 1.722593 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.479828 (-4.583434)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 20/2000, vlb -5.553237, \u001b[31m   time: 1.514090 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.295641 (-4.479828)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 21/2000, vlb -5.476247, \u001b[31m   time: 1.580366 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.209972 (-4.295641)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 22/2000, vlb -5.363171, \u001b[31m   time: 1.702268 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.281361 (-4.209972)\n",
      "\u001b[0m\n",
      "it 23/2000, vlb -5.227809, \u001b[31m   time: 1.517530 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.078648 (-4.209972)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 24/2000, vlb -5.196375, \u001b[31m   time: 1.508797 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -4.071771 (-4.078648)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 25/2000, vlb -5.057951, \u001b[31m   time: 1.494781 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.895844 (-4.071771)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 26/2000, vlb -5.038319, \u001b[31m   time: 1.530071 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.894335 (-3.895844)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 27/2000, vlb -4.959187, \u001b[31m   time: 1.533435 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.802391 (-3.894335)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 28/2000, vlb -4.940238, \u001b[31m   time: 1.586090 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.774830 (-3.802391)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 29/2000, vlb -4.812461, \u001b[31m   time: 1.508259 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.690182 (-3.774830)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 30/2000, vlb -4.839022, \u001b[31m   time: 1.498030 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.621664 (-3.690182)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 31/2000, vlb -4.729150, \u001b[31m   time: 1.518737 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.547381 (-3.621664)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 32/2000, vlb -4.658762, \u001b[31m   time: 1.493471 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.492163 (-3.547381)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 33/2000, vlb -4.630864, \u001b[31m   time: 1.575358 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.511453 (-3.492163)\n",
      "\u001b[0m\n",
      "it 34/2000, vlb -4.556060, \u001b[31m   time: 1.517340 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.432881 (-3.492163)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 35/2000, vlb -4.505419, \u001b[31m   time: 1.518271 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.428502 (-3.432881)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 36/2000, vlb -4.547716, \u001b[31m   time: 1.548722 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.735087 (-3.428502)\n",
      "\u001b[0m\n",
      "it 37/2000, vlb -4.453364, \u001b[31m   time: 1.437504 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.376914 (-3.428502)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 38/2000, vlb -4.406026, \u001b[31m   time: 1.511504 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.320169 (-3.376914)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 39/2000, vlb -4.368400, \u001b[31m   time: 1.537757 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.272199 (-3.320169)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 40/2000, vlb -4.350883, \u001b[31m   time: 1.532438 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.272543 (-3.272199)\n",
      "\u001b[0m\n",
      "it 41/2000, vlb -4.305871, \u001b[31m   time: 1.545517 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.197462 (-3.272199)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 42/2000, vlb -4.242790, \u001b[31m   time: 1.553710 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.117999 (-3.197462)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 43/2000, vlb -4.276455, \u001b[31m   time: 1.517289 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.331330 (-3.117999)\n",
      "\u001b[0m\n",
      "it 44/2000, vlb -4.258483, \u001b[31m   time: 1.533023 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.170142 (-3.117999)\n",
      "\u001b[0m\n",
      "it 45/2000, vlb -4.211755, \u001b[31m   time: 1.574595 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.126788 (-3.117999)\n",
      "\u001b[0m\n",
      "it 46/2000, vlb -4.160883, \u001b[31m   time: 1.835574 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.133866 (-3.117999)\n",
      "\u001b[0m\n",
      "it 47/2000, vlb -4.126658, \u001b[31m   time: 1.997272 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.039781 (-3.117999)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 48/2000, vlb -4.113439, \u001b[31m   time: 1.859054 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.294927 (-3.039781)\n",
      "\u001b[0m\n",
      "it 49/2000, vlb -4.068377, \u001b[31m   time: 1.988790 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.123009 (-3.039781)\n",
      "\u001b[0m\n",
      "it 50/2000, vlb -4.031464, \u001b[31m   time: 1.922934 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.956059 (-3.039781)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 51/2000, vlb -4.049516, \u001b[31m   time: 1.517944 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.030351 (-2.956059)\n",
      "\u001b[0m\n",
      "it 52/2000, vlb -4.046601, \u001b[31m   time: 1.590051 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.142626 (-2.956059)\n",
      "\u001b[0m\n",
      "it 53/2000, vlb -3.993357, \u001b[31m   time: 1.557519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.010762 (-2.956059)\n",
      "\u001b[0m\n",
      "it 54/2000, vlb -4.010660, \u001b[31m   time: 2.364297 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.956914 (-2.956059)\n",
      "\u001b[0m\n",
      "it 55/2000, vlb -3.989221, \u001b[31m   time: 2.354759 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.935410 (-2.956059)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 56/2000, vlb -3.974315, \u001b[31m   time: 2.010612 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.773743 (-2.935410)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 57/2000, vlb -3.950603, \u001b[31m   time: 1.889439 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.053717 (-2.773743)\n",
      "\u001b[0m\n",
      "it 58/2000, vlb -3.914890, \u001b[31m   time: 2.112087 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.303768 (-2.773743)\n",
      "\u001b[0m\n",
      "it 59/2000, vlb -3.884073, \u001b[31m   time: 1.887808 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -3.060243 (-2.773743)\n",
      "\u001b[0m\n",
      "it 60/2000, vlb -3.932626, \u001b[31m   time: 1.934271 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.916941 (-2.773743)\n",
      "\u001b[0m\n",
      "it 61/2000, vlb -3.893669, \u001b[31m   time: 1.683147 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.898474 (-2.773743)\n",
      "\u001b[0m\n",
      "it 62/2000, vlb -3.906889, \u001b[31m   time: 1.510970 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.823782 (-2.773743)\n",
      "\u001b[0m\n",
      "it 63/2000, vlb -3.883861, \u001b[31m   time: 1.523485 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.868474 (-2.773743)\n",
      "\u001b[0m\n",
      "it 64/2000, vlb -3.782522, \u001b[31m   time: 1.503913 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.817446 (-2.773743)\n",
      "\u001b[0m\n",
      "it 65/2000, vlb -3.834553, \u001b[31m   time: 1.523771 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.848197 (-2.773743)\n",
      "\u001b[0m\n",
      "it 66/2000, vlb -3.850298, \u001b[31m   time: 1.525995 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.917200 (-2.773743)\n",
      "\u001b[0m\n",
      "it 67/2000, vlb -3.809532, \u001b[31m   time: 1.587551 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.975694 (-2.773743)\n",
      "\u001b[0m\n",
      "it 68/2000, vlb -3.802726, \u001b[31m   time: 1.567448 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.916296 (-2.773743)\n",
      "\u001b[0m\n",
      "it 69/2000, vlb -3.772910, \u001b[31m   time: 1.526925 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.860693 (-2.773743)\n",
      "\u001b[0m\n",
      "it 70/2000, vlb -3.789446, \u001b[31m   time: 1.558930 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.768092 (-2.773743)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 71/2000, vlb -3.833452, \u001b[31m   time: 1.503224 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.914013 (-2.768092)\n",
      "\u001b[0m\n",
      "it 72/2000, vlb -3.759022, \u001b[31m   time: 1.499399 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.889725 (-2.768092)\n",
      "\u001b[0m\n",
      "it 73/2000, vlb -3.726753, \u001b[31m   time: 1.561162 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.757863 (-2.768092)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 74/2000, vlb -3.767687, \u001b[31m   time: 1.509468 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.806177 (-2.757863)\n",
      "\u001b[0m\n",
      "it 75/2000, vlb -3.718010, \u001b[31m   time: 1.993311 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.766850 (-2.757863)\n",
      "\u001b[0m\n",
      "it 76/2000, vlb -3.706120, \u001b[31m   time: 1.594369 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.783716 (-2.757863)\n",
      "\u001b[0m\n",
      "it 77/2000, vlb -3.713123, \u001b[31m   time: 1.510884 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.781463 (-2.757863)\n",
      "\u001b[0m\n",
      "it 78/2000, vlb -3.682210, \u001b[31m   time: 1.571785 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.861525 (-2.757863)\n",
      "\u001b[0m\n",
      "it 79/2000, vlb -3.717672, \u001b[31m   time: 1.610366 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.849834 (-2.757863)\n",
      "\u001b[0m\n",
      "it 80/2000, vlb -3.681684, \u001b[31m   time: 1.559820 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.718609 (-2.757863)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 81/2000, vlb -3.660021, \u001b[31m   time: 1.529492 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.763131 (-2.718609)\n",
      "\u001b[0m\n",
      "it 82/2000, vlb -3.691559, \u001b[31m   time: 1.524462 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.741606 (-2.718609)\n",
      "\u001b[0m\n",
      "it 83/2000, vlb -3.701692, \u001b[31m   time: 1.551593 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.761348 (-2.718609)\n",
      "\u001b[0m\n",
      "it 84/2000, vlb -3.641896, \u001b[31m   time: 1.536554 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.703633 (-2.718609)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 85/2000, vlb -3.647526, \u001b[31m   time: 1.531007 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.826874 (-2.703633)\n",
      "\u001b[0m\n",
      "it 86/2000, vlb -3.601959, \u001b[31m   time: 1.576881 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.811008 (-2.703633)\n",
      "\u001b[0m\n",
      "it 87/2000, vlb -3.622636, \u001b[31m   time: 1.559290 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.883757 (-2.703633)\n",
      "\u001b[0m\n",
      "it 88/2000, vlb -3.586321, \u001b[31m   time: 1.544889 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.677608 (-2.703633)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 89/2000, vlb -3.626782, \u001b[31m   time: 1.496052 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.720646 (-2.677608)\n",
      "\u001b[0m\n",
      "it 90/2000, vlb -3.574313, \u001b[31m   time: 1.522977 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.668927 (-2.677608)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 91/2000, vlb -3.514535, \u001b[31m   time: 1.513292 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.670930 (-2.668927)\n",
      "\u001b[0m\n",
      "it 92/2000, vlb -3.558396, \u001b[31m   time: 1.573972 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.694732 (-2.668927)\n",
      "\u001b[0m\n",
      "it 93/2000, vlb -3.545888, \u001b[31m   time: 1.529602 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.680219 (-2.668927)\n",
      "\u001b[0m\n",
      "it 94/2000, vlb -3.511724, \u001b[31m   time: 1.586428 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.761498 (-2.668927)\n",
      "\u001b[0m\n",
      "it 95/2000, vlb -3.520822, \u001b[31m   time: 1.830562 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.715372 (-2.668927)\n",
      "\u001b[0m\n",
      "it 96/2000, vlb -3.505778, \u001b[31m   time: 1.572034 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.710963 (-2.668927)\n",
      "\u001b[0m\n",
      "it 97/2000, vlb -3.506666, \u001b[31m   time: 1.503474 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.555545 (-2.668927)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 98/2000, vlb -3.503361, \u001b[31m   time: 1.613183 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.698657 (-2.555545)\n",
      "\u001b[0m\n",
      "it 99/2000, vlb -3.497264, \u001b[31m   time: 1.683499 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.561292 (-2.555545)\n",
      "\u001b[0m\n",
      "it 100/2000, vlb -3.527096, \u001b[31m   time: 1.536789 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.626593 (-2.555545)\n",
      "\u001b[0m\n",
      "it 101/2000, vlb -3.505554, \u001b[31m   time: 1.536947 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.532333 (-2.555545)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 102/2000, vlb -3.485264, \u001b[31m   time: 2.215779 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.649901 (-2.532333)\n",
      "\u001b[0m\n",
      "it 103/2000, vlb -3.502356, \u001b[31m   time: 1.975971 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.561876 (-2.532333)\n",
      "\u001b[0m\n",
      "it 104/2000, vlb -3.509655, \u001b[31m   time: 1.908843 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.676131 (-2.532333)\n",
      "\u001b[0m\n",
      "it 105/2000, vlb -3.497873, \u001b[31m   time: 1.775096 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.694547 (-2.532333)\n",
      "\u001b[0m\n",
      "it 106/2000, vlb -3.487383, \u001b[31m   time: 1.547660 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.682524 (-2.532333)\n",
      "\u001b[0m\n",
      "it 107/2000, vlb -3.492950, \u001b[31m   time: 1.790861 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.591330 (-2.532333)\n",
      "\u001b[0m\n",
      "it 108/2000, vlb -3.434257, \u001b[31m   time: 1.505201 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.633515 (-2.532333)\n",
      "\u001b[0m\n",
      "it 109/2000, vlb -3.447979, \u001b[31m   time: 1.719519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.614270 (-2.532333)\n",
      "\u001b[0m\n",
      "it 110/2000, vlb -3.472572, \u001b[31m   time: 1.876331 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.610761 (-2.532333)\n",
      "\u001b[0m\n",
      "it 111/2000, vlb -3.445094, \u001b[31m   time: 2.190917 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.579122 (-2.532333)\n",
      "\u001b[0m\n",
      "it 112/2000, vlb -3.441492, \u001b[31m   time: 1.783661 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.559622 (-2.532333)\n",
      "\u001b[0m\n",
      "it 113/2000, vlb -3.448139, \u001b[31m   time: 1.652268 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.536743 (-2.532333)\n",
      "\u001b[0m\n",
      "it 114/2000, vlb -3.382966, \u001b[31m   time: 1.541408 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.653291 (-2.532333)\n",
      "\u001b[0m\n",
      "it 115/2000, vlb -3.407579, \u001b[31m   time: 1.585302 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.463444 (-2.532333)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 116/2000, vlb -3.424014, \u001b[31m   time: 1.534375 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.538803 (-2.463444)\n",
      "\u001b[0m\n",
      "it 117/2000, vlb -3.403044, \u001b[31m   time: 1.548392 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.475213 (-2.463444)\n",
      "\u001b[0m\n",
      "it 118/2000, vlb -3.443144, \u001b[31m   time: 1.546846 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.463398 (-2.463444)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 119/2000, vlb -3.377213, \u001b[31m   time: 1.564130 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.500607 (-2.463398)\n",
      "\u001b[0m\n",
      "it 120/2000, vlb -3.393610, \u001b[31m   time: 1.599806 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.477406 (-2.463398)\n",
      "\u001b[0m\n",
      "it 121/2000, vlb -3.329018, \u001b[31m   time: 2.693646 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -2.516448 (-2.463398)\n",
      "\u001b[0m\n",
      "it 122/2000, vlb -3.386675, \u001b[31m   time: 2.037955 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.574922 (-2.463398)\n",
      "\u001b[0m\n",
      "it 123/2000, vlb -3.378626, \u001b[31m   time: 1.908550 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.528915 (-2.463398)\n",
      "\u001b[0m\n",
      "it 124/2000, vlb -3.333230, \u001b[31m   time: 1.910460 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.438495 (-2.463398)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 125/2000, vlb -3.356431, \u001b[31m   time: 1.969429 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.497544 (-2.438495)\n",
      "\u001b[0m\n",
      "it 126/2000, vlb -3.335909, \u001b[31m   time: 1.925340 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.429570 (-2.438495)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 127/2000, vlb -3.351274, \u001b[31m   time: 1.817053 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.466796 (-2.429570)\n",
      "\u001b[0m\n",
      "it 128/2000, vlb -3.335552, \u001b[31m   time: 1.733747 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.373957 (-2.429570)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 129/2000, vlb -3.395688, \u001b[31m   time: 1.792413 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.484561 (-2.373957)\n",
      "\u001b[0m\n",
      "it 130/2000, vlb -3.334634, \u001b[31m   time: 1.799954 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.359158 (-2.373957)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 131/2000, vlb -3.300471, \u001b[31m   time: 1.958409 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.424403 (-2.359158)\n",
      "\u001b[0m\n",
      "it 132/2000, vlb -3.365543, \u001b[31m   time: 1.995054 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.532369 (-2.359158)\n",
      "\u001b[0m\n",
      "it 133/2000, vlb -3.286841, \u001b[31m   time: 2.107779 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.373897 (-2.359158)\n",
      "\u001b[0m\n",
      "it 134/2000, vlb -3.303813, \u001b[31m   time: 1.546902 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.411750 (-2.359158)\n",
      "\u001b[0m\n",
      "it 135/2000, vlb -3.350339, \u001b[31m   time: 1.672993 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.356078 (-2.359158)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 136/2000, vlb -3.310600, \u001b[31m   time: 3.228148 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.355249 (-2.356078)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 137/2000, vlb -3.298626, \u001b[31m   time: 2.291157 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.426368 (-2.355249)\n",
      "\u001b[0m\n",
      "it 138/2000, vlb -3.308787, \u001b[31m   time: 2.010824 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.434276 (-2.355249)\n",
      "\u001b[0m\n",
      "it 139/2000, vlb -3.267970, \u001b[31m   time: 2.044763 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.298132 (-2.355249)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 140/2000, vlb -3.300016, \u001b[31m   time: 2.010967 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.366645 (-2.298132)\n",
      "\u001b[0m\n",
      "it 141/2000, vlb -3.275601, \u001b[31m   time: 1.935806 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.371700 (-2.298132)\n",
      "\u001b[0m\n",
      "it 142/2000, vlb -3.260874, \u001b[31m   time: 1.869216 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.497551 (-2.298132)\n",
      "\u001b[0m\n",
      "it 143/2000, vlb -3.252611, \u001b[31m   time: 2.131116 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.339110 (-2.298132)\n",
      "\u001b[0m\n",
      "it 144/2000, vlb -3.261275, \u001b[31m   time: 1.869371 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.471897 (-2.298132)\n",
      "\u001b[0m\n",
      "it 145/2000, vlb -3.279049, \u001b[31m   time: 2.071133 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.417083 (-2.298132)\n",
      "\u001b[0m\n",
      "it 146/2000, vlb -3.266146, \u001b[31m   time: 1.845557 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.282726 (-2.298132)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 147/2000, vlb -3.241395, \u001b[31m   time: 2.251641 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.348202 (-2.282726)\n",
      "\u001b[0m\n",
      "it 148/2000, vlb -3.247157, \u001b[31m   time: 2.173086 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.265144 (-2.282726)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 149/2000, vlb -3.254417, \u001b[31m   time: 2.028269 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.427696 (-2.265144)\n",
      "\u001b[0m\n",
      "it 150/2000, vlb -3.242853, \u001b[31m   time: 1.912658 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.482624 (-2.265144)\n",
      "\u001b[0m\n",
      "it 151/2000, vlb -3.238990, \u001b[31m   time: 1.876241 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.335902 (-2.265144)\n",
      "\u001b[0m\n",
      "it 152/2000, vlb -3.235437, \u001b[31m   time: 1.970963 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.393607 (-2.265144)\n",
      "\u001b[0m\n",
      "it 153/2000, vlb -3.221615, \u001b[31m   time: 1.794840 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.398582 (-2.265144)\n",
      "\u001b[0m\n",
      "it 154/2000, vlb -3.305371, \u001b[31m   time: 1.684952 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.527420 (-2.265144)\n",
      "\u001b[0m\n",
      "it 155/2000, vlb -3.239067, \u001b[31m   time: 1.712900 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.388190 (-2.265144)\n",
      "\u001b[0m\n",
      "it 156/2000, vlb -3.253632, \u001b[31m   time: 1.804585 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.362530 (-2.265144)\n",
      "\u001b[0m\n",
      "it 157/2000, vlb -3.240225, \u001b[31m   time: 1.904678 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.293183 (-2.265144)\n",
      "\u001b[0m\n",
      "it 158/2000, vlb -3.188696, \u001b[31m   time: 2.089540 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.426357 (-2.265144)\n",
      "\u001b[0m\n",
      "it 159/2000, vlb -3.242642, \u001b[31m   time: 1.877198 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.322847 (-2.265144)\n",
      "\u001b[0m\n",
      "it 160/2000, vlb -3.226406, \u001b[31m   time: 2.363205 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.318957 (-2.265144)\n",
      "\u001b[0m\n",
      "it 161/2000, vlb -3.145025, \u001b[31m   time: 2.511015 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.433109 (-2.265144)\n",
      "\u001b[0m\n",
      "it 162/2000, vlb -3.158552, \u001b[31m   time: 1.978703 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.223347 (-2.265144)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 163/2000, vlb -3.223538, \u001b[31m   time: 2.183934 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.327155 (-2.223347)\n",
      "\u001b[0m\n",
      "it 164/2000, vlb -3.210973, \u001b[31m   time: 1.867927 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.238338 (-2.223347)\n",
      "\u001b[0m\n",
      "it 165/2000, vlb -3.146112, \u001b[31m   time: 1.612129 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.284924 (-2.223347)\n",
      "\u001b[0m\n",
      "it 166/2000, vlb -3.170964, \u001b[31m   time: 1.836507 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.395433 (-2.223347)\n",
      "\u001b[0m\n",
      "it 167/2000, vlb -3.187735, \u001b[31m   time: 1.847397 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.419817 (-2.223347)\n",
      "\u001b[0m\n",
      "it 168/2000, vlb -3.172110, \u001b[31m   time: 2.199419 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.352994 (-2.223347)\n",
      "\u001b[0m\n",
      "it 169/2000, vlb -3.155653, \u001b[31m   time: 1.855314 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.343446 (-2.223347)\n",
      "\u001b[0m\n",
      "it 170/2000, vlb -3.185270, \u001b[31m   time: 1.735855 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.318855 (-2.223347)\n",
      "\u001b[0m\n",
      "it 171/2000, vlb -3.193226, \u001b[31m   time: 2.163252 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.398269 (-2.223347)\n",
      "\u001b[0m\n",
      "it 172/2000, vlb -3.145968, \u001b[31m   time: 2.203193 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.359524 (-2.223347)\n",
      "\u001b[0m\n",
      "it 173/2000, vlb -3.165634, \u001b[31m   time: 1.828053 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.228373 (-2.223347)\n",
      "\u001b[0m\n",
      "it 174/2000, vlb -3.139889, \u001b[31m   time: 2.097021 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.201142 (-2.223347)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 175/2000, vlb -3.182053, \u001b[31m   time: 2.429632 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.330968 (-2.201142)\n",
      "\u001b[0m\n",
      "it 176/2000, vlb -3.115713, \u001b[31m   time: 2.109068 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.258250 (-2.201142)\n",
      "\u001b[0m\n",
      "it 177/2000, vlb -3.119893, \u001b[31m   time: 1.711278 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.319322 (-2.201142)\n",
      "\u001b[0m\n",
      "it 178/2000, vlb -3.164329, \u001b[31m   time: 1.959556 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.444201 (-2.201142)\n",
      "\u001b[0m\n",
      "it 179/2000, vlb -3.155215, \u001b[31m   time: 1.952447 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.181190 (-2.201142)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 180/2000, vlb -3.143225, \u001b[31m   time: 1.909237 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.403399 (-2.181190)\n",
      "\u001b[0m\n",
      "it 181/2000, vlb -3.095611, \u001b[31m   time: 2.194710 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.257985 (-2.181190)\n",
      "\u001b[0m\n",
      "it 182/2000, vlb -3.184046, \u001b[31m   time: 1.657792 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.337732 (-2.181190)\n",
      "\u001b[0m\n",
      "it 183/2000, vlb -3.153151, \u001b[31m   time: 1.498009 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.223997 (-2.181190)\n",
      "\u001b[0m\n",
      "it 184/2000, vlb -3.096672, \u001b[31m   time: 1.532445 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.251692 (-2.181190)\n",
      "\u001b[0m\n",
      "it 185/2000, vlb -3.140907, \u001b[31m   time: 1.546650 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.306675 (-2.181190)\n",
      "\u001b[0m\n",
      "it 186/2000, vlb -3.101923, \u001b[31m   time: 1.561370 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.387404 (-2.181190)\n",
      "\u001b[0m\n",
      "it 187/2000, vlb -3.107980, \u001b[31m   time: 1.640069 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.329644 (-2.181190)\n",
      "\u001b[0m\n",
      "it 188/2000, vlb -3.207792, \u001b[31m   time: 1.827952 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.435725 (-2.181190)\n",
      "\u001b[0m\n",
      "it 189/2000, vlb -3.176752, \u001b[31m   time: 1.844492 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.268251 (-2.181190)\n",
      "\u001b[0m\n",
      "it 190/2000, vlb -3.109904, \u001b[31m   time: 1.866344 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.379403 (-2.181190)\n",
      "\u001b[0m\n",
      "it 191/2000, vlb -3.106503, \u001b[31m   time: 2.086191 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -2.171359 (-2.181190)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 192/2000, vlb -3.144948, \u001b[31m   time: 1.805535 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.346334 (-2.171359)\n",
      "\u001b[0m\n",
      "it 193/2000, vlb -3.130044, \u001b[31m   time: 2.244613 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.323810 (-2.171359)\n",
      "\u001b[0m\n",
      "it 194/2000, vlb -3.119055, \u001b[31m   time: 2.073700 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.149801 (-2.171359)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 195/2000, vlb -3.069220, \u001b[31m   time: 2.189183 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.295401 (-2.149801)\n",
      "\u001b[0m\n",
      "it 196/2000, vlb -3.109464, \u001b[31m   time: 2.138445 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.352058 (-2.149801)\n",
      "\u001b[0m\n",
      "it 197/2000, vlb -3.074163, \u001b[31m   time: 1.820407 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.344902 (-2.149801)\n",
      "\u001b[0m\n",
      "it 198/2000, vlb -3.142770, \u001b[31m   time: 1.733003 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.309773 (-2.149801)\n",
      "\u001b[0m\n",
      "it 199/2000, vlb -3.084371, \u001b[31m   time: 1.487493 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.162953 (-2.149801)\n",
      "\u001b[0m\n",
      "it 200/2000, vlb -3.088663, \u001b[31m   time: 1.517250 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.179996 (-2.149801)\n",
      "\u001b[0m\n",
      "it 201/2000, vlb -3.064322, \u001b[31m   time: 1.553978 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.117986 (-2.149801)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 202/2000, vlb -3.091784, \u001b[31m   time: 1.522578 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.348703 (-2.117986)\n",
      "\u001b[0m\n",
      "it 203/2000, vlb -3.116517, \u001b[31m   time: 1.453235 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.182078 (-2.117986)\n",
      "\u001b[0m\n",
      "it 204/2000, vlb -3.094008, \u001b[31m   time: 1.572168 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.329000 (-2.117986)\n",
      "\u001b[0m\n",
      "it 205/2000, vlb -3.044310, \u001b[31m   time: 1.556704 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.201109 (-2.117986)\n",
      "\u001b[0m\n",
      "it 206/2000, vlb -3.094223, \u001b[31m   time: 1.533190 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.262014 (-2.117986)\n",
      "\u001b[0m\n",
      "it 207/2000, vlb -3.088015, \u001b[31m   time: 1.535329 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.171233 (-2.117986)\n",
      "\u001b[0m\n",
      "it 208/2000, vlb -3.042500, \u001b[31m   time: 1.527849 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.396533 (-2.117986)\n",
      "\u001b[0m\n",
      "it 209/2000, vlb -3.048837, \u001b[31m   time: 1.769131 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.285171 (-2.117986)\n",
      "\u001b[0m\n",
      "it 210/2000, vlb -3.060852, \u001b[31m   time: 1.772614 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.234469 (-2.117986)\n",
      "\u001b[0m\n",
      "it 211/2000, vlb -3.049014, \u001b[31m   time: 1.874393 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.357789 (-2.117986)\n",
      "\u001b[0m\n",
      "it 212/2000, vlb -3.048942, \u001b[31m   time: 1.601290 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.250640 (-2.117986)\n",
      "\u001b[0m\n",
      "it 213/2000, vlb -3.058257, \u001b[31m   time: 1.855405 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.296094 (-2.117986)\n",
      "\u001b[0m\n",
      "it 214/2000, vlb -3.034019, \u001b[31m   time: 1.740304 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.270201 (-2.117986)\n",
      "\u001b[0m\n",
      "it 215/2000, vlb -3.052338, \u001b[31m   time: 1.869933 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.365278 (-2.117986)\n",
      "\u001b[0m\n",
      "it 216/2000, vlb -3.000821, \u001b[31m   time: 1.625569 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.225426 (-2.117986)\n",
      "\u001b[0m\n",
      "it 217/2000, vlb -3.090120, \u001b[31m   time: 1.831679 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216189 (-2.117986)\n",
      "\u001b[0m\n",
      "it 218/2000, vlb -3.016055, \u001b[31m   time: 1.714536 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.228549 (-2.117986)\n",
      "\u001b[0m\n",
      "it 219/2000, vlb -3.100170, \u001b[31m   time: 1.647974 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.161844 (-2.117986)\n",
      "\u001b[0m\n",
      "it 220/2000, vlb -3.053303, \u001b[31m   time: 1.679684 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.318247 (-2.117986)\n",
      "\u001b[0m\n",
      "it 221/2000, vlb -3.003051, \u001b[31m   time: 1.622453 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.179951 (-2.117986)\n",
      "\u001b[0m\n",
      "it 222/2000, vlb -3.016072, \u001b[31m   time: 1.526449 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.208831 (-2.117986)\n",
      "\u001b[0m\n",
      "it 223/2000, vlb -3.053302, \u001b[31m   time: 1.735647 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.291720 (-2.117986)\n",
      "\u001b[0m\n",
      "it 224/2000, vlb -3.072764, \u001b[31m   time: 1.948754 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.262218 (-2.117986)\n",
      "\u001b[0m\n",
      "it 225/2000, vlb -3.059195, \u001b[31m   time: 1.623160 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.184047 (-2.117986)\n",
      "\u001b[0m\n",
      "it 226/2000, vlb -3.027143, \u001b[31m   time: 1.535537 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.193790 (-2.117986)\n",
      "\u001b[0m\n",
      "it 227/2000, vlb -3.030888, \u001b[31m   time: 1.570117 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.283798 (-2.117986)\n",
      "\u001b[0m\n",
      "it 228/2000, vlb -3.050340, \u001b[31m   time: 1.785524 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.247637 (-2.117986)\n",
      "\u001b[0m\n",
      "it 229/2000, vlb -3.052434, \u001b[31m   time: 1.770745 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.346247 (-2.117986)\n",
      "\u001b[0m\n",
      "it 230/2000, vlb -3.014242, \u001b[31m   time: 1.924442 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.040309 (-2.117986)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 231/2000, vlb -2.978059, \u001b[31m   time: 1.764926 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136200 (-2.040309)\n",
      "\u001b[0m\n",
      "it 232/2000, vlb -3.000077, \u001b[31m   time: 1.601895 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.199358 (-2.040309)\n",
      "\u001b[0m\n",
      "it 233/2000, vlb -3.046745, \u001b[31m   time: 1.545890 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.118533 (-2.040309)\n",
      "\u001b[0m\n",
      "it 234/2000, vlb -2.995392, \u001b[31m   time: 1.530508 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.181460 (-2.040309)\n",
      "\u001b[0m\n",
      "it 235/2000, vlb -2.967273, \u001b[31m   time: 1.498850 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.189638 (-2.040309)\n",
      "\u001b[0m\n",
      "it 236/2000, vlb -3.052546, \u001b[31m   time: 1.523327 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.203481 (-2.040309)\n",
      "\u001b[0m\n",
      "it 237/2000, vlb -3.019405, \u001b[31m   time: 1.516157 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.197635 (-2.040309)\n",
      "\u001b[0m\n",
      "it 238/2000, vlb -3.006662, \u001b[31m   time: 1.521618 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.285326 (-2.040309)\n",
      "\u001b[0m\n",
      "it 239/2000, vlb -3.001226, \u001b[31m   time: 1.575794 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216011 (-2.040309)\n",
      "\u001b[0m\n",
      "it 240/2000, vlb -3.030105, \u001b[31m   time: 1.569051 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.163827 (-2.040309)\n",
      "\u001b[0m\n",
      "it 241/2000, vlb -3.068283, \u001b[31m   time: 1.520216 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.313500 (-2.040309)\n",
      "\u001b[0m\n",
      "it 242/2000, vlb -3.032670, \u001b[31m   time: 1.519617 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.320320 (-2.040309)\n",
      "\u001b[0m\n",
      "it 243/2000, vlb -2.980682, \u001b[31m   time: 1.537388 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.242913 (-2.040309)\n",
      "\u001b[0m\n",
      "it 244/2000, vlb -3.017870, \u001b[31m   time: 1.513651 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.163686 (-2.040309)\n",
      "\u001b[0m\n",
      "it 245/2000, vlb -2.971146, \u001b[31m   time: 1.559552 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.378738 (-2.040309)\n",
      "\u001b[0m\n",
      "it 246/2000, vlb -2.965822, \u001b[31m   time: 1.661769 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.140215 (-2.040309)\n",
      "\u001b[0m\n",
      "it 247/2000, vlb -3.034397, \u001b[31m   time: 1.486839 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.380011 (-2.040309)\n",
      "\u001b[0m\n",
      "it 248/2000, vlb -3.033288, \u001b[31m   time: 1.535511 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.299328 (-2.040309)\n",
      "\u001b[0m\n",
      "it 249/2000, vlb -3.018314, \u001b[31m   time: 1.545068 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.092832 (-2.040309)\n",
      "\u001b[0m\n",
      "it 250/2000, vlb -3.014741, \u001b[31m   time: 1.530644 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.219438 (-2.040309)\n",
      "\u001b[0m\n",
      "it 251/2000, vlb -2.970691, \u001b[31m   time: 1.560542 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.244584 (-2.040309)\n",
      "\u001b[0m\n",
      "it 252/2000, vlb -2.993169, \u001b[31m   time: 1.540739 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.337373 (-2.040309)\n",
      "\u001b[0m\n",
      "it 253/2000, vlb -3.027736, \u001b[31m   time: 1.552115 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.208438 (-2.040309)\n",
      "\u001b[0m\n",
      "it 254/2000, vlb -2.999411, \u001b[31m   time: 1.588839 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.190765 (-2.040309)\n",
      "\u001b[0m\n",
      "it 255/2000, vlb -2.971326, \u001b[31m   time: 1.538693 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.258665 (-2.040309)\n",
      "\u001b[0m\n",
      "it 256/2000, vlb -2.925585, \u001b[31m   time: 1.526312 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.243416 (-2.040309)\n",
      "\u001b[0m\n",
      "it 257/2000, vlb -2.965578, \u001b[31m   time: 1.589937 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.222582 (-2.040309)\n",
      "\u001b[0m\n",
      "it 258/2000, vlb -2.941173, \u001b[31m   time: 1.462242 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.230698 (-2.040309)\n",
      "\u001b[0m\n",
      "it 259/2000, vlb -2.975200, \u001b[31m   time: 1.564678 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.289081 (-2.040309)\n",
      "\u001b[0m\n",
      "it 260/2000, vlb -3.029461, \u001b[31m   time: 1.655754 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.071208 (-2.040309)\n",
      "\u001b[0m\n",
      "it 261/2000, vlb -3.000600, \u001b[31m   time: 1.544760 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.119137 (-2.040309)\n",
      "\u001b[0m\n",
      "it 262/2000, vlb -2.953835, \u001b[31m   time: 1.553307 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.173769 (-2.040309)\n",
      "\u001b[0m\n",
      "it 263/2000, vlb -2.978480, \u001b[31m   time: 1.578948 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.184915 (-2.040309)\n",
      "\u001b[0m\n",
      "it 264/2000, vlb -2.987693, \u001b[31m   time: 1.576709 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176946 (-2.040309)\n",
      "\u001b[0m\n",
      "it 265/2000, vlb -2.964634, \u001b[31m   time: 1.604422 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.109123 (-2.040309)\n",
      "\u001b[0m\n",
      "it 266/2000, vlb -2.977729, \u001b[31m   time: 1.535144 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.349191 (-2.040309)\n",
      "\u001b[0m\n",
      "it 267/2000, vlb -3.000988, \u001b[31m   time: 1.562503 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -2.169293 (-2.040309)\n",
      "\u001b[0m\n",
      "it 268/2000, vlb -2.956770, \u001b[31m   time: 1.537938 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.207567 (-2.040309)\n",
      "\u001b[0m\n",
      "it 269/2000, vlb -3.008544, \u001b[31m   time: 1.520718 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216259 (-2.040309)\n",
      "\u001b[0m\n",
      "it 270/2000, vlb -2.970154, \u001b[31m   time: 1.534194 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169743 (-2.040309)\n",
      "\u001b[0m\n",
      "it 271/2000, vlb -2.988941, \u001b[31m   time: 1.503095 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.184014 (-2.040309)\n",
      "\u001b[0m\n",
      "it 272/2000, vlb -2.975258, \u001b[31m   time: 1.576053 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145293 (-2.040309)\n",
      "\u001b[0m\n",
      "it 273/2000, vlb -3.010050, \u001b[31m   time: 1.547019 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.210954 (-2.040309)\n",
      "\u001b[0m\n",
      "it 274/2000, vlb -2.955395, \u001b[31m   time: 1.508851 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145847 (-2.040309)\n",
      "\u001b[0m\n",
      "it 275/2000, vlb -2.946391, \u001b[31m   time: 1.502043 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229393 (-2.040309)\n",
      "\u001b[0m\n",
      "it 276/2000, vlb -2.938841, \u001b[31m   time: 1.521262 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.349737 (-2.040309)\n",
      "\u001b[0m\n",
      "it 277/2000, vlb -2.960406, \u001b[31m   time: 1.516008 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.180957 (-2.040309)\n",
      "\u001b[0m\n",
      "it 278/2000, vlb -2.936426, \u001b[31m   time: 1.567578 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.164310 (-2.040309)\n",
      "\u001b[0m\n",
      "it 279/2000, vlb -2.994026, \u001b[31m   time: 1.524579 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.186020 (-2.040309)\n",
      "\u001b[0m\n",
      "it 280/2000, vlb -2.938719, \u001b[31m   time: 1.537924 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176399 (-2.040309)\n",
      "\u001b[0m\n",
      "it 281/2000, vlb -2.992619, \u001b[31m   time: 1.504564 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.172915 (-2.040309)\n",
      "\u001b[0m\n",
      "it 282/2000, vlb -2.941493, \u001b[31m   time: 1.525234 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.227427 (-2.040309)\n",
      "\u001b[0m\n",
      "it 283/2000, vlb -2.979086, \u001b[31m   time: 1.538100 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.196713 (-2.040309)\n",
      "\u001b[0m\n",
      "it 284/2000, vlb -2.954495, \u001b[31m   time: 1.465751 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.266208 (-2.040309)\n",
      "\u001b[0m\n",
      "it 285/2000, vlb -2.948815, \u001b[31m   time: 1.646287 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.099040 (-2.040309)\n",
      "\u001b[0m\n",
      "it 286/2000, vlb -2.976394, \u001b[31m   time: 1.541936 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.199765 (-2.040309)\n",
      "\u001b[0m\n",
      "it 287/2000, vlb -2.984741, \u001b[31m   time: 1.525106 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.212710 (-2.040309)\n",
      "\u001b[0m\n",
      "it 288/2000, vlb -2.992252, \u001b[31m   time: 1.509744 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.149003 (-2.040309)\n",
      "\u001b[0m\n",
      "it 289/2000, vlb -2.927182, \u001b[31m   time: 1.527811 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.067453 (-2.040309)\n",
      "\u001b[0m\n",
      "it 290/2000, vlb -3.000097, \u001b[31m   time: 1.516977 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.090230 (-2.040309)\n",
      "\u001b[0m\n",
      "it 291/2000, vlb -2.937637, \u001b[31m   time: 1.604467 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.289908 (-2.040309)\n",
      "\u001b[0m\n",
      "it 292/2000, vlb -2.891311, \u001b[31m   time: 1.552902 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.161018 (-2.040309)\n",
      "\u001b[0m\n",
      "it 293/2000, vlb -2.949988, \u001b[31m   time: 1.530035 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.328278 (-2.040309)\n",
      "\u001b[0m\n",
      "it 294/2000, vlb -2.959456, \u001b[31m   time: 1.522611 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.240972 (-2.040309)\n",
      "\u001b[0m\n",
      "it 295/2000, vlb -2.950686, \u001b[31m   time: 1.544819 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176991 (-2.040309)\n",
      "\u001b[0m\n",
      "it 296/2000, vlb -2.922291, \u001b[31m   time: 1.535748 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229519 (-2.040309)\n",
      "\u001b[0m\n",
      "it 297/2000, vlb -2.943535, \u001b[31m   time: 1.653938 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.227209 (-2.040309)\n",
      "\u001b[0m\n",
      "it 298/2000, vlb -2.906427, \u001b[31m   time: 1.683893 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.195157 (-2.040309)\n",
      "\u001b[0m\n",
      "it 299/2000, vlb -2.936409, \u001b[31m   time: 1.597857 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.228625 (-2.040309)\n",
      "\u001b[0m\n",
      "it 300/2000, vlb -2.954299, \u001b[31m   time: 1.534247 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.232155 (-2.040309)\n",
      "\u001b[0m\n",
      "it 301/2000, vlb -2.945469, \u001b[31m   time: 1.563866 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.233732 (-2.040309)\n",
      "\u001b[0m\n",
      "it 302/2000, vlb -2.897810, \u001b[31m   time: 1.502442 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.258267 (-2.040309)\n",
      "\u001b[0m\n",
      "it 303/2000, vlb -2.942995, \u001b[31m   time: 1.515090 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.134702 (-2.040309)\n",
      "\u001b[0m\n",
      "it 304/2000, vlb -2.940236, \u001b[31m   time: 1.588740 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.191722 (-2.040309)\n",
      "\u001b[0m\n",
      "it 305/2000, vlb -2.906532, \u001b[31m   time: 1.556021 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.220354 (-2.040309)\n",
      "\u001b[0m\n",
      "it 306/2000, vlb -2.954764, \u001b[31m   time: 1.532865 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229647 (-2.040309)\n",
      "\u001b[0m\n",
      "it 307/2000, vlb -2.876773, \u001b[31m   time: 1.534893 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.198699 (-2.040309)\n",
      "\u001b[0m\n",
      "it 308/2000, vlb -2.914810, \u001b[31m   time: 1.535732 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.115011 (-2.040309)\n",
      "\u001b[0m\n",
      "it 309/2000, vlb -2.982827, \u001b[31m   time: 1.526897 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.223045 (-2.040309)\n",
      "\u001b[0m\n",
      "it 310/2000, vlb -2.943885, \u001b[31m   time: 1.520407 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.340866 (-2.040309)\n",
      "\u001b[0m\n",
      "it 311/2000, vlb -2.914058, \u001b[31m   time: 1.565917 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.301858 (-2.040309)\n",
      "\u001b[0m\n",
      "it 312/2000, vlb -2.956563, \u001b[31m   time: 1.641119 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.221860 (-2.040309)\n",
      "\u001b[0m\n",
      "it 313/2000, vlb -2.967095, \u001b[31m   time: 1.736776 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.237540 (-2.040309)\n",
      "\u001b[0m\n",
      "it 314/2000, vlb -2.951682, \u001b[31m   time: 1.735522 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.171348 (-2.040309)\n",
      "\u001b[0m\n",
      "it 315/2000, vlb -2.904655, \u001b[31m   time: 1.730144 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.298053 (-2.040309)\n",
      "\u001b[0m\n",
      "it 316/2000, vlb -2.954221, \u001b[31m   time: 1.684561 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.125568 (-2.040309)\n",
      "\u001b[0m\n",
      "it 317/2000, vlb -2.933711, \u001b[31m   time: 1.690373 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.147790 (-2.040309)\n",
      "\u001b[0m\n",
      "it 318/2000, vlb -2.962878, \u001b[31m   time: 1.645891 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.247260 (-2.040309)\n",
      "\u001b[0m\n",
      "it 319/2000, vlb -2.912469, \u001b[31m   time: 1.602340 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.226507 (-2.040309)\n",
      "\u001b[0m\n",
      "it 320/2000, vlb -2.940260, \u001b[31m   time: 1.505280 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229258 (-2.040309)\n",
      "\u001b[0m\n",
      "it 321/2000, vlb -2.948066, \u001b[31m   time: 1.509957 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.223298 (-2.040309)\n",
      "\u001b[0m\n",
      "it 322/2000, vlb -2.917637, \u001b[31m   time: 1.535052 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229543 (-2.040309)\n",
      "\u001b[0m\n",
      "it 323/2000, vlb -2.943806, \u001b[31m   time: 1.586919 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.046501 (-2.040309)\n",
      "\u001b[0m\n",
      "it 324/2000, vlb -2.817048, \u001b[31m   time: 1.580555 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.197007 (-2.040309)\n",
      "\u001b[0m\n",
      "it 325/2000, vlb -2.949271, \u001b[31m   time: 1.540717 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.266540 (-2.040309)\n",
      "\u001b[0m\n",
      "it 326/2000, vlb -2.932266, \u001b[31m   time: 1.525785 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.219483 (-2.040309)\n",
      "\u001b[0m\n",
      "it 327/2000, vlb -2.858383, \u001b[31m   time: 1.546004 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086585 (-2.040309)\n",
      "\u001b[0m\n",
      "it 328/2000, vlb -2.849351, \u001b[31m   time: 1.551796 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.307633 (-2.040309)\n",
      "\u001b[0m\n",
      "it 329/2000, vlb -2.936695, \u001b[31m   time: 1.556598 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.115161 (-2.040309)\n",
      "\u001b[0m\n",
      "it 330/2000, vlb -2.946279, \u001b[31m   time: 1.548865 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.174792 (-2.040309)\n",
      "\u001b[0m\n",
      "it 331/2000, vlb -2.980529, \u001b[31m   time: 1.545898 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086618 (-2.040309)\n",
      "\u001b[0m\n",
      "it 332/2000, vlb -2.917850, \u001b[31m   time: 1.523387 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.123248 (-2.040309)\n",
      "\u001b[0m\n",
      "it 333/2000, vlb -2.933090, \u001b[31m   time: 1.507175 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.190209 (-2.040309)\n",
      "\u001b[0m\n",
      "it 334/2000, vlb -2.941354, \u001b[31m   time: 1.567483 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.097379 (-2.040309)\n",
      "\u001b[0m\n",
      "it 335/2000, vlb -2.897007, \u001b[31m   time: 1.547155 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.020424 (-2.040309)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 336/2000, vlb -2.909449, \u001b[31m   time: 1.590894 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.256260 (-2.020424)\n",
      "\u001b[0m\n",
      "it 337/2000, vlb -2.887693, \u001b[31m   time: 1.531704 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.223126 (-2.020424)\n",
      "\u001b[0m\n",
      "it 338/2000, vlb -2.879776, \u001b[31m   time: 1.528821 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169083 (-2.020424)\n",
      "\u001b[0m\n",
      "it 339/2000, vlb -2.834864, \u001b[31m   time: 1.500373 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.152154 (-2.020424)\n",
      "\u001b[0m\n",
      "it 340/2000, vlb -2.894610, \u001b[31m   time: 1.537851 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.128612 (-2.020424)\n",
      "\u001b[0m\n",
      "it 341/2000, vlb -2.906769, \u001b[31m   time: 1.525394 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.119354 (-2.020424)\n",
      "\u001b[0m\n",
      "it 342/2000, vlb -2.860788, \u001b[31m   time: 1.622475 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.063633 (-2.020424)\n",
      "\u001b[0m\n",
      "it 343/2000, vlb -2.871112, \u001b[31m   time: 1.511534 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.276327 (-2.020424)\n",
      "\u001b[0m\n",
      "it 344/2000, vlb -2.879038, \u001b[31m   time: 1.587746 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.147212 (-2.020424)\n",
      "\u001b[0m\n",
      "it 345/2000, vlb -2.913511, \u001b[31m   time: 1.504907 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.138019 (-2.020424)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 346/2000, vlb -2.929362, \u001b[31m   time: 1.525709 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086172 (-2.020424)\n",
      "\u001b[0m\n",
      "it 347/2000, vlb -2.885387, \u001b[31m   time: 1.523838 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.178835 (-2.020424)\n",
      "\u001b[0m\n",
      "it 348/2000, vlb -2.869662, \u001b[31m   time: 1.563294 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.250089 (-2.020424)\n",
      "\u001b[0m\n",
      "it 349/2000, vlb -2.879508, \u001b[31m   time: 1.581398 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.256752 (-2.020424)\n",
      "\u001b[0m\n",
      "it 350/2000, vlb -2.859281, \u001b[31m   time: 1.525486 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.259175 (-2.020424)\n",
      "\u001b[0m\n",
      "it 351/2000, vlb -2.917242, \u001b[31m   time: 1.476790 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.206713 (-2.020424)\n",
      "\u001b[0m\n",
      "it 352/2000, vlb -2.892606, \u001b[31m   time: 1.521333 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.031537 (-2.020424)\n",
      "\u001b[0m\n",
      "it 353/2000, vlb -2.942614, \u001b[31m   time: 1.568662 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.109992 (-2.020424)\n",
      "\u001b[0m\n",
      "it 354/2000, vlb -2.841639, \u001b[31m   time: 1.517436 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.281631 (-2.020424)\n",
      "\u001b[0m\n",
      "it 355/2000, vlb -2.928566, \u001b[31m   time: 1.555945 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.162246 (-2.020424)\n",
      "\u001b[0m\n",
      "it 356/2000, vlb -2.882522, \u001b[31m   time: 1.543148 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.075053 (-2.020424)\n",
      "\u001b[0m\n",
      "it 357/2000, vlb -2.921421, \u001b[31m   time: 1.487964 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.256833 (-2.020424)\n",
      "\u001b[0m\n",
      "it 358/2000, vlb -2.886184, \u001b[31m   time: 1.494668 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.148932 (-2.020424)\n",
      "\u001b[0m\n",
      "it 359/2000, vlb -2.982587, \u001b[31m   time: 1.535389 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.131552 (-2.020424)\n",
      "\u001b[0m\n",
      "it 360/2000, vlb -2.939375, \u001b[31m   time: 1.563238 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.133536 (-2.020424)\n",
      "\u001b[0m\n",
      "it 361/2000, vlb -2.903301, \u001b[31m   time: 1.517883 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.237237 (-2.020424)\n",
      "\u001b[0m\n",
      "it 362/2000, vlb -2.904885, \u001b[31m   time: 1.559453 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176153 (-2.020424)\n",
      "\u001b[0m\n",
      "it 363/2000, vlb -2.891141, \u001b[31m   time: 1.524059 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.073484 (-2.020424)\n",
      "\u001b[0m\n",
      "it 364/2000, vlb -2.861332, \u001b[31m   time: 1.474547 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.181392 (-2.020424)\n",
      "\u001b[0m\n",
      "it 365/2000, vlb -2.848153, \u001b[31m   time: 1.566866 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.047287 (-2.020424)\n",
      "\u001b[0m\n",
      "it 366/2000, vlb -2.860179, \u001b[31m   time: 1.561741 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.057671 (-2.020424)\n",
      "\u001b[0m\n",
      "it 367/2000, vlb -2.922871, \u001b[31m   time: 1.584048 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.118614 (-2.020424)\n",
      "\u001b[0m\n",
      "it 368/2000, vlb -2.853774, \u001b[31m   time: 1.579321 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136714 (-2.020424)\n",
      "\u001b[0m\n",
      "it 369/2000, vlb -2.833930, \u001b[31m   time: 1.515646 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.236601 (-2.020424)\n",
      "\u001b[0m\n",
      "it 370/2000, vlb -2.819308, \u001b[31m   time: 1.537108 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136237 (-2.020424)\n",
      "\u001b[0m\n",
      "it 371/2000, vlb -2.876973, \u001b[31m   time: 1.527243 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.103302 (-2.020424)\n",
      "\u001b[0m\n",
      "it 372/2000, vlb -2.876234, \u001b[31m   time: 1.568684 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.101984 (-2.020424)\n",
      "\u001b[0m\n",
      "it 373/2000, vlb -2.849144, \u001b[31m   time: 1.549993 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.117724 (-2.020424)\n",
      "\u001b[0m\n",
      "it 374/2000, vlb -2.847825, \u001b[31m   time: 1.547193 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.243741 (-2.020424)\n",
      "\u001b[0m\n",
      "it 375/2000, vlb -2.899033, \u001b[31m   time: 1.543387 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.131149 (-2.020424)\n",
      "\u001b[0m\n",
      "it 376/2000, vlb -2.878801, \u001b[31m   time: 1.531395 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.260455 (-2.020424)\n",
      "\u001b[0m\n",
      "it 377/2000, vlb -2.905807, \u001b[31m   time: 1.519055 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.166868 (-2.020424)\n",
      "\u001b[0m\n",
      "it 378/2000, vlb -2.887163, \u001b[31m   time: 1.525198 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.121360 (-2.020424)\n",
      "\u001b[0m\n",
      "it 379/2000, vlb -2.882416, \u001b[31m   time: 1.509957 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.168366 (-2.020424)\n",
      "\u001b[0m\n",
      "it 380/2000, vlb -2.858816, \u001b[31m   time: 1.533106 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.279377 (-2.020424)\n",
      "\u001b[0m\n",
      "it 381/2000, vlb -2.859502, \u001b[31m   time: 1.549710 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.148417 (-2.020424)\n",
      "\u001b[0m\n",
      "it 382/2000, vlb -2.829977, \u001b[31m   time: 1.527344 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.028384 (-2.020424)\n",
      "\u001b[0m\n",
      "it 383/2000, vlb -2.831277, \u001b[31m   time: 1.528127 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.174894 (-2.020424)\n",
      "\u001b[0m\n",
      "it 384/2000, vlb -2.903497, \u001b[31m   time: 1.497615 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.095474 (-2.020424)\n",
      "\u001b[0m\n",
      "it 385/2000, vlb -2.884979, \u001b[31m   time: 1.503489 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.019125 (-2.020424)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 386/2000, vlb -2.921861, \u001b[31m   time: 1.533359 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.168679 (-2.019125)\n",
      "\u001b[0m\n",
      "it 387/2000, vlb -2.874872, \u001b[31m   time: 1.594445 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.279207 (-2.019125)\n",
      "\u001b[0m\n",
      "it 388/2000, vlb -2.905546, \u001b[31m   time: 1.538929 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.215896 (-2.019125)\n",
      "\u001b[0m\n",
      "it 389/2000, vlb -2.899871, \u001b[31m   time: 1.522900 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.118421 (-2.019125)\n",
      "\u001b[0m\n",
      "it 390/2000, vlb -2.813188, \u001b[31m   time: 1.541059 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.201680 (-2.019125)\n",
      "\u001b[0m\n",
      "it 391/2000, vlb -2.842402, \u001b[31m   time: 1.536191 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176156 (-2.019125)\n",
      "\u001b[0m\n",
      "it 392/2000, vlb -2.888843, \u001b[31m   time: 1.599404 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.264396 (-2.019125)\n",
      "\u001b[0m\n",
      "it 393/2000, vlb -2.843335, \u001b[31m   time: 1.609548 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.200064 (-2.019125)\n",
      "\u001b[0m\n",
      "it 394/2000, vlb -2.867964, \u001b[31m   time: 1.543883 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.160540 (-2.019125)\n",
      "\u001b[0m\n",
      "it 395/2000, vlb -2.851975, \u001b[31m   time: 1.509318 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.175517 (-2.019125)\n",
      "\u001b[0m\n",
      "it 396/2000, vlb -2.848016, \u001b[31m   time: 1.460687 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.110707 (-2.019125)\n",
      "\u001b[0m\n",
      "it 397/2000, vlb -2.830555, \u001b[31m   time: 1.499664 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.139356 (-2.019125)\n",
      "\u001b[0m\n",
      "it 398/2000, vlb -2.878638, \u001b[31m   time: 1.538541 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136214 (-2.019125)\n",
      "\u001b[0m\n",
      "it 399/2000, vlb -2.867472, \u001b[31m   time: 1.566770 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.142708 (-2.019125)\n",
      "\u001b[0m\n",
      "it 400/2000, vlb -2.833511, \u001b[31m   time: 1.641657 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.068744 (-2.019125)\n",
      "\u001b[0m\n",
      "it 401/2000, vlb -2.847614, \u001b[31m   time: 1.555150 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.177388 (-2.019125)\n",
      "\u001b[0m\n",
      "it 402/2000, vlb -2.830316, \u001b[31m   time: 1.528182 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.151719 (-2.019125)\n",
      "\u001b[0m\n",
      "it 403/2000, vlb -2.839010, \u001b[31m   time: 1.522653 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.181747 (-2.019125)\n",
      "\u001b[0m\n",
      "it 404/2000, vlb -2.840649, \u001b[31m   time: 1.507103 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.146074 (-2.019125)\n",
      "\u001b[0m\n",
      "it 405/2000, vlb -2.871730, \u001b[31m   time: 1.556989 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.337530 (-2.019125)\n",
      "\u001b[0m\n",
      "it 406/2000, vlb -2.858134, \u001b[31m   time: 1.485105 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.105911 (-2.019125)\n",
      "\u001b[0m\n",
      "it 407/2000, vlb -2.808448, \u001b[31m   time: 1.571899 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.084727 (-2.019125)\n",
      "\u001b[0m\n",
      "it 408/2000, vlb -2.865446, \u001b[31m   time: 1.609923 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169750 (-2.019125)\n",
      "\u001b[0m\n",
      "it 409/2000, vlb -2.897311, \u001b[31m   time: 1.539773 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.161178 (-2.019125)\n",
      "\u001b[0m\n",
      "it 410/2000, vlb -2.868624, \u001b[31m   time: 1.580584 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.151925 (-2.019125)\n",
      "\u001b[0m\n",
      "it 411/2000, vlb -2.859935, \u001b[31m   time: 1.528383 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.172583 (-2.019125)\n",
      "\u001b[0m\n",
      "it 412/2000, vlb -2.863163, \u001b[31m   time: 1.585857 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.193618 (-2.019125)\n",
      "\u001b[0m\n",
      "it 413/2000, vlb -2.838429, \u001b[31m   time: 1.520631 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216688 (-2.019125)\n",
      "\u001b[0m\n",
      "it 414/2000, vlb -2.844446, \u001b[31m   time: 1.524223 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.049179 (-2.019125)\n",
      "\u001b[0m\n",
      "it 415/2000, vlb -2.829585, \u001b[31m   time: 1.510684 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.109179 (-2.019125)\n",
      "\u001b[0m\n",
      "it 416/2000, vlb -2.835604, \u001b[31m   time: 1.575428 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.056407 (-2.019125)\n",
      "\u001b[0m\n",
      "it 417/2000, vlb -2.827747, \u001b[31m   time: 1.556769 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.116563 (-2.019125)\n",
      "\u001b[0m\n",
      "it 418/2000, vlb -2.835834, \u001b[31m   time: 1.562804 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.148497 (-2.019125)\n",
      "\u001b[0m\n",
      "it 419/2000, vlb -2.847756, \u001b[31m   time: 1.528269 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.124745 (-2.019125)\n",
      "\u001b[0m\n",
      "it 420/2000, vlb -2.852693, \u001b[31m   time: 1.618785 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.134150 (-2.019125)\n",
      "\u001b[0m\n",
      "it 421/2000, vlb -2.864698, \u001b[31m   time: 1.533896 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.135403 (-2.019125)\n",
      "\u001b[0m\n",
      "it 422/2000, vlb -2.838620, \u001b[31m   time: 1.510237 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169331 (-2.019125)\n",
      "\u001b[0m\n",
      "it 423/2000, vlb -2.784130, \u001b[31m   time: 1.533304 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.112691 (-2.019125)\n",
      "\u001b[0m\n",
      "it 424/2000, vlb -2.834215, \u001b[31m   time: 1.534274 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -2.209274 (-2.019125)\n",
      "\u001b[0m\n",
      "it 425/2000, vlb -2.784627, \u001b[31m   time: 1.504780 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.164382 (-2.019125)\n",
      "\u001b[0m\n",
      "it 426/2000, vlb -2.843056, \u001b[31m   time: 1.541274 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.183729 (-2.019125)\n",
      "\u001b[0m\n",
      "it 427/2000, vlb -2.834785, \u001b[31m   time: 1.523890 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.062116 (-2.019125)\n",
      "\u001b[0m\n",
      "it 428/2000, vlb -2.864480, \u001b[31m   time: 1.539259 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.238197 (-2.019125)\n",
      "\u001b[0m\n",
      "it 429/2000, vlb -2.842453, \u001b[31m   time: 1.535008 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.171480 (-2.019125)\n",
      "\u001b[0m\n",
      "it 430/2000, vlb -2.849138, \u001b[31m   time: 1.547235 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.182936 (-2.019125)\n",
      "\u001b[0m\n",
      "it 431/2000, vlb -2.862031, \u001b[31m   time: 1.574974 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086261 (-2.019125)\n",
      "\u001b[0m\n",
      "it 432/2000, vlb -2.835794, \u001b[31m   time: 1.510427 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.204956 (-2.019125)\n",
      "\u001b[0m\n",
      "it 433/2000, vlb -2.853546, \u001b[31m   time: 1.566558 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.284092 (-2.019125)\n",
      "\u001b[0m\n",
      "it 434/2000, vlb -2.797216, \u001b[31m   time: 1.526120 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.142378 (-2.019125)\n",
      "\u001b[0m\n",
      "it 435/2000, vlb -2.814046, \u001b[31m   time: 1.505338 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.212132 (-2.019125)\n",
      "\u001b[0m\n",
      "it 436/2000, vlb -2.828194, \u001b[31m   time: 1.516538 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.196584 (-2.019125)\n",
      "\u001b[0m\n",
      "it 437/2000, vlb -2.842309, \u001b[31m   time: 1.569258 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.299929 (-2.019125)\n",
      "\u001b[0m\n",
      "it 438/2000, vlb -2.828444, \u001b[31m   time: 1.562885 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.061161 (-2.019125)\n",
      "\u001b[0m\n",
      "it 439/2000, vlb -2.837244, \u001b[31m   time: 1.565125 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -1.998723 (-2.019125)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 440/2000, vlb -2.830420, \u001b[31m   time: 1.533749 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.159784 (-1.998723)\n",
      "\u001b[0m\n",
      "it 441/2000, vlb -2.826216, \u001b[31m   time: 1.555806 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.215587 (-1.998723)\n",
      "\u001b[0m\n",
      "it 442/2000, vlb -2.824593, \u001b[31m   time: 1.541506 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.312147 (-1.998723)\n",
      "\u001b[0m\n",
      "it 443/2000, vlb -2.847340, \u001b[31m   time: 2.075530 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.221091 (-1.998723)\n",
      "\u001b[0m\n",
      "it 444/2000, vlb -2.852621, \u001b[31m   time: 2.244354 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.139389 (-1.998723)\n",
      "\u001b[0m\n",
      "it 445/2000, vlb -2.868667, \u001b[31m   time: 2.107601 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.183832 (-1.998723)\n",
      "\u001b[0m\n",
      "it 446/2000, vlb -2.827016, \u001b[31m   time: 2.138152 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.110722 (-1.998723)\n",
      "\u001b[0m\n",
      "it 447/2000, vlb -2.776051, \u001b[31m   time: 1.861878 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.198937 (-1.998723)\n",
      "\u001b[0m\n",
      "it 448/2000, vlb -2.884318, \u001b[31m   time: 1.585375 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.157017 (-1.998723)\n",
      "\u001b[0m\n",
      "it 449/2000, vlb -2.827352, \u001b[31m   time: 1.704153 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.244386 (-1.998723)\n",
      "\u001b[0m\n",
      "it 450/2000, vlb -2.837525, \u001b[31m   time: 2.019609 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.215291 (-1.998723)\n",
      "\u001b[0m\n",
      "it 451/2000, vlb -2.808408, \u001b[31m   time: 1.953719 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.167001 (-1.998723)\n",
      "\u001b[0m\n",
      "it 452/2000, vlb -2.810879, \u001b[31m   time: 1.691044 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.194133 (-1.998723)\n",
      "\u001b[0m\n",
      "it 453/2000, vlb -2.852321, \u001b[31m   time: 1.832765 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.133153 (-1.998723)\n",
      "\u001b[0m\n",
      "it 454/2000, vlb -2.847021, \u001b[31m   time: 1.771386 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.189168 (-1.998723)\n",
      "\u001b[0m\n",
      "it 455/2000, vlb -2.807034, \u001b[31m   time: 1.627699 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.013587 (-1.998723)\n",
      "\u001b[0m\n",
      "it 456/2000, vlb -2.832591, \u001b[31m   time: 1.577381 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.120390 (-1.998723)\n",
      "\u001b[0m\n",
      "it 457/2000, vlb -2.819357, \u001b[31m   time: 1.682902 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.087041 (-1.998723)\n",
      "\u001b[0m\n",
      "it 458/2000, vlb -2.842930, \u001b[31m   time: 1.529982 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.218195 (-1.998723)\n",
      "\u001b[0m\n",
      "it 459/2000, vlb -2.851150, \u001b[31m   time: 1.718753 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.247761 (-1.998723)\n",
      "\u001b[0m\n",
      "it 460/2000, vlb -2.824909, \u001b[31m   time: 1.824965 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.219808 (-1.998723)\n",
      "\u001b[0m\n",
      "it 461/2000, vlb -2.812732, \u001b[31m   time: 1.761886 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.077911 (-1.998723)\n",
      "\u001b[0m\n",
      "it 462/2000, vlb -2.912891, \u001b[31m   time: 1.522174 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.224123 (-1.998723)\n",
      "\u001b[0m\n",
      "it 463/2000, vlb -2.853770, \u001b[31m   time: 1.592316 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.120794 (-1.998723)\n",
      "\u001b[0m\n",
      "it 464/2000, vlb -2.809634, \u001b[31m   time: 1.612739 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.185876 (-1.998723)\n",
      "\u001b[0m\n",
      "it 465/2000, vlb -2.796445, \u001b[31m   time: 1.598086 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.151518 (-1.998723)\n",
      "\u001b[0m\n",
      "it 466/2000, vlb -2.854195, \u001b[31m   time: 1.528183 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.142905 (-1.998723)\n",
      "\u001b[0m\n",
      "it 467/2000, vlb -2.819295, \u001b[31m   time: 1.527667 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.191980 (-1.998723)\n",
      "\u001b[0m\n",
      "it 468/2000, vlb -2.742111, \u001b[31m   time: 1.580170 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136934 (-1.998723)\n",
      "\u001b[0m\n",
      "it 469/2000, vlb -2.871606, \u001b[31m   time: 1.523404 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.082549 (-1.998723)\n",
      "\u001b[0m\n",
      "it 470/2000, vlb -2.831423, \u001b[31m   time: 1.552238 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086163 (-1.998723)\n",
      "\u001b[0m\n",
      "it 471/2000, vlb -2.805017, \u001b[31m   time: 1.497981 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.032717 (-1.998723)\n",
      "\u001b[0m\n",
      "it 472/2000, vlb -2.811418, \u001b[31m   time: 1.528994 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.080874 (-1.998723)\n",
      "\u001b[0m\n",
      "it 473/2000, vlb -2.791934, \u001b[31m   time: 1.530188 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229922 (-1.998723)\n",
      "\u001b[0m\n",
      "it 474/2000, vlb -2.786754, \u001b[31m   time: 1.577979 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.294289 (-1.998723)\n",
      "\u001b[0m\n",
      "it 475/2000, vlb -2.803509, \u001b[31m   time: 1.500501 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.060909 (-1.998723)\n",
      "\u001b[0m\n",
      "it 476/2000, vlb -2.846263, \u001b[31m   time: 1.552610 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.089067 (-1.998723)\n",
      "\u001b[0m\n",
      "it 477/2000, vlb -2.856316, \u001b[31m   time: 1.552184 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.252901 (-1.998723)\n",
      "\u001b[0m\n",
      "it 478/2000, vlb -2.811813, \u001b[31m   time: 1.570640 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.167585 (-1.998723)\n",
      "\u001b[0m\n",
      "it 479/2000, vlb -2.836167, \u001b[31m   time: 1.508794 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.188874 (-1.998723)\n",
      "\u001b[0m\n",
      "it 480/2000, vlb -2.824642, \u001b[31m   time: 1.540330 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.183400 (-1.998723)\n",
      "\u001b[0m\n",
      "it 481/2000, vlb -2.835590, \u001b[31m   time: 1.561981 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.185051 (-1.998723)\n",
      "\u001b[0m\n",
      "it 482/2000, vlb -2.832831, \u001b[31m   time: 1.513569 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.123370 (-1.998723)\n",
      "\u001b[0m\n",
      "it 483/2000, vlb -2.755542, \u001b[31m   time: 1.550674 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.133965 (-1.998723)\n",
      "\u001b[0m\n",
      "it 484/2000, vlb -2.790853, \u001b[31m   time: 1.510902 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.097821 (-1.998723)\n",
      "\u001b[0m\n",
      "it 485/2000, vlb -2.810217, \u001b[31m   time: 1.452095 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.285036 (-1.998723)\n",
      "\u001b[0m\n",
      "it 486/2000, vlb -2.828560, \u001b[31m   time: 1.520244 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.036457 (-1.998723)\n",
      "\u001b[0m\n",
      "it 487/2000, vlb -2.854523, \u001b[31m   time: 1.526513 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.260502 (-1.998723)\n",
      "\u001b[0m\n",
      "it 488/2000, vlb -2.808649, \u001b[31m   time: 1.536468 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.120419 (-1.998723)\n",
      "\u001b[0m\n",
      "it 489/2000, vlb -2.803123, \u001b[31m   time: 1.521669 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.111820 (-1.998723)\n",
      "\u001b[0m\n",
      "it 490/2000, vlb -2.830553, \u001b[31m   time: 1.781389 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.253701 (-1.998723)\n",
      "\u001b[0m\n",
      "it 491/2000, vlb -2.843692, \u001b[31m   time: 1.460014 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.193948 (-1.998723)\n",
      "\u001b[0m\n",
      "it 492/2000, vlb -2.793129, \u001b[31m   time: 1.529883 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.161654 (-1.998723)\n",
      "\u001b[0m\n",
      "it 493/2000, vlb -2.902512, \u001b[31m   time: 1.599563 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.315514 (-1.998723)\n",
      "\u001b[0m\n",
      "it 494/2000, vlb -2.831178, \u001b[31m   time: 1.957884 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.135556 (-1.998723)\n",
      "\u001b[0m\n",
      "it 495/2000, vlb -2.788645, \u001b[31m   time: 2.451571 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.240614 (-1.998723)\n",
      "\u001b[0m\n",
      "it 496/2000, vlb -2.774036, \u001b[31m   time: 2.103077 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.046694 (-1.998723)\n",
      "\u001b[0m\n",
      "it 497/2000, vlb -2.839096, \u001b[31m   time: 1.880760 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.060421 (-1.998723)\n",
      "\u001b[0m\n",
      "it 498/2000, vlb -2.773384, \u001b[31m   time: 1.597373 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.157761 (-1.998723)\n",
      "\u001b[0m\n",
      "it 499/2000, vlb -2.775844, \u001b[31m   time: 1.929606 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.144474 (-1.998723)\n",
      "\u001b[0m\n",
      "it 500/2000, vlb -2.785156, \u001b[31m   time: 1.866308 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.138947 (-1.998723)\n",
      "\u001b[0m\n",
      "it 501/2000, vlb -2.813517, \u001b[31m   time: 1.726884 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.194210 (-1.998723)\n",
      "\u001b[0m\n",
      "it 502/2000, vlb -2.793074, \u001b[31m   time: 1.721537 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086035 (-1.998723)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 503/2000, vlb -2.799752, \u001b[31m   time: 1.922454 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.177633 (-1.998723)\n",
      "\u001b[0m\n",
      "it 504/2000, vlb -2.832146, \u001b[31m   time: 1.935340 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.162543 (-1.998723)\n",
      "\u001b[0m\n",
      "it 505/2000, vlb -2.819397, \u001b[31m   time: 1.873298 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.184785 (-1.998723)\n",
      "\u001b[0m\n",
      "it 506/2000, vlb -2.807158, \u001b[31m   time: 1.841677 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.232241 (-1.998723)\n",
      "\u001b[0m\n",
      "it 507/2000, vlb -2.804971, \u001b[31m   time: 2.046750 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.229083 (-1.998723)\n",
      "\u001b[0m\n",
      "it 508/2000, vlb -2.780258, \u001b[31m   time: 2.034997 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.151479 (-1.998723)\n",
      "\u001b[0m\n",
      "it 509/2000, vlb -2.810008, \u001b[31m   time: 1.822101 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.061136 (-1.998723)\n",
      "\u001b[0m\n",
      "it 510/2000, vlb -2.766865, \u001b[31m   time: 1.554362 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.088377 (-1.998723)\n",
      "\u001b[0m\n",
      "it 511/2000, vlb -2.821385, \u001b[31m   time: 1.489643 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.244368 (-1.998723)\n",
      "\u001b[0m\n",
      "it 512/2000, vlb -2.782950, \u001b[31m   time: 1.789505 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216689 (-1.998723)\n",
      "\u001b[0m\n",
      "it 513/2000, vlb -2.817904, \u001b[31m   time: 2.151731 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.130452 (-1.998723)\n",
      "\u001b[0m\n",
      "it 514/2000, vlb -2.863034, \u001b[31m   time: 1.932396 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.092125 (-1.998723)\n",
      "\u001b[0m\n",
      "it 515/2000, vlb -2.790588, \u001b[31m   time: 1.830392 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.074781 (-1.998723)\n",
      "\u001b[0m\n",
      "it 516/2000, vlb -2.836280, \u001b[31m   time: 1.845175 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.214839 (-1.998723)\n",
      "\u001b[0m\n",
      "it 517/2000, vlb -2.801357, \u001b[31m   time: 2.047030 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.200379 (-1.998723)\n",
      "\u001b[0m\n",
      "it 518/2000, vlb -2.761516, \u001b[31m   time: 1.959998 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.219213 (-1.998723)\n",
      "\u001b[0m\n",
      "it 519/2000, vlb -2.806015, \u001b[31m   time: 1.910929 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.116761 (-1.998723)\n",
      "\u001b[0m\n",
      "it 520/2000, vlb -2.773243, \u001b[31m   time: 1.829398 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.154572 (-1.998723)\n",
      "\u001b[0m\n",
      "it 521/2000, vlb -2.754194, \u001b[31m   time: 1.511789 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.098475 (-1.998723)\n",
      "\u001b[0m\n",
      "it 522/2000, vlb -2.815268, \u001b[31m   time: 1.535979 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.049688 (-1.998723)\n",
      "\u001b[0m\n",
      "it 523/2000, vlb -2.779182, \u001b[31m   time: 1.708535 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.287989 (-1.998723)\n",
      "\u001b[0m\n",
      "it 524/2000, vlb -2.811736, \u001b[31m   time: 1.792110 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.149625 (-1.998723)\n",
      "\u001b[0m\n",
      "it 525/2000, vlb -2.788176, \u001b[31m   time: 1.658527 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.082529 (-1.998723)\n",
      "\u001b[0m\n",
      "it 526/2000, vlb -2.822008, \u001b[31m   time: 1.606873 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.182645 (-1.998723)\n",
      "\u001b[0m\n",
      "it 527/2000, vlb -2.816878, \u001b[31m   time: 1.766288 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.099544 (-1.998723)\n",
      "\u001b[0m\n",
      "it 528/2000, vlb -2.791766, \u001b[31m   time: 1.915555 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.159607 (-1.998723)\n",
      "\u001b[0m\n",
      "it 529/2000, vlb -2.813733, \u001b[31m   time: 1.850082 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.256962 (-1.998723)\n",
      "\u001b[0m\n",
      "it 530/2000, vlb -2.799506, \u001b[31m   time: 1.587300 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.150489 (-1.998723)\n",
      "\u001b[0m\n",
      "it 531/2000, vlb -2.810373, \u001b[31m   time: 1.592380 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.103175 (-1.998723)\n",
      "\u001b[0m\n",
      "it 532/2000, vlb -2.852127, \u001b[31m   time: 1.627202 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.086585 (-1.998723)\n",
      "\u001b[0m\n",
      "it 533/2000, vlb -2.796466, \u001b[31m   time: 2.381291 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.040382 (-1.998723)\n",
      "\u001b[0m\n",
      "it 534/2000, vlb -2.776603, \u001b[31m   time: 1.882469 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.209345 (-1.998723)\n",
      "\u001b[0m\n",
      "it 535/2000, vlb -2.803466, \u001b[31m   time: 1.699912 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.178021 (-1.998723)\n",
      "\u001b[0m\n",
      "it 536/2000, vlb -2.804839, \u001b[31m   time: 1.617642 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.071345 (-1.998723)\n",
      "\u001b[0m\n",
      "it 537/2000, vlb -2.806438, \u001b[31m   time: 1.597061 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.122491 (-1.998723)\n",
      "\u001b[0m\n",
      "it 538/2000, vlb -2.778305, \u001b[31m   time: 1.613919 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.317083 (-1.998723)\n",
      "\u001b[0m\n",
      "it 539/2000, vlb -2.797465, \u001b[31m   time: 1.600461 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.038112 (-1.998723)\n",
      "\u001b[0m\n",
      "it 540/2000, vlb -2.808456, \u001b[31m   time: 1.530656 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.092133 (-1.998723)\n",
      "\u001b[0m\n",
      "it 541/2000, vlb -2.849448, \u001b[31m   time: 1.569869 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.137044 (-1.998723)\n",
      "\u001b[0m\n",
      "it 542/2000, vlb -2.771107, \u001b[31m   time: 1.550734 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.021765 (-1.998723)\n",
      "\u001b[0m\n",
      "it 543/2000, vlb -2.835373, \u001b[31m   time: 1.587407 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.042100 (-1.998723)\n",
      "\u001b[0m\n",
      "it 544/2000, vlb -2.802780, \u001b[31m   time: 1.570202 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.157757 (-1.998723)\n",
      "\u001b[0m\n",
      "it 545/2000, vlb -2.774247, \u001b[31m   time: 1.552166 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.166492 (-1.998723)\n",
      "\u001b[0m\n",
      "it 546/2000, vlb -2.821343, \u001b[31m   time: 1.516620 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.108800 (-1.998723)\n",
      "\u001b[0m\n",
      "it 547/2000, vlb -2.817263, \u001b[31m   time: 1.554051 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.266457 (-1.998723)\n",
      "\u001b[0m\n",
      "it 548/2000, vlb -2.811552, \u001b[31m   time: 1.583962 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.096573 (-1.998723)\n",
      "\u001b[0m\n",
      "it 549/2000, vlb -2.791223, \u001b[31m   time: 1.551600 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145211 (-1.998723)\n",
      "\u001b[0m\n",
      "it 550/2000, vlb -2.761531, \u001b[31m   time: 1.567341 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136421 (-1.998723)\n",
      "\u001b[0m\n",
      "it 551/2000, vlb -2.768930, \u001b[31m   time: 1.678305 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.148342 (-1.998723)\n",
      "\u001b[0m\n",
      "it 552/2000, vlb -2.760969, \u001b[31m   time: 2.150112 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.026840 (-1.998723)\n",
      "\u001b[0m\n",
      "it 553/2000, vlb -2.871156, \u001b[31m   time: 2.238931 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176520 (-1.998723)\n",
      "\u001b[0m\n",
      "it 554/2000, vlb -2.816450, \u001b[31m   time: 2.007225 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.189443 (-1.998723)\n",
      "\u001b[0m\n",
      "it 555/2000, vlb -2.794780, \u001b[31m   time: 1.948268 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.101760 (-1.998723)\n",
      "\u001b[0m\n",
      "it 556/2000, vlb -2.791407, \u001b[31m   time: 1.823579 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.257436 (-1.998723)\n",
      "\u001b[0m\n",
      "it 557/2000, vlb -2.790407, \u001b[31m   time: 1.750215 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.076479 (-1.998723)\n",
      "\u001b[0m\n",
      "it 558/2000, vlb -2.774607, \u001b[31m   time: 1.495590 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.188673 (-1.998723)\n",
      "\u001b[0m\n",
      "it 559/2000, vlb -2.805743, \u001b[31m   time: 2.094303 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.319784 (-1.998723)\n",
      "\u001b[0m\n",
      "it 560/2000, vlb -2.851258, \u001b[31m   time: 5.041983 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.035721 (-1.998723)\n",
      "\u001b[0m\n",
      "it 561/2000, vlb -2.791666, \u001b[31m   time: 3.260741 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.066856 (-1.998723)\n",
      "\u001b[0m\n",
      "it 562/2000, vlb -2.796602, \u001b[31m   time: 3.064083 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.124457 (-1.998723)\n",
      "\u001b[0m\n",
      "it 563/2000, vlb -2.751076, \u001b[31m   time: 2.021977 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.218538 (-1.998723)\n",
      "\u001b[0m\n",
      "it 564/2000, vlb -2.795169, \u001b[31m   time: 3.171806 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.133228 (-1.998723)\n",
      "\u001b[0m\n",
      "it 565/2000, vlb -2.742548, \u001b[31m   time: 3.245581 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.061446 (-1.998723)\n",
      "\u001b[0m\n",
      "it 566/2000, vlb -2.816107, \u001b[31m   time: 4.177823 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.087526 (-1.998723)\n",
      "\u001b[0m\n",
      "it 567/2000, vlb -2.764604, \u001b[31m   time: 3.542479 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.185809 (-1.998723)\n",
      "\u001b[0m\n",
      "it 568/2000, vlb -2.792360, \u001b[31m   time: 3.181089 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.131080 (-1.998723)\n",
      "\u001b[0m\n",
      "it 569/2000, vlb -2.790476, \u001b[31m   time: 2.247807 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.227552 (-1.998723)\n",
      "\u001b[0m\n",
      "it 570/2000, vlb -2.761901, \u001b[31m   time: 1.913960 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.174784 (-1.998723)\n",
      "\u001b[0m\n",
      "it 571/2000, vlb -2.772376, \u001b[31m   time: 2.619979 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169590 (-1.998723)\n",
      "\u001b[0m\n",
      "it 572/2000, vlb -2.757497, \u001b[31m   time: 2.833563 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.098251 (-1.998723)\n",
      "\u001b[0m\n",
      "it 573/2000, vlb -2.819047, \u001b[31m   time: 2.693901 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145872 (-1.998723)\n",
      "\u001b[0m\n",
      "it 574/2000, vlb -2.787176, \u001b[31m   time: 2.261132 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.124717 (-1.998723)\n",
      "\u001b[0m\n",
      "it 575/2000, vlb -2.803475, \u001b[31m   time: 2.243741 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169561 (-1.998723)\n",
      "\u001b[0m\n",
      "it 576/2000, vlb -2.774484, \u001b[31m   time: 1.938768 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.167718 (-1.998723)\n",
      "\u001b[0m\n",
      "it 577/2000, vlb -2.801227, \u001b[31m   time: 1.883628 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.165719 (-1.998723)\n",
      "\u001b[0m\n",
      "it 578/2000, vlb -2.773598, \u001b[31m   time: 1.686728 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.191958 (-1.998723)\n",
      "\u001b[0m\n",
      "it 579/2000, vlb -2.795863, \u001b[31m   time: 2.362740 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.225960 (-1.998723)\n",
      "\u001b[0m\n",
      "it 580/2000, vlb -2.796328, \u001b[31m   time: 1.967740 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.207267 (-1.998723)\n",
      "\u001b[0m\n",
      "it 581/2000, vlb -2.819632, \u001b[31m   time: 2.280932 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.192178 (-1.998723)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 582/2000, vlb -2.751141, \u001b[31m   time: 1.917230 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.058791 (-1.998723)\n",
      "\u001b[0m\n",
      "it 583/2000, vlb -2.840520, \u001b[31m   time: 1.594543 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.124217 (-1.998723)\n",
      "\u001b[0m\n",
      "it 584/2000, vlb -2.781919, \u001b[31m   time: 1.681414 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -1.975160 (-1.998723)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 585/2000, vlb -2.767593, \u001b[31m   time: 1.590825 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.065042 (-1.975160)\n",
      "\u001b[0m\n",
      "it 586/2000, vlb -2.783789, \u001b[31m   time: 1.649249 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.215234 (-1.975160)\n",
      "\u001b[0m\n",
      "it 587/2000, vlb -2.809114, \u001b[31m   time: 1.570287 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.227826 (-1.975160)\n",
      "\u001b[0m\n",
      "it 588/2000, vlb -2.820382, \u001b[31m   time: 1.530960 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.063033 (-1.975160)\n",
      "\u001b[0m\n",
      "it 589/2000, vlb -2.768267, \u001b[31m   time: 1.592077 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136804 (-1.975160)\n",
      "\u001b[0m\n",
      "it 590/2000, vlb -2.774396, \u001b[31m   time: 1.521016 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.032209 (-1.975160)\n",
      "\u001b[0m\n",
      "it 591/2000, vlb -2.784359, \u001b[31m   time: 1.509726 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.063433 (-1.975160)\n",
      "\u001b[0m\n",
      "it 592/2000, vlb -2.794802, \u001b[31m   time: 1.491103 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.141265 (-1.975160)\n",
      "\u001b[0m\n",
      "it 593/2000, vlb -2.758811, \u001b[31m   time: 1.571462 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.187959 (-1.975160)\n",
      "\u001b[0m\n",
      "it 594/2000, vlb -2.802727, \u001b[31m   time: 1.546930 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.233211 (-1.975160)\n",
      "\u001b[0m\n",
      "it 595/2000, vlb -2.740844, \u001b[31m   time: 1.501403 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.066883 (-1.975160)\n",
      "\u001b[0m\n",
      "it 596/2000, vlb -2.778574, \u001b[31m   time: 1.559460 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.218126 (-1.975160)\n",
      "\u001b[0m\n",
      "it 597/2000, vlb -2.789071, \u001b[31m   time: 1.514663 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.202352 (-1.975160)\n",
      "\u001b[0m\n",
      "it 598/2000, vlb -2.823618, \u001b[31m   time: 1.455880 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.194106 (-1.975160)\n",
      "\u001b[0m\n",
      "it 599/2000, vlb -2.798070, \u001b[31m   time: 1.523171 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145596 (-1.975160)\n",
      "\u001b[0m\n",
      "it 600/2000, vlb -2.760915, \u001b[31m   time: 1.544637 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.109432 (-1.975160)\n",
      "\u001b[0m\n",
      "it 601/2000, vlb -2.841887, \u001b[31m   time: 1.531498 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.307522 (-1.975160)\n",
      "\u001b[0m\n",
      "it 602/2000, vlb -2.747090, \u001b[31m   time: 1.577002 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.135742 (-1.975160)\n",
      "\u001b[0m\n",
      "it 603/2000, vlb -2.692716, \u001b[31m   time: 1.506210 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.192026 (-1.975160)\n",
      "\u001b[0m\n",
      "it 604/2000, vlb -2.771858, \u001b[31m   time: 1.516825 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.063332 (-1.975160)\n",
      "\u001b[0m\n",
      "it 605/2000, vlb -2.766046, \u001b[31m   time: 1.521120 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.016062 (-1.975160)\n",
      "\u001b[0m\n",
      "it 606/2000, vlb -2.791228, \u001b[31m   time: 1.499186 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.336954 (-1.975160)\n",
      "\u001b[0m\n",
      "it 607/2000, vlb -2.753437, \u001b[31m   time: 1.507163 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.020902 (-1.975160)\n",
      "\u001b[0m\n",
      "it 608/2000, vlb -2.766179, \u001b[31m   time: 1.502461 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.198886 (-1.975160)\n",
      "\u001b[0m\n",
      "it 609/2000, vlb -2.766287, \u001b[31m   time: 1.578728 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.319259 (-1.975160)\n",
      "\u001b[0m\n",
      "it 610/2000, vlb -2.788592, \u001b[31m   time: 1.626307 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.246872 (-1.975160)\n",
      "\u001b[0m\n",
      "it 611/2000, vlb -2.746357, \u001b[31m   time: 1.519298 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.139907 (-1.975160)\n",
      "\u001b[0m\n",
      "it 612/2000, vlb -2.735168, \u001b[31m   time: 1.537849 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.122403 (-1.975160)\n",
      "\u001b[0m\n",
      "it 613/2000, vlb -2.789825, \u001b[31m   time: 1.526209 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.098161 (-1.975160)\n",
      "\u001b[0m\n",
      "it 614/2000, vlb -2.760225, \u001b[31m   time: 1.558903 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.130279 (-1.975160)\n",
      "\u001b[0m\n",
      "it 615/2000, vlb -2.793079, \u001b[31m   time: 1.561170 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.274379 (-1.975160)\n",
      "\u001b[0m\n",
      "it 616/2000, vlb -2.788065, \u001b[31m   time: 1.539834 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.096195 (-1.975160)\n",
      "\u001b[0m\n",
      "it 617/2000, vlb -2.788084, \u001b[31m   time: 1.483664 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.239052 (-1.975160)\n",
      "\u001b[0m\n",
      "it 618/2000, vlb -2.729654, \u001b[31m   time: 1.560692 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.177518 (-1.975160)\n",
      "\u001b[0m\n",
      "it 619/2000, vlb -2.777060, \u001b[31m   time: 1.538908 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.134742 (-1.975160)\n",
      "\u001b[0m\n",
      "it 620/2000, vlb -2.760727, \u001b[31m   time: 1.548204 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.032071 (-1.975160)\n",
      "\u001b[0m\n",
      "it 621/2000, vlb -2.754329, \u001b[31m   time: 1.596343 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.186313 (-1.975160)\n",
      "\u001b[0m\n",
      "it 622/2000, vlb -2.773427, \u001b[31m   time: 1.491884 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.049540 (-1.975160)\n",
      "\u001b[0m\n",
      "it 623/2000, vlb -2.752198, \u001b[31m   time: 1.519488 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.097698 (-1.975160)\n",
      "\u001b[0m\n",
      "it 624/2000, vlb -2.772098, \u001b[31m   time: 1.510481 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.150713 (-1.975160)\n",
      "\u001b[0m\n",
      "it 625/2000, vlb -2.791829, \u001b[31m   time: 1.541959 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -1.991808 (-1.975160)\n",
      "\u001b[0m\n",
      "it 626/2000, vlb -2.741750, \u001b[31m   time: 1.527599 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.261453 (-1.975160)\n",
      "\u001b[0m\n",
      "it 627/2000, vlb -2.820875, \u001b[31m   time: 1.586256 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.144726 (-1.975160)\n",
      "\u001b[0m\n",
      "it 628/2000, vlb -2.760120, \u001b[31m   time: 1.559658 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.091210 (-1.975160)\n",
      "\u001b[0m\n",
      "it 629/2000, vlb -2.732702, \u001b[31m   time: 1.531661 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.080737 (-1.975160)\n",
      "\u001b[0m\n",
      "it 630/2000, vlb -2.716267, \u001b[31m   time: 1.509969 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.051590 (-1.975160)\n",
      "\u001b[0m\n",
      "it 631/2000, vlb -2.806191, \u001b[31m   time: 1.530785 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.241068 (-1.975160)\n",
      "\u001b[0m\n",
      "it 632/2000, vlb -2.801371, \u001b[31m   time: 1.531737 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.075011 (-1.975160)\n",
      "\u001b[0m\n",
      "it 633/2000, vlb -2.809911, \u001b[31m   time: 1.551124 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.137511 (-1.975160)\n",
      "\u001b[0m\n",
      "it 634/2000, vlb -2.770211, \u001b[31m   time: 1.563518 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.004783 (-1.975160)\n",
      "\u001b[0m\n",
      "it 635/2000, vlb -2.800088, \u001b[31m   time: 1.517219 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.210306 (-1.975160)\n",
      "\u001b[0m\n",
      "it 636/2000, vlb -2.801717, \u001b[31m   time: 1.523110 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.259457 (-1.975160)\n",
      "\u001b[0m\n",
      "it 637/2000, vlb -2.804107, \u001b[31m   time: 1.852295 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.083565 (-1.975160)\n",
      "\u001b[0m\n",
      "it 638/2000, vlb -2.777896, \u001b[31m   time: 2.172283 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.230177 (-1.975160)\n",
      "\u001b[0m\n",
      "it 639/2000, vlb -2.817401, \u001b[31m   time: 2.034549 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.133736 (-1.975160)\n",
      "\u001b[0m\n",
      "it 640/2000, vlb -2.764139, \u001b[31m   time: 1.890173 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.286725 (-1.975160)\n",
      "\u001b[0m\n",
      "it 641/2000, vlb -2.788525, \u001b[31m   time: 1.732375 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.173233 (-1.975160)\n",
      "\u001b[0m\n",
      "it 642/2000, vlb -2.778246, \u001b[31m   time: 1.839234 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.110556 (-1.975160)\n",
      "\u001b[0m\n",
      "it 643/2000, vlb -2.731560, \u001b[31m   time: 1.775162 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.143264 (-1.975160)\n",
      "\u001b[0m\n",
      "it 644/2000, vlb -2.764474, \u001b[31m   time: 1.756284 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.174307 (-1.975160)\n",
      "\u001b[0m\n",
      "it 645/2000, vlb -2.769912, \u001b[31m   time: 1.916570 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.079792 (-1.975160)\n",
      "\u001b[0m\n",
      "it 646/2000, vlb -2.721358, \u001b[31m   time: 1.906033 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145652 (-1.975160)\n",
      "\u001b[0m\n",
      "it 647/2000, vlb -2.760267, \u001b[31m   time: 1.759303 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.228919 (-1.975160)\n",
      "\u001b[0m\n",
      "it 648/2000, vlb -2.743499, \u001b[31m   time: 1.691828 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.010366 (-1.975160)\n",
      "\u001b[0m\n",
      "it 649/2000, vlb -2.783500, \u001b[31m   time: 1.873048 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.066586 (-1.975160)\n",
      "\u001b[0m\n",
      "it 650/2000, vlb -2.749902, \u001b[31m   time: 2.483773 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.245053 (-1.975160)\n",
      "\u001b[0m\n",
      "it 651/2000, vlb -2.752353, \u001b[31m   time: 2.373257 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216301 (-1.975160)\n",
      "\u001b[0m\n",
      "it 652/2000, vlb -2.747753, \u001b[31m   time: 2.150979 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.165897 (-1.975160)\n",
      "\u001b[0m\n",
      "it 653/2000, vlb -2.803498, \u001b[31m   time: 2.471893 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.060161 (-1.975160)\n",
      "\u001b[0m\n",
      "it 654/2000, vlb -2.771333, \u001b[31m   time: 2.251935 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.194179 (-1.975160)\n",
      "\u001b[0m\n",
      "it 655/2000, vlb -2.744986, \u001b[31m   time: 2.164406 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -1.979213 (-1.975160)\n",
      "\u001b[0m\n",
      "it 656/2000, vlb -2.737562, \u001b[31m   time: 1.863027 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.192255 (-1.975160)\n",
      "\u001b[0m\n",
      "it 657/2000, vlb -2.761104, \u001b[31m   time: 1.574643 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.196341 (-1.975160)\n",
      "\u001b[0m\n",
      "it 658/2000, vlb -2.777499, \u001b[31m   time: 2.121038 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.097425 (-1.975160)\n",
      "\u001b[0m\n",
      "it 659/2000, vlb -2.722345, \u001b[31m   time: 2.427045 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.250090 (-1.975160)\n",
      "\u001b[0m\n",
      "it 660/2000, vlb -2.775731, \u001b[31m   time: 2.188785 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -2.231783 (-1.975160)\n",
      "\u001b[0m\n",
      "it 661/2000, vlb -2.767818, \u001b[31m   time: 1.799035 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.113998 (-1.975160)\n",
      "\u001b[0m\n",
      "it 662/2000, vlb -2.776016, \u001b[31m   time: 1.551502 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.187677 (-1.975160)\n",
      "\u001b[0m\n",
      "it 663/2000, vlb -2.733281, \u001b[31m   time: 1.541415 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.199460 (-1.975160)\n",
      "\u001b[0m\n",
      "it 664/2000, vlb -2.847155, \u001b[31m   time: 1.566950 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.187475 (-1.975160)\n",
      "\u001b[0m\n",
      "it 665/2000, vlb -2.756974, \u001b[31m   time: 1.543407 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.221610 (-1.975160)\n",
      "\u001b[0m\n",
      "it 666/2000, vlb -2.769070, \u001b[31m   time: 1.600021 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.110461 (-1.975160)\n",
      "\u001b[0m\n",
      "it 667/2000, vlb -2.762998, \u001b[31m   time: 1.546951 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.147192 (-1.975160)\n",
      "\u001b[0m\n",
      "it 668/2000, vlb -2.742754, \u001b[31m   time: 1.547191 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.201239 (-1.975160)\n",
      "\u001b[0m\n",
      "it 669/2000, vlb -2.746374, \u001b[31m   time: 1.565629 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.083755 (-1.975160)\n",
      "\u001b[0m\n",
      "it 670/2000, vlb -2.759847, \u001b[31m   time: 1.570588 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.141832 (-1.975160)\n",
      "\u001b[0m\n",
      "it 671/2000, vlb -2.763595, \u001b[31m   time: 1.530063 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.049889 (-1.975160)\n",
      "\u001b[0m\n",
      "it 672/2000, vlb -2.769830, \u001b[31m   time: 1.570875 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.117807 (-1.975160)\n",
      "\u001b[0m\n",
      "it 673/2000, vlb -2.770699, \u001b[31m   time: 1.532815 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.165835 (-1.975160)\n",
      "\u001b[0m\n",
      "it 674/2000, vlb -2.842470, \u001b[31m   time: 1.555271 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.216304 (-1.975160)\n",
      "\u001b[0m\n",
      "it 675/2000, vlb -2.730401, \u001b[31m   time: 1.554712 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.098250 (-1.975160)\n",
      "\u001b[0m\n",
      "it 676/2000, vlb -2.781302, \u001b[31m   time: 1.540618 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.125215 (-1.975160)\n",
      "\u001b[0m\n",
      "it 677/2000, vlb -2.754839, \u001b[31m   time: 1.547224 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.083618 (-1.975160)\n",
      "\u001b[0m\n",
      "it 678/2000, vlb -2.782957, \u001b[31m   time: 1.550360 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.162136 (-1.975160)\n",
      "\u001b[0m\n",
      "it 679/2000, vlb -2.711217, \u001b[31m   time: 1.556999 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.132715 (-1.975160)\n",
      "\u001b[0m\n",
      "it 680/2000, vlb -2.707662, \u001b[31m   time: 1.555602 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.109512 (-1.975160)\n",
      "\u001b[0m\n",
      "it 681/2000, vlb -2.774661, \u001b[31m   time: 1.538509 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.090802 (-1.975160)\n",
      "\u001b[0m\n",
      "it 682/2000, vlb -2.784631, \u001b[31m   time: 1.554655 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.209104 (-1.975160)\n",
      "\u001b[0m\n",
      "it 683/2000, vlb -2.755400, \u001b[31m   time: 1.575929 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.050093 (-1.975160)\n",
      "\u001b[0m\n",
      "it 684/2000, vlb -2.770061, \u001b[31m   time: 1.479164 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.142120 (-1.975160)\n",
      "\u001b[0m\n",
      "it 685/2000, vlb -2.820574, \u001b[31m   time: 1.591728 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.109621 (-1.975160)\n",
      "\u001b[0m\n",
      "it 686/2000, vlb -2.770661, \u001b[31m   time: 1.541806 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.240686 (-1.975160)\n",
      "\u001b[0m\n",
      "it 687/2000, vlb -2.732090, \u001b[31m   time: 1.522109 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.248600 (-1.975160)\n",
      "\u001b[0m\n",
      "it 688/2000, vlb -2.705815, \u001b[31m   time: 1.559950 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.116005 (-1.975160)\n",
      "\u001b[0m\n",
      "it 689/2000, vlb -2.759179, \u001b[31m   time: 1.560519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.088709 (-1.975160)\n",
      "\u001b[0m\n",
      "it 690/2000, vlb -2.771808, \u001b[31m   time: 1.527289 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.205560 (-1.975160)\n",
      "\u001b[0m\n",
      "it 691/2000, vlb -2.767992, \u001b[31m   time: 1.594065 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.162499 (-1.975160)\n",
      "\u001b[0m\n",
      "it 692/2000, vlb -2.772495, \u001b[31m   time: 1.540993 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.171323 (-1.975160)\n",
      "\u001b[0m\n",
      "it 693/2000, vlb -2.742535, \u001b[31m   time: 1.469968 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.105886 (-1.975160)\n",
      "\u001b[0m\n",
      "it 694/2000, vlb -2.736861, \u001b[31m   time: 1.570309 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.069703 (-1.975160)\n",
      "\u001b[0m\n",
      "it 695/2000, vlb -2.737484, \u001b[31m   time: 1.607017 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.258719 (-1.975160)\n",
      "\u001b[0m\n",
      "it 696/2000, vlb -2.739632, \u001b[31m   time: 1.539764 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.267766 (-1.975160)\n",
      "\u001b[0m\n",
      "it 697/2000, vlb -2.776872, \u001b[31m   time: 1.542049 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.076485 (-1.975160)\n",
      "\u001b[0m\n",
      "it 698/2000, vlb -2.751950, \u001b[31m   time: 1.907136 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.175313 (-1.975160)\n",
      "\u001b[0m\n",
      "it 699/2000, vlb -2.719091, \u001b[31m   time: 1.552028 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.163549 (-1.975160)\n",
      "\u001b[0m\n",
      "it 700/2000, vlb -2.754156, \u001b[31m   time: 1.544435 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.240514 (-1.975160)\n",
      "\u001b[0m\n",
      "it 701/2000, vlb -2.754448, \u001b[31m   time: 1.548122 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.176939 (-1.975160)\n",
      "\u001b[0m\n",
      "it 702/2000, vlb -2.776037, \u001b[31m   time: 1.532225 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.089586 (-1.975160)\n",
      "\u001b[0m\n",
      "it 703/2000, vlb -2.760118, \u001b[31m   time: 1.543640 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.137709 (-1.975160)\n",
      "\u001b[0m\n",
      "it 704/2000, vlb -2.699171, \u001b[31m   time: 1.580025 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.267769 (-1.975160)\n",
      "\u001b[0m\n",
      "it 705/2000, vlb -2.732102, \u001b[31m   time: 1.562530 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.250859 (-1.975160)\n",
      "\u001b[0m\n",
      "it 706/2000, vlb -2.703080, \u001b[31m   time: 1.551210 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.031368 (-1.975160)\n",
      "\u001b[0m\n",
      "it 707/2000, vlb -2.763584, \u001b[31m   time: 1.545522 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.024139 (-1.975160)\n",
      "\u001b[0m\n",
      "it 708/2000, vlb -2.782598, \u001b[31m   time: 1.529830 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.022077 (-1.975160)\n",
      "\u001b[0m\n",
      "it 709/2000, vlb -2.770707, \u001b[31m   time: 1.521844 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.150287 (-1.975160)\n",
      "\u001b[0m\n",
      "it 710/2000, vlb -2.709419, \u001b[31m   time: 1.662829 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.180403 (-1.975160)\n",
      "\u001b[0m\n",
      "it 711/2000, vlb -2.766720, \u001b[31m   time: 1.562798 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.049983 (-1.975160)\n",
      "\u001b[0m\n",
      "it 712/2000, vlb -2.776569, \u001b[31m   time: 1.574162 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.075694 (-1.975160)\n",
      "\u001b[0m\n",
      "it 713/2000, vlb -2.724744, \u001b[31m   time: 1.564192 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.148002 (-1.975160)\n",
      "\u001b[0m\n",
      "it 714/2000, vlb -2.778778, \u001b[31m   time: 1.530068 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.203485 (-1.975160)\n",
      "\u001b[0m\n",
      "it 715/2000, vlb -2.763157, \u001b[31m   time: 1.514639 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.196639 (-1.975160)\n",
      "\u001b[0m\n",
      "it 716/2000, vlb -2.731527, \u001b[31m   time: 1.558468 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.210929 (-1.975160)\n",
      "\u001b[0m\n",
      "it 717/2000, vlb -2.804072, \u001b[31m   time: 1.591156 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.048808 (-1.975160)\n",
      "\u001b[0m\n",
      "it 718/2000, vlb -2.788378, \u001b[31m   time: 1.523035 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.228407 (-1.975160)\n",
      "\u001b[0m\n",
      "it 719/2000, vlb -2.754767, \u001b[31m   time: 1.549770 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.193894 (-1.975160)\n",
      "\u001b[0m\n",
      "it 720/2000, vlb -2.815820, \u001b[31m   time: 1.485988 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.115681 (-1.975160)\n",
      "\u001b[0m\n",
      "it 721/2000, vlb -2.773324, \u001b[31m   time: 1.543324 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.263872 (-1.975160)\n",
      "\u001b[0m\n",
      "it 722/2000, vlb -2.703255, \u001b[31m   time: 1.542026 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.188062 (-1.975160)\n",
      "\u001b[0m\n",
      "it 723/2000, vlb -2.730731, \u001b[31m   time: 1.632640 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.075263 (-1.975160)\n",
      "\u001b[0m\n",
      "it 724/2000, vlb -2.769641, \u001b[31m   time: 1.636657 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.147385 (-1.975160)\n",
      "\u001b[0m\n",
      "it 725/2000, vlb -2.686718, \u001b[31m   time: 1.628385 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.108491 (-1.975160)\n",
      "\u001b[0m\n",
      "it 726/2000, vlb -2.687730, \u001b[31m   time: 1.545842 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.144423 (-1.975160)\n",
      "\u001b[0m\n",
      "it 727/2000, vlb -2.767200, \u001b[31m   time: 1.583481 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.175154 (-1.975160)\n",
      "\u001b[0m\n",
      "it 728/2000, vlb -2.727595, \u001b[31m   time: 1.558440 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.170112 (-1.975160)\n",
      "\u001b[0m\n",
      "it 729/2000, vlb -2.745755, \u001b[31m   time: 1.559168 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.174432 (-1.975160)\n",
      "\u001b[0m\n",
      "it 730/2000, vlb -2.761088, \u001b[31m   time: 1.526844 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.234552 (-1.975160)\n",
      "\u001b[0m\n",
      "it 731/2000, vlb -2.760742, \u001b[31m   time: 1.552241 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.089907 (-1.975160)\n",
      "\u001b[0m\n",
      "it 732/2000, vlb -2.712292, \u001b[31m   time: 1.845301 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.210465 (-1.975160)\n",
      "\u001b[0m\n",
      "it 733/2000, vlb -2.767631, \u001b[31m   time: 1.931917 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.162263 (-1.975160)\n",
      "\u001b[0m\n",
      "it 734/2000, vlb -2.709204, \u001b[31m   time: 2.473926 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.079774 (-1.975160)\n",
      "\u001b[0m\n",
      "it 735/2000, vlb -2.718445, \u001b[31m   time: 2.600424 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.211408 (-1.975160)\n",
      "\u001b[0m\n",
      "it 736/2000, vlb -2.799511, \u001b[31m   time: 2.052519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.121595 (-1.975160)\n",
      "\u001b[0m\n",
      "it 737/2000, vlb -2.722499, \u001b[31m   time: 1.745177 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.060263 (-1.975160)\n",
      "\u001b[0m\n",
      "it 738/2000, vlb -2.712944, \u001b[31m   time: 1.893594 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.002613 (-1.975160)\n",
      "\u001b[0m\n",
      "it 739/2000, vlb -2.725585, \u001b[31m   time: 1.715766 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -2.178837 (-1.975160)\n",
      "\u001b[0m\n",
      "it 740/2000, vlb -2.754018, \u001b[31m   time: 1.706073 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.104683 (-1.975160)\n",
      "\u001b[0m\n",
      "it 741/2000, vlb -2.793467, \u001b[31m   time: 1.831236 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.136558 (-1.975160)\n",
      "\u001b[0m\n",
      "it 742/2000, vlb -2.724116, \u001b[31m   time: 1.832630 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.155823 (-1.975160)\n",
      "\u001b[0m\n",
      "it 743/2000, vlb -2.776677, \u001b[31m   time: 1.577784 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.142561 (-1.975160)\n",
      "\u001b[0m\n",
      "it 744/2000, vlb -2.731278, \u001b[31m   time: 1.511984 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.179783 (-1.975160)\n",
      "\u001b[0m\n",
      "it 745/2000, vlb -2.766428, \u001b[31m   time: 1.553958 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.181906 (-1.975160)\n",
      "\u001b[0m\n",
      "it 746/2000, vlb -2.695700, \u001b[31m   time: 1.628538 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.263817 (-1.975160)\n",
      "\u001b[0m\n",
      "it 747/2000, vlb -2.765636, \u001b[31m   time: 1.544713 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.196851 (-1.975160)\n",
      "\u001b[0m\n",
      "it 748/2000, vlb -2.733151, \u001b[31m   time: 1.540051 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.204757 (-1.975160)\n",
      "\u001b[0m\n",
      "it 749/2000, vlb -2.767974, \u001b[31m   time: 1.575416 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.099112 (-1.975160)\n",
      "\u001b[0m\n",
      "it 750/2000, vlb -2.783411, \u001b[31m   time: 1.491974 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.172419 (-1.975160)\n",
      "\u001b[0m\n",
      "it 751/2000, vlb -2.765335, \u001b[31m   time: 1.551600 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.074686 (-1.975160)\n",
      "\u001b[0m\n",
      "it 752/2000, vlb -2.772519, \u001b[31m   time: 1.581517 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.211567 (-1.975160)\n",
      "\u001b[0m\n",
      "it 753/2000, vlb -2.749345, \u001b[31m   time: 1.576086 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.179068 (-1.975160)\n",
      "\u001b[0m\n",
      "it 754/2000, vlb -2.702454, \u001b[31m   time: 1.563667 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.205780 (-1.975160)\n",
      "\u001b[0m\n",
      "it 755/2000, vlb -2.698767, \u001b[31m   time: 1.609675 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.169598 (-1.975160)\n",
      "\u001b[0m\n",
      "it 756/2000, vlb -2.722524, \u001b[31m   time: 1.500272 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.171003 (-1.975160)\n",
      "\u001b[0m\n",
      "it 757/2000, vlb -2.744231, \u001b[31m   time: 1.545632 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.157506 (-1.975160)\n",
      "\u001b[0m\n",
      "it 758/2000, vlb -2.814070, \u001b[31m   time: 1.562126 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.171161 (-1.975160)\n",
      "\u001b[0m\n",
      "it 759/2000, vlb -2.768849, \u001b[31m   time: 1.575117 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.120196 (-1.975160)\n",
      "\u001b[0m\n",
      "it 760/2000, vlb -2.721692, \u001b[31m   time: 1.512113 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.128283 (-1.975160)\n",
      "\u001b[0m\n",
      "it 761/2000, vlb -2.756646, \u001b[31m   time: 1.555297 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.296221 (-1.975160)\n",
      "\u001b[0m\n",
      "it 762/2000, vlb -2.741950, \u001b[31m   time: 1.569609 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.152029 (-1.975160)\n",
      "\u001b[0m\n",
      "it 763/2000, vlb -2.706170, \u001b[31m   time: 1.547415 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.283146 (-1.975160)\n",
      "\u001b[0m\n",
      "it 764/2000, vlb -2.719313, \u001b[31m   time: 1.533024 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.145221 (-1.975160)\n",
      "\u001b[0m\n",
      "it 765/2000, vlb -2.744378, \u001b[31m   time: 1.589919 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.024134 (-1.975160)\n",
      "\u001b[0m\n",
      "it 766/2000, vlb -2.793226, \u001b[31m   time: 1.580674 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.129735 (-1.975160)\n",
      "\u001b[0m\n",
      "it 767/2000, vlb -2.721844, \u001b[31m   time: 1.523157 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.159519 (-1.975160)\n",
      "\u001b[0m\n",
      "it 768/2000, vlb -2.752603, \u001b[31m   time: 1.589997 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.214256 (-1.975160)\n",
      "\u001b[0m\n",
      "it 769/2000, vlb -2.732224, \u001b[31m   time: 1.533649 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.222257 (-1.975160)\n",
      "\u001b[0m\n",
      "it 770/2000, vlb -2.742622, \u001b[31m   time: 1.541227 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.139698 (-1.975160)\n",
      "\u001b[0m\n",
      "it 771/2000, vlb -2.725018, \u001b[31m   time: 1.594531 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.191515 (-1.975160)\n",
      "\u001b[0m\n",
      "it 772/2000, vlb -2.757290, \u001b[31m   time: 1.566713 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.230261 (-1.975160)\n",
      "\u001b[0m\n",
      "it 773/2000, vlb -2.722503, \u001b[31m   time: 1.546617 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.092519 (-1.975160)\n",
      "\u001b[0m\n",
      "it 774/2000, vlb -2.708713, \u001b[31m   time: 1.568097 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.124314 (-1.975160)\n",
      "\u001b[0m\n",
      "it 775/2000, vlb -2.726315, \u001b[31m   time: 1.549490 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.252513 (-1.975160)\n",
      "\u001b[0m\n",
      "it 776/2000, vlb -2.778089, \u001b[31m   time: 1.551802 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.089588 (-1.975160)\n",
      "\u001b[0m\n",
      "it 777/2000, vlb -2.700249, \u001b[31m   time: 1.544539 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.020285 (-1.975160)\n",
      "\u001b[0m\n",
      "it 778/2000, vlb -2.696139, \u001b[31m   time: 1.562051 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.186808 (-1.975160)\n",
      "\u001b[0m\n",
      "it 779/2000, vlb -2.741745, \u001b[31m   time: 1.545900 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.199665 (-1.975160)\n",
      "\u001b[0m\n",
      "it 780/2000, vlb -2.732980, \u001b[31m   time: 1.540474 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.120168 (-1.975160)\n",
      "\u001b[0m\n",
      "it 781/2000, vlb -2.743898, \u001b[31m   time: 1.589640 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.141574 (-1.975160)\n",
      "\u001b[0m\n",
      "it 782/2000, vlb -2.718095, \u001b[31m   time: 1.697612 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.211616 (-1.975160)\n",
      "\u001b[0m\n",
      "it 783/2000, vlb -2.727877, \u001b[31m   time: 1.571266 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.142416 (-1.975160)\n",
      "\u001b[0m\n",
      "it 784/2000, vlb -2.727924, \u001b[31m   time: 1.696489 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.147714 (-1.975160)\n",
      "\u001b[0m\n",
      "it 785/2000, vlb -2.807432, \u001b[31m   time: 1.597839 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -2.094019 (-1.975160)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW_compas_models/theta_last.dat\n",
      "\u001b[0m\n",
      "\u001b[31m   average time: 0.704117 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m\n",
      "RESULTS:\u001b[0m\n",
      "  best_vlb_dev: 0.000000\n",
      "  best_vlb_train: 0.000000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'humansize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/1655356068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                           cuda=cuda, flatten=False)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m vlb_train, vlb_dev = train_VAEAC(net, masker, save_dir, batch_size, nb_epochs, trainset, valset, cuda,\n\u001b[0m\u001b[1;32m     32\u001b[0m                      flat_ims=False, train_plot=False, Nclass=None, early_stop=early_stop)\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/4196670429.py\u001b[0m in \u001b[0;36mtrain_VAEAC\u001b[0;34m(net, masker, name, batch_size, nb_epochs, trainset, valset, cuda, flat_ims, train_plot, Nclass, early_stop, script_mode)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# print('  best_iwlb_dev: %f' % best_iw_dev)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  best_vlb_train: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_cost_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  nb_parameters: %d (%s)\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhumansize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m## ---------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'humansize' is not defined"
     ]
    }
   ],
   "source": [
    "masker = top_masker(p=1)\n",
    "\n",
    "x_train, x_test, x_means, x_stds, y_train, y_test, feature_names, X_dims = \\\n",
    "    get_my_COMPAS(rseed=42, separate_test=True, test_ratio=0.1, save_dir='../data/')\n",
    "x_train, x_test, input_dim_vec = join_compas_targets(x_train, x_test, y_train, y_test, X_dims)\n",
    "print('Compas', x_train.shape, x_test.shape)\n",
    "print(input_dim_vec)\n",
    "\n",
    "dname = 'compas'\n",
    "print(dname)\n",
    "\n",
    "trainset = Datafeed(x_train, x_train, transform=None)\n",
    "valset = Datafeed(x_test, x_test, transform=None)\n",
    "\n",
    "save_dir = '../saves/fc_preact_VAEAC_NEW_' + dname\n",
    "\n",
    "width = widths[names.index(dname)]\n",
    "depth = depths[names.index(dname)] # number of hidden layers\n",
    "latent_dim = latent_dims[names.index(dname)]\n",
    "\n",
    "batch_size = 128\n",
    "nb_epochs = 2000\n",
    "early_stop = 200\n",
    "lr = 1e-4\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "net = VAEAC_gauss_cat_net(input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=lr,\n",
    "                          cuda=cuda, flatten=False)\n",
    "\n",
    "vlb_train, vlb_dev = train_VAEAC(net, masker, save_dir, batch_size, nb_epochs, trainset, valset, cuda,\n",
    "                     flat_ims=False, train_plot=False, Nclass=None, early_stop=early_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0318b9",
   "metadata": {},
   "source": [
    "## Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d719bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "(27000, 24)\n",
      "(3000, 24)\n",
      "default_credit\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mVAE_gauss_net\u001b[0m\n",
      "    Total params: 0.80M\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n",
      "  init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/1070947545.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/2000, vlb -19.182486, \u001b[31m   time: 16.533756 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.254449 (-inf)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW2_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/2000, vlb -11.698959, \u001b[31m   time: 18.969596 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.840795 (-9.254449)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW2_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 2/2000, vlb -10.394569, \u001b[31m   time: 15.788894 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.176111 (-7.840795)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW2_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 3/2000, vlb -9.829430, \u001b[31m   time: 17.466390 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.881644 (-7.176111)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW2_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 4/2000, vlb -9.581752, \u001b[31m   time: 16.366702 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.702829 (-6.881644)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_preact_VAEAC_NEW2_default_credit_models/theta_best.dat\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/1230764105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m vlb_train, vlb_dev = train_VAEAC(net, masker, save_dir, batch_size, nb_epochs, trainset, valset, cuda,\n\u001b[0m\u001b[1;32m     38\u001b[0m                      flat_ims=False, train_plot=False, Nclass=None, early_stop=early_stop)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/4196670429.py\u001b[0m in \u001b[0;36mtrain_VAEAC\u001b[0;34m(net, masker, name, batch_size, nb_epochs, trainset, valset, cuda, flat_ims, train_plot, Nclass, early_stop, script_mode)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mvlb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/1958406935.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mapprox_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognition_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapprox_post\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/2369653937.py\u001b[0m in \u001b[0;36mprior_encode\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mprior_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_parse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/3151266841.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_31096/3581392151.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreact_leaky_MLPBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "masker = top_masker(p=1)\n",
    "\n",
    "x_train, x_test, x_means, x_stds = \\\n",
    "load_UCI(dset_name='default_credit', splits=10, seed=42, separate_targets=False, save_dir='../data/')\n",
    "\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2] #has this form for targets\n",
    "print(input_dim_vec)\n",
    "\n",
    "x_train = unnormalise_cat_vars(x_train, x_means, x_stds, input_dim_vec)\n",
    "x_test = unnormalise_cat_vars(x_test, x_means, x_stds, input_dim_vec)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "dname = 'default_credit'\n",
    "print(dname)\n",
    "\n",
    "trainset = Datafeed(x_train, x_train, transform=None)\n",
    "valset = Datafeed(x_test, x_test, transform=None)\n",
    "\n",
    "save_dir = '../saves/fc_preact_VAEAC_NEW2_' + dname\n",
    "\n",
    "width = widths[names.index(dname)]\n",
    "depth = depths[names.index(dname)] # number of hidden layers\n",
    "latent_dim = latent_dims[names.index(dname)]\n",
    "\n",
    "batch_size = 64\n",
    "nb_epochs = 2000\n",
    "early_stop = 200\n",
    "lr = 7e-4\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "net = VAEAC_gauss_cat_net(input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=lr, cuda=cuda, flatten=True)\n",
    "\n",
    "\n",
    "vlb_train, vlb_dev = train_VAEAC(net, masker, save_dir, batch_size, nb_epochs, trainset, valset, cuda,\n",
    "                     flat_ims=False, train_plot=False, Nclass=None, early_stop=early_stop)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91578089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72bdadb1",
   "metadata": {},
   "source": [
    "## Under VAEAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd078b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_gauss(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim, pred_sig=True):\n",
    "        super(VAE_gauss, self).__init__()\n",
    "\n",
    "        self.encoder = MLP_preact_recognition_net(input_dim, width, depth, latent_dim)\n",
    "        if pred_sig:\n",
    "            self.decoder = MLP_preact_generator_net(2*input_dim, width, depth, latent_dim)\n",
    "            self.rec_loglike = GaussianLoglike(min_sigma=1e-2)\n",
    "        else:\n",
    "            self.decoder = MLP_preact_generator_net(input_dim, width, depth, latent_dim)\n",
    "            self.m_rec_loglike = MSELoss(reduction='none')\n",
    "        self.pred_sig = pred_sig\n",
    "\n",
    "    def encode(self, x):\n",
    "        approx_post_params = self.encoder(x)\n",
    "        approx_post = normal_parse_params(approx_post_params, 1e-3)\n",
    "        return approx_post\n",
    "\n",
    "    def decode(self, z_sample):\n",
    "        rec_params = self.decoder(z_sample)\n",
    "        return rec_params\n",
    "\n",
    "    def vlb(self, prior, approx_post, x, rec_params):\n",
    "        if self.pred_sig:\n",
    "            rec = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        else:\n",
    "            rec = -self.m_rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "        kl = kl_divergence(approx_post, prior).view(x.shape[0], -1).sum(-1)\n",
    "        return rec - kl\n",
    "\n",
    "    def iwlb(self, prior, approx_post, x, K=50):\n",
    "        estimates = []\n",
    "        for i in range(K):\n",
    "            latent = approx_post.rsample()\n",
    "            rec_params = self.decode(latent)\n",
    "            if self.pred_sig:\n",
    "                rec_loglike = self.rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "            else:\n",
    "                rec_loglike = -self.m_rec_loglike(rec_params, x).view(x.shape[0], -1).sum(-1)\n",
    "\n",
    "            prior_log_prob = prior.log_prob(latent)\n",
    "            prior_log_prob = prior_log_prob.view(x.shape[0], -1)\n",
    "            prior_log_prob = prior_log_prob.sum(-1)\n",
    "\n",
    "            proposal_log_prob = approx_post.log_prob(latent)\n",
    "            proposal_log_prob = proposal_log_prob.view(x.shape[0], -1)\n",
    "            proposal_log_prob = proposal_log_prob.sum(-1)\n",
    "\n",
    "            estimate = rec_loglike + prior_log_prob - proposal_log_prob\n",
    "            estimates.append(estimate[:, None])\n",
    "\n",
    "        return torch.logsumexp(torch.cat(estimates, 1), 1) - np.log(K)\n",
    "\n",
    "\n",
    "class VAE_gauss_net(BaseNet):\n",
    "    def __init__(self, input_dim, width, depth, latent_dim, pred_sig=True, lr=1e-3, cuda=True):\n",
    "        super(VAE_gauss_net, self).__init__()\n",
    "        cprint('y', 'VAE_gauss_net')\n",
    "\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.pred_sig = pred_sig\n",
    "\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "        self.schedule = None\n",
    "\n",
    "        if self.cuda:\n",
    "            self.prior = self.prior = Normal(loc=torch.zeros(latent_dim).cuda(), scale=torch.ones(latent_dim).cuda())\n",
    "        else:\n",
    "            self.prior = Normal(loc=torch.zeros(latent_dim), scale=torch.ones(latent_dim))\n",
    "        self.vlb_scale = 1 / input_dim  # scale for dimensions of input so we can use same LR always\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        self.model = VAE_gauss(self.input_dim, self.width, self.depth, self.latent_dim, self.pred_sig)\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = RAdam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def fit(self, x):\n",
    "        self.set_mode_train(train=True)\n",
    "\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        approx_post = self.model.encode(x)\n",
    "        z_sample = approx_post.rsample()\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(self.prior, approx_post, x, rec_params)\n",
    "        loss = (- vlb * self.vlb_scale).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return vlb.mean().item(), rec_params\n",
    "\n",
    "    def eval(self, x, sample=False):\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        approx_post = self.model.encode(x)\n",
    "        if sample:\n",
    "            z_sample = approx_post.sample()\n",
    "        else:\n",
    "            z_sample = approx_post.loc\n",
    "        rec_params = self.model.decode(z_sample)\n",
    "\n",
    "        vlb = self.model.vlb(self.prior, approx_post, x, rec_params)\n",
    "\n",
    "        return vlb.mean().item(), rec_params\n",
    "\n",
    "    def eval_iw(self, x, k=50):\n",
    "        self.set_mode_train(train=False)\n",
    "        x,  = to_variable(var=(x, ), cuda=self.cuda)\n",
    "\n",
    "        approx_post = self.model.recognition_encode(x)\n",
    "\n",
    "        iw_lb = self.model.iwlb(self.prior, approx_post, x, k)\n",
    "        return iw_lb.mean().item()\n",
    "\n",
    "    def recongnition(self, x, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "        else:\n",
    "            x, = to_variable(var=(x,), volatile=True, cuda=self.cuda)\n",
    "        approx_post = self.model.encode(x)\n",
    "        return approx_post\n",
    "\n",
    "    def regenerate(self, z, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not z.requires_grad:\n",
    "                z.requires_grad = True\n",
    "        else:\n",
    "            z, = to_variable(var=(z,), volatile=True, cuda=self.cuda)\n",
    "        out = self.model.decode(z)\n",
    "        if self.pred_sig:\n",
    "            return normal_parse_params(out, 1e-2)\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a15675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(net, name, batch_size, nb_epochs, trainset, valset, cuda, flat_ims=False,\n",
    "              train_plot=False, Nclass=None, early_stop=None, script_mode=False):\n",
    "\n",
    "    models_dir = name + '_models'\n",
    "    results_dir = name + '_results'\n",
    "    mkdir(models_dir)\n",
    "    mkdir(results_dir)\n",
    "\n",
    "    if cuda:\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                                  num_workers=0)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "    else:\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                                  num_workers=0)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                                num_workers=0)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "    cprint('c', '\\nNetwork:')\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # train\n",
    "    cprint('c', '\\nTrain:')\n",
    "\n",
    "    print('  init cost variables:')\n",
    "    vlb_train = np.zeros(nb_epochs)\n",
    "    vlb_dev = np.zeros(nb_epochs)\n",
    "    best_vlb = -np.inf\n",
    "    best_vlb_train = -np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    nb_its_dev = 1\n",
    "\n",
    "    tic0 = time.time()\n",
    "    for i in range(epoch, nb_epochs):\n",
    "        net.set_mode_train(True)\n",
    "\n",
    "        tic = time.time()\n",
    "        nb_samples = 0\n",
    "        for x, y in trainloader:\n",
    "\n",
    "            if flat_ims:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "            if Nclass is not None:\n",
    "                y_oh = torch_onehot(y, Nclass).type(x.type())\n",
    "                x = torch.cat([x, y_oh], 1)\n",
    "\n",
    "            cost, _ = net.fit(x)\n",
    "\n",
    "            vlb_train[i] += cost * len(x)\n",
    "            nb_samples += len(x)\n",
    "\n",
    "        vlb_train[i] /= nb_samples\n",
    "\n",
    "        toc = time.time()\n",
    "\n",
    "        # ---- print\n",
    "        print(\"it %d/%d, vlb %f, \" % (i, nb_epochs, vlb_train[i]), end=\"\")\n",
    "        cprint('r', '   time: %f seconds\\n' % (toc - tic))\n",
    "        net.update_lr(i)\n",
    "\n",
    "        if vlb_train[i] > best_vlb_train:\n",
    "            best_vlb_train = vlb_train[i]\n",
    "\n",
    "        # ---- dev\n",
    "        if i % nb_its_dev == 0:\n",
    "            nb_samples = 0\n",
    "            for j, (x, y) in enumerate(valloader):\n",
    "\n",
    "                if flat_ims:\n",
    "                    x = x.view(x.shape[0], -1)\n",
    "                if Nclass is not None:\n",
    "                    y_oh = torch_onehot(y, Nclass).type(x.type())\n",
    "                    x = torch.cat([x, y_oh], 1)\n",
    "\n",
    "                cost, _ = net.eval(x)\n",
    "\n",
    "                vlb_dev[i] += cost * len(x)\n",
    "                nb_samples += len(x)\n",
    "\n",
    "            vlb_dev[i] /= nb_samples\n",
    "\n",
    "            cprint('g', '    vlb %f (%f)\\n' % (vlb_dev[i], best_vlb))\n",
    "\n",
    "            if train_plot:\n",
    "                zz = net.recongnition(x).sample()\n",
    "                o = net.regenerate(zz)\n",
    "                try:\n",
    "                    o = o.cpu()\n",
    "                except:\n",
    "                    o = o.loc.cpu()\n",
    "                if len(x.shape) == 2:\n",
    "                    side = int(np.sqrt(x.shape[1]))\n",
    "                    x = x.view(-1, 1, side, side).data\n",
    "                    o = o.view(-1, 1, side, side).data\n",
    "\n",
    "                # save_image(torch.cat([x[:8], o[:8]]), results_dir + '/rec_%d.png' % i, nrow=8)\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                dd = make_grid(torch.cat([x[:10], o[:10]]), nrow=10).numpy()\n",
    "                plt.imshow(np.transpose(dd, (1, 2, 0)), interpolation='nearest')\n",
    "                if script_mode:\n",
    "                    plt.savefig(results_dir + '/rec%d.png' % i)\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "                z_sample = normal(loc=0.0, scale=1.0, size=(36, net.latent_dim))\n",
    "                x_rec = net.regenerate(z_sample)\n",
    "                try:\n",
    "                    x_rec = x_rec.cpu()\n",
    "                except:\n",
    "                    x_rec = x_rec.loc.cpu()\n",
    "                if len(x_rec.shape) == 2:\n",
    "                    side = int(np.sqrt(x_rec.shape[1]))\n",
    "                    x_rec = x_rec.view(-1, 1, side, side)\n",
    "                plt.figure()\n",
    "                dd = make_grid(x_rec, nrow=6).numpy()\n",
    "                plt.imshow(np.transpose(dd, (1, 2, 0)), interpolation='nearest')\n",
    "                if script_mode:\n",
    "                    plt.savefig(results_dir + '/sample%d.png' % i)\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "        if vlb_dev[i] > best_vlb:\n",
    "            best_vlb = vlb_dev[i]\n",
    "            best_epoch = i\n",
    "            net.save(models_dir + '/theta_best.dat')\n",
    "\n",
    "        if early_stop is not None and (i - best_epoch) > early_stop:\n",
    "            break\n",
    "\n",
    "\n",
    "    net.save(models_dir + '/theta_last.dat')\n",
    "    toc0 = time.time()\n",
    "    runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n",
    "    cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # results\n",
    "    cprint('c', '\\nRESULTS:')\n",
    "    nb_parameters = net.get_nb_parameters()\n",
    "    best_cost_dev = best_vlb\n",
    "    best_cost_train = best_vlb_train\n",
    "\n",
    "    print('  best_vlb_dev: %f' % best_cost_dev)\n",
    "    print('  best_vlb_train: %f' % best_cost_train)\n",
    "    print('  nb_parameters: %d (%s)\\n' % (nb_parameters, humansize(nb_parameters)))\n",
    "\n",
    "    ## ---------------------------------------------------------------------------------------------------------------------\n",
    "    # fig cost vs its\n",
    "    if not train_plot:\n",
    "        import matplotlib\n",
    "        matplotlib.use('agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    if train_plot:\n",
    "        plt.figure()\n",
    "        plt.plot(np.clip(vlb_train, -1000, 1000), 'r')\n",
    "        plt.plot(np.clip(vlb_dev[::nb_its_dev], -1000, 1000), 'b')\n",
    "        plt.legend(['cost_train', 'cost_dev'])\n",
    "        plt.ylabel('vlb')\n",
    "        plt.xlabel('it')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(results_dir+'/train_cost.png')\n",
    "        if train_plot:\n",
    "            plt.show()\n",
    "    return vlb_train, vlb_dev\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c04fea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class under_VAEAC(BaseNet):\n",
    "    def __init__(self, base_VAE, width, depth, latent_dim, lr=1e-3, cuda=True):\n",
    "        super(under_VAEAC, self).__init__()\n",
    "        cprint('y', 'VAE_gauss_net')\n",
    "\n",
    "        self.base_VAEAC = base_VAE\n",
    "        self.pred_sig = False\n",
    "\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.input_dim = self.base_VAEAC.latent_dim\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "        self.schedule = None\n",
    "\n",
    "        if self.cuda:\n",
    "            self.prior = self.prior = Normal(loc=torch.zeros(latent_dim).cuda(), scale=torch.ones(latent_dim).cuda())\n",
    "        else:\n",
    "            self.prior = Normal(loc=torch.zeros(latent_dim), scale=torch.ones(latent_dim))\n",
    "        self.vlb_scale = 1 / self.input_dim  # scale for dimensions of input so we can use same LR always\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        self.model = VAE_gauss(self.input_dim, self.width, self.depth, self.latent_dim, self.pred_sig)\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def fit(self, x):\n",
    "        self.set_mode_train(train=True)\n",
    "\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        z_sample = self.base_VAEAC.recognition_encode(x).sample()\n",
    "        approx_post = self.model.encode(z_sample)\n",
    "        u_sample = approx_post.rsample()\n",
    "        rec_params = self.model.decode(u_sample)\n",
    "\n",
    "        vlb = self.model.vlb(self.prior, approx_post, z_sample, rec_params)\n",
    "        loss = (- vlb * self.vlb_scale).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return vlb.mean().item(), rec_params\n",
    "\n",
    "    def eval(self, x):\n",
    "\n",
    "        self.set_mode_train(train=False)\n",
    "\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        z_sample = self.base_VAEAC.recognition_encode(x).sample()\n",
    "        approx_post = self.model.encode(z_sample)\n",
    "        u_sample = approx_post.rsample()\n",
    "        rec_params = self.model.decode(u_sample)\n",
    "\n",
    "        vlb = self.model.vlb(self.prior, approx_post, z_sample, rec_params)\n",
    "\n",
    "        return vlb.mean().item(), rec_params\n",
    "\n",
    "    def eval_iw(self, x, k=50):\n",
    "        self.set_mode_train(train=False)\n",
    "        x,  = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        z_sample = self.base_VAEAC.recognition_encode(x).sample()\n",
    "        approx_post = self.model.recognition_encode(z_sample)\n",
    "\n",
    "        iw_lb = self.model.iwlb(self.prior, approx_post, z_sample, k)\n",
    "        return iw_lb.mean().item()\n",
    "\n",
    "    def recongnition(self, x, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "        else:\n",
    "            x, = to_variable(var=(x,), volatile=True, cuda=self.cuda)\n",
    "        approx_post = self.model.encode(x)\n",
    "        return approx_post\n",
    "\n",
    "    def regenerate(self, z, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not z.requires_grad:\n",
    "                z.requires_grad = True\n",
    "        else:\n",
    "            z, = to_variable(var=(z,), volatile=True, cuda=self.cuda)\n",
    "        out = self.model.decode(z)\n",
    "        return out.data\n",
    "\n",
    "    def u_recongnition(self, x, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "        else:\n",
    "            x, = to_variable(var=(x,), volatile=True, cuda=self.cuda)\n",
    "\n",
    "        z = self.base_VAEAC.recognition_encode(x).loc\n",
    "        approx_post = self.model.encode(z)\n",
    "        return approx_post\n",
    "\n",
    "    def u_mask_recongnition(self, x, mask, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "            mask, = to_variable(var=(mask, ), cuda=self.cuda)\n",
    "        else:\n",
    "            x, mask = to_variable(var=(x, mask), cuda=self.cuda)\n",
    "\n",
    "        z = self.base_VAEAC.prior_encode(x, mask).loc\n",
    "        approx_post = self.model.encode(z)\n",
    "        return approx_post\n",
    "\n",
    "    def u_regenerate(self, u, grad=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        if grad:\n",
    "            if not u.requires_grad:\n",
    "                u.requires_grad = True\n",
    "        else:\n",
    "            u, = to_variable(var=(u,), volatile=True, cuda=self.cuda)\n",
    "\n",
    "        z = self.model.decode(u)\n",
    "        out = self.base_VAEAC.decode(z)\n",
    "        if self.base_VAEAC.pred_sig:\n",
    "            return normal_parse_params(out, 1e-2)\n",
    "        else:\n",
    "            return out.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac94e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compas (5554, 19) (618, 19)\n",
      "[3 6 2 2 2 1 1 2]\n",
      "compas\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mVAE_gauss_net\u001b[0m\n",
      "    Total params: 0.08M\n",
      "\u001b[36mReading ../saves/fc_preact_VAEAC_NEW_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "  restoring epoch: 585, lr: 0.000100\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mVAE_gauss_net\u001b[0m\n",
      "    Total params: 0.05M\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n",
      "  init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_17901/1070947545.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/2000, vlb -14.701037, \u001b[31m   time: 0.784924 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -11.398861 (-inf)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/2000, vlb -10.097281, \u001b[31m   time: 0.645048 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -9.089679 (-11.398861)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 2/2000, vlb -8.366908, \u001b[31m   time: 0.632210 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.923545 (-9.089679)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 3/2000, vlb -7.598868, \u001b[31m   time: 0.562514 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.292997 (-7.923545)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 4/2000, vlb -7.387952, \u001b[31m   time: 0.750483 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.290502 (-7.292997)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 5/2000, vlb -7.300517, \u001b[31m   time: 0.669122 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.916430 (-7.290502)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 6/2000, vlb -7.153251, \u001b[31m   time: 0.910711 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.047253 (-6.916430)\n",
      "\u001b[0m\n",
      "it 7/2000, vlb -7.121366, \u001b[31m   time: 0.693296 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.951069 (-6.916430)\n",
      "\u001b[0m\n",
      "it 8/2000, vlb -7.057754, \u001b[31m   time: 0.540883 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -7.122017 (-6.916430)\n",
      "\u001b[0m\n",
      "it 9/2000, vlb -7.033934, \u001b[31m   time: 0.527526 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.805869 (-6.916430)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 10/2000, vlb -6.985825, \u001b[31m   time: 0.527304 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.701673 (-6.805869)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 11/2000, vlb -6.897507, \u001b[31m   time: 0.526775 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.574993 (-6.701673)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 12/2000, vlb -6.894179, \u001b[31m   time: 0.537015 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.670187 (-6.574993)\n",
      "\u001b[0m\n",
      "it 13/2000, vlb -6.818515, \u001b[31m   time: 0.529891 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.483544 (-6.574993)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 14/2000, vlb -6.687118, \u001b[31m   time: 0.533015 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.401055 (-6.483544)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 15/2000, vlb -6.668967, \u001b[31m   time: 0.526580 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.653291 (-6.401055)\n",
      "\u001b[0m\n",
      "it 16/2000, vlb -6.699790, \u001b[31m   time: 0.579959 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.406194 (-6.401055)\n",
      "\u001b[0m\n",
      "it 17/2000, vlb -6.591607, \u001b[31m   time: 0.584402 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.476365 (-6.401055)\n",
      "\u001b[0m\n",
      "it 18/2000, vlb -6.578250, \u001b[31m   time: 0.618774 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.538012 (-6.401055)\n",
      "\u001b[0m\n",
      "it 19/2000, vlb -6.554212, \u001b[31m   time: 0.527211 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.423792 (-6.401055)\n",
      "\u001b[0m\n",
      "it 20/2000, vlb -6.564198, \u001b[31m   time: 0.745000 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.598507 (-6.401055)\n",
      "\u001b[0m\n",
      "it 21/2000, vlb -6.448140, \u001b[31m   time: 0.933995 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.362984 (-6.401055)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 22/2000, vlb -6.439806, \u001b[31m   time: 1.025751 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.197454 (-6.362984)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 23/2000, vlb -6.379739, \u001b[31m   time: 1.021351 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.352121 (-6.197454)\n",
      "\u001b[0m\n",
      "it 24/2000, vlb -6.357132, \u001b[31m   time: 0.564359 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.335898 (-6.197454)\n",
      "\u001b[0m\n",
      "it 25/2000, vlb -6.401739, \u001b[31m   time: 0.543633 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.180095 (-6.197454)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 26/2000, vlb -6.319032, \u001b[31m   time: 1.340789 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.225343 (-6.180095)\n",
      "\u001b[0m\n",
      "it 27/2000, vlb -6.339602, \u001b[31m   time: 0.973916 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.246898 (-6.180095)\n",
      "\u001b[0m\n",
      "it 28/2000, vlb -6.260727, \u001b[31m   time: 1.603782 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.180725 (-6.180095)\n",
      "\u001b[0m\n",
      "it 29/2000, vlb -6.263765, \u001b[31m   time: 1.075768 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.025938 (-6.180095)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 30/2000, vlb -6.218257, \u001b[31m   time: 0.756071 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.083757 (-6.025938)\n",
      "\u001b[0m\n",
      "it 31/2000, vlb -6.211121, \u001b[31m   time: 0.930320 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.983557 (-6.025938)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 32/2000, vlb -6.225626, \u001b[31m   time: 0.799862 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.166002 (-5.983557)\n",
      "\u001b[0m\n",
      "it 33/2000, vlb -6.218015, \u001b[31m   time: 0.652331 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.165992 (-5.983557)\n",
      "\u001b[0m\n",
      "it 34/2000, vlb -6.227115, \u001b[31m   time: 0.633648 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.958838 (-5.983557)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 35/2000, vlb -6.200179, \u001b[31m   time: 0.523176 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.028883 (-5.958838)\n",
      "\u001b[0m\n",
      "it 36/2000, vlb -6.154027, \u001b[31m   time: 0.523510 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.060368 (-5.958838)\n",
      "\u001b[0m\n",
      "it 37/2000, vlb -6.151313, \u001b[31m   time: 0.535183 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.121877 (-5.958838)\n",
      "\u001b[0m\n",
      "it 38/2000, vlb -6.214512, \u001b[31m   time: 0.519793 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.033796 (-5.958838)\n",
      "\u001b[0m\n",
      "it 39/2000, vlb -6.199129, \u001b[31m   time: 0.526612 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.059789 (-5.958838)\n",
      "\u001b[0m\n",
      "it 40/2000, vlb -6.159418, \u001b[31m   time: 0.539350 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.951093 (-5.958838)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 41/2000, vlb -6.161637, \u001b[31m   time: 0.523400 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.102751 (-5.951093)\n",
      "\u001b[0m\n",
      "it 42/2000, vlb -6.192671, \u001b[31m   time: 0.650760 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.953614 (-5.951093)\n",
      "\u001b[0m\n",
      "it 43/2000, vlb -6.140363, \u001b[31m   time: 0.549723 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.033264 (-5.951093)\n",
      "\u001b[0m\n",
      "it 44/2000, vlb -6.148469, \u001b[31m   time: 0.581955 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.155905 (-5.951093)\n",
      "\u001b[0m\n",
      "it 45/2000, vlb -6.110888, \u001b[31m   time: 0.527723 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.015217 (-5.951093)\n",
      "\u001b[0m\n",
      "it 46/2000, vlb -6.188314, \u001b[31m   time: 0.524783 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.002004 (-5.951093)\n",
      "\u001b[0m\n",
      "it 47/2000, vlb -6.125612, \u001b[31m   time: 0.530143 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.009195 (-5.951093)\n",
      "\u001b[0m\n",
      "it 48/2000, vlb -6.157979, \u001b[31m   time: 0.529277 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.050209 (-5.951093)\n",
      "\u001b[0m\n",
      "it 49/2000, vlb -6.148269, \u001b[31m   time: 0.522658 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.087401 (-5.951093)\n",
      "\u001b[0m\n",
      "it 50/2000, vlb -6.132730, \u001b[31m   time: 0.528077 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.989377 (-5.951093)\n",
      "\u001b[0m\n",
      "it 51/2000, vlb -6.172958, \u001b[31m   time: 0.523272 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.952735 (-5.951093)\n",
      "\u001b[0m\n",
      "it 52/2000, vlb -6.143875, \u001b[31m   time: 0.518849 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.122985 (-5.951093)\n",
      "\u001b[0m\n",
      "it 53/2000, vlb -6.151714, \u001b[31m   time: 0.758795 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.015800 (-5.951093)\n",
      "\u001b[0m\n",
      "it 54/2000, vlb -6.160157, \u001b[31m   time: 0.903844 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.978299 (-5.951093)\n",
      "\u001b[0m\n",
      "it 55/2000, vlb -6.147172, \u001b[31m   time: 0.942200 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.990661 (-5.951093)\n",
      "\u001b[0m\n",
      "it 56/2000, vlb -6.095903, \u001b[31m   time: 0.660259 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.988316 (-5.951093)\n",
      "\u001b[0m\n",
      "it 57/2000, vlb -6.117849, \u001b[31m   time: 0.572480 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.047021 (-5.951093)\n",
      "\u001b[0m\n",
      "it 58/2000, vlb -6.092576, \u001b[31m   time: 0.527874 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.118358 (-5.951093)\n",
      "\u001b[0m\n",
      "it 59/2000, vlb -6.122056, \u001b[31m   time: 0.848730 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.952499 (-5.951093)\n",
      "\u001b[0m\n",
      "it 60/2000, vlb -6.107652, \u001b[31m   time: 0.536307 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.054821 (-5.951093)\n",
      "\u001b[0m\n",
      "it 61/2000, vlb -6.063589, \u001b[31m   time: 0.524716 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.017353 (-5.951093)\n",
      "\u001b[0m\n",
      "it 62/2000, vlb -6.135931, \u001b[31m   time: 0.661225 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.071136 (-5.951093)\n",
      "\u001b[0m\n",
      "it 63/2000, vlb -6.133053, \u001b[31m   time: 0.580329 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.918562 (-5.951093)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 64/2000, vlb -6.099116, \u001b[31m   time: 0.601670 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.923695 (-5.918562)\n",
      "\u001b[0m\n",
      "it 65/2000, vlb -6.092603, \u001b[31m   time: 0.739719 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -5.944459 (-5.918562)\n",
      "\u001b[0m\n",
      "it 66/2000, vlb -6.146011, \u001b[31m   time: 0.778199 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.880102 (-5.918562)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 67/2000, vlb -6.141405, \u001b[31m   time: 0.663560 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.003874 (-5.880102)\n",
      "\u001b[0m\n",
      "it 68/2000, vlb -6.139710, \u001b[31m   time: 0.598890 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.981514 (-5.880102)\n",
      "\u001b[0m\n",
      "it 69/2000, vlb -6.080537, \u001b[31m   time: 0.622848 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.951593 (-5.880102)\n",
      "\u001b[0m\n",
      "it 70/2000, vlb -6.146163, \u001b[31m   time: 0.627627 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.947422 (-5.880102)\n",
      "\u001b[0m\n",
      "it 71/2000, vlb -6.105737, \u001b[31m   time: 0.572939 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.899740 (-5.880102)\n",
      "\u001b[0m\n",
      "it 72/2000, vlb -6.109804, \u001b[31m   time: 0.527234 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.096789 (-5.880102)\n",
      "\u001b[0m\n",
      "it 73/2000, vlb -6.130235, \u001b[31m   time: 0.537746 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.973827 (-5.880102)\n",
      "\u001b[0m\n",
      "it 74/2000, vlb -6.104355, \u001b[31m   time: 0.563269 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.019366 (-5.880102)\n",
      "\u001b[0m\n",
      "it 75/2000, vlb -6.154775, \u001b[31m   time: 1.172286 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.889835 (-5.880102)\n",
      "\u001b[0m\n",
      "it 76/2000, vlb -6.127846, \u001b[31m   time: 1.692851 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.961782 (-5.880102)\n",
      "\u001b[0m\n",
      "it 77/2000, vlb -6.052824, \u001b[31m   time: 0.650645 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.904496 (-5.880102)\n",
      "\u001b[0m\n",
      "it 78/2000, vlb -6.084057, \u001b[31m   time: 0.655996 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.934965 (-5.880102)\n",
      "\u001b[0m\n",
      "it 79/2000, vlb -6.109952, \u001b[31m   time: 0.598711 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.007510 (-5.880102)\n",
      "\u001b[0m\n",
      "it 80/2000, vlb -6.092613, \u001b[31m   time: 0.611493 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.937535 (-5.880102)\n",
      "\u001b[0m\n",
      "it 81/2000, vlb -6.083019, \u001b[31m   time: 0.598402 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.909510 (-5.880102)\n",
      "\u001b[0m\n",
      "it 82/2000, vlb -6.118720, \u001b[31m   time: 0.577812 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.076282 (-5.880102)\n",
      "\u001b[0m\n",
      "it 83/2000, vlb -6.122903, \u001b[31m   time: 0.584256 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.936122 (-5.880102)\n",
      "\u001b[0m\n",
      "it 84/2000, vlb -6.112946, \u001b[31m   time: 0.666255 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.026385 (-5.880102)\n",
      "\u001b[0m\n",
      "it 85/2000, vlb -6.107060, \u001b[31m   time: 0.653787 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.980773 (-5.880102)\n",
      "\u001b[0m\n",
      "it 86/2000, vlb -6.088185, \u001b[31m   time: 0.656653 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.980981 (-5.880102)\n",
      "\u001b[0m\n",
      "it 87/2000, vlb -6.113957, \u001b[31m   time: 0.627869 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.031425 (-5.880102)\n",
      "\u001b[0m\n",
      "it 88/2000, vlb -6.075830, \u001b[31m   time: 0.644648 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.886681 (-5.880102)\n",
      "\u001b[0m\n",
      "it 89/2000, vlb -6.113735, \u001b[31m   time: 0.651637 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.951886 (-5.880102)\n",
      "\u001b[0m\n",
      "it 90/2000, vlb -6.081073, \u001b[31m   time: 0.594580 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.958853 (-5.880102)\n",
      "\u001b[0m\n",
      "it 91/2000, vlb -6.058083, \u001b[31m   time: 0.597488 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.936472 (-5.880102)\n",
      "\u001b[0m\n",
      "it 92/2000, vlb -6.113736, \u001b[31m   time: 0.780724 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.973117 (-5.880102)\n",
      "\u001b[0m\n",
      "it 93/2000, vlb -6.049870, \u001b[31m   time: 0.646261 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.832977 (-5.880102)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 94/2000, vlb -6.080860, \u001b[31m   time: 0.644865 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.980275 (-5.832977)\n",
      "\u001b[0m\n",
      "it 95/2000, vlb -6.071086, \u001b[31m   time: 0.593892 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.009345 (-5.832977)\n",
      "\u001b[0m\n",
      "it 96/2000, vlb -6.066060, \u001b[31m   time: 0.577507 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.914656 (-5.832977)\n",
      "\u001b[0m\n",
      "it 97/2000, vlb -6.057111, \u001b[31m   time: 0.617923 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.809683 (-5.832977)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 98/2000, vlb -6.096392, \u001b[31m   time: 0.646953 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.931837 (-5.809683)\n",
      "\u001b[0m\n",
      "it 99/2000, vlb -6.121412, \u001b[31m   time: 0.966812 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.948029 (-5.809683)\n",
      "\u001b[0m\n",
      "it 100/2000, vlb -6.069841, \u001b[31m   time: 0.713849 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.025108 (-5.809683)\n",
      "\u001b[0m\n",
      "it 101/2000, vlb -6.029894, \u001b[31m   time: 0.665502 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.030518 (-5.809683)\n",
      "\u001b[0m\n",
      "it 102/2000, vlb -6.112074, \u001b[31m   time: 0.564344 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.945414 (-5.809683)\n",
      "\u001b[0m\n",
      "it 103/2000, vlb -6.102894, \u001b[31m   time: 0.572825 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.911532 (-5.809683)\n",
      "\u001b[0m\n",
      "it 104/2000, vlb -6.073844, \u001b[31m   time: 0.928782 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.912081 (-5.809683)\n",
      "\u001b[0m\n",
      "it 105/2000, vlb -6.061396, \u001b[31m   time: 1.396566 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.995959 (-5.809683)\n",
      "\u001b[0m\n",
      "it 106/2000, vlb -6.099588, \u001b[31m   time: 0.879703 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.961440 (-5.809683)\n",
      "\u001b[0m\n",
      "it 107/2000, vlb -6.097634, \u001b[31m   time: 0.579470 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.985840 (-5.809683)\n",
      "\u001b[0m\n",
      "it 108/2000, vlb -6.065250, \u001b[31m   time: 0.972708 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.938907 (-5.809683)\n",
      "\u001b[0m\n",
      "it 109/2000, vlb -6.097832, \u001b[31m   time: 1.040226 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.894913 (-5.809683)\n",
      "\u001b[0m\n",
      "it 110/2000, vlb -6.069634, \u001b[31m   time: 1.079289 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.998092 (-5.809683)\n",
      "\u001b[0m\n",
      "it 111/2000, vlb -6.127787, \u001b[31m   time: 0.627599 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.835729 (-5.809683)\n",
      "\u001b[0m\n",
      "it 112/2000, vlb -6.086751, \u001b[31m   time: 0.515129 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.007981 (-5.809683)\n",
      "\u001b[0m\n",
      "it 113/2000, vlb -6.111319, \u001b[31m   time: 0.717198 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.990524 (-5.809683)\n",
      "\u001b[0m\n",
      "it 114/2000, vlb -6.066726, \u001b[31m   time: 0.807646 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.898330 (-5.809683)\n",
      "\u001b[0m\n",
      "it 115/2000, vlb -6.080757, \u001b[31m   time: 0.563217 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.049583 (-5.809683)\n",
      "\u001b[0m\n",
      "it 116/2000, vlb -6.084128, \u001b[31m   time: 0.522842 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.170220 (-5.809683)\n",
      "\u001b[0m\n",
      "it 117/2000, vlb -6.079027, \u001b[31m   time: 0.528642 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.923265 (-5.809683)\n",
      "\u001b[0m\n",
      "it 118/2000, vlb -6.103500, \u001b[31m   time: 0.783238 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.993928 (-5.809683)\n",
      "\u001b[0m\n",
      "it 119/2000, vlb -6.094628, \u001b[31m   time: 1.356659 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.892534 (-5.809683)\n",
      "\u001b[0m\n",
      "it 120/2000, vlb -6.067857, \u001b[31m   time: 1.390369 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.907021 (-5.809683)\n",
      "\u001b[0m\n",
      "it 121/2000, vlb -6.091933, \u001b[31m   time: 1.419241 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.755878 (-5.809683)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 122/2000, vlb -6.119149, \u001b[31m   time: 1.171003 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.911000 (-5.755878)\n",
      "\u001b[0m\n",
      "it 123/2000, vlb -6.069782, \u001b[31m   time: 0.804583 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.966330 (-5.755878)\n",
      "\u001b[0m\n",
      "it 124/2000, vlb -6.153586, \u001b[31m   time: 0.976380 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.954024 (-5.755878)\n",
      "\u001b[0m\n",
      "it 125/2000, vlb -6.050582, \u001b[31m   time: 1.583331 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.069723 (-5.755878)\n",
      "\u001b[0m\n",
      "it 126/2000, vlb -6.073446, \u001b[31m   time: 1.040272 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.010118 (-5.755878)\n",
      "\u001b[0m\n",
      "it 127/2000, vlb -6.056734, \u001b[31m   time: 1.479502 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.933624 (-5.755878)\n",
      "\u001b[0m\n",
      "it 128/2000, vlb -6.038244, \u001b[31m   time: 0.705100 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.951749 (-5.755878)\n",
      "\u001b[0m\n",
      "it 129/2000, vlb -6.049652, \u001b[31m   time: 0.772729 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.782378 (-5.755878)\n",
      "\u001b[0m\n",
      "it 130/2000, vlb -6.084754, \u001b[31m   time: 1.202366 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.942201 (-5.755878)\n",
      "\u001b[0m\n",
      "it 131/2000, vlb -6.025661, \u001b[31m   time: 1.071296 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.922940 (-5.755878)\n",
      "\u001b[0m\n",
      "it 132/2000, vlb -6.053543, \u001b[31m   time: 0.882606 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.879127 (-5.755878)\n",
      "\u001b[0m\n",
      "it 133/2000, vlb -6.076312, \u001b[31m   time: 0.864466 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.927863 (-5.755878)\n",
      "\u001b[0m\n",
      "it 134/2000, vlb -6.114104, \u001b[31m   time: 0.550889 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.976762 (-5.755878)\n",
      "\u001b[0m\n",
      "it 135/2000, vlb -6.056064, \u001b[31m   time: 0.827433 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.848686 (-5.755878)\n",
      "\u001b[0m\n",
      "it 136/2000, vlb -6.065149, \u001b[31m   time: 0.557266 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.948543 (-5.755878)\n",
      "\u001b[0m\n",
      "it 137/2000, vlb -6.102907, \u001b[31m   time: 0.705858 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.807948 (-5.755878)\n",
      "\u001b[0m\n",
      "it 138/2000, vlb -6.049243, \u001b[31m   time: 1.168256 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.934231 (-5.755878)\n",
      "\u001b[0m\n",
      "it 139/2000, vlb -6.074562, \u001b[31m   time: 0.881444 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.941358 (-5.755878)\n",
      "\u001b[0m\n",
      "it 140/2000, vlb -6.078198, \u001b[31m   time: 1.082739 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.951164 (-5.755878)\n",
      "\u001b[0m\n",
      "it 141/2000, vlb -6.076156, \u001b[31m   time: 1.194095 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.809183 (-5.755878)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 142/2000, vlb -6.118712, \u001b[31m   time: 0.695020 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.024364 (-5.755878)\n",
      "\u001b[0m\n",
      "it 143/2000, vlb -6.071700, \u001b[31m   time: 0.558199 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.955481 (-5.755878)\n",
      "\u001b[0m\n",
      "it 144/2000, vlb -6.025098, \u001b[31m   time: 0.549696 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.931567 (-5.755878)\n",
      "\u001b[0m\n",
      "it 145/2000, vlb -6.072117, \u001b[31m   time: 0.557927 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.921461 (-5.755878)\n",
      "\u001b[0m\n",
      "it 146/2000, vlb -6.040099, \u001b[31m   time: 0.561406 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.900092 (-5.755878)\n",
      "\u001b[0m\n",
      "it 147/2000, vlb -6.094528, \u001b[31m   time: 0.547864 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.864831 (-5.755878)\n",
      "\u001b[0m\n",
      "it 148/2000, vlb -6.048404, \u001b[31m   time: 0.779322 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.979649 (-5.755878)\n",
      "\u001b[0m\n",
      "it 149/2000, vlb -6.108491, \u001b[31m   time: 1.004430 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.919129 (-5.755878)\n",
      "\u001b[0m\n",
      "it 150/2000, vlb -6.056390, \u001b[31m   time: 0.733275 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.900243 (-5.755878)\n",
      "\u001b[0m\n",
      "it 151/2000, vlb -6.036307, \u001b[31m   time: 0.634225 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.928283 (-5.755878)\n",
      "\u001b[0m\n",
      "it 152/2000, vlb -6.068594, \u001b[31m   time: 0.951651 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.881363 (-5.755878)\n",
      "\u001b[0m\n",
      "it 153/2000, vlb -6.053750, \u001b[31m   time: 1.286238 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.906022 (-5.755878)\n",
      "\u001b[0m\n",
      "it 154/2000, vlb -6.089740, \u001b[31m   time: 1.097011 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.959467 (-5.755878)\n",
      "\u001b[0m\n",
      "it 155/2000, vlb -6.062647, \u001b[31m   time: 0.596684 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.975917 (-5.755878)\n",
      "\u001b[0m\n",
      "it 156/2000, vlb -6.044884, \u001b[31m   time: 0.640284 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.914596 (-5.755878)\n",
      "\u001b[0m\n",
      "it 157/2000, vlb -6.068138, \u001b[31m   time: 0.637145 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.928238 (-5.755878)\n",
      "\u001b[0m\n",
      "it 158/2000, vlb -6.043031, \u001b[31m   time: 0.792417 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.885069 (-5.755878)\n",
      "\u001b[0m\n",
      "it 159/2000, vlb -6.100595, \u001b[31m   time: 0.893336 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.978012 (-5.755878)\n",
      "\u001b[0m\n",
      "it 160/2000, vlb -6.056934, \u001b[31m   time: 0.863047 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.752071 (-5.755878)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 161/2000, vlb -5.985221, \u001b[31m   time: 0.756134 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.932148 (-5.752071)\n",
      "\u001b[0m\n",
      "it 162/2000, vlb -6.125548, \u001b[31m   time: 0.765182 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.874079 (-5.752071)\n",
      "\u001b[0m\n",
      "it 163/2000, vlb -6.065345, \u001b[31m   time: 0.988596 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.926806 (-5.752071)\n",
      "\u001b[0m\n",
      "it 164/2000, vlb -6.072374, \u001b[31m   time: 0.783086 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.867605 (-5.752071)\n",
      "\u001b[0m\n",
      "it 165/2000, vlb -6.079610, \u001b[31m   time: 0.744940 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.820732 (-5.752071)\n",
      "\u001b[0m\n",
      "it 166/2000, vlb -6.041904, \u001b[31m   time: 0.748988 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.912963 (-5.752071)\n",
      "\u001b[0m\n",
      "it 167/2000, vlb -6.044580, \u001b[31m   time: 0.766214 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.959282 (-5.752071)\n",
      "\u001b[0m\n",
      "it 168/2000, vlb -6.034240, \u001b[31m   time: 0.799781 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.048428 (-5.752071)\n",
      "\u001b[0m\n",
      "it 169/2000, vlb -6.097441, \u001b[31m   time: 0.762629 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.872636 (-5.752071)\n",
      "\u001b[0m\n",
      "it 170/2000, vlb -6.030743, \u001b[31m   time: 0.754111 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.997689 (-5.752071)\n",
      "\u001b[0m\n",
      "it 171/2000, vlb -6.018219, \u001b[31m   time: 0.778527 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.941922 (-5.752071)\n",
      "\u001b[0m\n",
      "it 172/2000, vlb -6.053238, \u001b[31m   time: 0.773004 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.893243 (-5.752071)\n",
      "\u001b[0m\n",
      "it 173/2000, vlb -6.052925, \u001b[31m   time: 0.769275 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.899733 (-5.752071)\n",
      "\u001b[0m\n",
      "it 174/2000, vlb -6.019499, \u001b[31m   time: 0.801703 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.939866 (-5.752071)\n",
      "\u001b[0m\n",
      "it 175/2000, vlb -6.052005, \u001b[31m   time: 0.786645 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.841063 (-5.752071)\n",
      "\u001b[0m\n",
      "it 176/2000, vlb -6.050391, \u001b[31m   time: 0.872063 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.075606 (-5.752071)\n",
      "\u001b[0m\n",
      "it 177/2000, vlb -6.071173, \u001b[31m   time: 0.735369 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.782152 (-5.752071)\n",
      "\u001b[0m\n",
      "it 178/2000, vlb -6.040410, \u001b[31m   time: 0.823134 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.813718 (-5.752071)\n",
      "\u001b[0m\n",
      "it 179/2000, vlb -6.040301, \u001b[31m   time: 0.750148 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.858799 (-5.752071)\n",
      "\u001b[0m\n",
      "it 180/2000, vlb -6.036021, \u001b[31m   time: 0.808134 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.095022 (-5.752071)\n",
      "\u001b[0m\n",
      "it 181/2000, vlb -6.004462, \u001b[31m   time: 0.771407 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.926455 (-5.752071)\n",
      "\u001b[0m\n",
      "it 182/2000, vlb -6.073669, \u001b[31m   time: 0.767053 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.853848 (-5.752071)\n",
      "\u001b[0m\n",
      "it 183/2000, vlb -6.073966, \u001b[31m   time: 0.845694 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.970291 (-5.752071)\n",
      "\u001b[0m\n",
      "it 184/2000, vlb -6.023700, \u001b[31m   time: 0.844329 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.894539 (-5.752071)\n",
      "\u001b[0m\n",
      "it 185/2000, vlb -6.021391, \u001b[31m   time: 0.732807 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.932824 (-5.752071)\n",
      "\u001b[0m\n",
      "it 186/2000, vlb -5.990817, \u001b[31m   time: 0.746336 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.839607 (-5.752071)\n",
      "\u001b[0m\n",
      "it 187/2000, vlb -6.057594, \u001b[31m   time: 0.874465 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.938192 (-5.752071)\n",
      "\u001b[0m\n",
      "it 188/2000, vlb -6.032068, \u001b[31m   time: 1.102527 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.933430 (-5.752071)\n",
      "\u001b[0m\n",
      "it 189/2000, vlb -6.014631, \u001b[31m   time: 0.761908 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.994715 (-5.752071)\n",
      "\u001b[0m\n",
      "it 190/2000, vlb -6.041780, \u001b[31m   time: 0.756774 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.910642 (-5.752071)\n",
      "\u001b[0m\n",
      "it 191/2000, vlb -6.004723, \u001b[31m   time: 0.763902 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.855607 (-5.752071)\n",
      "\u001b[0m\n",
      "it 192/2000, vlb -6.016773, \u001b[31m   time: 0.831919 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.958887 (-5.752071)\n",
      "\u001b[0m\n",
      "it 193/2000, vlb -6.047073, \u001b[31m   time: 0.785106 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.994872 (-5.752071)\n",
      "\u001b[0m\n",
      "it 194/2000, vlb -6.013631, \u001b[31m   time: 0.754883 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.840628 (-5.752071)\n",
      "\u001b[0m\n",
      "it 195/2000, vlb -6.016410, \u001b[31m   time: 0.771634 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.920074 (-5.752071)\n",
      "\u001b[0m\n",
      "it 196/2000, vlb -6.062624, \u001b[31m   time: 0.772993 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.873600 (-5.752071)\n",
      "\u001b[0m\n",
      "it 197/2000, vlb -6.050610, \u001b[31m   time: 0.763825 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.854587 (-5.752071)\n",
      "\u001b[0m\n",
      "it 198/2000, vlb -6.061782, \u001b[31m   time: 0.812466 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.860960 (-5.752071)\n",
      "\u001b[0m\n",
      "it 199/2000, vlb -6.038816, \u001b[31m   time: 0.773886 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.968091 (-5.752071)\n",
      "\u001b[0m\n",
      "it 200/2000, vlb -6.015299, \u001b[31m   time: 0.918130 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.850852 (-5.752071)\n",
      "\u001b[0m\n",
      "it 201/2000, vlb -6.104988, \u001b[31m   time: 0.973435 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.958876 (-5.752071)\n",
      "\u001b[0m\n",
      "it 202/2000, vlb -6.005633, \u001b[31m   time: 1.171122 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.898765 (-5.752071)\n",
      "\u001b[0m\n",
      "it 203/2000, vlb -6.020522, \u001b[31m   time: 1.333605 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.876499 (-5.752071)\n",
      "\u001b[0m\n",
      "it 204/2000, vlb -6.029695, \u001b[31m   time: 1.597258 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.976320 (-5.752071)\n",
      "\u001b[0m\n",
      "it 205/2000, vlb -6.050451, \u001b[31m   time: 0.748224 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.872636 (-5.752071)\n",
      "\u001b[0m\n",
      "it 206/2000, vlb -6.031594, \u001b[31m   time: 0.605685 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.965883 (-5.752071)\n",
      "\u001b[0m\n",
      "it 207/2000, vlb -6.029784, \u001b[31m   time: 0.680373 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.895091 (-5.752071)\n",
      "\u001b[0m\n",
      "it 208/2000, vlb -6.040441, \u001b[31m   time: 0.623991 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.915831 (-5.752071)\n",
      "\u001b[0m\n",
      "it 209/2000, vlb -6.018643, \u001b[31m   time: 0.619631 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.858716 (-5.752071)\n",
      "\u001b[0m\n",
      "it 210/2000, vlb -6.032587, \u001b[31m   time: 0.621884 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.871149 (-5.752071)\n",
      "\u001b[0m\n",
      "it 211/2000, vlb -6.009513, \u001b[31m   time: 0.656786 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.905255 (-5.752071)\n",
      "\u001b[0m\n",
      "it 212/2000, vlb -6.001523, \u001b[31m   time: 0.810273 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.899482 (-5.752071)\n",
      "\u001b[0m\n",
      "it 213/2000, vlb -6.050356, \u001b[31m   time: 0.625601 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.964601 (-5.752071)\n",
      "\u001b[0m\n",
      "it 214/2000, vlb -6.041560, \u001b[31m   time: 0.616291 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.853378 (-5.752071)\n",
      "\u001b[0m\n",
      "it 215/2000, vlb -5.991592, \u001b[31m   time: 0.693304 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.938392 (-5.752071)\n",
      "\u001b[0m\n",
      "it 216/2000, vlb -6.012353, \u001b[31m   time: 0.615386 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.947127 (-5.752071)\n",
      "\u001b[0m\n",
      "it 217/2000, vlb -5.986950, \u001b[31m   time: 0.611673 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.016267 (-5.752071)\n",
      "\u001b[0m\n",
      "it 218/2000, vlb -6.110102, \u001b[31m   time: 0.633281 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.955448 (-5.752071)\n",
      "\u001b[0m\n",
      "it 219/2000, vlb -5.994828, \u001b[31m   time: 0.684182 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.941988 (-5.752071)\n",
      "\u001b[0m\n",
      "it 220/2000, vlb -6.061181, \u001b[31m   time: 0.658748 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    vlb -5.985422 (-5.752071)\n",
      "\u001b[0m\n",
      "it 221/2000, vlb -6.032331, \u001b[31m   time: 0.641286 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.032875 (-5.752071)\n",
      "\u001b[0m\n",
      "it 222/2000, vlb -6.062815, \u001b[31m   time: 0.615746 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.801141 (-5.752071)\n",
      "\u001b[0m\n",
      "it 223/2000, vlb -6.058413, \u001b[31m   time: 0.619095 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.948525 (-5.752071)\n",
      "\u001b[0m\n",
      "it 224/2000, vlb -6.024577, \u001b[31m   time: 0.637255 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.980161 (-5.752071)\n",
      "\u001b[0m\n",
      "it 225/2000, vlb -6.031155, \u001b[31m   time: 0.618182 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.837657 (-5.752071)\n",
      "\u001b[0m\n",
      "it 226/2000, vlb -6.034582, \u001b[31m   time: 0.701375 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.920137 (-5.752071)\n",
      "\u001b[0m\n",
      "it 227/2000, vlb -6.010272, \u001b[31m   time: 0.818609 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.050950 (-5.752071)\n",
      "\u001b[0m\n",
      "it 228/2000, vlb -6.042468, \u001b[31m   time: 0.611920 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.997070 (-5.752071)\n",
      "\u001b[0m\n",
      "it 229/2000, vlb -5.969879, \u001b[31m   time: 0.609394 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.920860 (-5.752071)\n",
      "\u001b[0m\n",
      "it 230/2000, vlb -6.032652, \u001b[31m   time: 0.569449 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.967976 (-5.752071)\n",
      "\u001b[0m\n",
      "it 231/2000, vlb -6.036839, \u001b[31m   time: 0.570477 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.747014 (-5.752071)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 232/2000, vlb -6.015216, \u001b[31m   time: 0.580411 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.812767 (-5.747014)\n",
      "\u001b[0m\n",
      "it 233/2000, vlb -6.056433, \u001b[31m   time: 0.568684 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.852178 (-5.747014)\n",
      "\u001b[0m\n",
      "it 234/2000, vlb -6.016674, \u001b[31m   time: 0.572878 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.850368 (-5.747014)\n",
      "\u001b[0m\n",
      "it 235/2000, vlb -6.024449, \u001b[31m   time: 0.569885 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.900435 (-5.747014)\n",
      "\u001b[0m\n",
      "it 236/2000, vlb -6.002762, \u001b[31m   time: 0.572473 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.950094 (-5.747014)\n",
      "\u001b[0m\n",
      "it 237/2000, vlb -5.977305, \u001b[31m   time: 0.570792 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.874569 (-5.747014)\n",
      "\u001b[0m\n",
      "it 238/2000, vlb -6.048749, \u001b[31m   time: 0.575500 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.871955 (-5.747014)\n",
      "\u001b[0m\n",
      "it 239/2000, vlb -6.071951, \u001b[31m   time: 0.568757 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.895767 (-5.747014)\n",
      "\u001b[0m\n",
      "it 240/2000, vlb -6.029763, \u001b[31m   time: 0.567746 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.868468 (-5.747014)\n",
      "\u001b[0m\n",
      "it 241/2000, vlb -6.007532, \u001b[31m   time: 0.565655 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.102878 (-5.747014)\n",
      "\u001b[0m\n",
      "it 242/2000, vlb -6.028663, \u001b[31m   time: 0.617847 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.852197 (-5.747014)\n",
      "\u001b[0m\n",
      "it 243/2000, vlb -5.988943, \u001b[31m   time: 0.586580 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.880870 (-5.747014)\n",
      "\u001b[0m\n",
      "it 244/2000, vlb -5.985068, \u001b[31m   time: 0.588984 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.904857 (-5.747014)\n",
      "\u001b[0m\n",
      "it 245/2000, vlb -5.995655, \u001b[31m   time: 0.577144 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.929921 (-5.747014)\n",
      "\u001b[0m\n",
      "it 246/2000, vlb -6.028812, \u001b[31m   time: 0.570878 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.839483 (-5.747014)\n",
      "\u001b[0m\n",
      "it 247/2000, vlb -5.997012, \u001b[31m   time: 0.573281 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.863595 (-5.747014)\n",
      "\u001b[0m\n",
      "it 248/2000, vlb -6.024280, \u001b[31m   time: 0.577638 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.722203 (-5.747014)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_best.dat\n",
      "\u001b[0m\n",
      "it 249/2000, vlb -6.026912, \u001b[31m   time: 0.580447 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.917700 (-5.722203)\n",
      "\u001b[0m\n",
      "it 250/2000, vlb -6.054809, \u001b[31m   time: 0.581506 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.023323 (-5.722203)\n",
      "\u001b[0m\n",
      "it 251/2000, vlb -6.008585, \u001b[31m   time: 0.571407 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.953692 (-5.722203)\n",
      "\u001b[0m\n",
      "it 252/2000, vlb -6.032001, \u001b[31m   time: 0.588939 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.880991 (-5.722203)\n",
      "\u001b[0m\n",
      "it 253/2000, vlb -6.032583, \u001b[31m   time: 0.582363 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.900049 (-5.722203)\n",
      "\u001b[0m\n",
      "it 254/2000, vlb -6.031335, \u001b[31m   time: 0.580163 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.849755 (-5.722203)\n",
      "\u001b[0m\n",
      "it 255/2000, vlb -6.032920, \u001b[31m   time: 0.583051 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.951522 (-5.722203)\n",
      "\u001b[0m\n",
      "it 256/2000, vlb -5.983503, \u001b[31m   time: 0.570680 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.892973 (-5.722203)\n",
      "\u001b[0m\n",
      "it 257/2000, vlb -6.038729, \u001b[31m   time: 0.583988 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.828546 (-5.722203)\n",
      "\u001b[0m\n",
      "it 258/2000, vlb -6.038073, \u001b[31m   time: 0.568885 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.910356 (-5.722203)\n",
      "\u001b[0m\n",
      "it 259/2000, vlb -5.967421, \u001b[31m   time: 0.585939 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.816680 (-5.722203)\n",
      "\u001b[0m\n",
      "it 260/2000, vlb -6.020054, \u001b[31m   time: 0.628075 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.863328 (-5.722203)\n",
      "\u001b[0m\n",
      "it 261/2000, vlb -6.005899, \u001b[31m   time: 0.579204 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.860844 (-5.722203)\n",
      "\u001b[0m\n",
      "it 262/2000, vlb -6.007812, \u001b[31m   time: 0.582665 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.946551 (-5.722203)\n",
      "\u001b[0m\n",
      "it 263/2000, vlb -6.028066, \u001b[31m   time: 0.575221 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.021706 (-5.722203)\n",
      "\u001b[0m\n",
      "it 264/2000, vlb -5.984739, \u001b[31m   time: 0.574337 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.070712 (-5.722203)\n",
      "\u001b[0m\n",
      "it 265/2000, vlb -6.017447, \u001b[31m   time: 0.587219 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.815478 (-5.722203)\n",
      "\u001b[0m\n",
      "it 266/2000, vlb -6.045349, \u001b[31m   time: 0.568370 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.772766 (-5.722203)\n",
      "\u001b[0m\n",
      "it 267/2000, vlb -6.033462, \u001b[31m   time: 0.622421 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.918400 (-5.722203)\n",
      "\u001b[0m\n",
      "it 268/2000, vlb -6.017125, \u001b[31m   time: 0.612852 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.924222 (-5.722203)\n",
      "\u001b[0m\n",
      "it 269/2000, vlb -5.986629, \u001b[31m   time: 0.718900 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.845357 (-5.722203)\n",
      "\u001b[0m\n",
      "it 270/2000, vlb -6.021208, \u001b[31m   time: 1.072701 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.891927 (-5.722203)\n",
      "\u001b[0m\n",
      "it 271/2000, vlb -6.018026, \u001b[31m   time: 0.905735 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.930689 (-5.722203)\n",
      "\u001b[0m\n",
      "it 272/2000, vlb -5.996095, \u001b[31m   time: 0.898921 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.954401 (-5.722203)\n",
      "\u001b[0m\n",
      "it 273/2000, vlb -5.989066, \u001b[31m   time: 0.743020 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.763493 (-5.722203)\n",
      "\u001b[0m\n",
      "it 274/2000, vlb -6.002910, \u001b[31m   time: 0.849983 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.855079 (-5.722203)\n",
      "\u001b[0m\n",
      "it 275/2000, vlb -6.022003, \u001b[31m   time: 0.757327 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.973592 (-5.722203)\n",
      "\u001b[0m\n",
      "it 276/2000, vlb -5.999678, \u001b[31m   time: 0.691757 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.812682 (-5.722203)\n",
      "\u001b[0m\n",
      "it 277/2000, vlb -5.996514, \u001b[31m   time: 0.571927 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.867016 (-5.722203)\n",
      "\u001b[0m\n",
      "it 278/2000, vlb -5.988060, \u001b[31m   time: 0.576219 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.907339 (-5.722203)\n",
      "\u001b[0m\n",
      "it 279/2000, vlb -6.025346, \u001b[31m   time: 0.574727 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.878473 (-5.722203)\n",
      "\u001b[0m\n",
      "it 280/2000, vlb -5.977286, \u001b[31m   time: 0.576547 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.820948 (-5.722203)\n",
      "\u001b[0m\n",
      "it 281/2000, vlb -6.016915, \u001b[31m   time: 0.576265 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.755262 (-5.722203)\n",
      "\u001b[0m\n",
      "it 282/2000, vlb -6.056537, \u001b[31m   time: 0.590498 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.840596 (-5.722203)\n",
      "\u001b[0m\n",
      "it 283/2000, vlb -6.039327, \u001b[31m   time: 0.574674 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.995706 (-5.722203)\n",
      "\u001b[0m\n",
      "it 284/2000, vlb -6.009272, \u001b[31m   time: 0.628611 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.883275 (-5.722203)\n",
      "\u001b[0m\n",
      "it 285/2000, vlb -6.037385, \u001b[31m   time: 0.577508 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.966127 (-5.722203)\n",
      "\u001b[0m\n",
      "it 286/2000, vlb -6.010224, \u001b[31m   time: 0.567802 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.829697 (-5.722203)\n",
      "\u001b[0m\n",
      "it 287/2000, vlb -5.983402, \u001b[31m   time: 0.596665 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.823876 (-5.722203)\n",
      "\u001b[0m\n",
      "it 288/2000, vlb -6.008736, \u001b[31m   time: 0.588785 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.848681 (-5.722203)\n",
      "\u001b[0m\n",
      "it 289/2000, vlb -6.020971, \u001b[31m   time: 0.584457 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.833041 (-5.722203)\n",
      "\u001b[0m\n",
      "it 290/2000, vlb -6.011359, \u001b[31m   time: 0.590208 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.877411 (-5.722203)\n",
      "\u001b[0m\n",
      "it 291/2000, vlb -6.042108, \u001b[31m   time: 0.585161 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.953804 (-5.722203)\n",
      "\u001b[0m\n",
      "it 292/2000, vlb -6.026650, \u001b[31m   time: 0.582396 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.799567 (-5.722203)\n",
      "\u001b[0m\n",
      "it 293/2000, vlb -6.001813, \u001b[31m   time: 0.589694 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.828403 (-5.722203)\n",
      "\u001b[0m\n",
      "it 294/2000, vlb -6.012731, \u001b[31m   time: 0.635886 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.852604 (-5.722203)\n",
      "\u001b[0m\n",
      "it 295/2000, vlb -6.021924, \u001b[31m   time: 0.583077 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.849400 (-5.722203)\n",
      "\u001b[0m\n",
      "it 296/2000, vlb -6.021537, \u001b[31m   time: 0.568956 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.918850 (-5.722203)\n",
      "\u001b[0m\n",
      "it 297/2000, vlb -6.000638, \u001b[31m   time: 0.573107 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.877175 (-5.722203)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 298/2000, vlb -5.970429, \u001b[31m   time: 0.570001 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.915905 (-5.722203)\n",
      "\u001b[0m\n",
      "it 299/2000, vlb -6.031841, \u001b[31m   time: 0.569940 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.916170 (-5.722203)\n",
      "\u001b[0m\n",
      "it 300/2000, vlb -6.065870, \u001b[31m   time: 0.570196 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.850285 (-5.722203)\n",
      "\u001b[0m\n",
      "it 301/2000, vlb -6.016728, \u001b[31m   time: 0.571005 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.789905 (-5.722203)\n",
      "\u001b[0m\n",
      "it 302/2000, vlb -6.038583, \u001b[31m   time: 0.574775 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.873112 (-5.722203)\n",
      "\u001b[0m\n",
      "it 303/2000, vlb -6.046880, \u001b[31m   time: 0.573638 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.832935 (-5.722203)\n",
      "\u001b[0m\n",
      "it 304/2000, vlb -5.981013, \u001b[31m   time: 0.580135 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.941791 (-5.722203)\n",
      "\u001b[0m\n",
      "it 305/2000, vlb -6.037195, \u001b[31m   time: 0.571474 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.765086 (-5.722203)\n",
      "\u001b[0m\n",
      "it 306/2000, vlb -5.954249, \u001b[31m   time: 0.568071 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.985123 (-5.722203)\n",
      "\u001b[0m\n",
      "it 307/2000, vlb -6.039229, \u001b[31m   time: 0.588812 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.785161 (-5.722203)\n",
      "\u001b[0m\n",
      "it 308/2000, vlb -6.005060, \u001b[31m   time: 0.569245 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.833501 (-5.722203)\n",
      "\u001b[0m\n",
      "it 309/2000, vlb -5.978019, \u001b[31m   time: 0.575960 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.898718 (-5.722203)\n",
      "\u001b[0m\n",
      "it 310/2000, vlb -5.983991, \u001b[31m   time: 0.575662 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.905425 (-5.722203)\n",
      "\u001b[0m\n",
      "it 311/2000, vlb -5.984302, \u001b[31m   time: 0.582553 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.856491 (-5.722203)\n",
      "\u001b[0m\n",
      "it 312/2000, vlb -6.048717, \u001b[31m   time: 0.670394 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.002961 (-5.722203)\n",
      "\u001b[0m\n",
      "it 313/2000, vlb -6.034525, \u001b[31m   time: 0.896262 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.931647 (-5.722203)\n",
      "\u001b[0m\n",
      "it 314/2000, vlb -5.989976, \u001b[31m   time: 0.854765 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.898526 (-5.722203)\n",
      "\u001b[0m\n",
      "it 315/2000, vlb -6.017524, \u001b[31m   time: 0.714473 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.024556 (-5.722203)\n",
      "\u001b[0m\n",
      "it 316/2000, vlb -6.018790, \u001b[31m   time: 0.867660 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.846663 (-5.722203)\n",
      "\u001b[0m\n",
      "it 317/2000, vlb -5.993417, \u001b[31m   time: 0.626014 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.964593 (-5.722203)\n",
      "\u001b[0m\n",
      "it 318/2000, vlb -6.003135, \u001b[31m   time: 0.715299 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.994689 (-5.722203)\n",
      "\u001b[0m\n",
      "it 319/2000, vlb -5.967385, \u001b[31m   time: 0.671241 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.822706 (-5.722203)\n",
      "\u001b[0m\n",
      "it 320/2000, vlb -6.045637, \u001b[31m   time: 0.572543 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.895146 (-5.722203)\n",
      "\u001b[0m\n",
      "it 321/2000, vlb -5.966628, \u001b[31m   time: 1.546627 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.768269 (-5.722203)\n",
      "\u001b[0m\n",
      "it 322/2000, vlb -5.980651, \u001b[31m   time: 1.063525 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.775884 (-5.722203)\n",
      "\u001b[0m\n",
      "it 323/2000, vlb -6.012153, \u001b[31m   time: 1.209031 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.885773 (-5.722203)\n",
      "\u001b[0m\n",
      "it 324/2000, vlb -6.024351, \u001b[31m   time: 0.682393 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.884237 (-5.722203)\n",
      "\u001b[0m\n",
      "it 325/2000, vlb -6.010342, \u001b[31m   time: 0.868677 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.883371 (-5.722203)\n",
      "\u001b[0m\n",
      "it 326/2000, vlb -6.008250, \u001b[31m   time: 0.724648 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.838586 (-5.722203)\n",
      "\u001b[0m\n",
      "it 327/2000, vlb -6.011754, \u001b[31m   time: 0.941173 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.935972 (-5.722203)\n",
      "\u001b[0m\n",
      "it 328/2000, vlb -6.065901, \u001b[31m   time: 0.628173 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.731027 (-5.722203)\n",
      "\u001b[0m\n",
      "it 329/2000, vlb -6.018574, \u001b[31m   time: 0.665849 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.858481 (-5.722203)\n",
      "\u001b[0m\n",
      "it 330/2000, vlb -6.055401, \u001b[31m   time: 0.677379 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.888587 (-5.722203)\n",
      "\u001b[0m\n",
      "it 331/2000, vlb -5.990682, \u001b[31m   time: 0.548365 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.817244 (-5.722203)\n",
      "\u001b[0m\n",
      "it 332/2000, vlb -6.045275, \u001b[31m   time: 0.582926 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.874400 (-5.722203)\n",
      "\u001b[0m\n",
      "it 333/2000, vlb -6.016721, \u001b[31m   time: 0.583442 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.957103 (-5.722203)\n",
      "\u001b[0m\n",
      "it 334/2000, vlb -5.963214, \u001b[31m   time: 0.677348 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.926737 (-5.722203)\n",
      "\u001b[0m\n",
      "it 335/2000, vlb -6.007088, \u001b[31m   time: 1.132527 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.960018 (-5.722203)\n",
      "\u001b[0m\n",
      "it 336/2000, vlb -5.996011, \u001b[31m   time: 0.992824 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.853964 (-5.722203)\n",
      "\u001b[0m\n",
      "it 337/2000, vlb -5.984813, \u001b[31m   time: 0.545714 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.016960 (-5.722203)\n",
      "\u001b[0m\n",
      "it 338/2000, vlb -5.993949, \u001b[31m   time: 0.543755 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.968775 (-5.722203)\n",
      "\u001b[0m\n",
      "it 339/2000, vlb -5.991464, \u001b[31m   time: 0.576591 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.768101 (-5.722203)\n",
      "\u001b[0m\n",
      "it 340/2000, vlb -5.965570, \u001b[31m   time: 0.614608 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.914692 (-5.722203)\n",
      "\u001b[0m\n",
      "it 341/2000, vlb -5.961684, \u001b[31m   time: 0.747667 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.884536 (-5.722203)\n",
      "\u001b[0m\n",
      "it 342/2000, vlb -5.992787, \u001b[31m   time: 0.654253 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.809792 (-5.722203)\n",
      "\u001b[0m\n",
      "it 343/2000, vlb -6.005756, \u001b[31m   time: 0.726789 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.965357 (-5.722203)\n",
      "\u001b[0m\n",
      "it 344/2000, vlb -6.030730, \u001b[31m   time: 0.665916 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.878302 (-5.722203)\n",
      "\u001b[0m\n",
      "it 345/2000, vlb -5.939343, \u001b[31m   time: 0.983373 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.961752 (-5.722203)\n",
      "\u001b[0m\n",
      "it 346/2000, vlb -6.011050, \u001b[31m   time: 0.865199 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.862394 (-5.722203)\n",
      "\u001b[0m\n",
      "it 347/2000, vlb -6.033341, \u001b[31m   time: 0.541979 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.985190 (-5.722203)\n",
      "\u001b[0m\n",
      "it 348/2000, vlb -6.031915, \u001b[31m   time: 0.754829 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.815336 (-5.722203)\n",
      "\u001b[0m\n",
      "it 349/2000, vlb -6.051332, \u001b[31m   time: 0.735598 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.860375 (-5.722203)\n",
      "\u001b[0m\n",
      "it 350/2000, vlb -6.001680, \u001b[31m   time: 0.651722 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.797891 (-5.722203)\n",
      "\u001b[0m\n",
      "it 351/2000, vlb -5.992935, \u001b[31m   time: 0.593394 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.836903 (-5.722203)\n",
      "\u001b[0m\n",
      "it 352/2000, vlb -5.968117, \u001b[31m   time: 0.637995 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.858775 (-5.722203)\n",
      "\u001b[0m\n",
      "it 353/2000, vlb -5.983635, \u001b[31m   time: 0.585783 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.732293 (-5.722203)\n",
      "\u001b[0m\n",
      "it 354/2000, vlb -5.981150, \u001b[31m   time: 0.567133 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.009821 (-5.722203)\n",
      "\u001b[0m\n",
      "it 355/2000, vlb -6.019531, \u001b[31m   time: 0.595800 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.916613 (-5.722203)\n",
      "\u001b[0m\n",
      "it 356/2000, vlb -6.023228, \u001b[31m   time: 0.592634 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.004531 (-5.722203)\n",
      "\u001b[0m\n",
      "it 357/2000, vlb -5.983661, \u001b[31m   time: 0.574354 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.838268 (-5.722203)\n",
      "\u001b[0m\n",
      "it 358/2000, vlb -6.018341, \u001b[31m   time: 0.584173 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.956387 (-5.722203)\n",
      "\u001b[0m\n",
      "it 359/2000, vlb -5.996968, \u001b[31m   time: 0.605938 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.761475 (-5.722203)\n",
      "\u001b[0m\n",
      "it 360/2000, vlb -5.931142, \u001b[31m   time: 0.590480 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.920405 (-5.722203)\n",
      "\u001b[0m\n",
      "it 361/2000, vlb -6.029537, \u001b[31m   time: 0.585981 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.885878 (-5.722203)\n",
      "\u001b[0m\n",
      "it 362/2000, vlb -6.000046, \u001b[31m   time: 0.555727 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.817231 (-5.722203)\n",
      "\u001b[0m\n",
      "it 363/2000, vlb -5.973201, \u001b[31m   time: 0.618671 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.897289 (-5.722203)\n",
      "\u001b[0m\n",
      "it 364/2000, vlb -5.964679, \u001b[31m   time: 0.677544 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.923308 (-5.722203)\n",
      "\u001b[0m\n",
      "it 365/2000, vlb -6.032130, \u001b[31m   time: 0.584335 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.918475 (-5.722203)\n",
      "\u001b[0m\n",
      "it 366/2000, vlb -5.965193, \u001b[31m   time: 0.608809 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.852857 (-5.722203)\n",
      "\u001b[0m\n",
      "it 367/2000, vlb -5.963162, \u001b[31m   time: 0.576249 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.819239 (-5.722203)\n",
      "\u001b[0m\n",
      "it 368/2000, vlb -6.013185, \u001b[31m   time: 0.719086 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.942760 (-5.722203)\n",
      "\u001b[0m\n",
      "it 369/2000, vlb -5.996835, \u001b[31m   time: 0.601155 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.909148 (-5.722203)\n",
      "\u001b[0m\n",
      "it 370/2000, vlb -5.987857, \u001b[31m   time: 0.563400 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.840362 (-5.722203)\n",
      "\u001b[0m\n",
      "it 371/2000, vlb -6.018940, \u001b[31m   time: 0.549979 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.865982 (-5.722203)\n",
      "\u001b[0m\n",
      "it 372/2000, vlb -5.986912, \u001b[31m   time: 0.542593 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.964943 (-5.722203)\n",
      "\u001b[0m\n",
      "it 373/2000, vlb -6.014190, \u001b[31m   time: 0.550894 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.767305 (-5.722203)\n",
      "\u001b[0m\n",
      "it 374/2000, vlb -5.994095, \u001b[31m   time: 0.642917 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.940806 (-5.722203)\n",
      "\u001b[0m\n",
      "it 375/2000, vlb -6.021535, \u001b[31m   time: 0.717811 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.924330 (-5.722203)\n",
      "\u001b[0m\n",
      "it 376/2000, vlb -6.039656, \u001b[31m   time: 0.579676 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.880476 (-5.722203)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 377/2000, vlb -6.032511, \u001b[31m   time: 0.555007 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.908240 (-5.722203)\n",
      "\u001b[0m\n",
      "it 378/2000, vlb -5.972814, \u001b[31m   time: 0.583343 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.874425 (-5.722203)\n",
      "\u001b[0m\n",
      "it 379/2000, vlb -5.964904, \u001b[31m   time: 0.538458 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.829979 (-5.722203)\n",
      "\u001b[0m\n",
      "it 380/2000, vlb -6.021003, \u001b[31m   time: 0.531327 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.877202 (-5.722203)\n",
      "\u001b[0m\n",
      "it 381/2000, vlb -6.001778, \u001b[31m   time: 0.587768 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.858331 (-5.722203)\n",
      "\u001b[0m\n",
      "it 382/2000, vlb -6.032161, \u001b[31m   time: 0.721274 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.791344 (-5.722203)\n",
      "\u001b[0m\n",
      "it 383/2000, vlb -6.031584, \u001b[31m   time: 0.709136 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.892537 (-5.722203)\n",
      "\u001b[0m\n",
      "it 384/2000, vlb -5.990223, \u001b[31m   time: 0.594025 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.757034 (-5.722203)\n",
      "\u001b[0m\n",
      "it 385/2000, vlb -6.018463, \u001b[31m   time: 0.663535 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.824331 (-5.722203)\n",
      "\u001b[0m\n",
      "it 386/2000, vlb -5.994739, \u001b[31m   time: 0.686636 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.852992 (-5.722203)\n",
      "\u001b[0m\n",
      "it 387/2000, vlb -5.975746, \u001b[31m   time: 0.639118 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.927864 (-5.722203)\n",
      "\u001b[0m\n",
      "it 388/2000, vlb -6.034774, \u001b[31m   time: 0.676868 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.819563 (-5.722203)\n",
      "\u001b[0m\n",
      "it 389/2000, vlb -6.015616, \u001b[31m   time: 0.602960 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.804873 (-5.722203)\n",
      "\u001b[0m\n",
      "it 390/2000, vlb -6.036596, \u001b[31m   time: 0.650574 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.868544 (-5.722203)\n",
      "\u001b[0m\n",
      "it 391/2000, vlb -5.966375, \u001b[31m   time: 0.550165 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.897295 (-5.722203)\n",
      "\u001b[0m\n",
      "it 392/2000, vlb -5.984232, \u001b[31m   time: 0.535640 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.910034 (-5.722203)\n",
      "\u001b[0m\n",
      "it 393/2000, vlb -6.024319, \u001b[31m   time: 0.661647 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.918832 (-5.722203)\n",
      "\u001b[0m\n",
      "it 394/2000, vlb -5.990990, \u001b[31m   time: 0.556467 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.860734 (-5.722203)\n",
      "\u001b[0m\n",
      "it 395/2000, vlb -6.008702, \u001b[31m   time: 0.548220 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.860783 (-5.722203)\n",
      "\u001b[0m\n",
      "it 396/2000, vlb -5.967200, \u001b[31m   time: 0.661189 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.900764 (-5.722203)\n",
      "\u001b[0m\n",
      "it 397/2000, vlb -5.976218, \u001b[31m   time: 0.635776 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.895291 (-5.722203)\n",
      "\u001b[0m\n",
      "it 398/2000, vlb -5.989821, \u001b[31m   time: 0.776660 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.022016 (-5.722203)\n",
      "\u001b[0m\n",
      "it 399/2000, vlb -6.010865, \u001b[31m   time: 0.581884 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.915956 (-5.722203)\n",
      "\u001b[0m\n",
      "it 400/2000, vlb -6.025418, \u001b[31m   time: 0.843977 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.958399 (-5.722203)\n",
      "\u001b[0m\n",
      "it 401/2000, vlb -5.985455, \u001b[31m   time: 0.709265 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.901579 (-5.722203)\n",
      "\u001b[0m\n",
      "it 402/2000, vlb -6.012718, \u001b[31m   time: 0.577717 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.916414 (-5.722203)\n",
      "\u001b[0m\n",
      "it 403/2000, vlb -6.017253, \u001b[31m   time: 0.535991 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.840001 (-5.722203)\n",
      "\u001b[0m\n",
      "it 404/2000, vlb -5.969970, \u001b[31m   time: 0.583905 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.785725 (-5.722203)\n",
      "\u001b[0m\n",
      "it 405/2000, vlb -6.021540, \u001b[31m   time: 0.534523 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.835405 (-5.722203)\n",
      "\u001b[0m\n",
      "it 406/2000, vlb -6.023478, \u001b[31m   time: 0.530900 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.972541 (-5.722203)\n",
      "\u001b[0m\n",
      "it 407/2000, vlb -5.992787, \u001b[31m   time: 0.648452 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.931150 (-5.722203)\n",
      "\u001b[0m\n",
      "it 408/2000, vlb -5.989325, \u001b[31m   time: 0.586857 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.866887 (-5.722203)\n",
      "\u001b[0m\n",
      "it 409/2000, vlb -5.988914, \u001b[31m   time: 0.649519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.821723 (-5.722203)\n",
      "\u001b[0m\n",
      "it 410/2000, vlb -6.021989, \u001b[31m   time: 0.656960 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.931388 (-5.722203)\n",
      "\u001b[0m\n",
      "it 411/2000, vlb -6.011352, \u001b[31m   time: 1.341059 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.853372 (-5.722203)\n",
      "\u001b[0m\n",
      "it 412/2000, vlb -5.959198, \u001b[31m   time: 0.846713 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.840183 (-5.722203)\n",
      "\u001b[0m\n",
      "it 413/2000, vlb -6.024382, \u001b[31m   time: 0.676064 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.833605 (-5.722203)\n",
      "\u001b[0m\n",
      "it 414/2000, vlb -5.992522, \u001b[31m   time: 0.626063 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.818873 (-5.722203)\n",
      "\u001b[0m\n",
      "it 415/2000, vlb -6.006901, \u001b[31m   time: 0.666460 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.976676 (-5.722203)\n",
      "\u001b[0m\n",
      "it 416/2000, vlb -6.000351, \u001b[31m   time: 0.678224 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.731277 (-5.722203)\n",
      "\u001b[0m\n",
      "it 417/2000, vlb -5.971132, \u001b[31m   time: 0.689991 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.893038 (-5.722203)\n",
      "\u001b[0m\n",
      "it 418/2000, vlb -6.033026, \u001b[31m   time: 0.668027 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.867983 (-5.722203)\n",
      "\u001b[0m\n",
      "it 419/2000, vlb -5.994647, \u001b[31m   time: 0.602363 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.822889 (-5.722203)\n",
      "\u001b[0m\n",
      "it 420/2000, vlb -5.983229, \u001b[31m   time: 0.649207 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -6.023654 (-5.722203)\n",
      "\u001b[0m\n",
      "it 421/2000, vlb -6.002347, \u001b[31m   time: 0.773589 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.855843 (-5.722203)\n",
      "\u001b[0m\n",
      "it 422/2000, vlb -5.985578, \u001b[31m   time: 0.660156 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.813847 (-5.722203)\n",
      "\u001b[0m\n",
      "it 423/2000, vlb -5.969426, \u001b[31m   time: 0.690368 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.832192 (-5.722203)\n",
      "\u001b[0m\n",
      "it 424/2000, vlb -5.990943, \u001b[31m   time: 0.681192 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.889306 (-5.722203)\n",
      "\u001b[0m\n",
      "it 425/2000, vlb -6.037129, \u001b[31m   time: 0.619263 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.848347 (-5.722203)\n",
      "\u001b[0m\n",
      "it 426/2000, vlb -5.998970, \u001b[31m   time: 0.585637 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.941466 (-5.722203)\n",
      "\u001b[0m\n",
      "it 427/2000, vlb -6.012483, \u001b[31m   time: 0.707111 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.876675 (-5.722203)\n",
      "\u001b[0m\n",
      "it 428/2000, vlb -5.966525, \u001b[31m   time: 0.592886 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.938258 (-5.722203)\n",
      "\u001b[0m\n",
      "it 429/2000, vlb -5.985879, \u001b[31m   time: 0.656093 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.939001 (-5.722203)\n",
      "\u001b[0m\n",
      "it 430/2000, vlb -6.036882, \u001b[31m   time: 0.597153 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.845190 (-5.722203)\n",
      "\u001b[0m\n",
      "it 431/2000, vlb -6.027802, \u001b[31m   time: 0.574059 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.898980 (-5.722203)\n",
      "\u001b[0m\n",
      "it 432/2000, vlb -6.015156, \u001b[31m   time: 0.930589 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.802313 (-5.722203)\n",
      "\u001b[0m\n",
      "it 433/2000, vlb -6.016639, \u001b[31m   time: 0.582948 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.880338 (-5.722203)\n",
      "\u001b[0m\n",
      "it 434/2000, vlb -6.017715, \u001b[31m   time: 0.588146 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.769220 (-5.722203)\n",
      "\u001b[0m\n",
      "it 435/2000, vlb -5.945563, \u001b[31m   time: 0.960311 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.754749 (-5.722203)\n",
      "\u001b[0m\n",
      "it 436/2000, vlb -6.001492, \u001b[31m   time: 1.002523 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.802483 (-5.722203)\n",
      "\u001b[0m\n",
      "it 437/2000, vlb -5.996284, \u001b[31m   time: 0.793554 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.927814 (-5.722203)\n",
      "\u001b[0m\n",
      "it 438/2000, vlb -5.951736, \u001b[31m   time: 0.752352 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.988570 (-5.722203)\n",
      "\u001b[0m\n",
      "it 439/2000, vlb -6.004999, \u001b[31m   time: 0.695058 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.946841 (-5.722203)\n",
      "\u001b[0m\n",
      "it 440/2000, vlb -5.941751, \u001b[31m   time: 0.577421 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.824588 (-5.722203)\n",
      "\u001b[0m\n",
      "it 441/2000, vlb -5.976214, \u001b[31m   time: 0.581416 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.903252 (-5.722203)\n",
      "\u001b[0m\n",
      "it 442/2000, vlb -6.008894, \u001b[31m   time: 0.592519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.930803 (-5.722203)\n",
      "\u001b[0m\n",
      "it 443/2000, vlb -6.024486, \u001b[31m   time: 0.583276 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.917152 (-5.722203)\n",
      "\u001b[0m\n",
      "it 444/2000, vlb -6.015641, \u001b[31m   time: 0.573912 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.864659 (-5.722203)\n",
      "\u001b[0m\n",
      "it 445/2000, vlb -6.015293, \u001b[31m   time: 0.749592 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.820413 (-5.722203)\n",
      "\u001b[0m\n",
      "it 446/2000, vlb -5.985313, \u001b[31m   time: 0.992926 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.840926 (-5.722203)\n",
      "\u001b[0m\n",
      "it 447/2000, vlb -5.997628, \u001b[31m   time: 0.819751 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.746284 (-5.722203)\n",
      "\u001b[0m\n",
      "it 448/2000, vlb -6.030334, \u001b[31m   time: 0.658828 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.750652 (-5.722203)\n",
      "\u001b[0m\n",
      "it 449/2000, vlb -5.982410, \u001b[31m   time: 0.626688 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    vlb -5.929778 (-5.722203)\n",
      "\u001b[0m\n",
      "\u001b[36mWritting ../saves/fc_VAEAC_NEW_under2_compas_models/theta_last.dat\n",
      "\u001b[0m\n",
      "\u001b[31m   average time: 0.171231 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m\n",
      "RESULTS:\u001b[0m\n",
      "  best_vlb_dev: -5.722203\n",
      "  best_vlb_train: -5.931142\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'humansize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_17901/1910256205.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0munder_VAEAC_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munder_VAEAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m vlb_train, vlb_dev = train_VAE(under_VAEAC_net, savedir,\n\u001b[0m\u001b[1;32m     89\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                flat_ims=False, train_plot=False, Nclass=None, early_stop=early_stop)\n",
      "\u001b[0;32m/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_17901/1789939645.py\u001b[0m in \u001b[0;36mtrain_VAE\u001b[0;34m(net, name, batch_size, nb_epochs, trainset, valset, cuda, flat_ims, train_plot, Nclass, early_stop, script_mode)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  best_vlb_dev: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_cost_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  best_vlb_train: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_cost_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  nb_parameters: %d (%s)\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhumansize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m## ---------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'humansize' is not defined"
     ]
    }
   ],
   "source": [
    "# Credit\n",
    "\"\"\"\n",
    "dname = 'default_credit'\n",
    "print(dname)\n",
    "\n",
    "x_train, x_test, x_means, x_stds = \\\n",
    "load_UCI(dset_name=dname, splits=10, seed=42, separate_targets=False, save_dir='../data/')\n",
    "\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2] #has this form for targets\n",
    "print(input_dim_vec)\n",
    "\n",
    "x_train = unnormalise_cat_vars(x_train, x_means, x_stds, input_dim_vec)\n",
    "x_test = unnormalise_cat_vars(x_test, x_means, x_stds, input_dim_vec)\n",
    "\n",
    "x_train_flat = gauss_cat_to_flat(torch.Tensor(x_train), input_dim_vec)\n",
    "x_test_flat = gauss_cat_to_flat(torch.Tensor(x_test), input_dim_vec)\n",
    "\n",
    "\n",
    "print(x_train_flat.shape)\n",
    "print(x_test_flat.shape)\n",
    "\n",
    "trainset = Datafeed(x_train_flat, x_train_flat, transform=None)\n",
    "valset = Datafeed(x_test_flat, x_test_flat, transform=None)\n",
    "\n",
    "\n",
    "width = widths[names.index(dname)]\n",
    "depth = depths[names.index(dname)] # number of hidden layers\n",
    "latent_dim = latent_dims[names.index(dname)]\n",
    "lr = 1e-4\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "#base_network_wraper = VAEAC_gauss_cat_net(input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=lr, cuda=cuda, flatten=True)\n",
    "#base_network_wraper.load('../saves/fc_preact_VAEAC_NEW2_' + dname + '_models/theta_best.dat')\n",
    "\n",
    "base_network = net.model\n",
    "width = 150\n",
    "depth = 2\n",
    "latent_dim = under_latent_dims2[names.index(dname)]\n",
    "\n",
    "batch_size = 128\n",
    "nb_epochs = 2000\n",
    "early_stop = 200\n",
    "lr = 1e-4\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# COMPAS\n",
    "#\"\"\"\n",
    "x_train, x_test, x_means, x_stds, y_train, y_test, feature_names, X_dims = \\\n",
    "    get_my_COMPAS(rseed=42, separate_test=True, test_ratio=0.1, save_dir='../data/')\n",
    "\n",
    "x_train, x_test, input_dim_vec = join_compas_targets(x_train, x_test, y_train, y_test, X_dims)\n",
    "print('Compas', x_train.shape, x_test.shape)\n",
    "print(input_dim_vec)\n",
    "\n",
    "dname = 'compas'\n",
    "print(dname)\n",
    "\n",
    "trainset = Datafeed(x_train, x_train, transform=None)\n",
    "valset = Datafeed(x_test, x_test, transform=None)\n",
    "\n",
    "width = 150\n",
    "depth = 2\n",
    "latent_dim = under_latent_dims[names.index(dname)]\n",
    "\n",
    "batch_size = 128\n",
    "nb_epochs = 2000\n",
    "early_stop = 200\n",
    "lr = 1e-4\n",
    "\n",
    "cuda = False\n",
    "\n",
    "base_network_wraper = VAEAC_gauss_cat_net(input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=lr, cuda=cuda, flatten=True)\n",
    "base_network_wraper.load('../saves/fc_preact_VAEAC_NEW_' + dname + '_models/theta_best.dat')\n",
    "\n",
    "#VAEAC = VAEAC_gauss_cat_net(input_dim_vec, width, depth, latent_dim, pred_sig=False, lr=lr, cuda=cuda, flatten=flat_vaeac_bools[d_idx])\n",
    "#VAEAC.load('../saves/fc_preact_VAEAC_NEW_' + dname + '_models/theta_best.dat')\n",
    "\n",
    "base_network = base_network_wraper.model\n",
    "\n",
    "savedir = '../saves/fc_VAEAC_NEW_under2_' + dname  # remove the 2 to remove dimensionality reduction\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "under_VAEAC_net = under_VAEAC(base_network, width, depth, latent_dim, lr, cuda=cuda)\n",
    "\n",
    "vlb_train, vlb_dev = train_VAE(under_VAEAC_net, savedir,\n",
    "                               batch_size, nb_epochs, trainset, valset, cuda=cuda,\n",
    "                               flat_ims=False, train_plot=False, Nclass=None, early_stop=early_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fc8f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/m6rs_5bd7zsf3gjy2hg8y57r0000gn/T/ipykernel_10249/1070947545.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49812"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_VAEAC_net.get_nb_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d9790a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778085\n"
     ]
    }
   ],
   "source": [
    "number_p = 0\n",
    "for p in net.model.parameters():\n",
    "    for i in range(len(p.data)):\n",
    "        #print(len(p.data))\n",
    "        try:\n",
    "            number_p += len(p.data[i])\n",
    "        except:\n",
    "            number_p += 1\n",
    "print(number_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bee9aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1953,  0.1680, -0.0635,  ...,  0.1309,  0.0337, -0.1151],\n",
      "        [ 0.0867, -0.1051, -0.0316,  ...,  0.1187,  0.0668,  0.1751],\n",
      "        [ 0.0473, -0.1043,  0.0623,  ...,  0.0617,  0.0875,  0.0812],\n",
      "        ...,\n",
      "        [-0.1474,  0.2562, -0.1020,  ...,  0.1505,  0.1124,  0.0671],\n",
      "        [-0.0777,  0.1288,  0.0823,  ...,  0.0869,  0.1883, -0.0504],\n",
      "        [ 0.0840,  0.1529,  0.0006,  ...,  0.0037, -0.1448, -0.0819]])\n",
      "tensor([-0.0420,  0.0951,  0.0312, -0.0081,  0.0587, -0.1466,  0.2107,  0.1487,\n",
      "         0.1520, -0.1944,  0.2045,  0.0413, -0.2018,  0.2153, -0.0358,  0.0860,\n",
      "         0.1789,  0.1633,  0.2059, -0.2002,  0.2350,  0.0600,  0.0048, -0.1823,\n",
      "        -0.1383,  0.2303,  0.1632,  0.1677, -0.0273, -0.1063,  0.0492, -0.0949,\n",
      "        -0.1412,  0.0960,  0.2115, -0.1593, -0.2120,  0.0359, -0.0733, -0.1013,\n",
      "        -0.0405,  0.0021, -0.0675,  0.1887,  0.0983,  0.0666, -0.0523, -0.0020,\n",
      "         0.1542,  0.0323, -0.2225,  0.0058,  0.0914, -0.0639, -0.0398, -0.0056,\n",
      "         0.1752,  0.1858, -0.1554,  0.1764,  0.1144,  0.0876, -0.0972, -0.1501,\n",
      "         0.2246,  0.0807, -0.0747, -0.0354,  0.1914, -0.0531,  0.1662, -0.0600,\n",
      "         0.0779,  0.0240, -0.1035,  0.0095,  0.0736, -0.2000, -0.0374,  0.0016,\n",
      "         0.2160,  0.0627, -0.1768, -0.0429,  0.2389, -0.0291,  0.1740,  0.0294,\n",
      "         0.1521, -0.1208,  0.2155,  0.0587, -0.0382,  0.1923,  0.1369, -0.1661,\n",
      "        -0.0383,  0.1908,  0.0487, -0.0722, -0.1540, -0.1394,  0.1258,  0.0887,\n",
      "        -0.2133, -0.0617,  0.0390, -0.1926,  0.1767, -0.0184, -0.1178,  0.0142,\n",
      "         0.0668,  0.0635,  0.2471,  0.1226, -0.0080,  0.0483,  0.0743, -0.0576,\n",
      "        -0.2042, -0.0077, -0.0815, -0.2545,  0.0935, -0.1144,  0.1985,  0.1057,\n",
      "         0.0985,  0.0948,  0.1168,  0.1817,  0.1892, -0.0115, -0.0900,  0.0812,\n",
      "        -0.0763,  0.0173,  0.0227,  0.1199, -0.2372,  0.1071, -0.0741, -0.1400,\n",
      "        -0.0908,  0.0041,  0.1035, -0.1785,  0.0705,  0.2223, -0.1057,  0.0658,\n",
      "        -0.0599,  0.0539,  0.1126, -0.1399,  0.0630,  0.2510,  0.0171, -0.1483,\n",
      "         0.0133,  0.0837,  0.0842, -0.0138, -0.0706, -0.0942,  0.1554, -0.1260,\n",
      "        -0.0869,  0.1748, -0.0714, -0.0172, -0.0855, -0.2041,  0.1035, -0.1029,\n",
      "        -0.0657, -0.0483,  0.0300,  0.2015,  0.2305,  0.0392, -0.1829, -0.0027,\n",
      "        -0.0087,  0.2097, -0.0060, -0.2116,  0.0826, -0.0370,  0.0819,  0.0447,\n",
      "         0.0854,  0.1396, -0.1457, -0.2050,  0.2179,  0.2240, -0.0849,  0.2222,\n",
      "         0.0769, -0.0500, -0.0975, -0.1374,  0.2060, -0.1493, -0.0998,  0.2307,\n",
      "        -0.1120,  0.2623,  0.0647,  0.1365,  0.0568, -0.0112,  0.0854,  0.0873,\n",
      "        -0.1450, -0.1785, -0.1525, -0.0049,  0.0812, -0.1227,  0.0298,  0.1519,\n",
      "         0.1340, -0.0955,  0.0767, -0.1878,  0.1554, -0.2018,  0.0120, -0.0688,\n",
      "        -0.2146, -0.2159, -0.1413, -0.1513,  0.1841, -0.0091, -0.1306,  0.0117,\n",
      "        -0.0905, -0.0299,  0.1972, -0.1873, -0.1885,  0.0476,  0.1555, -0.2267,\n",
      "         0.1065,  0.2575, -0.0319, -0.1194,  0.1209,  0.1444, -0.0176, -0.1857,\n",
      "         0.0285, -0.1385, -0.1897,  0.1472,  0.1508,  0.1102, -0.1667,  0.2024,\n",
      "         0.1495,  0.1775, -0.0183, -0.0266, -0.1959,  0.1660,  0.0427, -0.2218,\n",
      "         0.2647, -0.0276,  0.1316, -0.0358, -0.0556,  0.1974,  0.1943, -0.0783,\n",
      "         0.0486,  0.1609, -0.0061, -0.0325,  0.2107,  0.2260, -0.0718,  0.1607,\n",
      "        -0.0186,  0.0005,  0.1658, -0.0142, -0.0119, -0.0325, -0.1750,  0.1724,\n",
      "        -0.1811, -0.1445,  0.0497, -0.0234, -0.0048,  0.0098,  0.2449, -0.1720,\n",
      "        -0.1738,  0.0535, -0.2071, -0.1699,  0.1711,  0.0805, -0.0405,  0.0264,\n",
      "         0.0411,  0.0076,  0.2176,  0.0218,  0.1697, -0.1927, -0.0611,  0.0660,\n",
      "         0.1005, -0.0769,  0.2028, -0.1890, -0.1019,  0.1857, -0.1811, -0.2128,\n",
      "        -0.0502, -0.1674,  0.0790, -0.0419, -0.0695,  0.1500,  0.0051, -0.2067,\n",
      "        -0.2143,  0.1683,  0.1079,  0.0974, -0.1670, -0.0572,  0.2179,  0.2138,\n",
      "         0.1447,  0.2220, -0.0732, -0.1904,  0.1612,  0.1183])\n",
      "tensor([0.9876, 0.9732, 0.9717, 0.9571, 0.9969, 0.8806, 0.9383, 0.9872, 0.9477,\n",
      "        0.9999, 0.9958, 1.0090, 1.0272, 0.9836, 0.9664, 1.0089, 1.0163, 0.9851,\n",
      "        1.0318, 0.9381, 0.9890, 0.9987, 0.9585, 0.9903, 0.9450, 1.0055, 0.9883,\n",
      "        1.0069, 0.9798, 0.9367, 1.0301, 0.8865, 0.9855, 0.9663, 1.0016, 1.0088,\n",
      "        0.9436, 1.0309, 0.9903, 1.0137, 0.9859, 0.9917, 0.9678, 1.0066, 1.0132,\n",
      "        0.9745, 1.0426, 1.0319, 0.9452, 0.9263, 0.9539, 0.9884, 1.1107, 0.9634,\n",
      "        0.9438, 0.9904, 0.9994, 0.9958, 0.9554, 1.0168, 0.9822, 0.9986, 0.9905,\n",
      "        0.9490, 1.0077, 0.9666, 1.0173, 1.0055, 1.0086, 0.9943, 1.0355, 0.9284,\n",
      "        0.9905, 1.0190, 0.9525, 1.0012, 1.0274, 1.0323, 1.0351, 0.9576, 0.9871,\n",
      "        0.9554, 0.9525, 1.0019, 0.9971, 0.9638, 1.0101, 1.0171, 0.9996, 1.0180,\n",
      "        0.9854, 1.0099, 1.0209, 1.0005, 0.9331, 0.9726, 0.9744, 0.9592, 1.0168,\n",
      "        1.0218, 0.9647, 0.9997, 1.0280, 1.0161, 0.9868, 1.0282, 0.9760, 1.0335,\n",
      "        1.0120, 1.0005, 1.0416, 1.0144, 0.9715, 0.9642, 1.0234, 0.9686, 0.9775,\n",
      "        0.9882, 0.9016, 0.9810, 0.9528, 1.0044, 0.9909, 0.9800, 1.0269, 0.9687,\n",
      "        1.0287, 1.0331, 0.9892, 0.9905, 0.9840, 1.0151, 0.9665, 0.9681, 0.9741,\n",
      "        1.0685, 1.0326, 1.0224, 1.0117, 0.9803, 1.0398, 0.9917, 0.9640, 0.9844,\n",
      "        0.9658, 0.9616, 0.9712, 0.9383, 0.9605, 0.9733, 0.9847, 0.9394, 0.9815,\n",
      "        0.9873, 0.9633, 1.0141, 0.9572, 0.9889, 0.9757, 0.9768, 0.9471, 1.0227,\n",
      "        0.9793, 1.0163, 0.9610, 1.0159, 0.9665, 0.9939, 0.9979, 0.9825, 0.9825,\n",
      "        1.0311, 0.9825, 0.9387, 0.9971, 1.0116, 0.9784, 0.9990, 1.0233, 0.9883,\n",
      "        0.9847, 1.0040, 1.0182, 1.0052, 1.0286, 0.9638, 0.9834, 0.9327, 1.0020,\n",
      "        0.9888, 1.0293, 1.0108, 1.0154, 0.9932, 0.9569, 0.9970, 1.0317, 0.9356,\n",
      "        0.9586, 0.9773, 1.0184, 1.0135, 0.9889, 0.9646, 0.9962, 0.9580, 0.9724,\n",
      "        1.0467, 1.0254, 1.0492, 0.9878, 0.9785, 0.9797, 1.0324, 0.9661, 1.0153,\n",
      "        1.1279, 1.0275, 0.9710, 1.0122, 1.0071, 0.9557, 1.0304, 0.9727, 0.9929,\n",
      "        0.9788, 0.9790, 0.9538, 1.0066, 0.9330, 0.9869, 1.0231, 0.9023, 1.0602,\n",
      "        0.9983, 0.9848, 0.9980, 0.9792, 1.0043, 1.0105, 1.0139, 1.0067, 0.9718,\n",
      "        0.9786, 1.0083, 1.0180, 0.9944, 1.0019, 0.9856, 0.9976, 1.0322, 1.0159,\n",
      "        1.0089, 0.9851, 0.9921, 1.0216, 0.9849, 1.0107, 0.9207, 0.9506, 0.9598,\n",
      "        0.9959, 1.0032, 1.0031, 0.9599, 1.0341, 1.0138, 1.0077, 1.0555, 0.9791,\n",
      "        0.9861, 0.9860, 1.0536, 0.9600, 0.9666, 0.9889, 0.9602, 1.0032, 0.9970,\n",
      "        0.9496, 1.0005, 0.9759, 0.9785, 1.0330, 0.9781, 0.9771, 0.9923, 0.9996,\n",
      "        1.0021, 1.0380, 0.9738, 0.9838, 0.9986, 0.9733, 1.0243, 0.9883, 0.9801,\n",
      "        1.0121, 0.9954, 0.9608, 1.0066, 0.9687, 1.0039, 0.9619, 0.9652, 0.9475,\n",
      "        1.0092, 0.9501, 0.9932, 0.9762, 1.0101, 0.9583, 1.0459, 0.9962, 1.0045,\n",
      "        0.9610, 1.0021, 0.9717, 0.9444, 0.9808, 0.9838, 1.0179, 0.9713, 0.9820,\n",
      "        0.9592, 0.9755, 1.0178, 0.9685, 0.9045, 0.9556, 0.9841, 1.0322, 1.0321,\n",
      "        1.0045, 0.9795, 1.0122, 0.9814, 0.9705, 1.0038, 0.9853, 0.9874, 0.9861,\n",
      "        1.0022, 1.0543, 1.0052, 0.9722, 1.0072, 0.9843, 1.0134, 1.0498])\n",
      "tensor([-1.9262e-02,  6.8808e-02, -2.7709e-02, -7.9781e-03,  5.2086e-04,\n",
      "        -2.9641e-02,  1.2010e-02,  6.0496e-02,  9.3870e-03, -2.3443e-02,\n",
      "        -2.9899e-03,  9.0187e-03, -7.2212e-03,  2.9913e-02, -4.5215e-02,\n",
      "        -7.9863e-03, -2.5696e-02,  1.2925e-02,  2.7612e-02,  5.9847e-02,\n",
      "         5.9145e-02, -5.9123e-02, -3.0768e-02, -4.0015e-02, -3.8799e-02,\n",
      "         1.8588e-02, -7.5539e-03,  1.1407e-02, -7.9261e-02,  4.2057e-02,\n",
      "        -3.1660e-02,  7.5483e-04, -7.2974e-03,  6.6604e-02,  4.0746e-02,\n",
      "         5.8240e-03, -4.4103e-04,  5.7515e-02, -1.5165e-03, -3.2856e-03,\n",
      "        -2.1731e-02, -3.7585e-02, -1.2027e-02,  8.2008e-03, -2.8148e-02,\n",
      "        -6.8415e-02,  4.9045e-02, -5.1184e-03, -9.7163e-03, -3.9261e-02,\n",
      "         5.4607e-02, -3.0264e-02,  6.2059e-02, -4.5310e-02, -1.0581e-02,\n",
      "         5.4883e-02,  7.2326e-02,  6.4441e-03, -1.6695e-03, -1.3685e-02,\n",
      "         2.9680e-02,  4.5392e-02, -7.7423e-03,  1.5334e-02, -1.2557e-02,\n",
      "        -1.9720e-02, -6.5372e-02,  2.2941e-02,  4.6141e-02,  4.5977e-02,\n",
      "        -2.0632e-02,  2.4224e-03,  2.5363e-02,  1.8250e-02,  8.8735e-03,\n",
      "        -1.9366e-02,  3.0012e-02, -8.5280e-03,  2.8335e-02, -5.7338e-02,\n",
      "        -2.1394e-02, -5.4109e-03,  2.8922e-02,  2.3728e-02,  7.0688e-02,\n",
      "         2.2296e-02,  1.4364e-03, -3.7522e-02, -2.4035e-02,  2.5778e-02,\n",
      "        -4.2108e-02, -4.6456e-02,  1.2510e-02,  6.2311e-04,  3.5344e-03,\n",
      "         2.7247e-03, -5.3089e-03,  2.2763e-02,  5.1632e-02, -1.7072e-02,\n",
      "        -4.5645e-03, -5.1766e-02, -1.6763e-03,  7.8325e-03,  4.9228e-02,\n",
      "        -1.6008e-02,  1.8120e-02, -8.1276e-03,  1.6122e-02, -1.6607e-02,\n",
      "        -2.0517e-02,  1.3496e-02, -4.8073e-02, -5.6107e-02, -1.9892e-02,\n",
      "         6.2271e-02,  2.3159e-02, -3.6944e-02, -8.4918e-03,  2.2747e-02,\n",
      "         3.9289e-02, -3.4095e-02,  2.9631e-02,  4.2823e-02,  4.0381e-02,\n",
      "         1.6333e-02,  1.6300e-02,  1.3065e-02,  1.5338e-05,  3.2305e-02,\n",
      "         3.3070e-02,  5.6642e-03,  1.7595e-02, -2.7387e-02,  1.0444e-02,\n",
      "         2.5394e-02,  6.8261e-02,  5.8893e-02, -4.9872e-02, -1.5014e-02,\n",
      "        -1.4407e-02, -3.7862e-02,  7.1918e-03,  2.7607e-02, -6.7100e-03,\n",
      "         1.5155e-03, -2.5426e-02,  4.9831e-02, -2.0772e-02,  4.7268e-02,\n",
      "        -6.7425e-03, -3.7260e-02,  3.1881e-03, -4.7137e-02, -6.2286e-02,\n",
      "        -2.1851e-02, -6.3547e-02,  5.3632e-03,  5.4303e-02, -2.8698e-02,\n",
      "        -5.7086e-02,  4.1721e-02,  6.2883e-02,  3.5069e-03, -5.2867e-02,\n",
      "         4.0767e-02, -4.3008e-03,  2.2340e-02, -3.4104e-02, -1.0424e-02,\n",
      "         1.3295e-02, -8.9642e-03, -4.4534e-02, -2.2958e-02, -5.6079e-03,\n",
      "         1.9897e-03,  7.5531e-02,  1.9228e-02, -8.9603e-03, -4.1270e-02,\n",
      "         1.4835e-03,  4.6044e-02,  4.3999e-02, -1.2212e-02, -2.3107e-02,\n",
      "         4.4801e-04,  4.0472e-02,  4.3104e-02,  6.6777e-03, -4.2531e-03,\n",
      "         1.6991e-02,  2.1619e-02,  3.4818e-02,  7.6285e-03,  4.7863e-03,\n",
      "        -1.5506e-03, -2.5538e-02,  2.8417e-03, -9.8136e-03, -5.9801e-03,\n",
      "         8.0864e-02,  3.1428e-02,  7.5658e-03,  2.7218e-02,  4.6474e-02,\n",
      "         3.2926e-02, -7.1620e-03,  2.7260e-02,  2.4225e-03,  8.3858e-02,\n",
      "        -3.3439e-02, -9.5333e-03, -2.1884e-02,  6.9214e-02,  1.4129e-02,\n",
      "         1.1217e-02,  4.2525e-02,  3.2221e-02, -7.3203e-03,  3.9458e-02,\n",
      "        -5.6014e-02, -2.3412e-02,  3.0586e-02,  1.2310e-02,  2.1869e-02,\n",
      "         1.4144e-02, -7.4028e-03,  1.9991e-02, -7.8582e-03,  6.1067e-02,\n",
      "        -7.4784e-02, -1.2307e-02,  2.0536e-02,  8.2082e-03,  6.3744e-02,\n",
      "        -3.1241e-02,  9.5708e-03,  4.7774e-02,  2.4200e-02,  4.1907e-02,\n",
      "        -1.0739e-02,  8.8580e-03, -1.1545e-02, -3.9819e-02,  4.2797e-02,\n",
      "         1.7787e-02, -8.8647e-03,  5.6656e-02,  2.8186e-02, -3.8903e-03,\n",
      "         2.5539e-02,  9.4593e-03,  4.0041e-02,  3.4093e-02, -5.8309e-03,\n",
      "         5.9342e-04, -2.4656e-03, -3.3458e-03, -5.2046e-02,  2.9881e-02,\n",
      "         3.7359e-02,  1.3456e-02,  8.4703e-04, -6.1181e-04,  4.1887e-02,\n",
      "        -5.4249e-04, -2.7966e-02,  3.7510e-02,  2.2977e-02,  5.8251e-02,\n",
      "         3.2375e-02,  9.7487e-03, -8.5164e-03,  2.6924e-02,  4.9820e-02,\n",
      "        -1.3774e-02, -1.5499e-02,  1.6504e-02, -1.8427e-02,  5.2729e-03,\n",
      "        -1.0275e-02, -5.3591e-02, -1.8835e-02,  8.2620e-02, -2.6378e-02,\n",
      "         4.1757e-02,  3.7953e-02, -2.0136e-02,  2.1273e-02, -5.5847e-03,\n",
      "         3.5576e-02, -4.5933e-03,  1.6068e-03,  7.6787e-03, -2.7052e-02,\n",
      "         9.7230e-03,  1.1144e-02, -1.0734e-02,  3.5131e-04,  3.3855e-02,\n",
      "        -5.8945e-02, -1.8785e-02, -3.8598e-03,  4.9779e-02, -2.4780e-02,\n",
      "        -1.3345e-02,  4.9903e-02, -4.5732e-02, -1.1392e-02,  2.5641e-02,\n",
      "         1.4635e-02,  2.0806e-02,  5.4765e-02, -5.3246e-02, -9.5838e-03,\n",
      "        -1.7550e-02,  4.4272e-02, -1.3776e-02,  8.6036e-03, -6.5184e-03,\n",
      "         4.2923e-02, -1.9712e-02,  4.4422e-02,  3.8219e-02, -6.1315e-03,\n",
      "         2.4058e-02,  2.3787e-02,  7.7424e-03, -1.0414e-02,  2.1284e-02,\n",
      "         2.5402e-02,  4.5648e-03,  7.3262e-03,  8.0529e-02,  4.3396e-03,\n",
      "         6.5539e-03,  3.7631e-02,  8.4009e-03, -4.8994e-02,  3.6077e-02,\n",
      "        -1.8451e-02, -3.1641e-02, -4.3811e-03,  2.7165e-02,  4.0062e-02,\n",
      "        -3.3648e-02,  3.3398e-02,  4.2256e-02,  7.1011e-04,  3.7615e-03])\n",
      "tensor([[ 4.5963e-05, -4.7313e-02,  7.9125e-03,  ..., -9.2213e-03,\n",
      "          1.9835e-02, -1.7928e-02],\n",
      "        [ 8.3867e-02, -5.5072e-02,  3.5573e-03,  ..., -1.7408e-02,\n",
      "          1.0537e-02, -7.5854e-02],\n",
      "        [ 5.3811e-02, -3.3852e-02,  2.5569e-02,  ..., -4.8031e-02,\n",
      "         -3.3776e-02,  5.0088e-04],\n",
      "        ...,\n",
      "        [-2.1221e-02,  1.2443e-02, -1.2909e-02,  ...,  8.8199e-03,\n",
      "          2.2996e-02,  1.7484e-02],\n",
      "        [ 9.5624e-03, -3.3259e-02, -5.0231e-02,  ...,  5.4299e-03,\n",
      "          1.5280e-02, -3.6116e-02],\n",
      "        [-6.6424e-03, -5.2713e-02,  4.1261e-02,  ..., -1.1734e-02,\n",
      "         -4.2039e-02, -2.2081e-02]])\n",
      "tensor([ 0.0347,  0.0051,  0.0095, -0.0613, -0.0357,  0.0105,  0.0558,  0.0516,\n",
      "        -0.0672,  0.0390,  0.0753, -0.0219,  0.0642, -0.0380, -0.0130, -0.0293,\n",
      "        -0.0111,  0.0084,  0.0216, -0.1348,  0.0702,  0.0642, -0.0356, -0.0238,\n",
      "         0.0159, -0.0588,  0.0169,  0.0559,  0.0066, -0.0361,  0.0125,  0.0777,\n",
      "        -0.0338, -0.0348,  0.0715, -0.0424,  0.0228,  0.0021, -0.0316,  0.0101,\n",
      "        -0.0504,  0.0497,  0.0408, -0.0326, -0.0774, -0.0157, -0.0209, -0.0683,\n",
      "         0.0394,  0.0198, -0.0669,  0.0210,  0.0219, -0.0103, -0.0269, -0.0158,\n",
      "         0.0443,  0.0436, -0.0870, -0.0329,  0.0184, -0.0381,  0.0431, -0.0308,\n",
      "         0.0525, -0.0458,  0.0003, -0.0304,  0.0855,  0.0427, -0.0133, -0.0588,\n",
      "         0.0564, -0.0172, -0.0126, -0.0234, -0.0274, -0.0195, -0.0215,  0.0219,\n",
      "         0.0293,  0.0440, -0.0358,  0.0239, -0.0181,  0.0361,  0.0215, -0.0282,\n",
      "        -0.0839,  0.0183, -0.0273,  0.0317,  0.0186, -0.0165,  0.0730, -0.0456,\n",
      "        -0.0149,  0.0167, -0.0494,  0.0617, -0.0428,  0.0837,  0.0480,  0.0170,\n",
      "        -0.0738, -0.0597, -0.0234,  0.0124,  0.0297,  0.0357,  0.0571, -0.0033,\n",
      "        -0.0206,  0.0211,  0.0249,  0.0055,  0.0006, -0.0271,  0.0320,  0.0601,\n",
      "         0.0125, -0.0066, -0.0151,  0.0358,  0.0264, -0.0367,  0.0319, -0.0425,\n",
      "         0.0514,  0.0604,  0.0755, -0.0156, -0.0084, -0.0600, -0.0036, -0.0446,\n",
      "         0.0149, -0.0488,  0.0371,  0.0392, -0.0498,  0.0624, -0.0452,  0.0200,\n",
      "         0.0122, -0.0649, -0.0452,  0.0282,  0.0489,  0.0159, -0.0111,  0.1017,\n",
      "         0.0014,  0.0320,  0.0262,  0.0120,  0.0253,  0.0421, -0.0434,  0.0794,\n",
      "         0.0467,  0.0132,  0.0410, -0.0359,  0.0328,  0.0358, -0.0372,  0.0429,\n",
      "        -0.0420,  0.0654,  0.0344, -0.0057,  0.0499,  0.0241, -0.0843, -0.0776,\n",
      "         0.0463,  0.0297, -0.0286, -0.0033,  0.0049,  0.0754,  0.0847, -0.0822,\n",
      "         0.0425,  0.0146, -0.0111, -0.0633,  0.1065, -0.0200,  0.0361, -0.0030,\n",
      "         0.0325, -0.0193, -0.0583,  0.0008, -0.0360, -0.0694, -0.0402,  0.0691,\n",
      "        -0.0140,  0.0602,  0.0436, -0.0034,  0.0502,  0.0076,  0.0306,  0.0126,\n",
      "         0.0901,  0.0141, -0.0055,  0.0210,  0.0327, -0.0166,  0.0368,  0.0364,\n",
      "         0.1112, -0.0185,  0.0527, -0.0076,  0.0768, -0.0624, -0.0256,  0.0326,\n",
      "         0.0331,  0.0153,  0.0553, -0.0018, -0.0062,  0.0068, -0.0296,  0.0860,\n",
      "         0.0062, -0.0264,  0.0100,  0.0301, -0.0052, -0.0138, -0.0790,  0.0482,\n",
      "        -0.0117,  0.0628,  0.0103, -0.0185, -0.0306, -0.0096, -0.0322,  0.0600,\n",
      "         0.0560,  0.0210, -0.0396, -0.0521,  0.0719,  0.0526, -0.0093, -0.0116,\n",
      "        -0.0015,  0.0415,  0.0326, -0.0556,  0.0059, -0.0111,  0.0377, -0.0462,\n",
      "         0.0083,  0.0363, -0.0184, -0.0326,  0.0386, -0.0022,  0.0232, -0.0720,\n",
      "        -0.0076,  0.0488,  0.0310,  0.0105, -0.1059,  0.0330,  0.0413,  0.0241,\n",
      "         0.0617,  0.0466,  0.0069, -0.0063, -0.0048,  0.0447, -0.0254, -0.0395,\n",
      "         0.0316,  0.0522,  0.0195,  0.0515,  0.0340,  0.0359, -0.0091,  0.0488,\n",
      "        -0.0247, -0.0172, -0.0188,  0.0517, -0.0312,  0.0474, -0.0233, -0.0150,\n",
      "        -0.0277,  0.0050,  0.0154, -0.0784,  0.0475, -0.0153,  0.0793,  0.0154,\n",
      "        -0.0446, -0.0227,  0.0759, -0.0089, -0.0088,  0.0011, -0.0180,  0.0703,\n",
      "        -0.0581,  0.0309,  0.0466,  0.0260,  0.0026, -0.0349, -0.0324, -0.0205,\n",
      "        -0.0131, -0.0231,  0.0632,  0.0289, -0.0298, -0.0033, -0.0059,  0.0091,\n",
      "         0.0696,  0.0361, -0.0467,  0.0453,  0.0816, -0.0069, -0.0285, -0.0046,\n",
      "        -0.0467, -0.0251,  0.0364, -0.0050,  0.0135, -0.0198])\n",
      "tensor([1.0276, 0.9734, 0.9957, 1.0078, 1.0151, 1.0305, 0.9878, 1.0024, 0.9848,\n",
      "        0.9885, 0.9671, 0.9577, 0.9735, 0.9976, 0.9931, 1.0471, 1.0200, 1.0076,\n",
      "        1.0147, 1.0976, 1.0151, 1.0188, 1.0208, 1.0023, 0.9693, 0.9917, 1.0252,\n",
      "        1.0278, 0.9826, 1.0219, 0.9958, 0.9717, 1.0553, 0.9846, 1.0318, 1.0027,\n",
      "        0.9813, 1.0103, 1.0031, 0.9662, 0.9919, 0.9906, 0.9656, 0.9655, 1.0095,\n",
      "        0.9703, 1.0270, 1.0539, 0.9987, 1.0018, 1.0788, 1.0008, 1.0141, 1.0225,\n",
      "        0.9876, 1.0063, 1.0317, 1.0050, 0.9833, 0.9641, 1.0407, 1.0003, 1.0027,\n",
      "        1.0242, 1.0027, 1.0354, 1.0505, 0.9687, 0.9794, 0.9811, 0.9985, 0.9983,\n",
      "        0.9880, 1.0080, 0.9740, 0.9943, 0.9915, 1.0074, 1.0049, 0.9850, 1.0111,\n",
      "        0.9620, 1.0144, 1.0112, 0.9646, 0.9897, 1.0078, 1.0050, 1.0339, 1.0247,\n",
      "        0.9894, 0.9860, 1.0322, 1.0284, 0.9617, 0.9929, 0.9691, 0.9840, 0.9773,\n",
      "        1.0174, 1.0004, 0.9786, 1.0732, 1.0262, 1.0148, 1.0317, 1.0114, 1.0083,\n",
      "        0.9789, 1.0044, 0.9950, 1.0026, 0.9888, 1.0235, 0.9867, 0.9979, 1.0289,\n",
      "        0.9779, 0.9652, 1.0048, 0.9974, 0.9973, 1.0047, 0.9879, 1.0275, 1.0569,\n",
      "        1.0324, 0.9800, 0.9852, 0.9513, 0.9791, 1.0330, 1.0028, 0.9975, 0.9552,\n",
      "        1.0100, 1.0201, 0.9832, 0.9597, 1.0090, 1.0094, 0.9727, 0.9789, 0.9863,\n",
      "        0.9616, 0.9913, 1.0209, 0.9954, 1.0049, 0.9845, 1.0359, 1.0044, 1.0041,\n",
      "        0.9999, 0.9971, 0.9938, 0.9813, 1.0475, 0.9600, 0.9691, 0.9972, 1.0279,\n",
      "        0.9597, 0.9878, 0.9768, 0.9905, 1.0116, 0.9689, 0.9886, 1.0035, 1.0130,\n",
      "        1.0079, 0.9864, 1.0016, 1.0102, 0.9657, 0.9814, 1.0073, 0.9785, 0.9734,\n",
      "        1.0022, 0.9741, 0.9904, 0.9756, 0.9953, 0.9937, 0.9845, 0.9992, 0.9822,\n",
      "        0.9847, 0.9808, 0.9834, 1.0167, 0.9824, 0.9566, 1.0134, 0.9866, 1.0094,\n",
      "        0.9836, 1.0023, 1.0117, 1.0030, 0.9680, 0.9864, 1.0629, 0.9799, 0.9989,\n",
      "        0.9914, 1.0161, 0.9927, 1.0228, 1.0208, 1.0056, 0.9903, 0.9812, 1.0128,\n",
      "        0.9802, 0.9686, 0.9837, 0.9587, 0.9947, 1.0057, 1.0099, 0.9736, 0.9867,\n",
      "        1.0106, 1.0019, 0.9777, 1.0266, 0.9839, 1.0092, 0.9791, 1.0120, 0.9951,\n",
      "        0.9892, 1.0080, 0.9924, 1.0151, 1.0514, 0.9986, 0.9767, 0.9932, 1.0072,\n",
      "        1.0096, 0.9693, 0.9893, 0.9941, 1.0092, 0.9834, 0.9917, 1.0273, 1.0228,\n",
      "        0.9961, 0.9971, 0.9910, 1.0073, 1.0079, 0.9845, 0.9848, 0.9819, 0.9515,\n",
      "        0.9866, 0.9800, 1.0095, 1.0334, 1.0131, 0.9525, 0.9887, 1.0006, 0.9878,\n",
      "        1.0286, 0.9987, 0.9834, 0.9541, 0.9848, 0.9973, 1.1001, 0.9669, 0.9908,\n",
      "        0.9613, 1.0240, 0.9648, 1.0000, 1.0100, 0.9762, 1.0238, 0.9801, 0.9944,\n",
      "        1.0194, 0.9932, 0.9892, 0.9858, 1.0204, 1.0209, 1.0051, 0.9804, 0.9982,\n",
      "        1.0412, 0.9724, 0.9410, 1.0054, 1.0076, 1.0047, 0.9616, 1.0797, 0.9864,\n",
      "        0.9831, 1.0180, 0.9940, 1.0127, 0.9759, 1.0594, 0.9919, 0.9868, 0.9981,\n",
      "        0.9792, 1.0028, 0.9713, 0.9710, 0.9807, 1.0127, 0.9971, 0.9967, 0.9640,\n",
      "        0.9967, 0.9670, 0.9862, 0.9880, 0.9866, 0.9486, 0.9962, 1.0195, 1.0055,\n",
      "        1.0060, 1.0463, 0.9530, 1.0020, 0.9688, 1.0120, 1.0150, 1.0151, 0.9696,\n",
      "        1.0005, 1.0241, 0.9665, 0.9750, 1.0198, 1.0150, 0.9713, 1.0306])\n",
      "tensor([-3.5350e-02,  1.4544e-02,  1.3029e-02, -4.5930e-02,  1.1225e-02,\n",
      "         1.1952e-02, -2.6069e-03, -2.4680e-02,  1.3814e-02, -5.9603e-03,\n",
      "         3.6558e-02,  2.7692e-02, -6.4048e-03,  1.0037e-02, -1.0070e-02,\n",
      "        -1.7275e-02,  1.6674e-02, -2.7602e-02, -4.0532e-02,  4.6684e-02,\n",
      "        -3.0559e-02, -2.1456e-02,  3.3872e-02, -2.3979e-02,  7.0430e-04,\n",
      "         7.2112e-03,  1.2325e-02, -3.6426e-02, -2.0055e-02,  4.4589e-02,\n",
      "        -9.8862e-03,  2.4613e-02, -1.7372e-02,  1.1600e-02, -1.6265e-02,\n",
      "        -2.4330e-02,  4.6533e-03,  5.4278e-02, -2.9920e-03,  2.8152e-02,\n",
      "        -2.0078e-02,  2.3122e-02,  2.5459e-02, -2.8040e-02, -8.7775e-03,\n",
      "         1.8702e-02,  2.7632e-03, -4.6198e-02,  2.9821e-02,  2.2518e-02,\n",
      "         5.2416e-02, -1.1100e-02,  1.0222e-02,  1.5708e-02,  2.8826e-02,\n",
      "         1.2678e-02,  2.2529e-02, -3.5432e-02,  3.4163e-02, -2.9744e-03,\n",
      "        -1.1407e-02, -2.2160e-02,  3.1458e-02,  3.6269e-02,  6.3464e-03,\n",
      "         8.0826e-03,  1.7367e-02,  2.9274e-02, -3.4223e-02,  5.6659e-03,\n",
      "        -1.0145e-02,  3.9194e-04, -6.9186e-03, -2.0809e-02,  4.4090e-02,\n",
      "        -1.0095e-02, -2.8433e-02,  2.2805e-02,  2.9220e-02,  1.3711e-02,\n",
      "        -5.9642e-02,  1.4878e-02,  3.5361e-02, -2.7359e-02,  1.8694e-02,\n",
      "         1.5357e-02, -1.2007e-02, -8.3162e-03, -1.1112e-02, -2.2560e-02,\n",
      "         7.3673e-04, -6.8736e-03, -3.9925e-03, -2.3595e-02,  2.7152e-02,\n",
      "        -1.8236e-02,  4.7175e-02,  1.2756e-02,  6.7276e-03,  4.3013e-02,\n",
      "         3.2018e-02,  4.6339e-03, -3.7869e-03, -5.3183e-02, -8.4378e-03,\n",
      "         2.2388e-02,  1.6571e-02, -3.7221e-02, -1.2483e-02,  2.1794e-03,\n",
      "         2.2247e-02, -7.0703e-04, -3.0174e-02,  2.5105e-02, -2.7229e-02,\n",
      "        -4.7152e-02, -2.7540e-02, -2.2321e-02,  1.1478e-02,  2.0905e-02,\n",
      "        -3.0561e-02, -2.3679e-02,  2.1322e-02, -2.3602e-03, -5.9481e-02,\n",
      "        -1.6024e-02, -1.7491e-02, -1.1836e-03, -3.1539e-03, -1.3152e-02,\n",
      "         5.6931e-02, -2.6342e-02, -1.2109e-02, -8.2168e-03,  5.0936e-02,\n",
      "        -3.3346e-02,  4.2103e-02, -2.3183e-02,  3.3327e-02,  4.6228e-02,\n",
      "        -3.4010e-02, -2.2589e-02, -1.4561e-03,  2.6052e-02,  3.9765e-02,\n",
      "        -5.0117e-02,  2.3261e-04,  7.1917e-03, -1.5897e-02,  1.8670e-02,\n",
      "        -2.5867e-02, -4.0815e-02,  5.3983e-03, -2.0648e-02, -1.3693e-02,\n",
      "        -1.7737e-03, -2.7294e-02,  5.2415e-03, -1.6004e-02,  5.4567e-02,\n",
      "        -4.5197e-02, -3.4419e-02,  9.3330e-03,  3.2222e-02, -2.8663e-03,\n",
      "         1.3755e-02,  2.2604e-02, -5.0868e-03, -3.6231e-02, -3.9697e-04,\n",
      "         1.4922e-02, -5.7933e-02,  1.9755e-02, -2.3488e-02,  1.7444e-02,\n",
      "         4.5066e-02,  4.5853e-03,  6.8704e-03,  8.0424e-03, -3.4096e-02,\n",
      "        -3.7074e-02, -1.4356e-02, -3.6809e-02,  6.3309e-03,  1.8600e-02,\n",
      "         1.2181e-03,  9.5870e-03,  4.6199e-02, -2.0432e-02,  4.0745e-02,\n",
      "        -1.9347e-02,  1.6188e-02, -1.7725e-03, -4.5266e-02,  6.9166e-04,\n",
      "         1.7140e-03,  4.3890e-02, -4.2235e-02, -3.1289e-02,  1.4253e-02,\n",
      "         6.0712e-02, -7.4071e-02,  3.0854e-03, -1.1153e-03, -2.3178e-02,\n",
      "         1.4160e-02,  1.0558e-02, -1.0060e-02, -8.1522e-03,  2.4040e-03,\n",
      "        -8.1727e-04, -1.2081e-04,  2.2357e-02,  3.5634e-02,  8.0477e-03,\n",
      "         1.7610e-02,  1.1644e-02, -8.5299e-03, -1.2960e-02,  1.3231e-02,\n",
      "         4.2892e-02, -8.0465e-03,  2.3163e-02, -2.7743e-02,  1.5291e-03,\n",
      "         3.0255e-02,  6.4247e-03,  3.0443e-02, -3.9913e-03,  2.3711e-02,\n",
      "        -1.0543e-02, -1.9637e-02, -1.9586e-02, -1.0059e-02,  3.0858e-02,\n",
      "        -2.7976e-02, -1.8511e-02, -2.7751e-02, -2.1409e-02, -2.6789e-02,\n",
      "         3.6398e-03, -2.3267e-03,  2.8849e-02, -1.5588e-02, -1.6449e-02,\n",
      "        -8.7423e-03, -2.2012e-02, -6.6562e-03,  3.0040e-02,  9.0777e-03,\n",
      "         2.4204e-03, -2.1653e-02, -3.8930e-02, -2.4384e-02,  1.4804e-02,\n",
      "         3.4419e-02, -3.7753e-02, -1.3193e-03,  8.1317e-03,  2.0632e-02,\n",
      "         8.0026e-03, -7.0535e-03,  8.9526e-03, -3.6372e-02, -6.1832e-03,\n",
      "        -1.1020e-02,  3.0251e-02,  2.0859e-03,  3.0837e-02, -9.9613e-03,\n",
      "        -1.5744e-02,  2.5834e-03, -2.9797e-02, -2.1005e-02,  1.4507e-02,\n",
      "        -1.1474e-02, -1.8025e-02,  1.4232e-02,  5.2274e-03, -1.2668e-02,\n",
      "        -9.8186e-04,  4.0867e-03, -8.1167e-03, -3.4265e-02,  6.0216e-03,\n",
      "         5.6454e-03, -1.5457e-03,  1.6552e-02,  3.9761e-02, -1.0269e-02,\n",
      "         1.0324e-02, -1.6654e-03,  3.3594e-03,  2.1380e-02,  1.7027e-02,\n",
      "         7.5875e-02,  1.0034e-02, -1.7652e-02,  1.1878e-02, -1.9520e-03,\n",
      "         2.4688e-03,  1.6417e-02,  1.3519e-02, -1.3754e-02, -3.2320e-02,\n",
      "        -1.3942e-02, -2.8841e-02,  2.1106e-02, -2.8115e-03, -2.7969e-02,\n",
      "        -1.1159e-02, -1.4443e-02, -8.7004e-03, -5.0777e-03, -2.0218e-02,\n",
      "        -1.5662e-02,  1.0083e-02,  1.0443e-02,  1.6605e-02, -1.9987e-02,\n",
      "         3.2370e-03, -6.3985e-02, -1.8802e-02, -1.9201e-02,  3.3417e-02,\n",
      "        -4.8423e-02, -1.1690e-02, -1.5085e-02,  4.6856e-03, -3.2940e-02,\n",
      "        -1.3441e-02, -2.2589e-03,  2.2053e-02,  1.9735e-02, -1.7714e-02,\n",
      "        -5.1835e-03,  4.4337e-03,  3.8068e-02,  4.9846e-06, -7.1225e-02,\n",
      "         3.4681e-02,  6.9338e-03, -1.8490e-02, -2.1908e-02,  7.6246e-03,\n",
      "         1.0069e-02, -2.1550e-02,  1.0254e-02, -1.8278e-02, -2.6174e-03])\n",
      "tensor([[-0.0770,  0.0347,  0.0074,  ..., -0.0336,  0.0143,  0.0743],\n",
      "        [-0.0192,  0.0327,  0.0788,  ..., -0.0576, -0.0430,  0.0561],\n",
      "        [-0.0069,  0.0412, -0.0471,  ..., -0.0413, -0.0583,  0.0006],\n",
      "        ...,\n",
      "        [-0.0324, -0.0533, -0.0025,  ...,  0.0153,  0.0354, -0.0625],\n",
      "        [-0.0351,  0.0120, -0.0232,  ...,  0.0581, -0.0030,  0.0478],\n",
      "        [ 0.0375, -0.0448, -0.0452,  ...,  0.0433, -0.0350, -0.0641]])\n",
      "tensor([ 3.1220e-02, -6.4367e-02, -5.0851e-02,  2.5917e-02, -4.5012e-02,\n",
      "         2.9362e-02,  1.9246e-02,  6.8199e-02, -4.2455e-03,  5.2977e-02,\n",
      "         2.5955e-02, -1.9022e-02,  8.4306e-02,  7.8209e-03,  1.0526e-02,\n",
      "        -2.5088e-02,  8.5779e-02, -2.4915e-02, -3.8811e-02, -1.5853e-02,\n",
      "         7.4089e-03,  5.5927e-02,  4.8042e-02,  3.3678e-02, -1.2334e-02,\n",
      "        -1.0018e-02,  2.4896e-02,  1.2468e-02,  4.9789e-02,  1.7878e-02,\n",
      "        -1.3859e-02, -3.1982e-03, -4.6200e-02,  4.8855e-02,  9.1821e-02,\n",
      "         4.9626e-02, -4.2201e-02,  2.3957e-02,  4.0595e-03, -3.7398e-02,\n",
      "         3.7986e-02,  4.5612e-02, -1.6361e-03, -3.9586e-02,  1.7108e-02,\n",
      "        -4.2307e-02,  3.8448e-02,  5.3015e-03,  3.5367e-02, -3.5653e-02,\n",
      "         1.0286e-02, -4.9044e-02, -3.8599e-02, -5.5869e-02,  1.1401e-02,\n",
      "         2.6030e-02, -1.6078e-02, -9.1632e-03, -1.1468e-02,  4.9287e-02,\n",
      "        -1.2999e-02,  4.6635e-02,  2.8266e-02, -1.1957e-03, -4.4946e-02,\n",
      "         2.2004e-02, -3.7596e-02,  2.6022e-02,  6.0958e-02,  2.8824e-02,\n",
      "         6.2551e-02, -2.0607e-02, -5.0752e-03,  7.7025e-02,  4.8286e-02,\n",
      "         6.0685e-02,  5.0243e-02, -1.3424e-03, -3.2029e-02,  1.2732e-02,\n",
      "         6.8487e-02,  1.6726e-02,  2.5311e-02,  4.0938e-02, -3.7663e-02,\n",
      "        -6.9774e-03, -2.6668e-02,  4.3938e-02,  1.9049e-02,  2.5011e-02,\n",
      "         5.0649e-03,  2.7766e-02, -1.8677e-02, -6.5871e-03, -1.0926e-02,\n",
      "        -4.5367e-02, -1.4554e-02, -8.9167e-03,  1.2815e-02,  1.9678e-02,\n",
      "        -6.5054e-02,  7.9996e-03, -5.6171e-04,  2.2121e-02, -7.9475e-02,\n",
      "        -1.4613e-02,  1.1928e-02, -7.1760e-03,  2.1885e-02,  7.4417e-02,\n",
      "        -3.4661e-02,  4.3362e-02, -8.3427e-03,  1.1697e-02, -4.1059e-02,\n",
      "        -2.2433e-02,  2.9944e-02, -4.1845e-02, -3.2012e-02,  2.7519e-02,\n",
      "         3.0520e-02, -6.6486e-03,  1.9922e-02,  4.1011e-05,  2.4321e-02,\n",
      "        -3.4112e-02, -8.1252e-03, -1.3817e-03,  4.1487e-02,  5.5383e-03,\n",
      "         7.4264e-02,  5.8538e-02, -1.2504e-02, -5.8637e-02, -3.2831e-02,\n",
      "        -3.8373e-02,  3.7144e-02, -4.6573e-02, -4.4477e-03,  1.4093e-02,\n",
      "         2.4116e-02,  3.7189e-02,  1.8752e-02,  2.8613e-02,  3.1591e-02,\n",
      "        -5.8729e-02, -2.5585e-02,  1.1315e-02,  3.4952e-02,  4.1815e-02,\n",
      "        -4.2700e-02,  9.5975e-02, -5.4345e-02,  4.4778e-02,  3.4699e-02,\n",
      "        -1.4143e-03, -4.2060e-02,  4.5085e-03,  3.6229e-02,  8.6210e-02,\n",
      "         5.6177e-02, -2.5983e-02,  5.1932e-02, -2.1423e-02,  1.7566e-02,\n",
      "         8.7870e-02,  5.8296e-02,  7.4138e-02,  8.4713e-02,  2.6736e-02,\n",
      "         2.2297e-02, -3.9376e-02,  2.6866e-02,  1.8884e-02, -6.2928e-02,\n",
      "        -1.1927e-01,  7.9880e-03,  2.8906e-02,  4.5301e-02, -7.4961e-02,\n",
      "         3.2721e-02,  7.2418e-02,  6.7919e-02, -3.9072e-02, -4.5895e-03,\n",
      "        -1.5853e-03, -3.0371e-02, -3.7048e-02,  5.1904e-02,  4.0411e-02,\n",
      "        -8.3111e-04,  7.5006e-02, -1.7369e-02, -1.9430e-02,  8.6174e-03,\n",
      "        -1.6283e-02, -1.4449e-02, -4.4124e-03,  6.7219e-02,  2.5801e-03,\n",
      "         3.5575e-02,  2.3887e-02,  7.3724e-02, -2.7450e-02,  5.9700e-02,\n",
      "        -4.4520e-02,  1.5025e-02,  4.0414e-02,  1.2516e-02, -6.9264e-02,\n",
      "        -5.9417e-02, -2.6525e-02,  6.7678e-02, -1.2832e-02,  5.0105e-03,\n",
      "         4.0910e-02,  1.0097e-01, -3.5914e-02,  2.8993e-02, -4.8939e-03,\n",
      "         1.0175e-01, -4.1305e-02,  1.1802e-02, -3.7813e-02, -2.6506e-02,\n",
      "         2.8449e-02,  7.3423e-02,  1.0151e-02, -6.7958e-02,  3.9225e-03,\n",
      "        -2.4804e-02, -3.9276e-03,  5.4167e-02, -5.4194e-02,  4.5707e-02,\n",
      "         7.6104e-03, -1.4399e-02,  1.5504e-02, -1.5404e-02,  4.8668e-02,\n",
      "        -6.3860e-02,  7.4544e-02, -7.2998e-02,  2.2758e-02,  1.6362e-02,\n",
      "         4.3762e-02, -2.2281e-03,  4.9973e-02,  4.8246e-02,  5.3134e-02,\n",
      "        -3.1200e-02,  1.8368e-03, -1.1808e-02, -8.7060e-03,  2.1497e-02,\n",
      "        -5.0635e-02, -5.4812e-02,  7.8076e-02,  8.1736e-02,  2.0540e-02,\n",
      "         4.8063e-02, -1.1393e-02, -1.6909e-02,  3.8772e-02,  2.5120e-03,\n",
      "        -1.0431e-02, -5.7217e-02, -2.5625e-02, -1.8534e-03,  3.7000e-02,\n",
      "        -6.7892e-04, -8.4087e-03, -3.5301e-02,  5.0963e-02,  4.7199e-02,\n",
      "        -1.0314e-02, -5.1786e-02, -1.9911e-02,  7.9702e-02, -4.2759e-02,\n",
      "         4.7687e-02, -1.4493e-02, -1.4170e-03,  4.3998e-02, -4.6188e-02,\n",
      "         3.0044e-02, -1.5390e-02, -3.2464e-02, -2.9193e-03, -1.5669e-02,\n",
      "        -8.2792e-03,  3.3157e-02,  2.0329e-02,  1.2330e-02, -1.9292e-02,\n",
      "         3.7264e-02,  4.6310e-02,  2.3605e-02, -1.8521e-03,  5.1313e-02,\n",
      "        -2.3791e-02, -2.9857e-02, -4.8621e-02, -5.4848e-03,  3.3813e-03,\n",
      "         5.3147e-02,  4.2042e-02, -5.6409e-02,  8.6589e-02,  6.4586e-02,\n",
      "         3.0701e-02, -4.3648e-02,  8.4899e-03, -2.5204e-02,  1.7927e-02,\n",
      "         3.1091e-02, -4.4601e-02, -2.4615e-02, -2.9417e-02, -1.9232e-02,\n",
      "        -6.1471e-02, -5.9971e-02, -9.8965e-03,  2.1335e-02, -6.8786e-03,\n",
      "        -1.6642e-02,  1.9179e-02, -1.7309e-02,  1.4843e-03,  4.9123e-02,\n",
      "         7.0532e-02,  4.9847e-02,  7.3972e-02,  7.2877e-02, -6.6248e-03,\n",
      "        -3.3546e-02,  6.9865e-02, -3.2413e-02,  4.0398e-02,  2.2823e-02,\n",
      "         7.1041e-02,  1.2250e-02,  2.2351e-02,  6.0800e-03,  1.6917e-03,\n",
      "        -2.5096e-02, -3.3802e-03, -4.1258e-02,  7.3368e-02,  1.6909e-02])\n",
      "tensor([0.9919, 0.9576, 0.9811, 0.9651, 0.9635, 0.9802, 0.9853, 1.0039, 0.9933,\n",
      "        0.9623, 0.9718, 0.9842, 0.9897, 0.9812, 0.9484, 0.9757, 0.9711, 0.9700,\n",
      "        0.9854, 0.9577, 0.9423, 0.9521, 0.9719, 0.9733, 0.9581, 0.9735, 0.9702,\n",
      "        0.9868, 0.9906, 0.9787, 1.0252, 0.9752, 0.9649, 0.9821, 0.9929, 0.9642,\n",
      "        0.9635, 1.0294, 0.9881, 0.9807, 0.9316, 0.9410, 0.9825, 0.9654, 0.9852,\n",
      "        0.9745, 0.9801, 0.9946, 0.9821, 0.9462, 0.9836, 0.9553, 0.9902, 0.9726,\n",
      "        1.0154, 0.9567, 0.9701, 0.9774, 0.9715, 0.9715, 0.9402, 0.9711, 0.9590,\n",
      "        0.9445, 0.9643, 0.9546, 0.9834, 0.9694, 0.9546, 0.9643, 0.9710, 1.0158,\n",
      "        0.9915, 0.9437, 0.9822, 0.9569, 0.9762, 0.9644, 1.0053, 0.9721, 0.9582,\n",
      "        0.9626, 0.9433, 0.9915, 0.9699, 0.9544, 0.9871, 0.9702, 0.9716, 0.9834,\n",
      "        0.9841, 0.9715, 0.9696, 0.9884, 0.9725, 0.9669, 0.9538, 1.0165, 0.9846,\n",
      "        0.9789, 0.9878, 0.9689, 0.9682, 0.9725, 1.0017, 0.9300, 0.9205, 0.9698,\n",
      "        0.9573, 0.9611, 0.9688, 0.9783, 0.9792, 0.9616, 0.9552, 0.9684, 0.9823,\n",
      "        1.0161, 0.9550, 0.9911, 0.9747, 0.9865, 0.9784, 0.9777, 0.9633, 0.9911,\n",
      "        0.9986, 0.9640, 0.9686, 0.9618, 0.9600, 0.9759, 0.9681, 0.9452, 0.9651,\n",
      "        0.9637, 0.9612, 0.9723, 0.9511, 0.9703, 0.9575, 0.9596, 0.9730, 0.9417,\n",
      "        0.9548, 0.9622, 0.9938, 0.9807, 0.9678, 0.9602, 0.9780, 0.9688, 0.9867,\n",
      "        0.9611, 0.9707, 0.9819, 0.9795, 0.9631, 0.9705, 0.9447, 0.9796, 0.9750,\n",
      "        0.9664, 0.9696, 0.9893, 0.9526, 0.9593, 0.9587, 1.0137, 1.0085, 0.9536,\n",
      "        0.9850, 0.9744, 0.9593, 0.9750, 1.0203, 0.9568, 0.9746, 0.9660, 1.0010,\n",
      "        0.9763, 0.9566, 0.9680, 0.9614, 0.9804, 0.9702, 0.9783, 0.9279, 0.9528,\n",
      "        0.9855, 0.9604, 0.9749, 0.9695, 0.9855, 0.9655, 0.9736, 0.9755, 0.9745,\n",
      "        0.9705, 0.9568, 0.9915, 0.9834, 0.9710, 0.9521, 0.9838, 0.9748, 0.9512,\n",
      "        0.9922, 0.9635, 0.9585, 1.0037, 0.9800, 0.9741, 0.9556, 0.9806, 0.9967,\n",
      "        0.9761, 0.9767, 0.9504, 0.9778, 0.9653, 0.9860, 0.9464, 0.9659, 0.9700,\n",
      "        1.0087, 0.9511, 0.9576, 1.0116, 0.9804, 0.9625, 0.9418, 0.9561, 0.9623,\n",
      "        0.9672, 0.9622, 0.9743, 0.9694, 0.9770, 0.9532, 0.9772, 0.9615, 0.9806,\n",
      "        0.9910, 0.9729, 0.9506, 1.0117, 0.9687, 0.9665, 0.9522, 1.0053, 0.9685,\n",
      "        0.9557, 0.9974, 0.9603, 0.9674, 0.9676, 0.9719, 0.9860, 0.9819, 0.9524,\n",
      "        0.9787, 0.9420, 0.9621, 1.0045, 0.9771, 0.9721, 0.9713, 0.9587, 0.9708,\n",
      "        0.9509, 0.9782, 0.9734, 0.9727, 0.9706, 0.9772, 1.0704, 0.9742, 0.9759,\n",
      "        0.9552, 0.9682, 0.9605, 0.9692, 0.9558, 0.9604, 1.0157, 1.0005, 0.9906,\n",
      "        0.9638, 0.9870, 0.9871, 0.9754, 0.9550, 0.9604, 0.9325, 0.9642, 0.9680,\n",
      "        0.9502, 0.9823, 0.9651, 0.9645, 0.9758, 0.9553, 0.9847, 0.9827, 0.9744,\n",
      "        0.9791, 0.9517, 0.9694, 0.9378, 0.9612, 1.0090, 0.9761, 0.9719, 0.9685,\n",
      "        0.9395, 0.9740, 0.9664, 0.9775, 0.9613, 0.9796, 0.9979, 0.9767, 0.9550,\n",
      "        0.9737, 0.9677, 0.9341, 0.9586, 0.9828, 0.9518, 0.9707, 0.9615, 0.9807,\n",
      "        0.9683, 0.9838, 0.9513, 0.9552, 0.9736, 0.9624, 0.9662, 0.9757, 0.9819,\n",
      "        0.9939, 0.9508, 0.9852, 0.9840, 0.9838, 0.9646, 0.9495, 0.9699])\n",
      "tensor([-0.0226,  0.0538, -0.0304, -0.0098, -0.0627, -0.0219,  0.0288, -0.0105,\n",
      "        -0.0439,  0.0502, -0.0290,  0.0008,  0.0318, -0.0215,  0.0049,  0.0006,\n",
      "        -0.0370, -0.0284, -0.0326, -0.0080,  0.0376, -0.0410, -0.0019, -0.0089,\n",
      "         0.0106,  0.0117,  0.0672,  0.0755, -0.0321, -0.0181, -0.0018, -0.0104,\n",
      "        -0.0053,  0.0507, -0.0463, -0.0272,  0.0375,  0.0580,  0.0277, -0.0274,\n",
      "         0.0584,  0.0443,  0.0370, -0.0239,  0.0466,  0.0283, -0.0166,  0.0271,\n",
      "        -0.0219,  0.0404, -0.0206, -0.0433, -0.0419, -0.0040, -0.0287, -0.0216,\n",
      "        -0.0360,  0.0113, -0.0292, -0.0121,  0.0128,  0.0073,  0.0142, -0.0043,\n",
      "         0.0455, -0.0239,  0.0687, -0.0356, -0.0038, -0.0295, -0.0279,  0.0225,\n",
      "        -0.0423,  0.0161, -0.0070,  0.0353,  0.0574,  0.0290, -0.0213,  0.0148,\n",
      "         0.0412,  0.0224,  0.0521,  0.0329, -0.0406,  0.0632,  0.0655, -0.0137,\n",
      "        -0.0107, -0.0483, -0.0255,  0.0113, -0.0397, -0.0186, -0.0219, -0.0272,\n",
      "         0.0295, -0.0540,  0.0249, -0.0104, -0.0544,  0.0181, -0.0064,  0.0421,\n",
      "         0.0527, -0.0031,  0.0209, -0.0273,  0.0445, -0.0115, -0.0180, -0.0525,\n",
      "         0.0684,  0.0268,  0.0297,  0.0037, -0.0334,  0.0559, -0.0135,  0.0262,\n",
      "        -0.0073, -0.0536,  0.0367,  0.0370,  0.0492, -0.0243, -0.0249,  0.0564,\n",
      "        -0.0323,  0.0475,  0.0380,  0.0363,  0.0292,  0.0296, -0.0212, -0.0284,\n",
      "         0.0024, -0.0171, -0.0420, -0.0194,  0.0465,  0.0109,  0.0269,  0.0133,\n",
      "        -0.0097,  0.0419, -0.0456,  0.0554, -0.0141,  0.0081, -0.0290,  0.0180,\n",
      "        -0.0461,  0.0228, -0.0122, -0.0166, -0.0348, -0.0175,  0.0140,  0.0294,\n",
      "         0.0454,  0.0232, -0.0644, -0.0007, -0.0214, -0.0726, -0.0321,  0.0073,\n",
      "         0.0493, -0.0533,  0.0176, -0.0137,  0.0167,  0.0321, -0.0149,  0.0079,\n",
      "         0.0196,  0.0377, -0.0253,  0.0492, -0.0208, -0.0314, -0.0249, -0.0498,\n",
      "        -0.0063,  0.0046, -0.0281,  0.0252,  0.0158,  0.0198, -0.0183, -0.0288,\n",
      "         0.0306, -0.0366, -0.0438,  0.0158, -0.0165, -0.0193,  0.0122, -0.0367,\n",
      "        -0.0310,  0.0207, -0.0164, -0.0295,  0.0243, -0.0184, -0.0240, -0.0269,\n",
      "         0.0260,  0.0326, -0.0128,  0.0201, -0.0422, -0.0027, -0.0115, -0.0209,\n",
      "         0.0332,  0.0414,  0.0384, -0.0347,  0.0167,  0.0446, -0.0073, -0.0060,\n",
      "        -0.0205,  0.0087,  0.0570, -0.0283,  0.0373,  0.0302, -0.0311,  0.0443,\n",
      "         0.0146, -0.0538,  0.0091, -0.0333, -0.0389, -0.0028, -0.0088, -0.0593,\n",
      "         0.0176, -0.0075, -0.0379, -0.0507, -0.0304, -0.0203, -0.0194, -0.0297,\n",
      "         0.0260,  0.0254,  0.0131,  0.0297, -0.0343, -0.0046,  0.0265,  0.0380,\n",
      "        -0.0683, -0.0740, -0.0397, -0.0493,  0.0575,  0.0233,  0.0267, -0.0381,\n",
      "         0.0405, -0.0256, -0.0002,  0.0137,  0.0168,  0.0080, -0.0579, -0.0265,\n",
      "        -0.0727, -0.0255, -0.0308,  0.0350,  0.0894,  0.0109,  0.0200, -0.0303,\n",
      "        -0.0425,  0.0093, -0.0321,  0.0097, -0.0300, -0.0347,  0.0307, -0.0310,\n",
      "        -0.0165, -0.0126, -0.0199,  0.0453,  0.0281,  0.0370,  0.0057, -0.0380,\n",
      "        -0.0212, -0.0268, -0.0235,  0.0277,  0.0200,  0.0242,  0.0421,  0.0045,\n",
      "        -0.0489, -0.0019,  0.0130,  0.0218,  0.0299, -0.0126,  0.0185, -0.0074,\n",
      "        -0.0175,  0.0084, -0.0208,  0.0642, -0.0090, -0.0129,  0.0289,  0.0152,\n",
      "        -0.0528, -0.0220,  0.0456,  0.0353,  0.0185, -0.0272,  0.0164, -0.0344,\n",
      "         0.0223, -0.0085, -0.0148,  0.0416, -0.0436, -0.0175,  0.0229, -0.0189,\n",
      "         0.0194, -0.0445,  0.0047,  0.0414, -0.0046, -0.0292, -0.0073,  0.0510,\n",
      "         0.0293,  0.0477, -0.0332, -0.0036,  0.0384, -0.0208])\n",
      "tensor([[ 0.0197,  0.0170, -0.0218,  ...,  0.0335,  0.0120,  0.0485],\n",
      "        [ 0.0874,  0.0221, -0.0034,  ..., -0.0036, -0.0230, -0.0055],\n",
      "        [ 0.0230,  0.0156, -0.0149,  ...,  0.0041,  0.0165, -0.0266],\n",
      "        ...,\n",
      "        [ 0.0295,  0.0033,  0.0144,  ...,  0.0327, -0.0194,  0.0147],\n",
      "        [ 0.0323,  0.0046, -0.0191,  ...,  0.0060,  0.0001,  0.0367],\n",
      "        [-0.0169, -0.0113,  0.0556,  ...,  0.0321, -0.0220, -0.0177]])\n",
      "tensor([ 0.0466,  0.0187,  0.0439, -0.0222, -0.0308, -0.0481, -0.0520,  0.0114])\n",
      "tensor([[-0.0739,  0.1198, -0.0276,  ..., -0.0088,  0.0488, -0.0371],\n",
      "        [ 0.0008, -0.1393, -0.1285,  ...,  0.0470, -0.0160,  0.1164],\n",
      "        [ 0.1466,  0.0598,  0.1393,  ..., -0.0500, -0.0836, -0.0630],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0698, -0.0759,  ..., -0.0509, -0.0376,  0.1457],\n",
      "        [-0.0373,  0.0848, -0.1624,  ...,  0.1388, -0.0036, -0.0975],\n",
      "        [-0.0968, -0.1052,  0.0692,  ...,  0.0342,  0.1335,  0.0043]])\n",
      "tensor([-3.0543e-02, -3.5821e-02,  1.2162e-01, -1.0187e-01, -9.1161e-02,\n",
      "         4.5207e-02,  2.0954e-01,  5.8366e-02,  2.3705e-02,  9.1012e-02,\n",
      "        -1.0781e-02,  2.1154e-01,  1.2733e-01,  1.2345e-01, -6.8523e-02,\n",
      "        -8.5949e-02,  2.3186e-01, -4.0249e-02,  8.9672e-02, -1.7098e-01,\n",
      "         1.2167e-01, -1.4403e-01,  1.9679e-01,  1.8696e-01, -3.0602e-02,\n",
      "         1.1708e-01,  2.7519e-01,  9.7253e-02, -7.5421e-02,  1.1782e-01,\n",
      "         1.4252e-01, -1.1547e-01,  1.7381e-01,  2.0104e-01, -5.9491e-02,\n",
      "         1.3054e-01,  7.6997e-02, -5.6495e-03, -9.8097e-02,  1.6119e-02,\n",
      "         1.6657e-01, -2.2475e-02,  6.2619e-02,  9.1626e-02,  6.2916e-02,\n",
      "        -4.4277e-02, -5.7589e-02,  7.4381e-02,  2.6277e-01, -7.9904e-02,\n",
      "        -1.4272e-01,  3.5406e-02, -1.3599e-01,  1.2097e-01,  7.7743e-02,\n",
      "         2.4754e-01,  1.6101e-01,  7.9228e-02,  1.1073e-01, -4.1832e-02,\n",
      "         1.1375e-01,  1.4721e-01,  2.6687e-01, -7.3177e-02,  1.0892e-01,\n",
      "        -1.0496e-01, -6.2271e-02,  8.5179e-02,  1.6241e-01,  3.8793e-02,\n",
      "         9.3146e-04,  1.0429e-01,  1.8227e-01,  5.8587e-02,  1.2392e-01,\n",
      "         6.3384e-02,  3.1772e-02,  2.2902e-01, -7.6355e-02, -4.2899e-02,\n",
      "        -3.7909e-02,  1.9008e-01,  1.8625e-01,  1.5118e-01,  5.3555e-02,\n",
      "         1.0429e-01, -8.5525e-02,  6.0124e-02,  9.5218e-02,  8.3532e-02,\n",
      "         1.0526e-03, -8.8173e-02,  7.5813e-02,  1.1198e-01, -1.2428e-01,\n",
      "        -1.7935e-02,  2.0867e-01,  1.5171e-01,  2.6043e-01,  1.0289e-02,\n",
      "        -1.0227e-01,  1.8176e-01, -6.5464e-02,  1.7260e-01, -4.4620e-02,\n",
      "         1.7386e-01, -9.9804e-02,  2.7085e-02,  4.8649e-02,  9.0978e-02,\n",
      "        -1.4522e-02,  5.0144e-02,  2.7064e-02,  1.1646e-01,  9.5457e-02,\n",
      "         3.4164e-02, -1.0861e-01,  1.5659e-01, -1.5228e-02,  8.3819e-02,\n",
      "         1.7339e-01, -1.5891e-02, -2.1988e-03,  1.2582e-02,  2.0374e-01,\n",
      "         1.5293e-02, -1.2125e-01,  1.8066e-01, -2.8012e-02,  8.5298e-02,\n",
      "        -1.1308e-01,  2.7320e-01,  2.5258e-02, -8.8448e-02,  1.9618e-01,\n",
      "         4.8639e-02, -9.2476e-03,  6.7800e-02,  9.2085e-02, -1.1441e-01,\n",
      "         5.9660e-02, -5.6994e-02,  2.6814e-01,  1.1946e-01,  2.9347e-02,\n",
      "         2.6254e-01,  5.9447e-02,  1.3827e-01,  5.1153e-02, -5.9081e-02,\n",
      "        -5.3996e-02,  1.3619e-01,  1.2323e-01,  1.8285e-01, -8.4436e-03,\n",
      "         1.4477e-01,  4.1536e-02, -1.0732e-01,  3.2855e-02,  2.0624e-01,\n",
      "        -1.0505e-01,  9.9968e-03,  1.6997e-01, -1.0132e-01,  7.3262e-02,\n",
      "         1.1771e-01, -5.6171e-02, -9.7614e-02, -9.3018e-02,  7.7950e-02,\n",
      "         8.8889e-02, -9.8612e-02,  2.5723e-02,  9.8365e-02,  4.7671e-02,\n",
      "         2.1980e-01, -1.5436e-01, -1.0643e-01,  4.0180e-02,  1.1196e-01,\n",
      "         1.6786e-01,  1.0621e-01,  2.3366e-01, -4.0035e-02,  1.2793e-01,\n",
      "         3.3726e-02,  4.1785e-02, -5.1227e-02,  7.1775e-02,  2.0989e-01,\n",
      "         1.3254e-01,  1.6535e-01,  2.1443e-01, -1.2260e-01,  2.1879e-01,\n",
      "         1.2227e-01,  1.1674e-01,  7.1581e-03,  1.8211e-01,  1.1956e-01,\n",
      "         2.4998e-02,  1.9623e-01, -1.5321e-02,  1.0718e-01, -7.8355e-02,\n",
      "        -1.1326e-01,  1.9297e-01,  1.2302e-01,  2.1488e-02,  1.8375e-01,\n",
      "        -7.0644e-02,  2.0471e-01,  3.0901e-03, -1.4418e-02,  1.3463e-01,\n",
      "         1.1034e-01,  6.4821e-02,  2.3115e-01,  2.0275e-01,  1.3634e-01,\n",
      "        -1.3591e-01,  1.6902e-02, -1.9240e-02,  1.1929e-01,  1.3207e-01,\n",
      "         2.0507e-01,  4.3778e-03, -4.0236e-02, -4.2740e-04,  2.6730e-01,\n",
      "        -2.2275e-01, -6.4235e-02, -9.8890e-02,  2.9866e-02,  2.2385e-01,\n",
      "         1.7711e-01,  2.0513e-01, -4.7634e-02, -1.0972e-01, -1.9416e-02,\n",
      "         7.4810e-02,  7.7781e-02,  1.5393e-02,  1.4977e-01,  7.3896e-02,\n",
      "         2.9498e-02,  1.4788e-01, -4.6658e-02,  1.6507e-02, -1.4274e-02,\n",
      "         1.6919e-01,  7.9606e-02,  1.3096e-01,  1.0997e-01,  9.3153e-02,\n",
      "        -2.1021e-03,  1.4450e-01,  6.0856e-02, -1.0615e-02,  2.4149e-02,\n",
      "        -4.2761e-02,  2.6228e-02, -1.1105e-01,  1.4887e-01, -1.2350e-02,\n",
      "         1.2003e-01,  2.3322e-01,  4.1488e-02, -1.1564e-02, -3.2250e-02,\n",
      "         1.1118e-01, -1.0945e-01, -7.6545e-03, -6.3192e-02,  1.7922e-01,\n",
      "         1.8046e-01,  7.7163e-02, -3.8353e-02,  2.1646e-01,  1.4877e-01,\n",
      "         1.8486e-01,  1.6874e-01, -1.0730e-01,  1.0086e-01, -8.8698e-02,\n",
      "         5.3817e-03,  9.7886e-02, -6.4851e-02,  2.6151e-01,  4.5403e-02,\n",
      "        -2.0648e-02,  2.1013e-01, -3.7825e-02, -5.4148e-02,  1.6665e-02,\n",
      "         3.7667e-02, -1.2040e-02,  3.7119e-02,  8.5423e-02,  1.4835e-01,\n",
      "         1.8971e-01, -3.2630e-02,  9.5849e-02,  2.5131e-01,  4.1384e-02,\n",
      "        -8.5663e-02,  1.5133e-01, -3.2198e-03,  5.7627e-02,  2.5137e-01,\n",
      "         8.8389e-02, -9.0132e-02,  6.6890e-02,  3.0833e-02,  1.2972e-01,\n",
      "         2.1958e-01,  1.2693e-01,  1.7336e-01, -1.3838e-01,  1.7328e-01,\n",
      "        -9.3433e-02, -8.9950e-03,  8.1280e-02,  2.0431e-01,  1.2210e-01,\n",
      "        -4.3468e-03, -3.9147e-02,  3.5477e-02,  7.5938e-02,  1.8368e-01,\n",
      "         2.0307e-01,  8.4911e-02, -6.0621e-02,  4.1936e-03, -6.6686e-02,\n",
      "         4.7311e-02,  2.0628e-02,  1.4621e-01,  1.6897e-01,  1.6376e-01,\n",
      "         1.4580e-01,  5.2465e-02, -4.7107e-02,  6.4156e-05,  1.0928e-01,\n",
      "         2.1441e-01,  1.9604e-01,  1.2788e-01, -1.1484e-01,  9.2929e-02])\n",
      "tensor([0.8370, 1.0221, 0.9643, 0.9487, 0.9680, 0.9880, 1.0300, 0.9946, 1.0491,\n",
      "        1.0613, 0.9966, 0.9778, 1.0537, 1.0010, 1.0088, 0.9859, 1.0182, 0.9610,\n",
      "        0.9706, 0.9879, 0.9871, 0.8480, 0.9949, 0.9483, 0.9744, 0.9835, 1.0292,\n",
      "        1.0012, 0.9129, 0.9844, 1.0035, 0.9612, 0.9120, 1.0149, 0.9712, 1.0041,\n",
      "        0.9834, 0.9493, 1.0498, 1.0433, 1.0328, 1.0107, 0.9573, 0.9878, 0.9903,\n",
      "        0.9961, 0.9495, 0.9479, 1.0765, 1.0338, 0.8552, 0.9552, 0.8884, 1.0010,\n",
      "        1.0111, 1.0366, 0.9958, 0.9753, 0.9013, 0.9925, 0.9529, 0.9425, 1.0064,\n",
      "        0.9120, 0.9254, 0.9822, 0.8394, 0.9850, 0.9944, 0.9843, 0.9361, 0.9779,\n",
      "        1.0303, 0.9631, 1.0454, 0.9669, 0.9724, 1.0070, 0.9705, 0.9247, 0.9423,\n",
      "        0.9700, 0.9599, 0.9972, 1.0038, 0.9821, 1.0182, 0.9316, 1.0535, 1.0187,\n",
      "        0.9785, 0.9937, 1.0310, 0.9272, 0.9466, 0.9002, 0.9571, 1.0134, 1.0091,\n",
      "        0.9566, 0.8773, 0.9298, 0.9477, 1.0468, 0.9303, 1.0157, 0.9693, 0.9573,\n",
      "        0.9196, 1.0130, 0.9548, 0.9565, 0.9654, 1.0298, 0.9356, 1.0103, 1.0068,\n",
      "        0.9468, 0.9871, 0.9526, 0.9386, 0.9482, 1.0074, 0.9868, 0.9948, 1.0155,\n",
      "        0.9523, 0.8772, 0.9884, 0.9778, 0.8733, 1.0624, 0.8389, 0.8882, 1.0002,\n",
      "        0.9853, 0.8586, 1.0254, 0.9911, 0.9320, 1.0054, 0.9765, 1.0595, 0.9842,\n",
      "        1.0129, 1.0574, 1.0000, 0.9989, 0.9136, 0.9450, 0.9892, 0.9939, 0.9437,\n",
      "        0.9699, 1.0203, 1.0223, 0.9352, 0.8951, 0.9947, 0.9286, 0.9288, 1.0160,\n",
      "        0.9936, 0.9106, 1.0284, 0.9070, 0.9832, 0.9564, 0.9573, 0.9880, 0.9783,\n",
      "        0.9561, 0.9438, 0.9883, 0.9353, 0.9880, 0.9083, 0.9769, 0.9582, 0.9529,\n",
      "        1.0698, 0.8368, 0.9761, 1.0341, 0.9798, 0.9696, 0.9683, 0.9386, 0.9465,\n",
      "        1.0129, 0.9554, 0.9825, 1.0318, 0.9247, 1.0344, 0.9937, 0.9700, 0.9778,\n",
      "        1.0553, 0.9864, 0.9859, 1.0122, 0.9990, 1.0022, 0.9684, 1.0514, 1.0284,\n",
      "        0.9689, 0.9975, 0.9975, 0.9609, 0.9656, 0.9820, 1.0384, 0.9788, 1.0250,\n",
      "        0.8833, 1.0267, 1.0498, 1.0383, 0.9076, 1.0305, 0.8974, 0.9997, 0.9006,\n",
      "        1.0337, 0.9680, 0.9258, 0.9348, 1.0909, 0.9921, 0.9691, 0.9979, 1.0362,\n",
      "        1.0264, 1.0361, 0.9368, 1.0192, 0.9917, 0.9943, 0.9959, 0.9517, 0.9784,\n",
      "        0.9831, 1.0035, 0.9686, 1.0070, 0.9539, 0.9805, 0.9559, 0.9421, 1.0040,\n",
      "        0.9912, 1.0161, 0.9428, 0.9832, 1.0089, 0.9156, 0.9662, 0.9420, 0.8753,\n",
      "        0.9870, 0.9779, 1.0154, 1.0317, 1.0312, 1.0223, 0.9640, 1.0440, 0.9761,\n",
      "        0.9412, 0.9771, 1.0514, 0.9157, 0.9665, 0.9501, 0.9356, 1.0660, 1.0329,\n",
      "        0.9822, 1.0183, 0.9916, 0.9992, 0.9586, 0.9702, 0.9340, 0.9576, 0.9409,\n",
      "        1.0127, 0.9395, 0.9584, 1.0333, 0.9963, 0.9300, 0.9801, 1.0262, 1.0208,\n",
      "        0.9722, 0.9517, 0.9605, 1.0541, 0.9659, 1.0307, 1.0707, 0.9970, 1.0347,\n",
      "        1.0109, 1.0004, 0.9633, 1.0177, 0.9524, 0.9063, 0.9568, 0.9308, 0.9855,\n",
      "        1.0098, 0.9938, 1.0740, 0.8708, 1.0050, 0.9169, 1.0769, 0.9522, 0.9060,\n",
      "        0.9898, 0.9358, 0.8765, 1.0051, 1.0079, 0.9404, 1.0156, 0.9816, 1.0031,\n",
      "        1.0247, 0.9829, 1.0289, 0.9706, 0.9765, 1.0295, 0.9969, 1.0025, 0.9270,\n",
      "        0.9036, 1.0194, 0.8235, 1.0202, 1.0172, 0.9887, 0.9781, 1.0222])\n",
      "tensor([-8.1144e-03, -1.1477e-01,  6.5374e-02,  7.1216e-02,  1.6664e-01,\n",
      "        -1.9901e-02, -5.4041e-02,  1.2363e-01, -2.1770e-03,  1.3605e-01,\n",
      "        -6.4105e-02, -5.7969e-02, -1.2041e-01, -1.2723e-01, -1.4060e-01,\n",
      "        -1.1969e-01,  2.2015e-01, -1.3179e-03, -7.3500e-02,  8.6607e-02,\n",
      "        -1.4935e-02,  1.0440e-01,  8.7954e-03,  1.3460e-02,  1.0356e-02,\n",
      "        -4.8980e-02,  6.7917e-02, -6.1129e-02, -2.0193e-02,  1.1643e-01,\n",
      "        -4.1386e-02, -8.3423e-02,  2.2341e-03,  1.7840e-01,  5.0502e-02,\n",
      "        -4.3699e-02, -1.3264e-01, -4.2652e-02, -8.1347e-02, -6.8727e-02,\n",
      "        -1.6505e-02,  1.8421e-03,  4.6652e-02,  4.0345e-02,  2.5943e-02,\n",
      "        -5.1128e-02,  1.4282e-01,  3.2128e-02, -2.1327e-02, -1.3249e-01,\n",
      "        -1.7046e-02,  9.7437e-02,  1.1447e-01,  5.9549e-02,  1.6295e-01,\n",
      "         3.8790e-02,  8.5921e-02,  6.9810e-02,  6.6768e-02, -3.2995e-02,\n",
      "         9.4957e-02,  8.5988e-03, -6.4181e-02, -4.5814e-02, -8.1845e-03,\n",
      "        -1.3149e-01, -2.7017e-02,  4.3474e-02, -1.0657e-01, -1.0830e-02,\n",
      "         1.1168e-01, -1.8270e-02,  1.8009e-01, -1.2698e-02, -2.2515e-02,\n",
      "         5.3589e-02, -7.4970e-02,  1.9552e-02,  5.2082e-02,  2.2937e-03,\n",
      "        -3.2120e-02,  1.7009e-01,  6.4640e-02, -1.4250e-01, -4.7977e-02,\n",
      "         9.5050e-02, -4.1076e-02,  4.3931e-02,  4.1493e-02, -7.0248e-04,\n",
      "         1.0054e-01,  3.7532e-02, -6.1912e-03,  3.3785e-02,  3.4195e-02,\n",
      "         1.0011e-01, -9.3150e-04, -1.9278e-01, -9.2620e-02, -6.6880e-02,\n",
      "        -3.4881e-02,  7.4292e-02,  9.4718e-02, -4.3925e-03, -1.1759e-02,\n",
      "        -9.3252e-02,  2.4573e-02,  1.1865e-03, -7.2230e-02, -7.3656e-02,\n",
      "         1.5216e-01,  9.8712e-02,  2.9949e-02,  6.4871e-03, -6.1234e-02,\n",
      "        -6.3716e-04, -1.8832e-01,  1.6440e-01, -3.4098e-02, -7.9614e-02,\n",
      "        -3.2163e-02, -2.8197e-02, -5.4475e-02,  7.7480e-02,  1.3228e-01,\n",
      "        -4.7472e-02,  8.4632e-02,  2.5547e-02, -3.4490e-02, -8.1728e-02,\n",
      "         9.1207e-02,  5.8275e-03,  1.2863e-01, -1.3331e-02, -3.6641e-02,\n",
      "        -5.8843e-02,  5.8967e-02, -1.0698e-01,  1.3907e-01, -1.3259e-02,\n",
      "        -8.7982e-02, -7.4879e-02,  6.6379e-02, -2.1053e-02,  1.4107e-01,\n",
      "        -1.0160e-01, -1.1111e-01, -4.2767e-02, -1.4831e-01,  5.4159e-02,\n",
      "        -1.4913e-01, -2.3089e-02,  1.5194e-01,  1.5491e-02, -1.4185e-01,\n",
      "         5.8096e-02,  2.0699e-03,  3.6854e-02,  5.0500e-02, -4.6747e-02,\n",
      "        -5.9488e-03,  1.0648e-01, -1.2815e-01, -8.4211e-04,  3.8928e-02,\n",
      "        -2.0866e-02, -8.0412e-03,  5.5991e-02,  9.1247e-02, -1.3911e-01,\n",
      "         1.3721e-01, -5.6909e-02, -9.6634e-02, -1.4635e-01,  7.3759e-02,\n",
      "         1.4711e-01, -5.7070e-02, -5.9861e-02,  2.1037e-02, -6.1670e-02,\n",
      "        -4.8901e-02, -1.9954e-03,  1.9451e-01, -1.3784e-01,  1.2642e-01,\n",
      "        -1.4795e-01,  9.9879e-02,  3.6984e-02, -3.1923e-02, -1.3582e-01,\n",
      "         5.4003e-02, -7.6928e-03, -2.9329e-03,  1.9424e-01, -2.5528e-04,\n",
      "         7.3750e-02,  4.3357e-02,  6.3562e-02, -1.4393e-01, -5.7903e-02,\n",
      "         3.2249e-02, -1.8477e-02, -1.0983e-01,  1.7166e-01,  1.0049e-01,\n",
      "        -9.0256e-02,  1.1341e-01,  4.2288e-02, -1.0401e-03, -1.6779e-01,\n",
      "         8.2802e-02, -5.3941e-02,  1.8284e-03, -5.8344e-04,  8.3532e-02,\n",
      "        -1.7525e-02, -2.3756e-02, -8.2716e-02,  6.0895e-02, -1.6640e-01,\n",
      "         3.3623e-02,  6.4700e-02,  5.0722e-02,  8.0817e-02,  2.2480e-01,\n",
      "        -1.4670e-01, -1.3324e-01,  1.6592e-02,  4.8687e-02, -5.3927e-02,\n",
      "        -1.4498e-01, -8.2600e-02, -1.4261e-01, -1.1942e-02, -1.3534e-02,\n",
      "         3.3677e-03,  3.1670e-02,  2.5212e-02, -4.5288e-02, -2.2336e-02,\n",
      "        -1.0292e-01, -4.2005e-02,  5.0229e-02, -6.1796e-02,  1.3958e-01,\n",
      "        -1.1141e-02, -6.2033e-03,  1.4374e-01, -2.1762e-02, -1.0884e-01,\n",
      "        -5.9575e-02, -5.5757e-02, -1.5575e-01, -5.6297e-02,  2.5913e-01,\n",
      "        -7.1701e-02,  2.5687e-03,  5.9178e-02, -1.1603e-01, -3.7085e-02,\n",
      "        -1.0919e-02, -1.8227e-01, -1.3923e-01,  1.5664e-01, -2.7265e-02,\n",
      "         1.3327e-01, -5.2999e-02,  8.1670e-02, -9.2690e-02, -5.9331e-02,\n",
      "         1.6527e-02, -1.0694e-01, -1.0637e-02,  4.3608e-02,  1.3251e-01,\n",
      "         1.0316e-01,  2.2908e-02, -7.3523e-02,  5.8124e-02,  2.8313e-02,\n",
      "        -6.1745e-02,  9.9176e-02, -1.7280e-02,  4.8946e-02, -5.0848e-02,\n",
      "         1.1215e-01,  3.3671e-03, -1.1047e-01,  1.3350e-01,  7.9876e-02,\n",
      "        -3.9340e-02, -4.9876e-02, -6.2516e-02, -1.2915e-02,  5.9618e-02,\n",
      "         1.4237e-02, -4.4857e-02, -9.1821e-02,  2.4345e-02,  7.4726e-02,\n",
      "         1.2336e-01,  1.0910e-01,  2.3629e-01,  6.1586e-02,  6.3471e-02,\n",
      "        -1.6998e-01,  1.8545e-02,  4.5022e-02,  1.8300e-01,  7.2371e-02,\n",
      "         1.3217e-01,  8.1778e-03,  1.0253e-02, -2.4598e-02, -4.7790e-02,\n",
      "        -1.2665e-01, -6.5223e-03, -2.6463e-02,  3.2004e-02, -6.0030e-02,\n",
      "        -5.6529e-02, -6.7958e-02,  6.9051e-02, -5.2029e-02, -2.0657e-02,\n",
      "        -8.7977e-02,  4.0982e-02, -2.0531e-03, -1.2463e-01,  3.6412e-02,\n",
      "        -8.6987e-03,  4.6096e-02,  7.2024e-02, -2.1125e-01,  8.7709e-02,\n",
      "         3.5188e-02,  4.7298e-02,  2.2774e-02, -3.1049e-02,  1.9253e-02,\n",
      "        -3.1815e-02,  9.9070e-03,  3.2314e-02, -9.8031e-02,  4.4015e-02,\n",
      "        -3.9436e-02, -5.3085e-02, -1.6634e-01,  1.6482e-02,  1.0628e-01])\n",
      "tensor([[ 0.0045,  0.0479, -0.0243,  ...,  0.0017,  0.0420,  0.0303],\n",
      "        [-0.0112,  0.0099, -0.0159,  ..., -0.0154, -0.0031, -0.0407],\n",
      "        [ 0.0504, -0.0389, -0.0315,  ...,  0.0269,  0.0071, -0.0259],\n",
      "        ...,\n",
      "        [ 0.0177, -0.0305, -0.0268,  ...,  0.0076,  0.0512,  0.0038],\n",
      "        [ 0.0047,  0.0543, -0.0521,  ...,  0.0069, -0.0438, -0.0285],\n",
      "        [ 0.0054,  0.0565,  0.0435,  ..., -0.0210, -0.0063, -0.0416]])\n",
      "tensor([-0.0304, -0.0259,  0.0006, -0.0254,  0.0673,  0.0076, -0.0397, -0.0381,\n",
      "        -0.0411, -0.0570, -0.0126, -0.0166, -0.0312, -0.0345,  0.0069,  0.0278,\n",
      "        -0.0293,  0.0541,  0.1054,  0.0705,  0.0199, -0.0928,  0.0654, -0.0828,\n",
      "        -0.0079, -0.0337,  0.0607, -0.0004, -0.0502,  0.1061, -0.0520,  0.0047,\n",
      "         0.0089, -0.1322,  0.0213, -0.0380,  0.0107, -0.0041,  0.0212,  0.0564,\n",
      "        -0.0140, -0.0122, -0.0468, -0.0085,  0.0847, -0.0289, -0.0222, -0.0288,\n",
      "         0.0344,  0.0006, -0.0755, -0.1015,  0.0648, -0.0095, -0.0099, -0.0080,\n",
      "         0.0709,  0.0134, -0.0177, -0.0768, -0.0337, -0.0227,  0.0568,  0.0330,\n",
      "        -0.0115, -0.0334, -0.1446,  0.0177,  0.0119, -0.1012,  0.0380, -0.0203,\n",
      "        -0.0245, -0.0384, -0.0106, -0.0129,  0.0492, -0.0038,  0.0255,  0.0551,\n",
      "         0.0090, -0.0741,  0.0491, -0.0539, -0.0135, -0.0647, -0.0437, -0.0484,\n",
      "        -0.1294, -0.0757,  0.0880, -0.0575, -0.0074,  0.0407,  0.0468, -0.1713,\n",
      "        -0.0152,  0.0428,  0.0776, -0.0802,  0.0363,  0.0770, -0.0689, -0.0245,\n",
      "         0.0263, -0.0031,  0.0788,  0.0051,  0.0207, -0.0369, -0.0171, -0.0236,\n",
      "        -0.1416, -0.0010, -0.0200, -0.0266, -0.0494, -0.0361,  0.0471, -0.0189,\n",
      "        -0.0166, -0.0037, -0.0313, -0.0034,  0.0139, -0.0441,  0.0146, -0.0140,\n",
      "         0.0315,  0.0461, -0.1807,  0.0696,  0.0514, -0.0909, -0.0622, -0.0036,\n",
      "         0.0152,  0.0432, -0.0044, -0.0188,  0.0016, -0.0570,  0.1194,  0.0533,\n",
      "        -0.0242, -0.0587,  0.0413, -0.0508,  0.0362,  0.0680,  0.0425,  0.0300,\n",
      "        -0.0651, -0.0587,  0.0446, -0.0082, -0.0307,  0.0430,  0.0897, -0.0247,\n",
      "        -0.0077, -0.0530,  0.0051, -0.0199, -0.0196,  0.0013, -0.0278,  0.0409,\n",
      "         0.0101, -0.0332,  0.0453, -0.0542, -0.0219, -0.0277, -0.0403,  0.0150,\n",
      "        -0.0187, -0.0579, -0.0675,  0.0321,  0.0252,  0.0177, -0.0123,  0.0534,\n",
      "        -0.0099,  0.0033,  0.0732,  0.0472, -0.0346, -0.0547,  0.0227, -0.0831,\n",
      "         0.0696, -0.0329,  0.0606,  0.0225, -0.1579,  0.0851,  0.0176, -0.0045,\n",
      "        -0.0773,  0.1072,  0.0544,  0.0157, -0.1035,  0.0164,  0.0237, -0.0281,\n",
      "        -0.0105,  0.0016, -0.0124,  0.0711,  0.0130, -0.1629,  0.0423, -0.0298,\n",
      "        -0.0368, -0.0352,  0.0448,  0.0215,  0.0625, -0.1029,  0.0150,  0.0519,\n",
      "        -0.0206,  0.0098,  0.0134,  0.0355, -0.0206,  0.1163, -0.0632,  0.0625,\n",
      "         0.0359, -0.1378, -0.0287, -0.0469,  0.0124, -0.1485, -0.0760,  0.0556,\n",
      "         0.0716, -0.1722,  0.0267,  0.0544,  0.0016, -0.0019, -0.1193,  0.0520,\n",
      "        -0.0083, -0.0526,  0.0921, -0.0146,  0.0465, -0.1075, -0.0407, -0.0494,\n",
      "        -0.0080,  0.1083, -0.0139,  0.0290,  0.0757, -0.0482, -0.0794, -0.0409,\n",
      "        -0.0278,  0.1029, -0.0326, -0.0264, -0.0257, -0.0650, -0.0816, -0.0036,\n",
      "        -0.0316,  0.0143, -0.0356,  0.0149, -0.0155,  0.0578,  0.0381,  0.0025,\n",
      "         0.0231, -0.0380,  0.0594,  0.0226, -0.0200,  0.0804,  0.0841, -0.0577,\n",
      "         0.0182, -0.0517, -0.1953, -0.0243, -0.0247, -0.0274,  0.0359, -0.0899,\n",
      "         0.0156,  0.0212, -0.0534, -0.0315,  0.0624, -0.0055, -0.0245,  0.0303,\n",
      "        -0.0021, -0.0571, -0.0627,  0.0491,  0.1401,  0.1133, -0.0540, -0.0852,\n",
      "        -0.0402,  0.0331,  0.0440,  0.0845,  0.0642, -0.0145, -0.0297, -0.2073,\n",
      "        -0.1083,  0.0754, -0.0226,  0.0336, -0.0243, -0.1141, -0.0795,  0.0166,\n",
      "        -0.0037, -0.0360,  0.0333,  0.0233,  0.0533, -0.0403, -0.1543,  0.0134,\n",
      "         0.0880, -0.0506,  0.0095,  0.0206,  0.0316, -0.0759, -0.0027, -0.0014,\n",
      "         0.0044,  0.0700, -0.0142, -0.0792,  0.0037,  0.0897])\n",
      "tensor([0.9773, 1.0180, 0.9657, 0.9664, 0.9859, 0.9889, 1.0059, 0.9501, 1.0717,\n",
      "        1.0873, 1.0021, 0.9841, 0.9734, 0.9902, 0.9558, 1.0329, 1.0050, 1.0458,\n",
      "        0.9666, 0.9482, 0.9712, 1.1008, 0.9727, 1.0203, 0.9933, 0.9694, 0.9899,\n",
      "        1.0129, 1.0232, 1.0106, 0.9734, 0.9549, 1.0045, 1.0593, 0.9628, 0.9459,\n",
      "        0.9828, 0.9327, 1.0186, 1.0187, 0.9979, 0.9824, 1.0711, 1.0706, 0.9905,\n",
      "        0.9849, 0.9892, 0.9855, 0.9690, 0.9776, 1.0665, 0.9744, 1.0045, 0.9832,\n",
      "        0.9740, 0.9855, 0.9908, 1.0356, 0.9873, 1.0128, 0.9729, 1.0878, 0.9827,\n",
      "        0.9961, 0.9564, 0.9539, 1.0524, 1.0281, 1.0108, 1.0142, 0.9549, 0.9774,\n",
      "        1.0707, 0.9920, 0.9589, 0.9830, 1.0264, 0.9766, 0.9733, 0.9637, 1.0279,\n",
      "        1.0677, 0.9805, 1.0235, 0.9811, 1.0182, 0.9820, 1.0378, 1.1031, 1.0191,\n",
      "        0.9674, 1.1976, 0.9978, 0.9481, 1.0194, 1.0284, 0.9988, 0.9349, 0.9895,\n",
      "        1.0412, 0.9863, 0.9674, 1.0434, 0.9988, 0.9690, 0.9823, 1.0015, 0.9412,\n",
      "        1.0693, 1.0450, 1.0368, 1.0766, 1.0858, 0.9559, 0.9082, 0.9808, 1.0013,\n",
      "        0.9810, 0.9779, 0.9855, 0.9828, 1.1215, 0.9613, 1.0408, 1.1043, 0.9883,\n",
      "        1.0107, 0.9640, 0.9663, 0.9802, 1.0189, 0.9814, 0.9523, 1.0413, 0.9916,\n",
      "        0.9903, 1.0234, 0.9914, 0.9556, 0.9892, 1.1197, 1.0289, 0.9727, 0.9704,\n",
      "        0.9506, 0.9940, 1.0009, 0.9988, 0.9642, 1.0177, 0.9516, 0.9872, 1.0066,\n",
      "        0.9606, 0.9954, 0.9653, 0.9158, 1.1389, 0.9857, 0.9738, 0.9574, 0.9989,\n",
      "        1.0022, 1.0289, 1.0337, 1.0204, 0.9695, 0.9774, 0.9992, 0.9685, 1.0588,\n",
      "        1.0037, 0.9411, 1.0685, 1.0302, 1.0028, 0.9778, 1.0043, 0.9845, 0.9650,\n",
      "        0.9603, 1.0447, 1.0437, 1.0170, 0.9762, 0.9627, 0.9966, 0.9692, 1.0182,\n",
      "        0.9715, 0.9788, 0.9902, 1.0042, 0.9594, 0.9882, 1.0183, 0.9993, 0.9718,\n",
      "        0.9785, 0.9869, 1.0187, 0.9740, 1.0059, 0.9994, 1.0186, 0.9648, 0.9907,\n",
      "        0.9893, 0.9657, 0.9990, 0.9323, 0.9639, 1.0256, 1.0827, 1.0057, 1.0061,\n",
      "        0.9818, 0.9609, 0.9498, 1.0053, 0.9558, 1.0565, 0.9810, 0.9907, 0.9615,\n",
      "        0.9580, 1.0378, 0.9673, 0.9524, 0.9887, 1.0312, 0.9869, 0.9338, 1.1124,\n",
      "        0.9954, 0.9752, 1.0069, 1.0399, 0.9764, 0.9713, 1.0072, 1.0681, 1.0491,\n",
      "        1.0006, 0.9871, 0.9931, 0.9556, 1.0069, 0.9974, 1.0354, 1.0055, 1.0101,\n",
      "        0.9754, 1.0314, 1.0016, 0.9906, 0.9716, 0.9668, 1.0110, 0.9092, 0.9737,\n",
      "        0.9893, 1.0221, 0.9898, 1.0187, 0.9942, 1.0067, 0.9789, 0.9605, 0.9899,\n",
      "        1.0691, 0.9645, 1.0108, 0.9953, 0.9998, 0.9396, 0.9452, 0.9772, 0.9839,\n",
      "        0.9492, 1.0158, 0.9458, 0.9996, 0.9598, 0.9885, 0.9549, 1.0054, 1.0739,\n",
      "        0.9731, 1.0789, 1.1329, 1.0086, 1.0475, 1.0289, 1.0332, 1.0420, 0.9626,\n",
      "        0.9424, 1.0043, 0.9748, 0.9579, 1.0684, 1.0307, 0.9588, 0.9748, 1.0065,\n",
      "        0.9850, 0.9859, 1.0342, 0.9817, 0.9908, 0.9846, 0.9733, 0.9588, 0.9485,\n",
      "        1.0645, 1.0141, 1.0070, 1.1046, 1.1741, 1.0385, 0.9683, 1.0114, 0.9335,\n",
      "        0.9741, 1.1568, 1.1207, 1.0231, 1.0103, 0.9802, 0.9571, 0.9520, 0.9869,\n",
      "        0.9984, 1.0452, 1.0117, 0.9749, 1.0114, 0.9913, 0.9860, 0.9722, 0.9980,\n",
      "        0.9742, 0.9794, 0.9306, 0.9517, 0.9469, 1.0021, 0.9977, 0.9707])\n",
      "tensor([-0.0981, -0.1447,  0.0858,  0.0857,  0.0792,  0.0315,  0.0168, -0.0729,\n",
      "         0.0654,  0.0756,  0.0943, -0.0968, -0.1231, -0.1121,  0.0367, -0.1001,\n",
      "        -0.0402, -0.1235, -0.0498, -0.0215,  0.0777,  0.0414,  0.0203,  0.0377,\n",
      "        -0.1197, -0.0743,  0.1209, -0.0150, -0.0553,  0.0143, -0.0307, -0.0098,\n",
      "         0.0031, -0.1200, -0.0469,  0.0359, -0.0814,  0.0627, -0.0880, -0.0736,\n",
      "        -0.0101, -0.0163,  0.0216,  0.0166,  0.0747,  0.0865,  0.1388,  0.0492,\n",
      "         0.0340,  0.1141, -0.0075,  0.0336,  0.0557,  0.0406, -0.1004, -0.0900,\n",
      "         0.0335,  0.0148, -0.0056, -0.0401, -0.0708,  0.0655, -0.0283, -0.0146,\n",
      "        -0.0911,  0.0502, -0.0892,  0.1004,  0.0131, -0.1103,  0.1092, -0.0285,\n",
      "         0.0258,  0.0412, -0.0049,  0.0454, -0.0017,  0.1613,  0.0095,  0.1778,\n",
      "         0.0621, -0.0085, -0.0204, -0.0685, -0.0605, -0.0300, -0.0391,  0.1249,\n",
      "        -0.0720,  0.0903,  0.0437, -0.0250,  0.0491, -0.0487,  0.0571, -0.0659,\n",
      "         0.0130, -0.0342,  0.0984,  0.0754,  0.0509,  0.1435, -0.0024, -0.0186,\n",
      "         0.0188,  0.0220, -0.0937, -0.0261,  0.0018, -0.0124,  0.0376, -0.0957,\n",
      "        -0.1117,  0.0366, -0.0006, -0.0930,  0.0086, -0.0678,  0.1132,  0.0272,\n",
      "         0.0050, -0.0173, -0.1866,  0.0477, -0.0935, -0.0240,  0.0280, -0.1194,\n",
      "        -0.0565, -0.0578, -0.0674, -0.0688, -0.0259,  0.0385, -0.0942,  0.0284,\n",
      "        -0.0206,  0.1064,  0.0614, -0.0139, -0.0218, -0.1134,  0.0802,  0.0083,\n",
      "         0.0271, -0.1470, -0.0353, -0.0268,  0.0242,  0.0214,  0.0421,  0.1293,\n",
      "        -0.0404, -0.0633, -0.0012, -0.0991,  0.0874, -0.0036,  0.0077, -0.0232,\n",
      "        -0.0234, -0.0165,  0.1568, -0.0514,  0.0205, -0.0121, -0.0654, -0.0052,\n",
      "        -0.0491, -0.0748,  0.0240,  0.0500, -0.0049,  0.0648,  0.0817, -0.0026,\n",
      "         0.1139, -0.1146,  0.0170, -0.0393,  0.0365, -0.0167,  0.0531, -0.0074,\n",
      "        -0.0772,  0.0809,  0.0567,  0.0528, -0.0310,  0.0361,  0.1002, -0.1192,\n",
      "        -0.0128,  0.0864,  0.0826, -0.0320,  0.0506, -0.0253, -0.0090, -0.0159,\n",
      "         0.0648, -0.0650, -0.0275, -0.0258, -0.0523, -0.0038, -0.0532,  0.0810,\n",
      "         0.0442, -0.0270,  0.0093,  0.0249,  0.1049,  0.0393, -0.0028, -0.0350,\n",
      "        -0.0285,  0.0526,  0.0231, -0.0878,  0.0239,  0.0573,  0.0138,  0.0188,\n",
      "         0.0466,  0.0260, -0.0127, -0.0833,  0.1594,  0.0759, -0.0604,  0.0546,\n",
      "        -0.0071, -0.0754,  0.0630, -0.0357, -0.0226, -0.2310,  0.0098,  0.0182,\n",
      "        -0.0724,  0.0173,  0.1451, -0.0251,  0.0810,  0.0097, -0.1290, -0.0591,\n",
      "        -0.0549,  0.0751, -0.0862, -0.0156, -0.0534, -0.1199, -0.0837, -0.1032,\n",
      "         0.0306, -0.0107, -0.0436,  0.0070,  0.0044, -0.0763, -0.0839,  0.0097,\n",
      "        -0.0509, -0.0051, -0.0104, -0.0435,  0.1566, -0.1259,  0.1162,  0.0427,\n",
      "        -0.0356,  0.0227,  0.0845, -0.0675, -0.0741,  0.0307,  0.0206,  0.0084,\n",
      "         0.0643,  0.0195,  0.0107, -0.0696,  0.0410,  0.0042,  0.0275, -0.0082,\n",
      "         0.0689,  0.0087,  0.1199,  0.0123,  0.0680,  0.0649,  0.0720, -0.0175,\n",
      "         0.0771, -0.0680, -0.0118, -0.0700,  0.0816, -0.0166,  0.0826,  0.1277,\n",
      "         0.0515, -0.0849,  0.0226,  0.0588,  0.0013, -0.1070, -0.0513, -0.0154,\n",
      "        -0.0392,  0.0598,  0.0029,  0.0473, -0.0660, -0.0715,  0.0610,  0.0209,\n",
      "         0.0140, -0.0459, -0.0520,  0.0216,  0.0028, -0.0537, -0.0282,  0.0597,\n",
      "        -0.0679, -0.1188,  0.0381,  0.0701, -0.0548, -0.0148,  0.0219, -0.0056,\n",
      "         0.0664,  0.0441, -0.0045,  0.0527, -0.0439,  0.0737,  0.1422,  0.0320,\n",
      "         0.0540,  0.0893,  0.0403, -0.0629,  0.0502,  0.0888])\n",
      "tensor([[ 0.0206,  0.0586, -0.0106,  ..., -0.0037,  0.0276, -0.0502],\n",
      "        [ 0.0392, -0.0088,  0.0330,  ...,  0.0184, -0.0493,  0.0568],\n",
      "        [-0.0090, -0.0361, -0.0015,  ...,  0.0018, -0.0065,  0.0037],\n",
      "        ...,\n",
      "        [-0.0088,  0.0149,  0.0138,  ..., -0.0069,  0.0211,  0.0133],\n",
      "        [-0.0255,  0.0366, -0.0025,  ..., -0.0355, -0.0220,  0.0022],\n",
      "        [ 0.0318,  0.0662,  0.0542,  ...,  0.0263,  0.0183, -0.0109]])\n",
      "tensor([-0.0720, -0.0885,  0.0625, -0.0260,  0.0721, -0.0023, -0.0389,  0.0767,\n",
      "        -0.0258, -0.1227,  0.0468,  0.0079,  0.0777, -0.0407,  0.0593,  0.0539,\n",
      "         0.0205,  0.0290,  0.0422,  0.0405,  0.0446, -0.0914,  0.0093, -0.0645,\n",
      "        -0.0303,  0.0303,  0.0347,  0.0379,  0.0383,  0.0005, -0.0035,  0.0052,\n",
      "         0.0606, -0.0305, -0.0146,  0.0429,  0.0107, -0.0187,  0.0583,  0.0173,\n",
      "         0.0677, -0.0616,  0.0253, -0.0033,  0.0542,  0.0097,  0.0112,  0.0363,\n",
      "         0.0560, -0.0436,  0.1094, -0.0219,  0.0424,  0.0415,  0.0027,  0.0186,\n",
      "         0.0473,  0.0023, -0.0708,  0.0295, -0.0069,  0.0356,  0.0562, -0.0656,\n",
      "         0.0390,  0.0706, -0.1649,  0.0204,  0.0958, -0.0100,  0.0053,  0.0141,\n",
      "         0.0155, -0.0022, -0.0050,  0.1083,  0.0767,  0.0387,  0.0132,  0.0727,\n",
      "         0.1003,  0.0316,  0.0484,  0.0101,  0.0230, -0.0057,  0.0682,  0.0148,\n",
      "        -0.0892, -0.0353,  0.0422,  0.0310, -0.0262,  0.0361,  0.0023, -0.1123,\n",
      "        -0.1262, -0.0662, -0.0110, -0.0543,  0.0741,  0.0337,  0.0665,  0.0021,\n",
      "        -0.0411,  0.0445,  0.0647,  0.0333, -0.0271, -0.1226, -0.0169, -0.0555,\n",
      "         0.0055, -0.0108, -0.0274, -0.0330, -0.0263,  0.0460,  0.0926,  0.0037,\n",
      "        -0.0746, -0.0133,  0.0051, -0.0338, -0.0204,  0.0627,  0.0134, -0.0173,\n",
      "         0.0462,  0.0211, -0.1683, -0.0380, -0.0011, -0.1388, -0.0297,  0.0363,\n",
      "         0.0161,  0.0037,  0.0330, -0.0626,  0.0347,  0.0126,  0.0425,  0.0228,\n",
      "         0.0024,  0.0116,  0.0527,  0.0236, -0.0331,  0.0776,  0.0648,  0.0632,\n",
      "         0.0218,  0.0173,  0.0761,  0.0127,  0.0490,  0.0602,  0.0217,  0.0063,\n",
      "        -0.0204,  0.0963, -0.0152, -0.0132,  0.0216,  0.0017,  0.0326,  0.0787,\n",
      "         0.0386,  0.0067, -0.0080, -0.0184,  0.0623,  0.0043, -0.0607, -0.0383,\n",
      "        -0.0195, -0.1301, -0.0003,  0.0522,  0.0050,  0.0864,  0.0999,  0.0511,\n",
      "         0.0364, -0.0083,  0.0826,  0.0396,  0.0424,  0.0276, -0.0024, -0.0824,\n",
      "         0.0698,  0.0045,  0.0694,  0.0929, -0.1128,  0.0569, -0.0332,  0.0006,\n",
      "        -0.0434,  0.0202,  0.0575,  0.0257, -0.0956, -0.0036, -0.0017,  0.0144,\n",
      "        -0.0522, -0.0140,  0.0454,  0.0170,  0.0542, -0.1030,  0.0767, -0.0700,\n",
      "        -0.0798, -0.0221, -0.0162, -0.0140,  0.0166, -0.1165, -0.0437,  0.0488,\n",
      "         0.0213,  0.0554, -0.0431,  0.0579,  0.0465,  0.0321,  0.0322,  0.0257,\n",
      "        -0.0191, -0.0721,  0.0538, -0.0756,  0.0200,  0.0329, -0.0714,  0.0236,\n",
      "         0.0283, -0.1400, -0.0463,  0.0041,  0.0066, -0.0171, -0.0407,  0.0704,\n",
      "         0.0813,  0.0251,  0.0022,  0.0231,  0.0393, -0.0236,  0.0775, -0.0562,\n",
      "         0.0427, -0.0113,  0.0104,  0.0560, -0.0443, -0.0455, -0.0931, -0.0176,\n",
      "        -0.0755,  0.1408,  0.0372, -0.0503, -0.0040, -0.0410,  0.0679, -0.0018,\n",
      "         0.0277, -0.0299, -0.0869,  0.0617,  0.0132,  0.0652,  0.0316,  0.0191,\n",
      "         0.0769, -0.0066,  0.0884, -0.0073, -0.0923, -0.0182,  0.0424,  0.0037,\n",
      "        -0.0120,  0.0510, -0.0211, -0.0378,  0.1332, -0.0468,  0.0524,  0.0493,\n",
      "        -0.0325,  0.0047,  0.0095,  0.0044,  0.0990, -0.0559, -0.0379,  0.0937,\n",
      "         0.0312, -0.0159,  0.0361,  0.0325,  0.1214,  0.0470, -0.0960,  0.0297,\n",
      "         0.0068,  0.0501, -0.0023,  0.0809,  0.0420,  0.0040, -0.0105,  0.0095,\n",
      "        -0.0206, -0.0619, -0.0602,  0.0799, -0.0731, -0.0937, -0.1228, -0.0057,\n",
      "        -0.0017,  0.0359,  0.0469,  0.0217,  0.0471,  0.0480,  0.0280, -0.0177,\n",
      "         0.0769,  0.0271,  0.0708,  0.0151,  0.0058,  0.0381, -0.0405,  0.0244,\n",
      "         0.0114,  0.1012,  0.0775, -0.0390,  0.0427,  0.1021])\n",
      "tensor([0.9961, 0.9584, 0.9426, 0.9500, 0.9654, 0.9326, 0.9693, 0.9571, 1.0326,\n",
      "        1.0008, 0.9414, 0.9597, 0.9726, 0.9570, 0.9361, 0.9946, 0.9409, 0.9289,\n",
      "        0.9575, 0.9475, 0.9542, 1.0505, 0.9575, 0.9725, 0.9631, 0.9650, 0.9311,\n",
      "        0.9729, 0.9574, 0.9538, 0.9619, 0.9862, 0.9742, 0.9685, 0.9466, 0.9448,\n",
      "        0.9627, 1.0173, 0.9651, 0.9649, 0.9549, 0.9689, 1.0485, 1.0501, 0.9455,\n",
      "        0.9671, 0.9883, 0.9359, 0.9414, 1.0024, 0.9736, 0.9211, 0.9498, 0.9460,\n",
      "        0.9549, 0.9440, 0.9352, 0.9972, 0.9706, 0.9764, 0.9477, 0.9768, 0.9382,\n",
      "        1.0597, 0.9656, 0.9437, 1.0058, 0.9800, 0.9392, 0.9844, 0.9473, 0.9609,\n",
      "        0.9557, 0.9668, 0.9589, 0.9656, 0.9699, 0.9720, 0.9476, 0.9293, 0.9494,\n",
      "        0.9957, 0.9568, 0.9883, 0.9945, 0.9470, 0.9572, 1.0071, 1.0400, 0.9659,\n",
      "        0.9459, 1.0267, 0.9769, 0.9457, 0.9499, 1.0073, 1.0144, 0.9699, 0.9541,\n",
      "        1.0645, 0.9565, 0.9775, 0.9354, 0.9681, 1.0138, 0.9370, 0.9666, 0.9526,\n",
      "        1.0948, 1.1175, 1.0283, 1.0012, 1.0328, 0.9434, 0.9504, 0.9669, 0.9906,\n",
      "        0.9699, 0.9294, 0.9728, 0.9584, 1.0057, 0.9492, 0.9797, 1.0070, 0.9496,\n",
      "        0.9728, 0.9578, 0.9453, 0.9598, 1.0352, 0.9408, 0.9566, 0.9612, 0.9955,\n",
      "        0.9683, 0.9528, 0.9340, 0.9494, 1.0311, 1.0197, 0.9610, 0.9530, 0.9629,\n",
      "        0.9547, 1.0039, 0.9956, 0.9528, 0.9487, 0.9574, 0.9480, 0.9440, 0.9479,\n",
      "        0.9605, 0.9781, 0.9411, 0.9374, 1.0678, 0.9337, 0.9386, 0.9323, 0.9647,\n",
      "        0.9652, 0.9995, 0.9330, 0.9550, 0.9483, 0.9587, 0.9702, 0.9618, 0.9714,\n",
      "        1.0259, 0.9614, 1.0171, 0.9871, 0.9653, 0.9343, 0.9761, 0.9656, 0.9384,\n",
      "        0.9531, 1.0183, 0.9639, 0.9621, 0.9725, 0.9151, 0.9494, 0.9403, 0.9404,\n",
      "        0.9963, 0.9673, 0.9601, 0.9609, 0.9369, 0.9661, 0.9636, 1.0350, 0.9416,\n",
      "        0.9626, 0.9570, 0.9681, 0.9482, 0.9673, 0.9595, 0.9817, 1.0039, 0.9683,\n",
      "        0.9901, 0.9777, 0.9663, 0.9413, 0.9686, 0.9010, 1.0026, 0.9611, 0.9661,\n",
      "        0.9653, 0.9400, 0.9407, 0.9717, 0.9264, 0.9965, 0.9436, 0.9374, 0.9206,\n",
      "        0.9180, 0.9930, 0.9620, 0.9190, 0.9621, 0.9978, 0.9543, 0.9716, 1.0587,\n",
      "        0.9357, 1.0004, 0.9297, 0.9591, 0.9870, 0.9477, 0.9598, 1.0270, 1.0004,\n",
      "        1.0188, 0.9497, 0.9463, 0.9714, 1.0221, 0.9971, 0.9334, 0.9290, 0.9624,\n",
      "        0.9527, 0.9739, 0.9642, 0.9659, 0.9688, 0.8866, 0.9741, 0.9200, 0.9545,\n",
      "        0.9719, 1.0034, 0.9612, 0.9598, 0.9589, 0.9446, 0.9985, 0.9667, 0.9904,\n",
      "        0.9732, 0.9476, 0.9652, 0.9209, 0.9693, 0.9834, 0.9082, 0.9768, 0.9288,\n",
      "        0.9520, 0.9773, 0.9791, 0.9521, 0.9873, 0.9785, 0.9132, 0.9402, 0.9927,\n",
      "        0.9502, 1.0130, 0.9530, 0.9596, 0.9704, 0.9623, 0.9619, 0.9532, 0.9428,\n",
      "        0.9142, 0.9603, 0.9439, 0.9632, 0.9913, 0.9740, 0.9680, 0.9555, 0.9783,\n",
      "        0.9540, 0.9325, 0.9536, 0.9366, 0.9504, 0.9495, 0.9548, 0.9590, 1.0076,\n",
      "        0.9690, 0.9622, 0.9678, 0.9899, 0.9737, 0.9648, 0.9095, 0.9605, 0.9262,\n",
      "        1.0008, 1.0936, 1.0966, 0.9631, 1.0013, 0.9533, 0.9690, 0.9210, 0.9362,\n",
      "        0.9558, 0.9406, 1.0009, 0.9723, 0.9568, 0.9492, 0.9617, 0.9689, 0.9516,\n",
      "        0.9673, 0.9513, 0.9387, 0.9292, 0.9580, 0.9734, 0.9472, 0.9582])\n",
      "tensor([ 7.1255e-02, -1.1446e-01, -1.4952e-01, -4.9643e-02,  1.1153e-01,\n",
      "        -1.0721e-01,  1.6778e-01,  1.9671e-02,  1.3573e-01, -6.6729e-04,\n",
      "        -1.8647e-01,  1.6062e-01,  5.7368e-02,  1.0469e-01,  1.5631e-01,\n",
      "        -1.1661e-01, -1.1810e-01,  6.6659e-02, -2.0056e-02, -1.4072e-01,\n",
      "         5.6093e-02,  7.6967e-02,  8.6200e-02, -1.4530e-01, -1.3944e-01,\n",
      "        -7.2337e-02, -7.7419e-02, -6.2910e-02, -5.2494e-02,  1.3175e-02,\n",
      "         1.2075e-01, -1.0314e-01,  3.7735e-02, -2.0240e-02, -1.0003e-01,\n",
      "         1.5289e-01, -1.1382e-01, -4.4267e-03, -4.8755e-02,  3.1001e-02,\n",
      "        -1.0690e-01,  2.3532e-02, -1.5242e-01, -2.3668e-02, -1.1323e-01,\n",
      "        -2.4979e-03,  9.0862e-02, -1.3700e-01, -7.3049e-02,  1.0472e-01,\n",
      "        -3.1433e-02, -1.5827e-02,  1.3542e-01, -1.7294e-01,  1.3904e-01,\n",
      "        -1.4445e-01, -1.9507e-01,  1.5866e-01, -8.8607e-02,  1.6912e-01,\n",
      "         7.4109e-02,  1.4530e-01, -7.7246e-02,  9.5019e-02,  1.2795e-01,\n",
      "         2.7948e-02,  1.0764e-01, -9.3208e-02,  1.0894e-01, -1.0231e-02,\n",
      "        -1.7440e-01,  1.5083e-02, -1.6680e-01, -8.5034e-02, -3.8688e-02,\n",
      "        -7.4587e-02,  3.2319e-02, -4.4447e-02, -1.2976e-01, -1.0644e-01,\n",
      "        -4.1961e-02,  5.1871e-02,  1.1935e-01, -4.3845e-02, -4.0445e-02,\n",
      "        -9.8009e-03, -1.6025e-01,  5.4008e-02,  1.3999e-01,  9.2516e-02,\n",
      "         1.3982e-02, -4.9031e-02,  1.1082e-01,  9.0290e-02, -3.0474e-02,\n",
      "         1.1164e-01, -7.7280e-02,  7.0085e-02,  1.9428e-02,  5.5313e-02,\n",
      "         1.1106e-01, -1.1883e-02,  3.7335e-02, -7.9301e-02,  1.0811e-01,\n",
      "        -1.1222e-01,  1.5074e-01, -3.5795e-02,  2.7488e-02, -3.5600e-03,\n",
      "         8.4681e-02,  3.7762e-02, -9.7633e-03, -1.8905e-01, -7.1461e-02,\n",
      "         1.2992e-01, -1.3973e-01, -4.4679e-02, -1.0386e-01,  9.7433e-02,\n",
      "         7.8750e-02,  8.2856e-02, -1.1721e-01, -4.1345e-02,  9.3564e-02,\n",
      "        -9.2854e-02,  1.1935e-01, -1.1652e-01,  1.6174e-02,  1.2212e-01,\n",
      "         8.6132e-02, -1.3363e-01,  8.2934e-02, -9.2710e-02, -3.3534e-02,\n",
      "         8.3959e-02,  1.3878e-01, -1.5862e-01,  9.1869e-03,  5.9080e-02,\n",
      "         7.9278e-02,  1.7799e-01,  8.4116e-02, -1.3343e-01,  9.9810e-02,\n",
      "        -9.6545e-02,  4.7383e-02, -8.6331e-02,  7.1847e-03,  1.6491e-01,\n",
      "         1.4662e-01,  1.2823e-01, -2.2107e-02,  7.9926e-02, -1.3234e-01,\n",
      "         1.6597e-01,  1.3737e-01, -3.7415e-02,  1.4595e-01,  5.1886e-02,\n",
      "        -5.1679e-02,  8.8925e-02, -1.1383e-01, -2.4260e-02, -1.0519e-01,\n",
      "         1.7529e-01, -3.5633e-02, -3.8340e-02, -1.1919e-01,  3.9863e-02,\n",
      "        -7.1174e-02,  8.5152e-02, -6.4063e-02, -1.0907e-01,  1.3946e-02,\n",
      "        -7.5489e-02, -1.2254e-01,  1.6496e-02, -1.3728e-02, -1.0907e-01,\n",
      "        -1.2434e-01,  1.2942e-02,  3.7925e-02,  1.0458e-01,  1.1242e-02,\n",
      "        -4.5544e-02, -9.1723e-02, -6.7543e-02,  6.1198e-02,  1.5548e-01,\n",
      "        -1.1915e-01,  2.7597e-02, -1.8035e-01,  1.2251e-01,  1.4531e-01,\n",
      "         4.5695e-02,  1.2519e-01,  1.6632e-01, -9.0415e-02, -9.5918e-02,\n",
      "        -8.9977e-02, -1.7291e-02, -9.7382e-02, -1.4566e-02, -7.2189e-02,\n",
      "         1.8011e-03,  1.3028e-01,  4.5420e-02,  2.5145e-02, -9.2173e-02,\n",
      "        -5.8469e-02,  9.2367e-02, -1.1986e-01, -1.3530e-01, -1.3963e-01,\n",
      "         1.2209e-01,  5.5936e-04, -5.0808e-02, -7.4634e-02,  4.9620e-02,\n",
      "        -1.1516e-01,  1.3946e-01, -1.3667e-01,  1.4245e-02,  1.7096e-01,\n",
      "         6.4940e-03, -1.3598e-01, -1.3759e-01,  1.3729e-01,  4.7029e-02,\n",
      "        -6.9926e-02,  1.2544e-01, -5.5896e-02,  1.0131e-01, -1.4268e-01,\n",
      "        -6.6309e-02, -7.4353e-02,  1.7377e-01, -4.7109e-02, -1.3729e-02,\n",
      "        -8.0726e-03,  9.5052e-02, -1.4615e-01, -5.8619e-02, -1.2865e-01,\n",
      "        -1.2545e-01,  7.6196e-02, -1.9686e-02,  1.4760e-01,  8.0157e-02,\n",
      "         9.4014e-02, -4.0117e-02,  1.2042e-01,  1.1177e-01,  1.3027e-01,\n",
      "        -3.0185e-02, -1.2567e-01, -1.3577e-01,  1.5464e-01, -1.4710e-01,\n",
      "         4.3994e-02, -9.9803e-02, -4.5403e-02, -1.1377e-01, -8.6547e-03,\n",
      "        -2.3723e-02,  1.1733e-01, -1.7608e-01, -9.1242e-02,  1.0616e-02,\n",
      "        -8.0084e-02, -1.1333e-01, -5.4316e-02, -1.0779e-01, -1.8977e-02,\n",
      "         4.6597e-02, -3.8798e-02,  4.7470e-05,  2.6071e-02, -2.3994e-02,\n",
      "         9.1402e-02,  1.9966e-02,  7.3941e-02,  5.2774e-02, -1.7478e-02,\n",
      "         1.2389e-01, -1.1391e-01,  2.6951e-02, -1.1606e-01, -1.3344e-01,\n",
      "        -1.4759e-01, -5.7651e-03, -1.4172e-01, -8.3470e-02, -8.9579e-04,\n",
      "         9.7065e-02, -7.3963e-02,  1.5741e-01, -1.3600e-01,  4.3365e-03,\n",
      "        -3.8324e-02,  9.2979e-02,  8.6552e-02,  4.5212e-02, -1.2754e-01,\n",
      "         1.2311e-01,  1.4091e-01, -1.7458e-01,  1.0042e-01,  4.4123e-02,\n",
      "         1.0499e-01, -1.0710e-01, -7.5058e-02,  5.3561e-02, -2.5272e-02,\n",
      "        -5.1344e-02, -9.7772e-02,  1.6128e-01, -9.1485e-02,  1.0397e-01,\n",
      "         1.2419e-02, -2.3559e-02, -8.6567e-02,  1.3798e-01,  8.0930e-02,\n",
      "        -4.8980e-02, -8.7553e-02, -1.5975e-01,  3.0054e-02, -3.2420e-02,\n",
      "         2.0201e-02,  7.8407e-02, -1.3206e-01, -6.7589e-03,  4.9661e-02,\n",
      "         1.3081e-01, -1.4031e-01, -1.8108e-01,  1.5774e-01, -1.2043e-01,\n",
      "        -7.0231e-02,  1.2344e-01,  1.4412e-01,  6.9671e-03, -9.3140e-02,\n",
      "        -1.1692e-01, -1.0187e-01,  1.2905e-01,  7.2723e-03,  1.6543e-01])\n",
      "tensor([[ 4.9389e-04, -3.6792e-02, -2.1432e-02,  ..., -1.9962e-02,\n",
      "         -5.2565e-03,  1.6962e-02],\n",
      "        [ 2.0479e-03,  1.6671e-03, -1.4008e-03,  ..., -3.2802e-02,\n",
      "         -3.2941e-03,  2.8445e-02],\n",
      "        [-6.1091e-02,  2.4868e-02, -1.1177e-02,  ..., -1.0235e-02,\n",
      "         -1.8755e-02, -2.2258e-04],\n",
      "        ...,\n",
      "        [ 2.3627e-02, -1.8557e-02, -3.2102e-02,  ...,  4.4563e-02,\n",
      "          2.9497e-02,  1.1738e-02],\n",
      "        [ 5.0182e-05,  5.9447e-03, -3.5349e-03,  ...,  5.9359e-03,\n",
      "          1.6808e-02,  1.7560e-02],\n",
      "        [ 5.9696e-03, -1.0979e-02, -1.9197e-02,  ...,  6.1531e-02,\n",
      "         -2.2316e-02,  3.5027e-02]])\n",
      "tensor([ 0.0116, -0.0288,  0.0308,  0.0226,  0.2309,  0.1195,  0.1605,  0.1157])\n",
      "tensor([[-0.0784, -0.1295, -0.5098,  0.0275],\n",
      "        [-0.2481,  0.1075, -0.2494,  0.0249],\n",
      "        [ 0.1772,  0.2915,  0.1700, -0.1111],\n",
      "        ...,\n",
      "        [ 0.4124,  0.3857, -0.4344, -0.0914],\n",
      "        [-0.3666, -0.3978,  0.3891, -0.0222],\n",
      "        [ 0.2643,  0.2642,  0.4051, -0.1835]])\n",
      "tensor([-4.3020e-02,  2.9969e-01,  6.5399e-02,  3.0189e-01, -5.0614e-01,\n",
      "         3.7838e-01, -4.2457e-01, -2.2316e-01,  1.9417e-01,  3.0755e-01,\n",
      "        -1.8473e-01,  4.2207e-01, -1.0232e-01, -1.4918e-01, -2.6085e-01,\n",
      "         3.2919e-01,  1.6166e-01, -1.4737e-01, -4.7426e-01, -4.7206e-01,\n",
      "         5.2078e-01,  1.3810e-01, -2.7125e-01,  1.5792e-01, -4.7280e-01,\n",
      "         7.3925e-02,  1.8158e-01, -1.4815e-02, -2.8621e-01, -2.0399e-01,\n",
      "         4.1990e-02, -1.1153e-01,  3.2641e-01, -4.2025e-01, -4.5760e-02,\n",
      "         4.0333e-01,  4.8967e-01, -6.3954e-02, -2.1781e-01,  3.8280e-01,\n",
      "        -2.6189e-01, -2.7963e-02,  3.6660e-01,  1.2413e-02,  1.3932e-01,\n",
      "         4.9994e-01,  3.8468e-01, -1.4283e-01,  1.2342e-01, -4.6008e-01,\n",
      "        -4.6035e-01, -8.6044e-02,  3.2241e-02, -2.3757e-01,  8.4951e-02,\n",
      "        -2.4551e-01,  2.3315e-01,  6.3135e-02,  2.4338e-01, -4.4695e-02,\n",
      "         2.6393e-01,  4.6519e-01, -4.8289e-01,  3.4122e-01,  1.7276e-01,\n",
      "        -3.0560e-01, -4.5741e-01, -4.6753e-01,  2.6667e-01,  1.4752e-01,\n",
      "        -2.4959e-01,  2.2586e-01, -4.6134e-01, -1.4954e-01,  5.1866e-01,\n",
      "        -4.8048e-01, -4.0899e-01, -1.7042e-01,  3.4021e-01,  4.9576e-01,\n",
      "        -4.2467e-01,  3.9106e-01, -2.9685e-01,  5.6869e-02,  1.3299e-01,\n",
      "         9.8934e-02,  1.5276e-01, -7.8478e-02,  4.5528e-01,  3.0151e-02,\n",
      "        -4.9500e-01,  3.0414e-01,  1.7387e-01,  4.5944e-04, -3.8290e-01,\n",
      "        -2.7455e-02, -1.4940e-01,  3.8179e-01, -2.5497e-01,  2.6123e-02,\n",
      "         4.3612e-01, -1.9063e-01,  1.9382e-01, -5.8208e-02,  9.2423e-02,\n",
      "        -2.5205e-01,  8.0242e-02, -5.3147e-01,  3.5583e-01,  1.3991e-01,\n",
      "         3.4884e-01,  8.5409e-02, -3.0843e-01, -1.1506e-01, -3.4391e-01,\n",
      "         7.8779e-02, -4.4042e-01,  9.7868e-02, -2.8637e-01, -3.7152e-01,\n",
      "         8.1405e-03, -3.3772e-01, -5.1432e-01,  4.0029e-01,  7.1581e-03,\n",
      "        -3.9896e-02, -4.4091e-01,  1.9275e-01, -2.0327e-01, -1.8298e-01,\n",
      "         2.1414e-01, -3.7660e-01, -2.8724e-01, -4.7778e-01,  4.4487e-01,\n",
      "        -2.1097e-01, -2.1568e-01,  3.8005e-01, -2.9934e-01, -4.7102e-01,\n",
      "        -6.9711e-02, -3.2850e-01,  4.2776e-01,  3.7263e-02,  1.4695e-01,\n",
      "         3.4278e-01,  1.4984e-01,  2.1059e-01, -4.0187e-01,  2.5999e-01,\n",
      "        -2.4620e-01, -1.1500e-02,  3.8363e-02, -1.5345e-01, -2.0955e-01,\n",
      "         1.5547e-01, -3.0834e-01,  4.8383e-01,  1.8081e-01, -2.6497e-01,\n",
      "         3.8297e-01, -1.1881e-01, -3.5884e-01, -2.1329e-01,  4.5147e-01,\n",
      "        -2.6230e-01, -1.8329e-01, -4.8954e-01,  1.1010e-01,  3.1031e-01,\n",
      "        -1.8755e-01,  2.0964e-02, -5.4057e-03, -2.2887e-01,  2.9438e-01,\n",
      "        -2.7214e-01, -4.5021e-01, -5.2709e-01,  4.9499e-01,  1.9709e-01,\n",
      "        -3.6606e-01, -3.4032e-01, -1.8129e-01,  3.2917e-01, -1.2291e-01,\n",
      "        -4.2586e-01,  3.9982e-01, -2.7707e-01, -2.9440e-01, -8.2126e-02,\n",
      "         6.0296e-02, -3.6475e-02,  4.0823e-01,  2.4409e-01,  2.4589e-01,\n",
      "        -4.0850e-02, -2.7215e-02, -1.2572e-01, -3.5818e-02,  2.9811e-01,\n",
      "        -2.6556e-01, -3.6270e-02,  1.4641e-01,  1.0953e-01, -5.8666e-02,\n",
      "         2.1830e-01,  1.0167e-02, -3.4519e-01, -1.9280e-01,  3.7310e-01,\n",
      "         3.3991e-01,  3.5430e-01, -9.8209e-02, -5.0136e-01, -1.4529e-01,\n",
      "        -3.2692e-01, -4.8623e-01,  5.1324e-01, -3.4279e-01,  4.4396e-01,\n",
      "         2.7882e-02, -3.1055e-01, -5.0080e-01, -3.7689e-01,  4.2322e-01,\n",
      "        -4.6641e-02, -3.9868e-01, -2.9844e-01, -2.3105e-01,  3.1161e-01,\n",
      "         2.6747e-02, -5.8259e-02, -5.8371e-01,  1.6868e-01, -5.0295e-01,\n",
      "        -2.1525e-01, -2.5489e-01, -2.8370e-01,  4.1358e-01, -4.8061e-02,\n",
      "         1.1933e-01, -3.3910e-01, -4.3503e-01, -9.6355e-02,  4.3248e-01,\n",
      "         5.4411e-02, -3.6087e-01,  5.8935e-02,  4.1195e-01, -4.6014e-02,\n",
      "        -4.4776e-02,  1.1352e-01, -1.9175e-01, -4.3912e-01,  2.4847e-01,\n",
      "        -2.0782e-01,  4.2239e-01, -2.4262e-01,  4.0668e-01, -4.0237e-01,\n",
      "         2.9072e-01, -3.3332e-01, -2.9129e-01, -4.9142e-01, -5.4206e-01,\n",
      "         1.7218e-01, -2.5421e-01,  4.9640e-01, -4.4749e-02,  3.0032e-02,\n",
      "        -4.6002e-01, -4.5387e-02,  3.4294e-01, -4.4748e-02,  7.7214e-02,\n",
      "        -4.2339e-01, -1.0649e-01,  1.8151e-01,  1.3043e-01,  7.7580e-02,\n",
      "        -1.0599e-03, -5.9093e-02,  2.3774e-01, -2.8147e-01, -1.4200e-01,\n",
      "        -2.7043e-01,  1.3340e-01,  2.2301e-01, -4.5934e-03, -2.1648e-01,\n",
      "        -4.1928e-01, -3.6548e-01,  2.8747e-01, -4.8238e-01,  1.1651e-02,\n",
      "         3.0597e-01, -2.9933e-01, -4.1778e-01, -2.3436e-01, -3.5503e-01,\n",
      "         1.1685e-01,  3.1811e-01, -3.5806e-01,  1.2905e-01,  1.7959e-02,\n",
      "        -1.4593e-01,  1.3884e-01,  2.4195e-01,  2.4333e-01,  1.8740e-01,\n",
      "        -1.0046e-01,  2.5516e-01, -2.2813e-01, -4.8857e-01, -1.8231e-01,\n",
      "        -5.0858e-01,  4.3496e-01, -2.3021e-01,  4.4912e-01,  4.6785e-01,\n",
      "        -3.0700e-01, -8.5895e-03,  2.1984e-01, -5.3838e-01, -2.6413e-01,\n",
      "        -2.5318e-02,  1.2573e-01,  2.3074e-01, -1.2955e-01, -4.4345e-01,\n",
      "         2.1200e-01, -1.9676e-01, -1.4202e-01,  1.8499e-01, -4.0162e-01,\n",
      "         4.1014e-02,  4.3653e-01, -3.8940e-01,  3.3421e-02, -8.5253e-02,\n",
      "         4.4427e-01,  4.4633e-01, -4.5393e-01,  3.7066e-01, -4.0457e-01,\n",
      "         3.7730e-01, -5.3893e-01,  2.4798e-01,  2.5763e-01, -2.3542e-01])\n",
      "tensor([1.0214, 0.9607, 0.9753, 0.9525, 0.9841, 1.0175, 0.9466, 1.0020, 0.9733,\n",
      "        0.9353, 0.9889, 0.9632, 0.9799, 0.9367, 0.9546, 0.9776, 0.9271, 1.0126,\n",
      "        0.9684, 0.9806, 0.9855, 0.9571, 0.9970, 0.9661, 0.9900, 0.9763, 0.9787,\n",
      "        0.9664, 1.0212, 0.9590, 0.9766, 1.0290, 0.9634, 1.0003, 0.9690, 1.0052,\n",
      "        0.9625, 0.9661, 1.0015, 0.9565, 0.9995, 0.9442, 1.0138, 1.0041, 0.9874,\n",
      "        0.9901, 0.9443, 0.9799, 0.9638, 0.9981, 0.9909, 0.9542, 0.9780, 0.9394,\n",
      "        0.9751, 1.0121, 0.9627, 1.0053, 0.9772, 0.9654, 0.9879, 0.9595, 0.9794,\n",
      "        0.9583, 0.9640, 0.9683, 0.9291, 0.9645, 0.9467, 0.9437, 1.0086, 0.9789,\n",
      "        0.9937, 0.9638, 0.9621, 0.9702, 0.9637, 0.9546, 0.9457, 0.9364, 0.9875,\n",
      "        0.9772, 1.0080, 0.9940, 0.9943, 0.9446, 0.9418, 0.9863, 0.9592, 0.9714,\n",
      "        1.0097, 0.9746, 1.0206, 0.9791, 0.9685, 0.9607, 1.0621, 0.9502, 0.9719,\n",
      "        0.9686, 0.9776, 0.9408, 0.9587, 0.9993, 0.9898, 0.9913, 1.0089, 0.9942,\n",
      "        0.9770, 0.9643, 1.0060, 0.9728, 0.9395, 0.9816, 0.9987, 0.9799, 1.0013,\n",
      "        0.9507, 0.9725, 0.9871, 0.9726, 0.9823, 0.9817, 0.9956, 0.9648, 0.9513,\n",
      "        0.9469, 1.0043, 1.0093, 0.9838, 0.9581, 0.9980, 0.9586, 0.9341, 0.9498,\n",
      "        0.9360, 0.9692, 0.9791, 0.9952, 0.8891, 0.9517, 1.0032, 0.9788, 1.0254,\n",
      "        0.9926, 0.9951, 0.9957, 0.9889, 0.9567, 0.9878, 0.9763, 0.9736, 0.9523,\n",
      "        1.0265, 0.9872, 0.9872, 0.9862, 1.0008, 0.9674, 0.9797, 0.9618, 0.9817,\n",
      "        1.0299, 0.9613, 0.9606, 0.9636, 1.0804, 0.9932, 0.9638, 0.9713, 1.0084,\n",
      "        0.9574, 0.9995, 0.9877, 0.9436, 0.9922, 0.9414, 0.9972, 0.9651, 1.0031,\n",
      "        0.9894, 0.9650, 0.9786, 0.9754, 0.9883, 1.0024, 0.9721, 0.9772, 0.9417,\n",
      "        0.9540, 0.9689, 0.9947, 0.9573, 0.9793, 0.9658, 0.9786, 0.9807, 1.0685,\n",
      "        0.9678, 0.9633, 0.9811, 0.9694, 0.9778, 0.9784, 0.9675, 0.9522, 0.9669,\n",
      "        0.9736, 0.9887, 0.9506, 0.9556, 1.0429, 0.9548, 0.9908, 0.9534, 0.9973,\n",
      "        0.9722, 0.9594, 1.0234, 0.9782, 0.9918, 1.0366, 0.9978, 1.0172, 0.9702,\n",
      "        0.9470, 1.0002, 1.0043, 1.0556, 0.9546, 0.9626, 0.9640, 1.0128, 0.9227,\n",
      "        1.0228, 0.9630, 1.0923, 0.9534, 0.9497, 0.9575, 0.9307, 0.9842, 0.9799,\n",
      "        0.9514, 0.9744, 0.9964, 0.9791, 0.9983, 0.9338, 1.0304, 0.9687, 0.9793,\n",
      "        0.9414, 0.9556, 0.9418, 0.9726, 1.0133, 0.9682, 0.9624, 0.9522, 0.9750,\n",
      "        0.9746, 0.9742, 0.9715, 0.9995, 0.9534, 0.9812, 0.9298, 0.9679, 0.9761,\n",
      "        0.9820, 0.9611, 0.9784, 1.0509, 0.9581, 0.9741, 0.9699, 1.0246, 1.0269,\n",
      "        0.9768, 1.0561, 1.0022, 0.9554, 0.9633, 1.0148, 1.0124, 0.9731, 0.9418,\n",
      "        0.9586, 1.0183, 0.9640, 1.0010, 0.9368, 1.0142, 1.0028, 0.9431, 0.9629,\n",
      "        0.9711, 0.9746, 0.9797, 0.9707, 0.9861, 0.9514, 0.9577, 0.9402, 0.9643,\n",
      "        0.9719, 0.9409, 1.0413, 0.9679, 1.0423, 0.9732, 0.9561, 0.9585, 0.9716,\n",
      "        0.9739, 0.9695, 0.9349, 0.9455, 0.9541, 0.9518, 0.9774, 1.0202, 0.9810,\n",
      "        1.0103, 0.9516, 0.9575, 0.9936, 0.9593, 0.9706, 0.9716, 1.0004, 0.9593,\n",
      "        0.9749, 0.9647, 0.9730, 1.0134, 0.9926, 0.9746, 0.9837, 0.9848, 0.9700,\n",
      "        1.0456, 0.9505, 0.9845, 0.9519, 1.0104, 0.9886, 0.9549, 0.9849])\n",
      "tensor([ 0.0488,  0.0820, -0.0549,  0.0379,  0.0119,  0.0141,  0.0049,  0.0967,\n",
      "        -0.0088, -0.0090,  0.0291, -0.0280, -0.0598,  0.0181,  0.0076,  0.0065,\n",
      "         0.0115,  0.0235, -0.0380,  0.0255,  0.0322, -0.0392,  0.0023, -0.0052,\n",
      "        -0.0989,  0.0308, -0.0584,  0.0343,  0.0648, -0.0091, -0.0136,  0.0784,\n",
      "         0.0263,  0.0371, -0.0014,  0.0035, -0.0264,  0.1138,  0.0549, -0.0071,\n",
      "        -0.0208, -0.0527, -0.0504, -0.0629,  0.0162, -0.0363, -0.0358, -0.0645,\n",
      "        -0.0849, -0.0016,  0.0156, -0.0902, -0.0423,  0.0186, -0.0459, -0.0027,\n",
      "         0.0036,  0.0683,  0.0496,  0.0838, -0.0061, -0.0594, -0.0665,  0.0081,\n",
      "        -0.0146, -0.0643,  0.0135, -0.0214,  0.0075, -0.0309,  0.0130,  0.0389,\n",
      "        -0.0064, -0.0578, -0.0212,  0.0116, -0.0498, -0.0069, -0.0468, -0.0036,\n",
      "         0.0356, -0.0161, -0.0862,  0.0184, -0.0019, -0.0308,  0.0051,  0.0064,\n",
      "         0.0146, -0.0334,  0.0065, -0.0598, -0.0285,  0.0496, -0.0619, -0.0031,\n",
      "         0.0921,  0.0216,  0.0147,  0.0402, -0.0502,  0.0119, -0.1240,  0.0120,\n",
      "         0.0310,  0.0257,  0.0450,  0.0808, -0.0893, -0.0384,  0.0248, -0.0243,\n",
      "         0.0896, -0.0400, -0.0874,  0.0193, -0.0502,  0.0280, -0.0704,  0.0060,\n",
      "        -0.0207, -0.0131,  0.0021,  0.0303, -0.0267,  0.0089, -0.0189,  0.0200,\n",
      "        -0.0105,  0.0243,  0.0221, -0.0040,  0.0567, -0.0263, -0.0798,  0.0232,\n",
      "        -0.0419, -0.0252,  0.0264,  0.0596, -0.0134,  0.0443, -0.0569, -0.0400,\n",
      "         0.0345, -0.0321,  0.0265,  0.0032,  0.0462,  0.0026,  0.0058,  0.0778,\n",
      "        -0.0107,  0.0237, -0.0246,  0.0677,  0.0334,  0.0023,  0.0329, -0.0039,\n",
      "        -0.0657, -0.0281, -0.0512,  0.0586,  0.0116, -0.0163,  0.0583,  0.0248,\n",
      "         0.0117, -0.0200,  0.0103,  0.0567, -0.0736, -0.0940, -0.0574,  0.0160,\n",
      "         0.0685, -0.0544, -0.0161, -0.0147, -0.0137,  0.0357, -0.0145, -0.0185,\n",
      "         0.0126,  0.0170,  0.0355, -0.0348,  0.0333, -0.0147, -0.0524, -0.0258,\n",
      "        -0.0217,  0.0374, -0.0029, -0.0369,  0.0358, -0.0432,  0.0047, -0.0268,\n",
      "         0.0187,  0.0189,  0.0775, -0.0161,  0.0373,  0.0035, -0.0651, -0.0031,\n",
      "        -0.0560,  0.0141, -0.0172, -0.0387, -0.0049,  0.0447, -0.0283,  0.0310,\n",
      "        -0.0122, -0.0771,  0.0084,  0.0383, -0.0182,  0.0588,  0.0323, -0.0089,\n",
      "         0.0117, -0.0462, -0.0441, -0.0307,  0.0336,  0.0416, -0.0540, -0.0496,\n",
      "         0.0024, -0.1044, -0.0312, -0.0071,  0.0705, -0.0173, -0.0912,  0.0395,\n",
      "        -0.0239,  0.0047,  0.0379, -0.0210, -0.0298,  0.0107,  0.0150,  0.0258,\n",
      "        -0.0217,  0.0667, -0.0590, -0.0578, -0.0206, -0.0086, -0.0740,  0.0654,\n",
      "         0.0261, -0.0151, -0.0536,  0.0036, -0.0478,  0.0096, -0.0363, -0.0140,\n",
      "        -0.0173,  0.0389, -0.0813, -0.0603,  0.0012, -0.0014, -0.0011,  0.0354,\n",
      "         0.0588, -0.0531,  0.0156, -0.0762,  0.0138,  0.0003, -0.0225,  0.0383,\n",
      "        -0.0350,  0.0076, -0.0648, -0.0609, -0.0326,  0.0076, -0.0064,  0.0059,\n",
      "        -0.0252,  0.0428, -0.0310,  0.0339, -0.0116, -0.0207,  0.0082, -0.0336,\n",
      "        -0.0006, -0.0714,  0.0014, -0.0133,  0.0509, -0.0076, -0.0505,  0.0008,\n",
      "        -0.0561, -0.0119,  0.0180, -0.0930, -0.0345, -0.0565,  0.0919,  0.0472,\n",
      "         0.1384, -0.0189,  0.0298,  0.0276,  0.0493,  0.0147, -0.0002, -0.0120,\n",
      "         0.0032, -0.0037,  0.0341,  0.0535,  0.0770,  0.0357, -0.0287, -0.0154,\n",
      "         0.0335, -0.0668, -0.0227, -0.0123, -0.0855, -0.0028, -0.0627,  0.0157,\n",
      "        -0.0378, -0.0165, -0.0730, -0.0157, -0.0699,  0.0549,  0.0308,  0.0397,\n",
      "        -0.0565,  0.0091,  0.0140,  0.0361,  0.0060,  0.0498])\n",
      "tensor([[-0.0562, -0.0275,  0.0060,  ..., -0.0115, -0.0477, -0.0365],\n",
      "        [-0.0033,  0.0109, -0.0192,  ..., -0.0086, -0.0638, -0.0599],\n",
      "        [-0.0561,  0.0195, -0.0375,  ..., -0.0382,  0.0477, -0.0713],\n",
      "        ...,\n",
      "        [-0.0341,  0.0589,  0.0352,  ...,  0.0022, -0.0411, -0.0056],\n",
      "        [-0.0303, -0.0055, -0.0358,  ...,  0.0133, -0.0170,  0.0268],\n",
      "        [ 0.0500,  0.0515, -0.0328,  ...,  0.0040, -0.0572,  0.0202]])\n",
      "tensor([-0.0516, -0.0315, -0.0649, -0.0264, -0.0465, -0.0282, -0.0249,  0.0140,\n",
      "        -0.0140, -0.0606,  0.0795, -0.0463, -0.0802, -0.0683,  0.0423, -0.0379,\n",
      "        -0.0756,  0.0067, -0.0238, -0.0600,  0.0647, -0.0417, -0.0580, -0.0487,\n",
      "        -0.0377, -0.0712, -0.0115,  0.0677, -0.1367, -0.0193, -0.0922, -0.0460,\n",
      "         0.0222,  0.0022, -0.0546, -0.0021,  0.0124,  0.0243, -0.1006,  0.0265,\n",
      "        -0.0838, -0.0336,  0.0300, -0.0539, -0.0034,  0.1055, -0.0186, -0.0067,\n",
      "         0.0198, -0.0454, -0.0604,  0.0229, -0.0157, -0.0006, -0.0288,  0.0174,\n",
      "         0.0269, -0.0319,  0.0072, -0.0128,  0.0296,  0.0067, -0.0252, -0.1206,\n",
      "        -0.0445, -0.0155, -0.0021,  0.0393,  0.0393, -0.0284, -0.0207,  0.0328,\n",
      "        -0.0869, -0.0853,  0.1081,  0.0111, -0.0234, -0.0162, -0.0535,  0.0835,\n",
      "         0.0227,  0.0159, -0.0214,  0.0144, -0.1333,  0.0442, -0.0564, -0.0527,\n",
      "        -0.0875,  0.0147, -0.0630, -0.0221, -0.0141,  0.0493, -0.0129, -0.0489,\n",
      "        -0.0315,  0.0431,  0.0095, -0.0986,  0.0444,  0.0235,  0.0093, -0.0177,\n",
      "        -0.0168, -0.0642,  0.0143, -0.0590,  0.0023,  0.0115, -0.0146,  0.0476,\n",
      "         0.0221, -0.1196, -0.0074, -0.0386, -0.0219,  0.0390, -0.0058,  0.0463,\n",
      "         0.0578,  0.0361,  0.0137,  0.0045, -0.0316, -0.0184,  0.0243,  0.0360,\n",
      "        -0.0412,  0.0102, -0.0116,  0.0214,  0.0013, -0.0484,  0.0185, -0.0100,\n",
      "         0.0407, -0.0302, -0.0698, -0.0775,  0.0424, -0.0132, -0.0401, -0.0349,\n",
      "        -0.1585, -0.0277,  0.0492, -0.0412, -0.0259, -0.0109, -0.0444, -0.0546,\n",
      "         0.0507, -0.0110, -0.0712,  0.0713, -0.0502,  0.0775, -0.0290, -0.0380,\n",
      "         0.0292, -0.1119, -0.1075, -0.0159, -0.0094, -0.1256, -0.0179, -0.0658,\n",
      "        -0.0102, -0.0295,  0.0303, -0.0316, -0.0083, -0.0454,  0.0132, -0.0017,\n",
      "        -0.0682, -0.0135,  0.0481, -0.0999, -0.0119, -0.0396,  0.0280,  0.0619,\n",
      "        -0.0382, -0.0210,  0.0075, -0.0248, -0.0703,  0.0410, -0.0458, -0.0060,\n",
      "        -0.0332, -0.0511, -0.0547, -0.0614,  0.0732, -0.0325,  0.0287,  0.0206,\n",
      "         0.0304, -0.0706, -0.0056, -0.0141, -0.0373,  0.0520, -0.0478, -0.0722,\n",
      "         0.0770,  0.0381, -0.0056,  0.0513, -0.0307, -0.0395, -0.0078, -0.0432,\n",
      "         0.0168, -0.0488,  0.0091,  0.0526,  0.0755, -0.0087, -0.0094, -0.1160,\n",
      "         0.0433, -0.0192, -0.0290, -0.0046,  0.0399,  0.0195,  0.0206,  0.0225,\n",
      "        -0.1350, -0.0784, -0.0151, -0.0293, -0.0325, -0.0198, -0.0338, -0.0058,\n",
      "        -0.0611,  0.0136, -0.0412, -0.1146, -0.0347,  0.0399,  0.0269, -0.0095,\n",
      "        -0.0064, -0.0064,  0.0095,  0.0391, -0.0406,  0.0294,  0.0096, -0.0533,\n",
      "        -0.0717, -0.0263,  0.0889,  0.0132, -0.0124, -0.0304, -0.0049,  0.0533,\n",
      "         0.0185, -0.0531,  0.0072,  0.0628, -0.0334, -0.0475, -0.0007,  0.0092,\n",
      "         0.0100, -0.1176, -0.0268,  0.0273, -0.0303, -0.0633, -0.0578, -0.0502,\n",
      "         0.0209,  0.0257,  0.0897, -0.0270, -0.0587,  0.0162, -0.0280, -0.0796,\n",
      "         0.0118, -0.0998,  0.0527,  0.0140, -0.0566, -0.1184,  0.0262,  0.0704,\n",
      "        -0.0224, -0.0155, -0.0184, -0.0867,  0.0138,  0.0345, -0.0886, -0.0243,\n",
      "        -0.0185, -0.0134,  0.0279,  0.0372, -0.0233, -0.0243, -0.0835,  0.0070,\n",
      "        -0.0879, -0.0186, -0.0254, -0.0918, -0.0111,  0.0395, -0.0692, -0.0192,\n",
      "        -0.0111, -0.0070,  0.0169, -0.0404, -0.0346, -0.0487,  0.0467, -0.0058,\n",
      "         0.0258,  0.0350,  0.0144, -0.0068, -0.0341, -0.0500, -0.0047, -0.0787,\n",
      "        -0.0293, -0.0772, -0.0164,  0.0194, -0.0194,  0.0057,  0.0038,  0.0138,\n",
      "        -0.0567, -0.0607, -0.0023, -0.0083, -0.0300,  0.0390])\n",
      "tensor([1.0421, 1.0052, 0.9821, 1.0109, 1.0011, 1.0182, 0.9673, 1.0031, 1.0448,\n",
      "        1.0042, 0.9768, 1.0079, 0.9980, 0.9977, 1.0166, 0.9862, 0.9788, 1.0313,\n",
      "        0.9901, 1.0279, 0.9840, 0.9668, 0.9685, 0.9738, 1.0242, 1.0028, 0.9881,\n",
      "        0.9920, 0.9912, 1.0130, 1.0404, 1.0210, 1.0019, 1.0073, 1.0333, 0.9885,\n",
      "        0.9964, 1.0199, 0.9895, 0.9538, 1.0097, 1.0626, 1.0214, 0.9877, 1.0074,\n",
      "        1.0198, 0.9500, 1.0195, 0.9594, 1.0381, 1.0440, 1.0199, 1.0195, 1.0008,\n",
      "        1.0116, 0.9543, 0.9907, 1.0012, 1.0003, 0.9826, 1.0133, 1.0091, 1.0398,\n",
      "        1.0366, 0.9840, 1.0357, 0.9990, 1.0268, 1.0155, 1.0042, 0.9763, 1.0158,\n",
      "        0.9877, 0.9888, 1.0160, 0.9973, 1.0046, 1.0354, 1.0204, 0.9468, 1.0313,\n",
      "        1.0227, 0.9981, 0.9776, 1.0895, 1.0115, 1.0001, 0.9868, 0.9902, 1.0011,\n",
      "        1.0465, 0.9968, 0.9801, 0.9933, 1.0131, 1.0490, 1.0446, 0.9746, 1.0454,\n",
      "        0.9952, 0.9932, 0.9972, 0.9942, 0.9809, 0.9904, 0.9857, 0.9930, 1.0312,\n",
      "        0.9825, 0.9870, 0.9534, 0.9576, 1.0338, 1.0042, 0.9712, 1.0389, 0.9895,\n",
      "        1.0234, 1.0247, 1.0169, 0.9827, 1.0188, 0.9663, 1.0121, 1.0220, 1.0139,\n",
      "        1.0064, 1.0251, 0.9865, 0.9819, 0.9872, 0.9999, 0.9970, 1.0669, 0.9892,\n",
      "        0.9882, 1.0282, 0.9871, 1.0112, 1.0374, 1.0138, 1.0172, 1.0148, 0.9546,\n",
      "        1.0293, 0.9937, 0.9643, 0.9802, 0.9792, 1.0203, 1.0069, 0.9592, 1.0038,\n",
      "        1.0281, 0.9906, 1.0092, 1.0229, 1.0044, 0.9852, 0.9992, 1.0271, 1.0139,\n",
      "        1.0485, 0.9785, 0.9797, 1.0496, 0.9701, 1.0131, 1.0059, 1.0013, 1.0112,\n",
      "        1.0231, 1.0297, 1.0077, 1.0097, 1.0927, 1.0705, 1.0244, 0.9862, 0.9695,\n",
      "        0.9905, 0.9753, 1.0094, 0.9623, 0.9782, 0.9994, 1.0348, 0.9868, 1.0093,\n",
      "        0.9958, 0.9881, 1.0126, 0.9821, 1.0298, 1.0068, 1.0041, 0.9519, 0.9651,\n",
      "        0.9660, 0.9731, 0.9855, 0.9911, 1.0130, 1.0235, 1.0284, 0.9930, 0.9959,\n",
      "        0.9971, 0.9505, 0.9900, 0.9990, 0.9766, 1.0389, 0.9969, 0.9763, 1.0360,\n",
      "        1.0168, 1.0222, 1.0021, 0.9618, 1.0065, 0.9793, 1.0168, 1.0096, 1.0105,\n",
      "        1.0069, 1.0019, 0.9796, 0.9995, 0.9798, 0.9835, 0.9857, 1.0191, 1.0066,\n",
      "        0.9913, 0.9869, 1.0015, 0.9966, 0.9836, 0.9932, 0.9971, 1.0423, 1.0455,\n",
      "        1.0071, 0.9449, 1.0022, 0.9723, 1.0068, 0.9856, 1.0601, 0.9691, 1.0021,\n",
      "        0.9626, 1.0200, 0.9809, 1.0581, 1.0350, 1.0231, 1.0058, 0.9835, 1.0340,\n",
      "        1.0331, 0.9997, 0.9998, 0.9977, 0.9904, 0.9929, 0.9577, 1.0225, 1.0397,\n",
      "        1.0755, 0.9925, 0.9765, 0.9841, 1.0426, 1.0421, 1.0265, 1.0267, 1.0135,\n",
      "        1.0038, 0.9826, 1.0029, 0.9843, 1.0085, 1.0392, 1.0236, 0.9665, 0.9861,\n",
      "        0.9772, 1.0345, 1.0119, 1.0195, 1.0142, 1.0125, 1.0071, 0.9839, 0.9707,\n",
      "        1.0563, 1.0329, 0.9912, 0.9655, 1.0086, 1.0114, 0.9801, 0.9540, 1.0059,\n",
      "        0.9840, 0.9769, 1.0116, 1.0123, 1.0375, 0.9744, 1.0247, 0.9986, 0.9987,\n",
      "        1.0158, 0.9761, 1.0329, 1.0465, 0.9888, 1.0308, 1.0301, 1.0077, 1.0303,\n",
      "        0.9967, 1.0198, 1.0119, 1.0182, 0.9968, 0.9613, 0.9739, 1.0142, 1.0130,\n",
      "        1.0615, 1.0537, 1.0306, 1.0320, 0.9998, 0.9781, 1.0428, 0.9837, 0.9831,\n",
      "        1.0055, 0.9791, 1.0217, 0.9556, 0.9823, 1.0007, 0.9994, 1.0041])\n",
      "tensor([ 2.6530e-02,  3.4068e-02,  6.7312e-02, -7.8475e-03, -1.3262e-02,\n",
      "         7.5315e-03,  1.1240e-02, -4.1953e-02,  4.3788e-03,  1.3003e-02,\n",
      "        -1.0826e-02, -3.8767e-02,  2.1830e-02,  2.0539e-02,  4.0463e-03,\n",
      "         2.3981e-02, -4.3788e-02, -9.6494e-03,  4.1471e-02, -3.5621e-04,\n",
      "         1.8546e-02, -6.3270e-02, -3.5969e-03,  1.1481e-02, -3.9631e-03,\n",
      "        -6.5629e-03,  9.8632e-02, -1.2366e-02, -4.4768e-03,  1.6067e-02,\n",
      "        -2.1741e-02, -8.0580e-03, -4.1869e-02, -2.9693e-02,  3.8821e-02,\n",
      "        -9.4130e-03, -4.1922e-02,  2.9888e-03,  1.4397e-02, -7.6406e-04,\n",
      "         2.3460e-02, -3.8164e-02,  4.5126e-02,  5.8815e-02,  6.8374e-02,\n",
      "         3.8053e-02,  1.4067e-02,  8.3054e-02, -6.1149e-02, -4.5795e-02,\n",
      "        -2.5191e-02,  1.8380e-02,  7.3665e-02,  1.2341e-02,  1.0799e-02,\n",
      "        -7.4914e-02, -3.9902e-02, -7.8940e-03, -1.2031e-03,  3.0925e-02,\n",
      "         2.3278e-02,  4.8276e-02, -4.7751e-02, -3.0060e-02, -5.1525e-02,\n",
      "        -2.1637e-02,  3.5585e-02,  5.4899e-02,  2.7492e-02,  5.9021e-02,\n",
      "         9.9745e-02,  2.2124e-02,  7.6397e-04, -6.2784e-02,  4.6928e-03,\n",
      "         1.7939e-02, -5.6119e-02,  7.1678e-02, -1.4697e-02,  3.8676e-02,\n",
      "         8.9099e-02, -2.7013e-02,  4.9152e-02, -1.8754e-02, -5.1652e-02,\n",
      "        -5.6167e-02, -1.3397e-03,  1.1871e-02, -5.2695e-02,  1.6686e-02,\n",
      "        -2.6515e-02, -1.9629e-02, -3.1140e-02, -1.8567e-02, -5.4428e-02,\n",
      "        -1.7093e-02,  2.2931e-02,  1.7468e-02,  1.0947e-02, -1.4821e-02,\n",
      "         4.6458e-02, -2.8857e-02, -9.8483e-03, -2.4354e-02,  4.0958e-03,\n",
      "         1.1553e-02,  1.4093e-02,  1.8364e-02, -1.9876e-03,  1.5568e-02,\n",
      "        -5.4005e-02,  3.2357e-03, -2.3236e-02,  5.6477e-03, -1.0799e-02,\n",
      "        -8.8480e-03, -3.9217e-02, -8.9828e-03,  3.4407e-02,  6.3522e-03,\n",
      "        -1.4279e-02,  2.3888e-02,  2.6430e-02,  3.4631e-02,  5.9434e-02,\n",
      "         5.6107e-03, -3.7069e-02, -9.6610e-03,  4.2594e-02,  2.5945e-02,\n",
      "         6.9011e-03, -2.0582e-02, -8.9410e-03, -5.3910e-02,  3.9308e-02,\n",
      "         4.4552e-02, -2.9592e-02, -6.2558e-02,  1.3149e-02,  5.5392e-03,\n",
      "         1.4186e-02, -1.9986e-02,  8.8822e-03, -1.4202e-02,  2.7615e-02,\n",
      "         5.3317e-02,  2.4163e-02, -2.8994e-03,  9.8716e-03,  6.1870e-02,\n",
      "         5.0399e-02, -1.7055e-02,  1.5262e-02, -5.9504e-02,  1.0424e-02,\n",
      "        -5.2957e-02,  2.7312e-02,  2.4682e-02, -9.2089e-03,  1.4456e-02,\n",
      "         5.5120e-03, -7.7923e-03, -3.3280e-02, -3.1693e-02,  3.6217e-02,\n",
      "         1.9619e-02,  4.4898e-02, -3.6008e-02,  1.1219e-02, -1.7697e-02,\n",
      "         2.2847e-02,  1.5782e-02,  6.2070e-02, -2.2819e-02,  8.4239e-02,\n",
      "         7.4501e-03, -9.7937e-03, -6.3666e-02,  4.5607e-02, -3.1805e-02,\n",
      "         3.6856e-02,  3.9972e-02, -4.2071e-02, -4.5021e-03, -3.1917e-02,\n",
      "         2.2301e-02,  2.9831e-02, -2.4223e-02,  4.2356e-02,  4.3691e-03,\n",
      "        -2.2190e-02,  2.5498e-02,  4.9704e-05,  4.6759e-02,  4.6778e-02,\n",
      "        -3.7739e-02, -1.9008e-02, -1.3249e-02, -5.3888e-03, -5.6318e-02,\n",
      "        -1.7213e-02,  2.5543e-02, -3.2097e-02,  5.9015e-02,  3.4878e-02,\n",
      "         4.6962e-02,  7.8576e-02, -9.5014e-03,  1.6976e-02, -9.1342e-02,\n",
      "        -1.4488e-02,  3.2907e-02,  7.1920e-02,  3.9064e-02,  8.3003e-03,\n",
      "         1.2628e-02, -3.6837e-02,  3.9729e-02,  3.3719e-02,  2.0454e-02,\n",
      "         2.8438e-02,  9.0228e-03, -1.4908e-02,  6.6780e-02,  1.2661e-02,\n",
      "         5.1994e-02, -1.4851e-02,  3.0051e-02,  3.6721e-02,  5.2340e-03,\n",
      "         3.0619e-03,  3.0778e-02, -9.4560e-03,  3.2280e-02, -1.1014e-02,\n",
      "         4.3687e-02, -6.7893e-02, -4.6850e-02,  9.7631e-03,  3.2313e-02,\n",
      "         2.8892e-02, -1.3917e-02, -3.4229e-02,  1.6975e-02, -1.3078e-02,\n",
      "        -3.7331e-02,  1.0147e-02, -4.0304e-02, -5.5163e-03, -3.6798e-02,\n",
      "         3.0228e-02,  1.9561e-02, -4.3691e-03, -3.7808e-02, -7.8656e-03,\n",
      "         9.1757e-02,  3.0811e-02, -1.4044e-02,  4.7375e-02,  4.7435e-02,\n",
      "        -4.1955e-02, -2.9351e-02,  1.0494e-02,  3.7287e-02, -2.3301e-02,\n",
      "        -2.1342e-02,  2.9134e-02, -1.6506e-02,  3.6097e-02,  3.2266e-02,\n",
      "         2.9259e-02, -4.7643e-02, -5.4631e-03, -1.9915e-02, -8.0284e-02,\n",
      "         4.2786e-02,  3.2800e-02, -5.5490e-03,  2.5245e-02,  1.3271e-02,\n",
      "        -2.0215e-02,  2.7012e-02,  5.7934e-02,  1.6542e-02, -1.8728e-02,\n",
      "        -2.2956e-02, -3.0397e-02, -4.5016e-03,  5.1769e-02, -3.7549e-02,\n",
      "         6.8749e-03,  4.1289e-03,  3.3011e-02, -5.8532e-02,  5.0159e-02,\n",
      "         3.2656e-02,  2.1113e-03, -8.2517e-03,  2.4149e-02,  3.8592e-02,\n",
      "        -4.5529e-02, -3.7461e-02,  5.1672e-02,  1.5865e-02,  2.1098e-02,\n",
      "         9.4689e-03,  2.8948e-02, -3.2434e-02,  1.9499e-02, -1.7465e-02,\n",
      "         6.4700e-02,  6.2926e-02, -5.3374e-02,  6.8129e-03,  5.6141e-02,\n",
      "         1.6101e-02, -3.6139e-02,  2.8665e-02,  3.5079e-02, -7.9447e-03,\n",
      "        -1.3293e-02,  7.3510e-03, -1.2716e-02,  6.3565e-02, -1.6406e-02,\n",
      "        -5.9021e-02,  7.5282e-03, -1.8560e-02,  8.6926e-02, -9.3193e-03,\n",
      "        -3.4289e-02, -2.4119e-02, -4.7480e-02,  4.7163e-03, -3.2394e-02,\n",
      "         1.8527e-02,  3.9744e-02,  3.7574e-02, -2.8846e-02,  7.7723e-02,\n",
      "         1.2077e-02, -1.2148e-02, -3.3115e-02,  3.1379e-02,  9.3003e-03,\n",
      "        -1.2808e-04, -3.7130e-02,  4.0527e-02, -3.4974e-02,  5.0961e-02])\n",
      "tensor([[-0.0680, -0.0349, -0.0519,  ...,  0.0206,  0.0345, -0.0268],\n",
      "        [ 0.0047, -0.0663, -0.0292,  ..., -0.0101, -0.0019,  0.0266],\n",
      "        [ 0.0143,  0.0309, -0.0437,  ...,  0.0046,  0.0637,  0.0335],\n",
      "        ...,\n",
      "        [ 0.0597, -0.0180,  0.0300,  ..., -0.0700,  0.0120, -0.0122],\n",
      "        [-0.0315, -0.0946,  0.0342,  ...,  0.0589, -0.0048, -0.0078],\n",
      "        [ 0.0026, -0.0551,  0.0204,  ..., -0.0432, -0.0185, -0.0374]])\n",
      "tensor([-0.1055, -0.0142, -0.0393,  0.0444, -0.0327, -0.0736,  0.0404,  0.0006,\n",
      "        -0.0120, -0.0433,  0.0433, -0.0873,  0.0098, -0.0172,  0.0238,  0.0351,\n",
      "        -0.0554,  0.0007,  0.0221, -0.0263,  0.0825,  0.0188, -0.0299, -0.0494,\n",
      "        -0.0481, -0.0058, -0.0290, -0.0067, -0.0858,  0.0847, -0.0294,  0.0431,\n",
      "         0.0653, -0.0078,  0.0702,  0.0192, -0.0056,  0.0226, -0.0197,  0.0203,\n",
      "        -0.0706,  0.0192,  0.0412, -0.0388,  0.0244,  0.0077, -0.0041,  0.0260,\n",
      "         0.0444, -0.0028, -0.0072,  0.0027, -0.0439, -0.0287,  0.0158, -0.0058,\n",
      "         0.0410,  0.0288,  0.0214, -0.0343, -0.0290, -0.0196,  0.0147, -0.0677,\n",
      "        -0.0884, -0.0366,  0.0171, -0.0307,  0.0060, -0.0103, -0.0016, -0.0442,\n",
      "        -0.0925, -0.0045,  0.0720, -0.0186, -0.0189, -0.0284, -0.0600,  0.0052,\n",
      "        -0.0461,  0.0585, -0.0529,  0.0008,  0.0269, -0.0658, -0.0359,  0.0241,\n",
      "         0.0103, -0.0448, -0.0299, -0.0399,  0.0312,  0.0670, -0.0133, -0.0372,\n",
      "         0.0604,  0.0157,  0.0628,  0.0110, -0.0048, -0.0053, -0.0391, -0.0380,\n",
      "        -0.0891,  0.0016, -0.0404,  0.0066,  0.0463, -0.0500, -0.0026,  0.0100,\n",
      "        -0.0095, -0.0106, -0.0084, -0.0128,  0.0305, -0.0434,  0.0403,  0.0264,\n",
      "         0.0672,  0.0486,  0.0070, -0.0218,  0.0331,  0.0556, -0.0398, -0.0167,\n",
      "         0.0311, -0.0303, -0.0097, -0.0624, -0.0065,  0.0167,  0.0568, -0.0315,\n",
      "        -0.0321, -0.1150,  0.0399, -0.0150,  0.0113, -0.0092, -0.0132, -0.0478,\n",
      "        -0.1763,  0.0009,  0.0977,  0.0017,  0.0432, -0.0249, -0.0431, -0.0084,\n",
      "        -0.0065,  0.0039,  0.0545, -0.0258,  0.0111,  0.0406,  0.0111, -0.0100,\n",
      "         0.0041, -0.0345, -0.0063, -0.1012, -0.0153, -0.0805, -0.0614,  0.0287,\n",
      "        -0.0741, -0.0514,  0.0869,  0.0093,  0.0411,  0.0040, -0.0192, -0.0256,\n",
      "         0.0723,  0.0023,  0.0191, -0.0661,  0.0339, -0.0070, -0.0060,  0.0082,\n",
      "         0.0317,  0.0561, -0.0061,  0.0309, -0.0371, -0.0516, -0.0030, -0.0294,\n",
      "        -0.0451, -0.0686, -0.0615, -0.1006,  0.0965, -0.0179,  0.0126,  0.0063,\n",
      "         0.0412, -0.0626, -0.0437, -0.0226, -0.0665,  0.0180, -0.0498,  0.0086,\n",
      "         0.0561,  0.0168, -0.0678,  0.0538,  0.0212,  0.0275,  0.0150, -0.0136,\n",
      "         0.0471,  0.0281, -0.0290,  0.0136,  0.0512,  0.0289, -0.0465, -0.0798,\n",
      "        -0.0129,  0.0411, -0.0499,  0.0238,  0.0515, -0.0375,  0.0591, -0.0040,\n",
      "        -0.0931,  0.0242, -0.0879,  0.0112,  0.0210, -0.0221, -0.0094, -0.0397,\n",
      "        -0.0430, -0.0786, -0.0291, -0.0040, -0.0663,  0.0125, -0.0236, -0.0347,\n",
      "        -0.0112, -0.0275,  0.0040, -0.0528, -0.0341, -0.0186, -0.0188,  0.0525,\n",
      "        -0.0095, -0.0579,  0.0095,  0.0653,  0.0087, -0.0051,  0.0278,  0.0508,\n",
      "        -0.0061,  0.0438, -0.0568,  0.0160, -0.0082, -0.0027,  0.0080,  0.0138,\n",
      "         0.0377, -0.0665, -0.0346, -0.0241,  0.0690,  0.0299, -0.0091, -0.0560,\n",
      "         0.0597,  0.0254,  0.0548, -0.0487, -0.0418, -0.0264, -0.0036, -0.0265,\n",
      "        -0.0823, -0.1047, -0.0287,  0.0706, -0.1070, -0.1340, -0.0259,  0.0291,\n",
      "        -0.0178,  0.0379, -0.0066, -0.0564, -0.0215, -0.0454, -0.0660, -0.0810,\n",
      "        -0.0612, -0.0351,  0.0312, -0.0427,  0.0196,  0.0258, -0.0330, -0.0069,\n",
      "        -0.0731, -0.0620,  0.0282, -0.0913, -0.0217, -0.0255, -0.0352,  0.0288,\n",
      "        -0.0027, -0.0114, -0.0426,  0.0135, -0.0418, -0.0348, -0.0058,  0.0331,\n",
      "         0.0378,  0.0609,  0.0622, -0.0040,  0.0065, -0.0312, -0.0251, -0.0017,\n",
      "        -0.0376,  0.0140, -0.0206,  0.0005, -0.0452,  0.0248, -0.0772, -0.0353,\n",
      "        -0.0640, -0.0321, -0.0169,  0.0729, -0.0877, -0.0501])\n",
      "tensor([1.1148, 1.0141, 1.0548, 1.0368, 1.0481, 1.0464, 1.0362, 1.0098, 1.0570,\n",
      "        1.0138, 1.0650, 1.0548, 1.0176, 1.0360, 0.9849, 1.0148, 1.0273, 1.0450,\n",
      "        0.9993, 0.9943, 1.0344, 1.0194, 1.0069, 1.0280, 1.0707, 1.0314, 0.9807,\n",
      "        1.0301, 1.0656, 1.0639, 1.0158, 1.0774, 0.9911, 1.0202, 1.0284, 1.0395,\n",
      "        1.0048, 1.0222, 0.9598, 1.0272, 1.0131, 1.0464, 1.0313, 1.0447, 1.0433,\n",
      "        1.0491, 1.0265, 1.0357, 1.0277, 1.0640, 1.1031, 1.0382, 1.0608, 1.0049,\n",
      "        1.0169, 1.0651, 1.0599, 1.0296, 1.0190, 1.0565, 1.0975, 1.0964, 1.0636,\n",
      "        1.0858, 1.1103, 1.0148, 1.1150, 1.0316, 1.0196, 1.0764, 1.0368, 1.0305,\n",
      "        1.0579, 1.0245, 1.0122, 1.0240, 1.0243, 1.0361, 1.0408, 1.0258, 1.0534,\n",
      "        1.0300, 1.0150, 1.0148, 1.1104, 1.0179, 1.0375, 1.1150, 1.0061, 1.0883,\n",
      "        1.0451, 1.0324, 1.0150, 1.0291, 1.0310, 0.9939, 1.0330, 1.0334, 1.0532,\n",
      "        1.0646, 1.0297, 1.0111, 1.0311, 1.1973, 1.0490, 1.0353, 1.0394, 1.0500,\n",
      "        1.0635, 1.0529, 1.0230, 1.0270, 0.9999, 1.0281, 1.0255, 1.0577, 0.9895,\n",
      "        1.0642, 1.0232, 1.0373, 1.0520, 1.0139, 1.0136, 1.0102, 1.0114, 1.0849,\n",
      "        1.0295, 1.0333, 1.0479, 1.0028, 1.0530, 1.0175, 1.0257, 1.0313, 1.0125,\n",
      "        1.0514, 1.0123, 1.0544, 1.0061, 1.0032, 1.0078, 1.0259, 1.0279, 1.0048,\n",
      "        1.1384, 1.0247, 1.1074, 1.0146, 1.0376, 1.0450, 1.0196, 1.0425, 1.0546,\n",
      "        1.0394, 1.0445, 1.0280, 1.0564, 1.0031, 1.0220, 1.0195, 1.0217, 1.0132,\n",
      "        1.0571, 1.0498, 1.0699, 1.0769, 1.0432, 1.0593, 0.9973, 1.0127, 1.0188,\n",
      "        1.0346, 1.0429, 1.0588, 1.0302, 1.0309, 1.0700, 1.0541, 1.0049, 1.1042,\n",
      "        1.0160, 1.0060, 1.0411, 0.9783, 1.0621, 0.9909, 1.0407, 1.0125, 1.1026,\n",
      "        1.0127, 1.0452, 1.0576, 1.0514, 1.0759, 1.1319, 1.0630, 1.0454, 0.9996,\n",
      "        1.0311, 1.0308, 1.0389, 1.0083, 1.0693, 1.0669, 1.0640, 1.0365, 1.1174,\n",
      "        1.0213, 1.0392, 1.0146, 1.0710, 1.0647, 1.0396, 1.0135, 1.0627, 1.0278,\n",
      "        1.0304, 1.0123, 1.0725, 1.0405, 1.0650, 1.0202, 1.0154, 1.0154, 1.0354,\n",
      "        1.0536, 1.0213, 1.0656, 1.0390, 1.0398, 1.0160, 0.9966, 1.0843, 1.0373,\n",
      "        1.0001, 1.0423, 1.0084, 1.0398, 1.0356, 1.0320, 1.0907, 1.0578, 1.0450,\n",
      "        1.0264, 1.0476, 1.0479, 1.0325, 1.0899, 1.0582, 1.0416, 1.0448, 1.0274,\n",
      "        1.0658, 0.9916, 1.0130, 1.0361, 1.0178, 1.0288, 1.0943, 1.0254, 1.0932,\n",
      "        1.0225, 0.9969, 1.0483, 1.0138, 1.0475, 1.0560, 1.0308, 1.0149, 1.0659,\n",
      "        1.0496, 1.0327, 1.0585, 1.0088, 1.0533, 1.0587, 1.0017, 1.0372, 1.0104,\n",
      "        1.0476, 1.0089, 1.0262, 1.0588, 1.0031, 1.0393, 1.0153, 1.0527, 1.0350,\n",
      "        1.0230, 1.1048, 1.0438, 1.0562, 1.0787, 1.0798, 1.0069, 1.0465, 1.0197,\n",
      "        1.0574, 1.0887, 1.0507, 1.0307, 1.0410, 1.0302, 1.0299, 1.0315, 1.0135,\n",
      "        1.0214, 1.0707, 1.0321, 1.0357, 1.0057, 1.0579, 1.0603, 1.0529, 1.0457,\n",
      "        1.0758, 1.0392, 1.0133, 1.0939, 1.0209, 0.9829, 1.0161, 1.0406, 1.0188,\n",
      "        1.0195, 1.0696, 1.0549, 1.0186, 1.0516, 1.0240, 1.0055, 1.0768, 1.0526,\n",
      "        1.0950, 1.0771, 1.0412, 1.0531, 1.0068, 1.0706, 1.0415, 1.0456, 1.0440,\n",
      "        1.0662, 1.0423, 1.0919, 1.0246, 1.0229, 1.0328, 1.0970, 1.0104])\n",
      "tensor([-0.0502,  0.1835, -0.1844, -0.0763,  0.0981, -0.0632,  0.1781,  0.1799,\n",
      "        -0.1615, -0.0070,  0.0180, -0.1221,  0.0532, -0.0642,  0.1442, -0.0105,\n",
      "        -0.0110, -0.1797,  0.0989,  0.0290,  0.0524, -0.1219, -0.0814, -0.0964,\n",
      "         0.0850,  0.1046,  0.0888,  0.0730,  0.2475,  0.0987, -0.0807,  0.0227,\n",
      "         0.2099,  0.1751,  0.1787, -0.0726,  0.2360, -0.1719, -0.0662,  0.0993,\n",
      "        -0.1662,  0.1792,  0.0687, -0.0914,  0.2015,  0.1067, -0.1048,  0.2747,\n",
      "         0.0885, -0.2359, -0.1621,  0.0642, -0.0750,  0.0571,  0.1149, -0.1690,\n",
      "         0.1581,  0.0500,  0.1722, -0.1559,  0.1978,  0.1538,  0.2045, -0.2411,\n",
      "         0.1083,  0.1640, -0.1631, -0.0725,  0.1616,  0.0133, -0.0311, -0.2404,\n",
      "         0.0999, -0.1359, -0.1695, -0.1385, -0.0917,  0.1369,  0.0765,  0.1796,\n",
      "         0.1789,  0.1468, -0.2053,  0.0925, -0.0215,  0.1086,  0.2229,  0.0214,\n",
      "        -0.1603,  0.2229,  0.1009, -0.1305, -0.0197, -0.1939, -0.0919, -0.1292,\n",
      "         0.0940,  0.1249, -0.0296,  0.1658,  0.1623,  0.0304,  0.1712, -0.1425,\n",
      "         0.2158,  0.1802,  0.2118,  0.2391, -0.1955,  0.1230,  0.0807,  0.0138,\n",
      "        -0.0447, -0.1215,  0.0992, -0.1799, -0.1511, -0.0713,  0.1787,  0.2354,\n",
      "        -0.0908, -0.0950, -0.0093,  0.1304, -0.1023, -0.1671,  0.1482,  0.2177,\n",
      "        -0.0456, -0.1250,  0.0822, -0.0919,  0.1335,  0.2406, -0.1098, -0.0949,\n",
      "        -0.2020, -0.1000,  0.1127, -0.0588, -0.1748,  0.1471, -0.1005, -0.1136,\n",
      "         0.0628,  0.0628,  0.1542, -0.1733, -0.0977,  0.2574, -0.1552, -0.1288,\n",
      "         0.1105,  0.0325,  0.2301, -0.1985,  0.0388,  0.1362, -0.0735, -0.1593,\n",
      "        -0.1916,  0.1985, -0.1225, -0.1455, -0.1777,  0.2084, -0.0750, -0.2712,\n",
      "        -0.0989, -0.0199, -0.1780,  0.0529,  0.1424,  0.0915, -0.1351, -0.0340,\n",
      "         0.2285, -0.1627,  0.2559,  0.1475, -0.0866, -0.0639,  0.1266, -0.0215,\n",
      "        -0.1581, -0.0855, -0.1540, -0.1085,  0.2112,  0.1174, -0.0925,  0.0609,\n",
      "         0.2068, -0.2392, -0.0464, -0.1811, -0.0253, -0.0691,  0.1281, -0.0803,\n",
      "         0.0856, -0.0878,  0.1700, -0.1894,  0.1141,  0.2125, -0.1014,  0.1147,\n",
      "         0.0724, -0.1748,  0.1498, -0.2617, -0.0550, -0.0813, -0.1159, -0.1020,\n",
      "         0.0562, -0.1539,  0.1956,  0.1433, -0.1581,  0.0814,  0.0280, -0.1372,\n",
      "         0.1417, -0.1184,  0.0162,  0.1014, -0.0249,  0.1090,  0.1286,  0.1625,\n",
      "         0.0682, -0.1908,  0.1283, -0.1346,  0.0377,  0.1623,  0.2513, -0.1629,\n",
      "        -0.0419,  0.1360, -0.2449, -0.1193, -0.1957, -0.2435, -0.1803, -0.1047,\n",
      "        -0.1436, -0.1185, -0.2189, -0.0587, -0.1312, -0.1207, -0.2030,  0.0891,\n",
      "        -0.1623, -0.0724, -0.1750,  0.2263, -0.0869, -0.0677,  0.0577, -0.2483,\n",
      "         0.1628,  0.1870,  0.2058, -0.1071, -0.1557,  0.2590,  0.2499,  0.1801,\n",
      "        -0.1378,  0.1214, -0.2091, -0.1011, -0.1090, -0.1650, -0.0997,  0.2204,\n",
      "        -0.1191,  0.1421,  0.2736, -0.1255, -0.1790,  0.0421, -0.2486, -0.0122,\n",
      "         0.0617,  0.0741, -0.2152, -0.1700,  0.1184, -0.1648, -0.0906,  0.0261,\n",
      "        -0.0988, -0.0908,  0.0077,  0.1079, -0.1607, -0.1200, -0.0441, -0.1713,\n",
      "         0.0992,  0.1517, -0.0167,  0.1583,  0.0858,  0.1436, -0.0345,  0.1662,\n",
      "        -0.1596,  0.0313,  0.1974, -0.1423, -0.1691, -0.1880,  0.1543,  0.1643,\n",
      "         0.1695, -0.2335,  0.1707,  0.1607, -0.1587, -0.0932,  0.1273,  0.0040,\n",
      "        -0.0253, -0.0389, -0.0725,  0.1756, -0.0616, -0.1428, -0.0922, -0.1161,\n",
      "        -0.0915, -0.1616, -0.1734, -0.2097,  0.0257,  0.1436, -0.0120,  0.1366,\n",
      "         0.1910,  0.0631, -0.2381,  0.1449,  0.1477,  0.2067])\n",
      "tensor([[-0.0038,  0.0329, -0.0995,  ...,  0.0798, -0.0322, -0.0546],\n",
      "        [-0.0104,  0.0485,  0.0151,  ..., -0.0214,  0.0907, -0.0470],\n",
      "        [ 0.0438, -0.0056,  0.0693,  ..., -0.0544, -0.0832,  0.0021],\n",
      "        ...,\n",
      "        [-0.0098, -0.0338,  0.0007,  ...,  0.0295, -0.0061,  0.0332],\n",
      "        [-0.1034, -0.1140, -0.0630,  ..., -0.1009,  0.1711, -0.0071],\n",
      "        [ 0.1734,  0.0847,  0.0628,  ...,  0.0281, -0.1722,  0.0327]])\n",
      "tensor([ 0.0382,  0.0118, -0.1258,  0.1912, -0.1298,  0.0823, -0.0080, -0.1503,\n",
      "        -0.1260, -0.2725,  0.2707,  0.0453, -0.0321,  0.0530, -0.0065,  0.0183,\n",
      "         0.0470,  0.0210,  0.0005])\n"
     ]
    }
   ],
   "source": [
    "for p in net.model.parameters():\n",
    "    print(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c8d5cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1953,  0.1680, -0.0635,  ...,  0.1309,  0.0337, -0.1151],\n",
      "        [ 0.0867, -0.1051, -0.0316,  ...,  0.1187,  0.0668,  0.1751],\n",
      "        [ 0.0473, -0.1043,  0.0623,  ...,  0.0617,  0.0875,  0.0812],\n",
      "        ...,\n",
      "        [-0.1474,  0.2562, -0.1020,  ...,  0.1505,  0.1124,  0.0671],\n",
      "        [-0.0777,  0.1288,  0.0823,  ...,  0.0869,  0.1883, -0.0504],\n",
      "        [ 0.0840,  0.1529,  0.0006,  ...,  0.0037, -0.1448, -0.0819]])\n",
      "tensor([-0.0420,  0.0951,  0.0312, -0.0081,  0.0587, -0.1466,  0.2107,  0.1487,\n",
      "         0.1520, -0.1944,  0.2045,  0.0413, -0.2018,  0.2153, -0.0358,  0.0860,\n",
      "         0.1789,  0.1633,  0.2059, -0.2002,  0.2350,  0.0600,  0.0048, -0.1823,\n",
      "        -0.1383,  0.2303,  0.1632,  0.1677, -0.0273, -0.1063,  0.0492, -0.0949,\n",
      "        -0.1412,  0.0960,  0.2115, -0.1593, -0.2120,  0.0359, -0.0733, -0.1013,\n",
      "        -0.0405,  0.0021, -0.0675,  0.1887,  0.0983,  0.0666, -0.0523, -0.0020,\n",
      "         0.1542,  0.0323, -0.2225,  0.0058,  0.0914, -0.0639, -0.0398, -0.0056,\n",
      "         0.1752,  0.1858, -0.1554,  0.1764,  0.1144,  0.0876, -0.0972, -0.1501,\n",
      "         0.2246,  0.0807, -0.0747, -0.0354,  0.1914, -0.0531,  0.1662, -0.0600,\n",
      "         0.0779,  0.0240, -0.1035,  0.0095,  0.0736, -0.2000, -0.0374,  0.0016,\n",
      "         0.2160,  0.0627, -0.1768, -0.0429,  0.2389, -0.0291,  0.1740,  0.0294,\n",
      "         0.1521, -0.1208,  0.2155,  0.0587, -0.0382,  0.1923,  0.1369, -0.1661,\n",
      "        -0.0383,  0.1908,  0.0487, -0.0722, -0.1540, -0.1394,  0.1258,  0.0887,\n",
      "        -0.2133, -0.0617,  0.0390, -0.1926,  0.1767, -0.0184, -0.1178,  0.0142,\n",
      "         0.0668,  0.0635,  0.2471,  0.1226, -0.0080,  0.0483,  0.0743, -0.0576,\n",
      "        -0.2042, -0.0077, -0.0815, -0.2545,  0.0935, -0.1144,  0.1985,  0.1057,\n",
      "         0.0985,  0.0948,  0.1168,  0.1817,  0.1892, -0.0115, -0.0900,  0.0812,\n",
      "        -0.0763,  0.0173,  0.0227,  0.1199, -0.2372,  0.1071, -0.0741, -0.1400,\n",
      "        -0.0908,  0.0041,  0.1035, -0.1785,  0.0705,  0.2223, -0.1057,  0.0658,\n",
      "        -0.0599,  0.0539,  0.1126, -0.1399,  0.0630,  0.2510,  0.0171, -0.1483,\n",
      "         0.0133,  0.0837,  0.0842, -0.0138, -0.0706, -0.0942,  0.1554, -0.1260,\n",
      "        -0.0869,  0.1748, -0.0714, -0.0172, -0.0855, -0.2041,  0.1035, -0.1029,\n",
      "        -0.0657, -0.0483,  0.0300,  0.2015,  0.2305,  0.0392, -0.1829, -0.0027,\n",
      "        -0.0087,  0.2097, -0.0060, -0.2116,  0.0826, -0.0370,  0.0819,  0.0447,\n",
      "         0.0854,  0.1396, -0.1457, -0.2050,  0.2179,  0.2240, -0.0849,  0.2222,\n",
      "         0.0769, -0.0500, -0.0975, -0.1374,  0.2060, -0.1493, -0.0998,  0.2307,\n",
      "        -0.1120,  0.2623,  0.0647,  0.1365,  0.0568, -0.0112,  0.0854,  0.0873,\n",
      "        -0.1450, -0.1785, -0.1525, -0.0049,  0.0812, -0.1227,  0.0298,  0.1519,\n",
      "         0.1340, -0.0955,  0.0767, -0.1878,  0.1554, -0.2018,  0.0120, -0.0688,\n",
      "        -0.2146, -0.2159, -0.1413, -0.1513,  0.1841, -0.0091, -0.1306,  0.0117,\n",
      "        -0.0905, -0.0299,  0.1972, -0.1873, -0.1885,  0.0476,  0.1555, -0.2267,\n",
      "         0.1065,  0.2575, -0.0319, -0.1194,  0.1209,  0.1444, -0.0176, -0.1857,\n",
      "         0.0285, -0.1385, -0.1897,  0.1472,  0.1508,  0.1102, -0.1667,  0.2024,\n",
      "         0.1495,  0.1775, -0.0183, -0.0266, -0.1959,  0.1660,  0.0427, -0.2218,\n",
      "         0.2647, -0.0276,  0.1316, -0.0358, -0.0556,  0.1974,  0.1943, -0.0783,\n",
      "         0.0486,  0.1609, -0.0061, -0.0325,  0.2107,  0.2260, -0.0718,  0.1607,\n",
      "        -0.0186,  0.0005,  0.1658, -0.0142, -0.0119, -0.0325, -0.1750,  0.1724,\n",
      "        -0.1811, -0.1445,  0.0497, -0.0234, -0.0048,  0.0098,  0.2449, -0.1720,\n",
      "        -0.1738,  0.0535, -0.2071, -0.1699,  0.1711,  0.0805, -0.0405,  0.0264,\n",
      "         0.0411,  0.0076,  0.2176,  0.0218,  0.1697, -0.1927, -0.0611,  0.0660,\n",
      "         0.1005, -0.0769,  0.2028, -0.1890, -0.1019,  0.1857, -0.1811, -0.2128,\n",
      "        -0.0502, -0.1674,  0.0790, -0.0419, -0.0695,  0.1500,  0.0051, -0.2067,\n",
      "        -0.2143,  0.1683,  0.1079,  0.0974, -0.1670, -0.0572,  0.2179,  0.2138,\n",
      "         0.1447,  0.2220, -0.0732, -0.1904,  0.1612,  0.1183])\n",
      "tensor([0.9876, 0.9732, 0.9717, 0.9571, 0.9969, 0.8806, 0.9383, 0.9872, 0.9477,\n",
      "        0.9999, 0.9958, 1.0090, 1.0272, 0.9836, 0.9664, 1.0089, 1.0163, 0.9851,\n",
      "        1.0318, 0.9381, 0.9890, 0.9987, 0.9585, 0.9903, 0.9450, 1.0055, 0.9883,\n",
      "        1.0069, 0.9798, 0.9367, 1.0301, 0.8865, 0.9855, 0.9663, 1.0016, 1.0088,\n",
      "        0.9436, 1.0309, 0.9903, 1.0137, 0.9859, 0.9917, 0.9678, 1.0066, 1.0132,\n",
      "        0.9745, 1.0426, 1.0319, 0.9452, 0.9263, 0.9539, 0.9884, 1.1107, 0.9634,\n",
      "        0.9438, 0.9904, 0.9994, 0.9958, 0.9554, 1.0168, 0.9822, 0.9986, 0.9905,\n",
      "        0.9490, 1.0077, 0.9666, 1.0173, 1.0055, 1.0086, 0.9943, 1.0355, 0.9284,\n",
      "        0.9905, 1.0190, 0.9525, 1.0012, 1.0274, 1.0323, 1.0351, 0.9576, 0.9871,\n",
      "        0.9554, 0.9525, 1.0019, 0.9971, 0.9638, 1.0101, 1.0171, 0.9996, 1.0180,\n",
      "        0.9854, 1.0099, 1.0209, 1.0005, 0.9331, 0.9726, 0.9744, 0.9592, 1.0168,\n",
      "        1.0218, 0.9647, 0.9997, 1.0280, 1.0161, 0.9868, 1.0282, 0.9760, 1.0335,\n",
      "        1.0120, 1.0005, 1.0416, 1.0144, 0.9715, 0.9642, 1.0234, 0.9686, 0.9775,\n",
      "        0.9882, 0.9016, 0.9810, 0.9528, 1.0044, 0.9909, 0.9800, 1.0269, 0.9687,\n",
      "        1.0287, 1.0331, 0.9892, 0.9905, 0.9840, 1.0151, 0.9665, 0.9681, 0.9741,\n",
      "        1.0685, 1.0326, 1.0224, 1.0117, 0.9803, 1.0398, 0.9917, 0.9640, 0.9844,\n",
      "        0.9658, 0.9616, 0.9712, 0.9383, 0.9605, 0.9733, 0.9847, 0.9394, 0.9815,\n",
      "        0.9873, 0.9633, 1.0141, 0.9572, 0.9889, 0.9757, 0.9768, 0.9471, 1.0227,\n",
      "        0.9793, 1.0163, 0.9610, 1.0159, 0.9665, 0.9939, 0.9979, 0.9825, 0.9825,\n",
      "        1.0311, 0.9825, 0.9387, 0.9971, 1.0116, 0.9784, 0.9990, 1.0233, 0.9883,\n",
      "        0.9847, 1.0040, 1.0182, 1.0052, 1.0286, 0.9638, 0.9834, 0.9327, 1.0020,\n",
      "        0.9888, 1.0293, 1.0108, 1.0154, 0.9932, 0.9569, 0.9970, 1.0317, 0.9356,\n",
      "        0.9586, 0.9773, 1.0184, 1.0135, 0.9889, 0.9646, 0.9962, 0.9580, 0.9724,\n",
      "        1.0467, 1.0254, 1.0492, 0.9878, 0.9785, 0.9797, 1.0324, 0.9661, 1.0153,\n",
      "        1.1279, 1.0275, 0.9710, 1.0122, 1.0071, 0.9557, 1.0304, 0.9727, 0.9929,\n",
      "        0.9788, 0.9790, 0.9538, 1.0066, 0.9330, 0.9869, 1.0231, 0.9023, 1.0602,\n",
      "        0.9983, 0.9848, 0.9980, 0.9792, 1.0043, 1.0105, 1.0139, 1.0067, 0.9718,\n",
      "        0.9786, 1.0083, 1.0180, 0.9944, 1.0019, 0.9856, 0.9976, 1.0322, 1.0159,\n",
      "        1.0089, 0.9851, 0.9921, 1.0216, 0.9849, 1.0107, 0.9207, 0.9506, 0.9598,\n",
      "        0.9959, 1.0032, 1.0031, 0.9599, 1.0341, 1.0138, 1.0077, 1.0555, 0.9791,\n",
      "        0.9861, 0.9860, 1.0536, 0.9600, 0.9666, 0.9889, 0.9602, 1.0032, 0.9970,\n",
      "        0.9496, 1.0005, 0.9759, 0.9785, 1.0330, 0.9781, 0.9771, 0.9923, 0.9996,\n",
      "        1.0021, 1.0380, 0.9738, 0.9838, 0.9986, 0.9733, 1.0243, 0.9883, 0.9801,\n",
      "        1.0121, 0.9954, 0.9608, 1.0066, 0.9687, 1.0039, 0.9619, 0.9652, 0.9475,\n",
      "        1.0092, 0.9501, 0.9932, 0.9762, 1.0101, 0.9583, 1.0459, 0.9962, 1.0045,\n",
      "        0.9610, 1.0021, 0.9717, 0.9444, 0.9808, 0.9838, 1.0179, 0.9713, 0.9820,\n",
      "        0.9592, 0.9755, 1.0178, 0.9685, 0.9045, 0.9556, 0.9841, 1.0322, 1.0321,\n",
      "        1.0045, 0.9795, 1.0122, 0.9814, 0.9705, 1.0038, 0.9853, 0.9874, 0.9861,\n",
      "        1.0022, 1.0543, 1.0052, 0.9722, 1.0072, 0.9843, 1.0134, 1.0498])\n",
      "tensor([-1.9262e-02,  6.8808e-02, -2.7709e-02, -7.9781e-03,  5.2086e-04,\n",
      "        -2.9641e-02,  1.2010e-02,  6.0496e-02,  9.3870e-03, -2.3443e-02,\n",
      "        -2.9899e-03,  9.0187e-03, -7.2212e-03,  2.9913e-02, -4.5215e-02,\n",
      "        -7.9863e-03, -2.5696e-02,  1.2925e-02,  2.7612e-02,  5.9847e-02,\n",
      "         5.9145e-02, -5.9123e-02, -3.0768e-02, -4.0015e-02, -3.8799e-02,\n",
      "         1.8588e-02, -7.5539e-03,  1.1407e-02, -7.9261e-02,  4.2057e-02,\n",
      "        -3.1660e-02,  7.5483e-04, -7.2974e-03,  6.6604e-02,  4.0746e-02,\n",
      "         5.8240e-03, -4.4103e-04,  5.7515e-02, -1.5165e-03, -3.2856e-03,\n",
      "        -2.1731e-02, -3.7585e-02, -1.2027e-02,  8.2008e-03, -2.8148e-02,\n",
      "        -6.8415e-02,  4.9045e-02, -5.1184e-03, -9.7163e-03, -3.9261e-02,\n",
      "         5.4607e-02, -3.0264e-02,  6.2059e-02, -4.5310e-02, -1.0581e-02,\n",
      "         5.4883e-02,  7.2326e-02,  6.4441e-03, -1.6695e-03, -1.3685e-02,\n",
      "         2.9680e-02,  4.5392e-02, -7.7423e-03,  1.5334e-02, -1.2557e-02,\n",
      "        -1.9720e-02, -6.5372e-02,  2.2941e-02,  4.6141e-02,  4.5977e-02,\n",
      "        -2.0632e-02,  2.4224e-03,  2.5363e-02,  1.8250e-02,  8.8735e-03,\n",
      "        -1.9366e-02,  3.0012e-02, -8.5280e-03,  2.8335e-02, -5.7338e-02,\n",
      "        -2.1394e-02, -5.4109e-03,  2.8922e-02,  2.3728e-02,  7.0688e-02,\n",
      "         2.2296e-02,  1.4364e-03, -3.7522e-02, -2.4035e-02,  2.5778e-02,\n",
      "        -4.2108e-02, -4.6456e-02,  1.2510e-02,  6.2311e-04,  3.5344e-03,\n",
      "         2.7247e-03, -5.3089e-03,  2.2763e-02,  5.1632e-02, -1.7072e-02,\n",
      "        -4.5645e-03, -5.1766e-02, -1.6763e-03,  7.8325e-03,  4.9228e-02,\n",
      "        -1.6008e-02,  1.8120e-02, -8.1276e-03,  1.6122e-02, -1.6607e-02,\n",
      "        -2.0517e-02,  1.3496e-02, -4.8073e-02, -5.6107e-02, -1.9892e-02,\n",
      "         6.2271e-02,  2.3159e-02, -3.6944e-02, -8.4918e-03,  2.2747e-02,\n",
      "         3.9289e-02, -3.4095e-02,  2.9631e-02,  4.2823e-02,  4.0381e-02,\n",
      "         1.6333e-02,  1.6300e-02,  1.3065e-02,  1.5338e-05,  3.2305e-02,\n",
      "         3.3070e-02,  5.6642e-03,  1.7595e-02, -2.7387e-02,  1.0444e-02,\n",
      "         2.5394e-02,  6.8261e-02,  5.8893e-02, -4.9872e-02, -1.5014e-02,\n",
      "        -1.4407e-02, -3.7862e-02,  7.1918e-03,  2.7607e-02, -6.7100e-03,\n",
      "         1.5155e-03, -2.5426e-02,  4.9831e-02, -2.0772e-02,  4.7268e-02,\n",
      "        -6.7425e-03, -3.7260e-02,  3.1881e-03, -4.7137e-02, -6.2286e-02,\n",
      "        -2.1851e-02, -6.3547e-02,  5.3632e-03,  5.4303e-02, -2.8698e-02,\n",
      "        -5.7086e-02,  4.1721e-02,  6.2883e-02,  3.5069e-03, -5.2867e-02,\n",
      "         4.0767e-02, -4.3008e-03,  2.2340e-02, -3.4104e-02, -1.0424e-02,\n",
      "         1.3295e-02, -8.9642e-03, -4.4534e-02, -2.2958e-02, -5.6079e-03,\n",
      "         1.9897e-03,  7.5531e-02,  1.9228e-02, -8.9603e-03, -4.1270e-02,\n",
      "         1.4835e-03,  4.6044e-02,  4.3999e-02, -1.2212e-02, -2.3107e-02,\n",
      "         4.4801e-04,  4.0472e-02,  4.3104e-02,  6.6777e-03, -4.2531e-03,\n",
      "         1.6991e-02,  2.1619e-02,  3.4818e-02,  7.6285e-03,  4.7863e-03,\n",
      "        -1.5506e-03, -2.5538e-02,  2.8417e-03, -9.8136e-03, -5.9801e-03,\n",
      "         8.0864e-02,  3.1428e-02,  7.5658e-03,  2.7218e-02,  4.6474e-02,\n",
      "         3.2926e-02, -7.1620e-03,  2.7260e-02,  2.4225e-03,  8.3858e-02,\n",
      "        -3.3439e-02, -9.5333e-03, -2.1884e-02,  6.9214e-02,  1.4129e-02,\n",
      "         1.1217e-02,  4.2525e-02,  3.2221e-02, -7.3203e-03,  3.9458e-02,\n",
      "        -5.6014e-02, -2.3412e-02,  3.0586e-02,  1.2310e-02,  2.1869e-02,\n",
      "         1.4144e-02, -7.4028e-03,  1.9991e-02, -7.8582e-03,  6.1067e-02,\n",
      "        -7.4784e-02, -1.2307e-02,  2.0536e-02,  8.2082e-03,  6.3744e-02,\n",
      "        -3.1241e-02,  9.5708e-03,  4.7774e-02,  2.4200e-02,  4.1907e-02,\n",
      "        -1.0739e-02,  8.8580e-03, -1.1545e-02, -3.9819e-02,  4.2797e-02,\n",
      "         1.7787e-02, -8.8647e-03,  5.6656e-02,  2.8186e-02, -3.8903e-03,\n",
      "         2.5539e-02,  9.4593e-03,  4.0041e-02,  3.4093e-02, -5.8309e-03,\n",
      "         5.9342e-04, -2.4656e-03, -3.3458e-03, -5.2046e-02,  2.9881e-02,\n",
      "         3.7359e-02,  1.3456e-02,  8.4703e-04, -6.1181e-04,  4.1887e-02,\n",
      "        -5.4249e-04, -2.7966e-02,  3.7510e-02,  2.2977e-02,  5.8251e-02,\n",
      "         3.2375e-02,  9.7487e-03, -8.5164e-03,  2.6924e-02,  4.9820e-02,\n",
      "        -1.3774e-02, -1.5499e-02,  1.6504e-02, -1.8427e-02,  5.2729e-03,\n",
      "        -1.0275e-02, -5.3591e-02, -1.8835e-02,  8.2620e-02, -2.6378e-02,\n",
      "         4.1757e-02,  3.7953e-02, -2.0136e-02,  2.1273e-02, -5.5847e-03,\n",
      "         3.5576e-02, -4.5933e-03,  1.6068e-03,  7.6787e-03, -2.7052e-02,\n",
      "         9.7230e-03,  1.1144e-02, -1.0734e-02,  3.5131e-04,  3.3855e-02,\n",
      "        -5.8945e-02, -1.8785e-02, -3.8598e-03,  4.9779e-02, -2.4780e-02,\n",
      "        -1.3345e-02,  4.9903e-02, -4.5732e-02, -1.1392e-02,  2.5641e-02,\n",
      "         1.4635e-02,  2.0806e-02,  5.4765e-02, -5.3246e-02, -9.5838e-03,\n",
      "        -1.7550e-02,  4.4272e-02, -1.3776e-02,  8.6036e-03, -6.5184e-03,\n",
      "         4.2923e-02, -1.9712e-02,  4.4422e-02,  3.8219e-02, -6.1315e-03,\n",
      "         2.4058e-02,  2.3787e-02,  7.7424e-03, -1.0414e-02,  2.1284e-02,\n",
      "         2.5402e-02,  4.5648e-03,  7.3262e-03,  8.0529e-02,  4.3396e-03,\n",
      "         6.5539e-03,  3.7631e-02,  8.4009e-03, -4.8994e-02,  3.6077e-02,\n",
      "        -1.8451e-02, -3.1641e-02, -4.3811e-03,  2.7165e-02,  4.0062e-02,\n",
      "        -3.3648e-02,  3.3398e-02,  4.2256e-02,  7.1011e-04,  3.7615e-03])\n",
      "tensor([[ 4.5963e-05, -4.7313e-02,  7.9125e-03,  ..., -9.2213e-03,\n",
      "          1.9835e-02, -1.7928e-02],\n",
      "        [ 8.3867e-02, -5.5072e-02,  3.5573e-03,  ..., -1.7408e-02,\n",
      "          1.0537e-02, -7.5854e-02],\n",
      "        [ 5.3811e-02, -3.3852e-02,  2.5569e-02,  ..., -4.8031e-02,\n",
      "         -3.3776e-02,  5.0088e-04],\n",
      "        ...,\n",
      "        [-2.1221e-02,  1.2443e-02, -1.2909e-02,  ...,  8.8199e-03,\n",
      "          2.2996e-02,  1.7484e-02],\n",
      "        [ 9.5624e-03, -3.3259e-02, -5.0231e-02,  ...,  5.4299e-03,\n",
      "          1.5280e-02, -3.6116e-02],\n",
      "        [-6.6424e-03, -5.2713e-02,  4.1261e-02,  ..., -1.1734e-02,\n",
      "         -4.2039e-02, -2.2081e-02]])\n",
      "tensor([ 0.0347,  0.0051,  0.0095, -0.0613, -0.0357,  0.0105,  0.0558,  0.0516,\n",
      "        -0.0672,  0.0390,  0.0753, -0.0219,  0.0642, -0.0380, -0.0130, -0.0293,\n",
      "        -0.0111,  0.0084,  0.0216, -0.1348,  0.0702,  0.0642, -0.0356, -0.0238,\n",
      "         0.0159, -0.0588,  0.0169,  0.0559,  0.0066, -0.0361,  0.0125,  0.0777,\n",
      "        -0.0338, -0.0348,  0.0715, -0.0424,  0.0228,  0.0021, -0.0316,  0.0101,\n",
      "        -0.0504,  0.0497,  0.0408, -0.0326, -0.0774, -0.0157, -0.0209, -0.0683,\n",
      "         0.0394,  0.0198, -0.0669,  0.0210,  0.0219, -0.0103, -0.0269, -0.0158,\n",
      "         0.0443,  0.0436, -0.0870, -0.0329,  0.0184, -0.0381,  0.0431, -0.0308,\n",
      "         0.0525, -0.0458,  0.0003, -0.0304,  0.0855,  0.0427, -0.0133, -0.0588,\n",
      "         0.0564, -0.0172, -0.0126, -0.0234, -0.0274, -0.0195, -0.0215,  0.0219,\n",
      "         0.0293,  0.0440, -0.0358,  0.0239, -0.0181,  0.0361,  0.0215, -0.0282,\n",
      "        -0.0839,  0.0183, -0.0273,  0.0317,  0.0186, -0.0165,  0.0730, -0.0456,\n",
      "        -0.0149,  0.0167, -0.0494,  0.0617, -0.0428,  0.0837,  0.0480,  0.0170,\n",
      "        -0.0738, -0.0597, -0.0234,  0.0124,  0.0297,  0.0357,  0.0571, -0.0033,\n",
      "        -0.0206,  0.0211,  0.0249,  0.0055,  0.0006, -0.0271,  0.0320,  0.0601,\n",
      "         0.0125, -0.0066, -0.0151,  0.0358,  0.0264, -0.0367,  0.0319, -0.0425,\n",
      "         0.0514,  0.0604,  0.0755, -0.0156, -0.0084, -0.0600, -0.0036, -0.0446,\n",
      "         0.0149, -0.0488,  0.0371,  0.0392, -0.0498,  0.0624, -0.0452,  0.0200,\n",
      "         0.0122, -0.0649, -0.0452,  0.0282,  0.0489,  0.0159, -0.0111,  0.1017,\n",
      "         0.0014,  0.0320,  0.0262,  0.0120,  0.0253,  0.0421, -0.0434,  0.0794,\n",
      "         0.0467,  0.0132,  0.0410, -0.0359,  0.0328,  0.0358, -0.0372,  0.0429,\n",
      "        -0.0420,  0.0654,  0.0344, -0.0057,  0.0499,  0.0241, -0.0843, -0.0776,\n",
      "         0.0463,  0.0297, -0.0286, -0.0033,  0.0049,  0.0754,  0.0847, -0.0822,\n",
      "         0.0425,  0.0146, -0.0111, -0.0633,  0.1065, -0.0200,  0.0361, -0.0030,\n",
      "         0.0325, -0.0193, -0.0583,  0.0008, -0.0360, -0.0694, -0.0402,  0.0691,\n",
      "        -0.0140,  0.0602,  0.0436, -0.0034,  0.0502,  0.0076,  0.0306,  0.0126,\n",
      "         0.0901,  0.0141, -0.0055,  0.0210,  0.0327, -0.0166,  0.0368,  0.0364,\n",
      "         0.1112, -0.0185,  0.0527, -0.0076,  0.0768, -0.0624, -0.0256,  0.0326,\n",
      "         0.0331,  0.0153,  0.0553, -0.0018, -0.0062,  0.0068, -0.0296,  0.0860,\n",
      "         0.0062, -0.0264,  0.0100,  0.0301, -0.0052, -0.0138, -0.0790,  0.0482,\n",
      "        -0.0117,  0.0628,  0.0103, -0.0185, -0.0306, -0.0096, -0.0322,  0.0600,\n",
      "         0.0560,  0.0210, -0.0396, -0.0521,  0.0719,  0.0526, -0.0093, -0.0116,\n",
      "        -0.0015,  0.0415,  0.0326, -0.0556,  0.0059, -0.0111,  0.0377, -0.0462,\n",
      "         0.0083,  0.0363, -0.0184, -0.0326,  0.0386, -0.0022,  0.0232, -0.0720,\n",
      "        -0.0076,  0.0488,  0.0310,  0.0105, -0.1059,  0.0330,  0.0413,  0.0241,\n",
      "         0.0617,  0.0466,  0.0069, -0.0063, -0.0048,  0.0447, -0.0254, -0.0395,\n",
      "         0.0316,  0.0522,  0.0195,  0.0515,  0.0340,  0.0359, -0.0091,  0.0488,\n",
      "        -0.0247, -0.0172, -0.0188,  0.0517, -0.0312,  0.0474, -0.0233, -0.0150,\n",
      "        -0.0277,  0.0050,  0.0154, -0.0784,  0.0475, -0.0153,  0.0793,  0.0154,\n",
      "        -0.0446, -0.0227,  0.0759, -0.0089, -0.0088,  0.0011, -0.0180,  0.0703,\n",
      "        -0.0581,  0.0309,  0.0466,  0.0260,  0.0026, -0.0349, -0.0324, -0.0205,\n",
      "        -0.0131, -0.0231,  0.0632,  0.0289, -0.0298, -0.0033, -0.0059,  0.0091,\n",
      "         0.0696,  0.0361, -0.0467,  0.0453,  0.0816, -0.0069, -0.0285, -0.0046,\n",
      "        -0.0467, -0.0251,  0.0364, -0.0050,  0.0135, -0.0198])\n",
      "tensor([1.0276, 0.9734, 0.9957, 1.0078, 1.0151, 1.0305, 0.9878, 1.0024, 0.9848,\n",
      "        0.9885, 0.9671, 0.9577, 0.9735, 0.9976, 0.9931, 1.0471, 1.0200, 1.0076,\n",
      "        1.0147, 1.0976, 1.0151, 1.0188, 1.0208, 1.0023, 0.9693, 0.9917, 1.0252,\n",
      "        1.0278, 0.9826, 1.0219, 0.9958, 0.9717, 1.0553, 0.9846, 1.0318, 1.0027,\n",
      "        0.9813, 1.0103, 1.0031, 0.9662, 0.9919, 0.9906, 0.9656, 0.9655, 1.0095,\n",
      "        0.9703, 1.0270, 1.0539, 0.9987, 1.0018, 1.0788, 1.0008, 1.0141, 1.0225,\n",
      "        0.9876, 1.0063, 1.0317, 1.0050, 0.9833, 0.9641, 1.0407, 1.0003, 1.0027,\n",
      "        1.0242, 1.0027, 1.0354, 1.0505, 0.9687, 0.9794, 0.9811, 0.9985, 0.9983,\n",
      "        0.9880, 1.0080, 0.9740, 0.9943, 0.9915, 1.0074, 1.0049, 0.9850, 1.0111,\n",
      "        0.9620, 1.0144, 1.0112, 0.9646, 0.9897, 1.0078, 1.0050, 1.0339, 1.0247,\n",
      "        0.9894, 0.9860, 1.0322, 1.0284, 0.9617, 0.9929, 0.9691, 0.9840, 0.9773,\n",
      "        1.0174, 1.0004, 0.9786, 1.0732, 1.0262, 1.0148, 1.0317, 1.0114, 1.0083,\n",
      "        0.9789, 1.0044, 0.9950, 1.0026, 0.9888, 1.0235, 0.9867, 0.9979, 1.0289,\n",
      "        0.9779, 0.9652, 1.0048, 0.9974, 0.9973, 1.0047, 0.9879, 1.0275, 1.0569,\n",
      "        1.0324, 0.9800, 0.9852, 0.9513, 0.9791, 1.0330, 1.0028, 0.9975, 0.9552,\n",
      "        1.0100, 1.0201, 0.9832, 0.9597, 1.0090, 1.0094, 0.9727, 0.9789, 0.9863,\n",
      "        0.9616, 0.9913, 1.0209, 0.9954, 1.0049, 0.9845, 1.0359, 1.0044, 1.0041,\n",
      "        0.9999, 0.9971, 0.9938, 0.9813, 1.0475, 0.9600, 0.9691, 0.9972, 1.0279,\n",
      "        0.9597, 0.9878, 0.9768, 0.9905, 1.0116, 0.9689, 0.9886, 1.0035, 1.0130,\n",
      "        1.0079, 0.9864, 1.0016, 1.0102, 0.9657, 0.9814, 1.0073, 0.9785, 0.9734,\n",
      "        1.0022, 0.9741, 0.9904, 0.9756, 0.9953, 0.9937, 0.9845, 0.9992, 0.9822,\n",
      "        0.9847, 0.9808, 0.9834, 1.0167, 0.9824, 0.9566, 1.0134, 0.9866, 1.0094,\n",
      "        0.9836, 1.0023, 1.0117, 1.0030, 0.9680, 0.9864, 1.0629, 0.9799, 0.9989,\n",
      "        0.9914, 1.0161, 0.9927, 1.0228, 1.0208, 1.0056, 0.9903, 0.9812, 1.0128,\n",
      "        0.9802, 0.9686, 0.9837, 0.9587, 0.9947, 1.0057, 1.0099, 0.9736, 0.9867,\n",
      "        1.0106, 1.0019, 0.9777, 1.0266, 0.9839, 1.0092, 0.9791, 1.0120, 0.9951,\n",
      "        0.9892, 1.0080, 0.9924, 1.0151, 1.0514, 0.9986, 0.9767, 0.9932, 1.0072,\n",
      "        1.0096, 0.9693, 0.9893, 0.9941, 1.0092, 0.9834, 0.9917, 1.0273, 1.0228,\n",
      "        0.9961, 0.9971, 0.9910, 1.0073, 1.0079, 0.9845, 0.9848, 0.9819, 0.9515,\n",
      "        0.9866, 0.9800, 1.0095, 1.0334, 1.0131, 0.9525, 0.9887, 1.0006, 0.9878,\n",
      "        1.0286, 0.9987, 0.9834, 0.9541, 0.9848, 0.9973, 1.1001, 0.9669, 0.9908,\n",
      "        0.9613, 1.0240, 0.9648, 1.0000, 1.0100, 0.9762, 1.0238, 0.9801, 0.9944,\n",
      "        1.0194, 0.9932, 0.9892, 0.9858, 1.0204, 1.0209, 1.0051, 0.9804, 0.9982,\n",
      "        1.0412, 0.9724, 0.9410, 1.0054, 1.0076, 1.0047, 0.9616, 1.0797, 0.9864,\n",
      "        0.9831, 1.0180, 0.9940, 1.0127, 0.9759, 1.0594, 0.9919, 0.9868, 0.9981,\n",
      "        0.9792, 1.0028, 0.9713, 0.9710, 0.9807, 1.0127, 0.9971, 0.9967, 0.9640,\n",
      "        0.9967, 0.9670, 0.9862, 0.9880, 0.9866, 0.9486, 0.9962, 1.0195, 1.0055,\n",
      "        1.0060, 1.0463, 0.9530, 1.0020, 0.9688, 1.0120, 1.0150, 1.0151, 0.9696,\n",
      "        1.0005, 1.0241, 0.9665, 0.9750, 1.0198, 1.0150, 0.9713, 1.0306])\n",
      "tensor([-3.5350e-02,  1.4544e-02,  1.3029e-02, -4.5930e-02,  1.1225e-02,\n",
      "         1.1952e-02, -2.6069e-03, -2.4680e-02,  1.3814e-02, -5.9603e-03,\n",
      "         3.6558e-02,  2.7692e-02, -6.4048e-03,  1.0037e-02, -1.0070e-02,\n",
      "        -1.7275e-02,  1.6674e-02, -2.7602e-02, -4.0532e-02,  4.6684e-02,\n",
      "        -3.0559e-02, -2.1456e-02,  3.3872e-02, -2.3979e-02,  7.0430e-04,\n",
      "         7.2112e-03,  1.2325e-02, -3.6426e-02, -2.0055e-02,  4.4589e-02,\n",
      "        -9.8862e-03,  2.4613e-02, -1.7372e-02,  1.1600e-02, -1.6265e-02,\n",
      "        -2.4330e-02,  4.6533e-03,  5.4278e-02, -2.9920e-03,  2.8152e-02,\n",
      "        -2.0078e-02,  2.3122e-02,  2.5459e-02, -2.8040e-02, -8.7775e-03,\n",
      "         1.8702e-02,  2.7632e-03, -4.6198e-02,  2.9821e-02,  2.2518e-02,\n",
      "         5.2416e-02, -1.1100e-02,  1.0222e-02,  1.5708e-02,  2.8826e-02,\n",
      "         1.2678e-02,  2.2529e-02, -3.5432e-02,  3.4163e-02, -2.9744e-03,\n",
      "        -1.1407e-02, -2.2160e-02,  3.1458e-02,  3.6269e-02,  6.3464e-03,\n",
      "         8.0826e-03,  1.7367e-02,  2.9274e-02, -3.4223e-02,  5.6659e-03,\n",
      "        -1.0145e-02,  3.9194e-04, -6.9186e-03, -2.0809e-02,  4.4090e-02,\n",
      "        -1.0095e-02, -2.8433e-02,  2.2805e-02,  2.9220e-02,  1.3711e-02,\n",
      "        -5.9642e-02,  1.4878e-02,  3.5361e-02, -2.7359e-02,  1.8694e-02,\n",
      "         1.5357e-02, -1.2007e-02, -8.3162e-03, -1.1112e-02, -2.2560e-02,\n",
      "         7.3673e-04, -6.8736e-03, -3.9925e-03, -2.3595e-02,  2.7152e-02,\n",
      "        -1.8236e-02,  4.7175e-02,  1.2756e-02,  6.7276e-03,  4.3013e-02,\n",
      "         3.2018e-02,  4.6339e-03, -3.7869e-03, -5.3183e-02, -8.4378e-03,\n",
      "         2.2388e-02,  1.6571e-02, -3.7221e-02, -1.2483e-02,  2.1794e-03,\n",
      "         2.2247e-02, -7.0703e-04, -3.0174e-02,  2.5105e-02, -2.7229e-02,\n",
      "        -4.7152e-02, -2.7540e-02, -2.2321e-02,  1.1478e-02,  2.0905e-02,\n",
      "        -3.0561e-02, -2.3679e-02,  2.1322e-02, -2.3602e-03, -5.9481e-02,\n",
      "        -1.6024e-02, -1.7491e-02, -1.1836e-03, -3.1539e-03, -1.3152e-02,\n",
      "         5.6931e-02, -2.6342e-02, -1.2109e-02, -8.2168e-03,  5.0936e-02,\n",
      "        -3.3346e-02,  4.2103e-02, -2.3183e-02,  3.3327e-02,  4.6228e-02,\n",
      "        -3.4010e-02, -2.2589e-02, -1.4561e-03,  2.6052e-02,  3.9765e-02,\n",
      "        -5.0117e-02,  2.3261e-04,  7.1917e-03, -1.5897e-02,  1.8670e-02,\n",
      "        -2.5867e-02, -4.0815e-02,  5.3983e-03, -2.0648e-02, -1.3693e-02,\n",
      "        -1.7737e-03, -2.7294e-02,  5.2415e-03, -1.6004e-02,  5.4567e-02,\n",
      "        -4.5197e-02, -3.4419e-02,  9.3330e-03,  3.2222e-02, -2.8663e-03,\n",
      "         1.3755e-02,  2.2604e-02, -5.0868e-03, -3.6231e-02, -3.9697e-04,\n",
      "         1.4922e-02, -5.7933e-02,  1.9755e-02, -2.3488e-02,  1.7444e-02,\n",
      "         4.5066e-02,  4.5853e-03,  6.8704e-03,  8.0424e-03, -3.4096e-02,\n",
      "        -3.7074e-02, -1.4356e-02, -3.6809e-02,  6.3309e-03,  1.8600e-02,\n",
      "         1.2181e-03,  9.5870e-03,  4.6199e-02, -2.0432e-02,  4.0745e-02,\n",
      "        -1.9347e-02,  1.6188e-02, -1.7725e-03, -4.5266e-02,  6.9166e-04,\n",
      "         1.7140e-03,  4.3890e-02, -4.2235e-02, -3.1289e-02,  1.4253e-02,\n",
      "         6.0712e-02, -7.4071e-02,  3.0854e-03, -1.1153e-03, -2.3178e-02,\n",
      "         1.4160e-02,  1.0558e-02, -1.0060e-02, -8.1522e-03,  2.4040e-03,\n",
      "        -8.1727e-04, -1.2081e-04,  2.2357e-02,  3.5634e-02,  8.0477e-03,\n",
      "         1.7610e-02,  1.1644e-02, -8.5299e-03, -1.2960e-02,  1.3231e-02,\n",
      "         4.2892e-02, -8.0465e-03,  2.3163e-02, -2.7743e-02,  1.5291e-03,\n",
      "         3.0255e-02,  6.4247e-03,  3.0443e-02, -3.9913e-03,  2.3711e-02,\n",
      "        -1.0543e-02, -1.9637e-02, -1.9586e-02, -1.0059e-02,  3.0858e-02,\n",
      "        -2.7976e-02, -1.8511e-02, -2.7751e-02, -2.1409e-02, -2.6789e-02,\n",
      "         3.6398e-03, -2.3267e-03,  2.8849e-02, -1.5588e-02, -1.6449e-02,\n",
      "        -8.7423e-03, -2.2012e-02, -6.6562e-03,  3.0040e-02,  9.0777e-03,\n",
      "         2.4204e-03, -2.1653e-02, -3.8930e-02, -2.4384e-02,  1.4804e-02,\n",
      "         3.4419e-02, -3.7753e-02, -1.3193e-03,  8.1317e-03,  2.0632e-02,\n",
      "         8.0026e-03, -7.0535e-03,  8.9526e-03, -3.6372e-02, -6.1832e-03,\n",
      "        -1.1020e-02,  3.0251e-02,  2.0859e-03,  3.0837e-02, -9.9613e-03,\n",
      "        -1.5744e-02,  2.5834e-03, -2.9797e-02, -2.1005e-02,  1.4507e-02,\n",
      "        -1.1474e-02, -1.8025e-02,  1.4232e-02,  5.2274e-03, -1.2668e-02,\n",
      "        -9.8186e-04,  4.0867e-03, -8.1167e-03, -3.4265e-02,  6.0216e-03,\n",
      "         5.6454e-03, -1.5457e-03,  1.6552e-02,  3.9761e-02, -1.0269e-02,\n",
      "         1.0324e-02, -1.6654e-03,  3.3594e-03,  2.1380e-02,  1.7027e-02,\n",
      "         7.5875e-02,  1.0034e-02, -1.7652e-02,  1.1878e-02, -1.9520e-03,\n",
      "         2.4688e-03,  1.6417e-02,  1.3519e-02, -1.3754e-02, -3.2320e-02,\n",
      "        -1.3942e-02, -2.8841e-02,  2.1106e-02, -2.8115e-03, -2.7969e-02,\n",
      "        -1.1159e-02, -1.4443e-02, -8.7004e-03, -5.0777e-03, -2.0218e-02,\n",
      "        -1.5662e-02,  1.0083e-02,  1.0443e-02,  1.6605e-02, -1.9987e-02,\n",
      "         3.2370e-03, -6.3985e-02, -1.8802e-02, -1.9201e-02,  3.3417e-02,\n",
      "        -4.8423e-02, -1.1690e-02, -1.5085e-02,  4.6856e-03, -3.2940e-02,\n",
      "        -1.3441e-02, -2.2589e-03,  2.2053e-02,  1.9735e-02, -1.7714e-02,\n",
      "        -5.1835e-03,  4.4337e-03,  3.8068e-02,  4.9846e-06, -7.1225e-02,\n",
      "         3.4681e-02,  6.9338e-03, -1.8490e-02, -2.1908e-02,  7.6246e-03,\n",
      "         1.0069e-02, -2.1550e-02,  1.0254e-02, -1.8278e-02, -2.6174e-03])\n",
      "tensor([[-0.0770,  0.0347,  0.0074,  ..., -0.0336,  0.0143,  0.0743],\n",
      "        [-0.0192,  0.0327,  0.0788,  ..., -0.0576, -0.0430,  0.0561],\n",
      "        [-0.0069,  0.0412, -0.0471,  ..., -0.0413, -0.0583,  0.0006],\n",
      "        ...,\n",
      "        [-0.0324, -0.0533, -0.0025,  ...,  0.0153,  0.0354, -0.0625],\n",
      "        [-0.0351,  0.0120, -0.0232,  ...,  0.0581, -0.0030,  0.0478],\n",
      "        [ 0.0375, -0.0448, -0.0452,  ...,  0.0433, -0.0350, -0.0641]])\n",
      "tensor([ 3.1220e-02, -6.4367e-02, -5.0851e-02,  2.5917e-02, -4.5012e-02,\n",
      "         2.9362e-02,  1.9246e-02,  6.8199e-02, -4.2455e-03,  5.2977e-02,\n",
      "         2.5955e-02, -1.9022e-02,  8.4306e-02,  7.8209e-03,  1.0526e-02,\n",
      "        -2.5088e-02,  8.5779e-02, -2.4915e-02, -3.8811e-02, -1.5853e-02,\n",
      "         7.4089e-03,  5.5927e-02,  4.8042e-02,  3.3678e-02, -1.2334e-02,\n",
      "        -1.0018e-02,  2.4896e-02,  1.2468e-02,  4.9789e-02,  1.7878e-02,\n",
      "        -1.3859e-02, -3.1982e-03, -4.6200e-02,  4.8855e-02,  9.1821e-02,\n",
      "         4.9626e-02, -4.2201e-02,  2.3957e-02,  4.0595e-03, -3.7398e-02,\n",
      "         3.7986e-02,  4.5612e-02, -1.6361e-03, -3.9586e-02,  1.7108e-02,\n",
      "        -4.2307e-02,  3.8448e-02,  5.3015e-03,  3.5367e-02, -3.5653e-02,\n",
      "         1.0286e-02, -4.9044e-02, -3.8599e-02, -5.5869e-02,  1.1401e-02,\n",
      "         2.6030e-02, -1.6078e-02, -9.1632e-03, -1.1468e-02,  4.9287e-02,\n",
      "        -1.2999e-02,  4.6635e-02,  2.8266e-02, -1.1957e-03, -4.4946e-02,\n",
      "         2.2004e-02, -3.7596e-02,  2.6022e-02,  6.0958e-02,  2.8824e-02,\n",
      "         6.2551e-02, -2.0607e-02, -5.0752e-03,  7.7025e-02,  4.8286e-02,\n",
      "         6.0685e-02,  5.0243e-02, -1.3424e-03, -3.2029e-02,  1.2732e-02,\n",
      "         6.8487e-02,  1.6726e-02,  2.5311e-02,  4.0938e-02, -3.7663e-02,\n",
      "        -6.9774e-03, -2.6668e-02,  4.3938e-02,  1.9049e-02,  2.5011e-02,\n",
      "         5.0649e-03,  2.7766e-02, -1.8677e-02, -6.5871e-03, -1.0926e-02,\n",
      "        -4.5367e-02, -1.4554e-02, -8.9167e-03,  1.2815e-02,  1.9678e-02,\n",
      "        -6.5054e-02,  7.9996e-03, -5.6171e-04,  2.2121e-02, -7.9475e-02,\n",
      "        -1.4613e-02,  1.1928e-02, -7.1760e-03,  2.1885e-02,  7.4417e-02,\n",
      "        -3.4661e-02,  4.3362e-02, -8.3427e-03,  1.1697e-02, -4.1059e-02,\n",
      "        -2.2433e-02,  2.9944e-02, -4.1845e-02, -3.2012e-02,  2.7519e-02,\n",
      "         3.0520e-02, -6.6486e-03,  1.9922e-02,  4.1011e-05,  2.4321e-02,\n",
      "        -3.4112e-02, -8.1252e-03, -1.3817e-03,  4.1487e-02,  5.5383e-03,\n",
      "         7.4264e-02,  5.8538e-02, -1.2504e-02, -5.8637e-02, -3.2831e-02,\n",
      "        -3.8373e-02,  3.7144e-02, -4.6573e-02, -4.4477e-03,  1.4093e-02,\n",
      "         2.4116e-02,  3.7189e-02,  1.8752e-02,  2.8613e-02,  3.1591e-02,\n",
      "        -5.8729e-02, -2.5585e-02,  1.1315e-02,  3.4952e-02,  4.1815e-02,\n",
      "        -4.2700e-02,  9.5975e-02, -5.4345e-02,  4.4778e-02,  3.4699e-02,\n",
      "        -1.4143e-03, -4.2060e-02,  4.5085e-03,  3.6229e-02,  8.6210e-02,\n",
      "         5.6177e-02, -2.5983e-02,  5.1932e-02, -2.1423e-02,  1.7566e-02,\n",
      "         8.7870e-02,  5.8296e-02,  7.4138e-02,  8.4713e-02,  2.6736e-02,\n",
      "         2.2297e-02, -3.9376e-02,  2.6866e-02,  1.8884e-02, -6.2928e-02,\n",
      "        -1.1927e-01,  7.9880e-03,  2.8906e-02,  4.5301e-02, -7.4961e-02,\n",
      "         3.2721e-02,  7.2418e-02,  6.7919e-02, -3.9072e-02, -4.5895e-03,\n",
      "        -1.5853e-03, -3.0371e-02, -3.7048e-02,  5.1904e-02,  4.0411e-02,\n",
      "        -8.3111e-04,  7.5006e-02, -1.7369e-02, -1.9430e-02,  8.6174e-03,\n",
      "        -1.6283e-02, -1.4449e-02, -4.4124e-03,  6.7219e-02,  2.5801e-03,\n",
      "         3.5575e-02,  2.3887e-02,  7.3724e-02, -2.7450e-02,  5.9700e-02,\n",
      "        -4.4520e-02,  1.5025e-02,  4.0414e-02,  1.2516e-02, -6.9264e-02,\n",
      "        -5.9417e-02, -2.6525e-02,  6.7678e-02, -1.2832e-02,  5.0105e-03,\n",
      "         4.0910e-02,  1.0097e-01, -3.5914e-02,  2.8993e-02, -4.8939e-03,\n",
      "         1.0175e-01, -4.1305e-02,  1.1802e-02, -3.7813e-02, -2.6506e-02,\n",
      "         2.8449e-02,  7.3423e-02,  1.0151e-02, -6.7958e-02,  3.9225e-03,\n",
      "        -2.4804e-02, -3.9276e-03,  5.4167e-02, -5.4194e-02,  4.5707e-02,\n",
      "         7.6104e-03, -1.4399e-02,  1.5504e-02, -1.5404e-02,  4.8668e-02,\n",
      "        -6.3860e-02,  7.4544e-02, -7.2998e-02,  2.2758e-02,  1.6362e-02,\n",
      "         4.3762e-02, -2.2281e-03,  4.9973e-02,  4.8246e-02,  5.3134e-02,\n",
      "        -3.1200e-02,  1.8368e-03, -1.1808e-02, -8.7060e-03,  2.1497e-02,\n",
      "        -5.0635e-02, -5.4812e-02,  7.8076e-02,  8.1736e-02,  2.0540e-02,\n",
      "         4.8063e-02, -1.1393e-02, -1.6909e-02,  3.8772e-02,  2.5120e-03,\n",
      "        -1.0431e-02, -5.7217e-02, -2.5625e-02, -1.8534e-03,  3.7000e-02,\n",
      "        -6.7892e-04, -8.4087e-03, -3.5301e-02,  5.0963e-02,  4.7199e-02,\n",
      "        -1.0314e-02, -5.1786e-02, -1.9911e-02,  7.9702e-02, -4.2759e-02,\n",
      "         4.7687e-02, -1.4493e-02, -1.4170e-03,  4.3998e-02, -4.6188e-02,\n",
      "         3.0044e-02, -1.5390e-02, -3.2464e-02, -2.9193e-03, -1.5669e-02,\n",
      "        -8.2792e-03,  3.3157e-02,  2.0329e-02,  1.2330e-02, -1.9292e-02,\n",
      "         3.7264e-02,  4.6310e-02,  2.3605e-02, -1.8521e-03,  5.1313e-02,\n",
      "        -2.3791e-02, -2.9857e-02, -4.8621e-02, -5.4848e-03,  3.3813e-03,\n",
      "         5.3147e-02,  4.2042e-02, -5.6409e-02,  8.6589e-02,  6.4586e-02,\n",
      "         3.0701e-02, -4.3648e-02,  8.4899e-03, -2.5204e-02,  1.7927e-02,\n",
      "         3.1091e-02, -4.4601e-02, -2.4615e-02, -2.9417e-02, -1.9232e-02,\n",
      "        -6.1471e-02, -5.9971e-02, -9.8965e-03,  2.1335e-02, -6.8786e-03,\n",
      "        -1.6642e-02,  1.9179e-02, -1.7309e-02,  1.4843e-03,  4.9123e-02,\n",
      "         7.0532e-02,  4.9847e-02,  7.3972e-02,  7.2877e-02, -6.6248e-03,\n",
      "        -3.3546e-02,  6.9865e-02, -3.2413e-02,  4.0398e-02,  2.2823e-02,\n",
      "         7.1041e-02,  1.2250e-02,  2.2351e-02,  6.0800e-03,  1.6917e-03,\n",
      "        -2.5096e-02, -3.3802e-03, -4.1258e-02,  7.3368e-02,  1.6909e-02])\n",
      "tensor([0.9919, 0.9576, 0.9811, 0.9651, 0.9635, 0.9802, 0.9853, 1.0039, 0.9933,\n",
      "        0.9623, 0.9718, 0.9842, 0.9897, 0.9812, 0.9484, 0.9757, 0.9711, 0.9700,\n",
      "        0.9854, 0.9577, 0.9423, 0.9521, 0.9719, 0.9733, 0.9581, 0.9735, 0.9702,\n",
      "        0.9868, 0.9906, 0.9787, 1.0252, 0.9752, 0.9649, 0.9821, 0.9929, 0.9642,\n",
      "        0.9635, 1.0294, 0.9881, 0.9807, 0.9316, 0.9410, 0.9825, 0.9654, 0.9852,\n",
      "        0.9745, 0.9801, 0.9946, 0.9821, 0.9462, 0.9836, 0.9553, 0.9902, 0.9726,\n",
      "        1.0154, 0.9567, 0.9701, 0.9774, 0.9715, 0.9715, 0.9402, 0.9711, 0.9590,\n",
      "        0.9445, 0.9643, 0.9546, 0.9834, 0.9694, 0.9546, 0.9643, 0.9710, 1.0158,\n",
      "        0.9915, 0.9437, 0.9822, 0.9569, 0.9762, 0.9644, 1.0053, 0.9721, 0.9582,\n",
      "        0.9626, 0.9433, 0.9915, 0.9699, 0.9544, 0.9871, 0.9702, 0.9716, 0.9834,\n",
      "        0.9841, 0.9715, 0.9696, 0.9884, 0.9725, 0.9669, 0.9538, 1.0165, 0.9846,\n",
      "        0.9789, 0.9878, 0.9689, 0.9682, 0.9725, 1.0017, 0.9300, 0.9205, 0.9698,\n",
      "        0.9573, 0.9611, 0.9688, 0.9783, 0.9792, 0.9616, 0.9552, 0.9684, 0.9823,\n",
      "        1.0161, 0.9550, 0.9911, 0.9747, 0.9865, 0.9784, 0.9777, 0.9633, 0.9911,\n",
      "        0.9986, 0.9640, 0.9686, 0.9618, 0.9600, 0.9759, 0.9681, 0.9452, 0.9651,\n",
      "        0.9637, 0.9612, 0.9723, 0.9511, 0.9703, 0.9575, 0.9596, 0.9730, 0.9417,\n",
      "        0.9548, 0.9622, 0.9938, 0.9807, 0.9678, 0.9602, 0.9780, 0.9688, 0.9867,\n",
      "        0.9611, 0.9707, 0.9819, 0.9795, 0.9631, 0.9705, 0.9447, 0.9796, 0.9750,\n",
      "        0.9664, 0.9696, 0.9893, 0.9526, 0.9593, 0.9587, 1.0137, 1.0085, 0.9536,\n",
      "        0.9850, 0.9744, 0.9593, 0.9750, 1.0203, 0.9568, 0.9746, 0.9660, 1.0010,\n",
      "        0.9763, 0.9566, 0.9680, 0.9614, 0.9804, 0.9702, 0.9783, 0.9279, 0.9528,\n",
      "        0.9855, 0.9604, 0.9749, 0.9695, 0.9855, 0.9655, 0.9736, 0.9755, 0.9745,\n",
      "        0.9705, 0.9568, 0.9915, 0.9834, 0.9710, 0.9521, 0.9838, 0.9748, 0.9512,\n",
      "        0.9922, 0.9635, 0.9585, 1.0037, 0.9800, 0.9741, 0.9556, 0.9806, 0.9967,\n",
      "        0.9761, 0.9767, 0.9504, 0.9778, 0.9653, 0.9860, 0.9464, 0.9659, 0.9700,\n",
      "        1.0087, 0.9511, 0.9576, 1.0116, 0.9804, 0.9625, 0.9418, 0.9561, 0.9623,\n",
      "        0.9672, 0.9622, 0.9743, 0.9694, 0.9770, 0.9532, 0.9772, 0.9615, 0.9806,\n",
      "        0.9910, 0.9729, 0.9506, 1.0117, 0.9687, 0.9665, 0.9522, 1.0053, 0.9685,\n",
      "        0.9557, 0.9974, 0.9603, 0.9674, 0.9676, 0.9719, 0.9860, 0.9819, 0.9524,\n",
      "        0.9787, 0.9420, 0.9621, 1.0045, 0.9771, 0.9721, 0.9713, 0.9587, 0.9708,\n",
      "        0.9509, 0.9782, 0.9734, 0.9727, 0.9706, 0.9772, 1.0704, 0.9742, 0.9759,\n",
      "        0.9552, 0.9682, 0.9605, 0.9692, 0.9558, 0.9604, 1.0157, 1.0005, 0.9906,\n",
      "        0.9638, 0.9870, 0.9871, 0.9754, 0.9550, 0.9604, 0.9325, 0.9642, 0.9680,\n",
      "        0.9502, 0.9823, 0.9651, 0.9645, 0.9758, 0.9553, 0.9847, 0.9827, 0.9744,\n",
      "        0.9791, 0.9517, 0.9694, 0.9378, 0.9612, 1.0090, 0.9761, 0.9719, 0.9685,\n",
      "        0.9395, 0.9740, 0.9664, 0.9775, 0.9613, 0.9796, 0.9979, 0.9767, 0.9550,\n",
      "        0.9737, 0.9677, 0.9341, 0.9586, 0.9828, 0.9518, 0.9707, 0.9615, 0.9807,\n",
      "        0.9683, 0.9838, 0.9513, 0.9552, 0.9736, 0.9624, 0.9662, 0.9757, 0.9819,\n",
      "        0.9939, 0.9508, 0.9852, 0.9840, 0.9838, 0.9646, 0.9495, 0.9699])\n",
      "tensor([-0.0226,  0.0538, -0.0304, -0.0098, -0.0627, -0.0219,  0.0288, -0.0105,\n",
      "        -0.0439,  0.0502, -0.0290,  0.0008,  0.0318, -0.0215,  0.0049,  0.0006,\n",
      "        -0.0370, -0.0284, -0.0326, -0.0080,  0.0376, -0.0410, -0.0019, -0.0089,\n",
      "         0.0106,  0.0117,  0.0672,  0.0755, -0.0321, -0.0181, -0.0018, -0.0104,\n",
      "        -0.0053,  0.0507, -0.0463, -0.0272,  0.0375,  0.0580,  0.0277, -0.0274,\n",
      "         0.0584,  0.0443,  0.0370, -0.0239,  0.0466,  0.0283, -0.0166,  0.0271,\n",
      "        -0.0219,  0.0404, -0.0206, -0.0433, -0.0419, -0.0040, -0.0287, -0.0216,\n",
      "        -0.0360,  0.0113, -0.0292, -0.0121,  0.0128,  0.0073,  0.0142, -0.0043,\n",
      "         0.0455, -0.0239,  0.0687, -0.0356, -0.0038, -0.0295, -0.0279,  0.0225,\n",
      "        -0.0423,  0.0161, -0.0070,  0.0353,  0.0574,  0.0290, -0.0213,  0.0148,\n",
      "         0.0412,  0.0224,  0.0521,  0.0329, -0.0406,  0.0632,  0.0655, -0.0137,\n",
      "        -0.0107, -0.0483, -0.0255,  0.0113, -0.0397, -0.0186, -0.0219, -0.0272,\n",
      "         0.0295, -0.0540,  0.0249, -0.0104, -0.0544,  0.0181, -0.0064,  0.0421,\n",
      "         0.0527, -0.0031,  0.0209, -0.0273,  0.0445, -0.0115, -0.0180, -0.0525,\n",
      "         0.0684,  0.0268,  0.0297,  0.0037, -0.0334,  0.0559, -0.0135,  0.0262,\n",
      "        -0.0073, -0.0536,  0.0367,  0.0370,  0.0492, -0.0243, -0.0249,  0.0564,\n",
      "        -0.0323,  0.0475,  0.0380,  0.0363,  0.0292,  0.0296, -0.0212, -0.0284,\n",
      "         0.0024, -0.0171, -0.0420, -0.0194,  0.0465,  0.0109,  0.0269,  0.0133,\n",
      "        -0.0097,  0.0419, -0.0456,  0.0554, -0.0141,  0.0081, -0.0290,  0.0180,\n",
      "        -0.0461,  0.0228, -0.0122, -0.0166, -0.0348, -0.0175,  0.0140,  0.0294,\n",
      "         0.0454,  0.0232, -0.0644, -0.0007, -0.0214, -0.0726, -0.0321,  0.0073,\n",
      "         0.0493, -0.0533,  0.0176, -0.0137,  0.0167,  0.0321, -0.0149,  0.0079,\n",
      "         0.0196,  0.0377, -0.0253,  0.0492, -0.0208, -0.0314, -0.0249, -0.0498,\n",
      "        -0.0063,  0.0046, -0.0281,  0.0252,  0.0158,  0.0198, -0.0183, -0.0288,\n",
      "         0.0306, -0.0366, -0.0438,  0.0158, -0.0165, -0.0193,  0.0122, -0.0367,\n",
      "        -0.0310,  0.0207, -0.0164, -0.0295,  0.0243, -0.0184, -0.0240, -0.0269,\n",
      "         0.0260,  0.0326, -0.0128,  0.0201, -0.0422, -0.0027, -0.0115, -0.0209,\n",
      "         0.0332,  0.0414,  0.0384, -0.0347,  0.0167,  0.0446, -0.0073, -0.0060,\n",
      "        -0.0205,  0.0087,  0.0570, -0.0283,  0.0373,  0.0302, -0.0311,  0.0443,\n",
      "         0.0146, -0.0538,  0.0091, -0.0333, -0.0389, -0.0028, -0.0088, -0.0593,\n",
      "         0.0176, -0.0075, -0.0379, -0.0507, -0.0304, -0.0203, -0.0194, -0.0297,\n",
      "         0.0260,  0.0254,  0.0131,  0.0297, -0.0343, -0.0046,  0.0265,  0.0380,\n",
      "        -0.0683, -0.0740, -0.0397, -0.0493,  0.0575,  0.0233,  0.0267, -0.0381,\n",
      "         0.0405, -0.0256, -0.0002,  0.0137,  0.0168,  0.0080, -0.0579, -0.0265,\n",
      "        -0.0727, -0.0255, -0.0308,  0.0350,  0.0894,  0.0109,  0.0200, -0.0303,\n",
      "        -0.0425,  0.0093, -0.0321,  0.0097, -0.0300, -0.0347,  0.0307, -0.0310,\n",
      "        -0.0165, -0.0126, -0.0199,  0.0453,  0.0281,  0.0370,  0.0057, -0.0380,\n",
      "        -0.0212, -0.0268, -0.0235,  0.0277,  0.0200,  0.0242,  0.0421,  0.0045,\n",
      "        -0.0489, -0.0019,  0.0130,  0.0218,  0.0299, -0.0126,  0.0185, -0.0074,\n",
      "        -0.0175,  0.0084, -0.0208,  0.0642, -0.0090, -0.0129,  0.0289,  0.0152,\n",
      "        -0.0528, -0.0220,  0.0456,  0.0353,  0.0185, -0.0272,  0.0164, -0.0344,\n",
      "         0.0223, -0.0085, -0.0148,  0.0416, -0.0436, -0.0175,  0.0229, -0.0189,\n",
      "         0.0194, -0.0445,  0.0047,  0.0414, -0.0046, -0.0292, -0.0073,  0.0510,\n",
      "         0.0293,  0.0477, -0.0332, -0.0036,  0.0384, -0.0208])\n",
      "tensor([[ 0.0197,  0.0170, -0.0218,  ...,  0.0335,  0.0120,  0.0485],\n",
      "        [ 0.0874,  0.0221, -0.0034,  ..., -0.0036, -0.0230, -0.0055],\n",
      "        [ 0.0230,  0.0156, -0.0149,  ...,  0.0041,  0.0165, -0.0266],\n",
      "        ...,\n",
      "        [ 0.0295,  0.0033,  0.0144,  ...,  0.0327, -0.0194,  0.0147],\n",
      "        [ 0.0323,  0.0046, -0.0191,  ...,  0.0060,  0.0001,  0.0367],\n",
      "        [-0.0169, -0.0113,  0.0556,  ...,  0.0321, -0.0220, -0.0177]])\n",
      "tensor([ 0.0466,  0.0187,  0.0439, -0.0222, -0.0308, -0.0481, -0.0520,  0.0114])\n",
      "tensor([[-0.0739,  0.1198, -0.0276,  ..., -0.0088,  0.0488, -0.0371],\n",
      "        [ 0.0008, -0.1393, -0.1285,  ...,  0.0470, -0.0160,  0.1164],\n",
      "        [ 0.1466,  0.0598,  0.1393,  ..., -0.0500, -0.0836, -0.0630],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0698, -0.0759,  ..., -0.0509, -0.0376,  0.1457],\n",
      "        [-0.0373,  0.0848, -0.1624,  ...,  0.1388, -0.0036, -0.0975],\n",
      "        [-0.0968, -0.1052,  0.0692,  ...,  0.0342,  0.1335,  0.0043]])\n",
      "tensor([-3.0543e-02, -3.5821e-02,  1.2162e-01, -1.0187e-01, -9.1161e-02,\n",
      "         4.5207e-02,  2.0954e-01,  5.8366e-02,  2.3705e-02,  9.1012e-02,\n",
      "        -1.0781e-02,  2.1154e-01,  1.2733e-01,  1.2345e-01, -6.8523e-02,\n",
      "        -8.5949e-02,  2.3186e-01, -4.0249e-02,  8.9672e-02, -1.7098e-01,\n",
      "         1.2167e-01, -1.4403e-01,  1.9679e-01,  1.8696e-01, -3.0602e-02,\n",
      "         1.1708e-01,  2.7519e-01,  9.7253e-02, -7.5421e-02,  1.1782e-01,\n",
      "         1.4252e-01, -1.1547e-01,  1.7381e-01,  2.0104e-01, -5.9491e-02,\n",
      "         1.3054e-01,  7.6997e-02, -5.6495e-03, -9.8097e-02,  1.6119e-02,\n",
      "         1.6657e-01, -2.2475e-02,  6.2619e-02,  9.1626e-02,  6.2916e-02,\n",
      "        -4.4277e-02, -5.7589e-02,  7.4381e-02,  2.6277e-01, -7.9904e-02,\n",
      "        -1.4272e-01,  3.5406e-02, -1.3599e-01,  1.2097e-01,  7.7743e-02,\n",
      "         2.4754e-01,  1.6101e-01,  7.9228e-02,  1.1073e-01, -4.1832e-02,\n",
      "         1.1375e-01,  1.4721e-01,  2.6687e-01, -7.3177e-02,  1.0892e-01,\n",
      "        -1.0496e-01, -6.2271e-02,  8.5179e-02,  1.6241e-01,  3.8793e-02,\n",
      "         9.3146e-04,  1.0429e-01,  1.8227e-01,  5.8587e-02,  1.2392e-01,\n",
      "         6.3384e-02,  3.1772e-02,  2.2902e-01, -7.6355e-02, -4.2899e-02,\n",
      "        -3.7909e-02,  1.9008e-01,  1.8625e-01,  1.5118e-01,  5.3555e-02,\n",
      "         1.0429e-01, -8.5525e-02,  6.0124e-02,  9.5218e-02,  8.3532e-02,\n",
      "         1.0526e-03, -8.8173e-02,  7.5813e-02,  1.1198e-01, -1.2428e-01,\n",
      "        -1.7935e-02,  2.0867e-01,  1.5171e-01,  2.6043e-01,  1.0289e-02,\n",
      "        -1.0227e-01,  1.8176e-01, -6.5464e-02,  1.7260e-01, -4.4620e-02,\n",
      "         1.7386e-01, -9.9804e-02,  2.7085e-02,  4.8649e-02,  9.0978e-02,\n",
      "        -1.4522e-02,  5.0144e-02,  2.7064e-02,  1.1646e-01,  9.5457e-02,\n",
      "         3.4164e-02, -1.0861e-01,  1.5659e-01, -1.5228e-02,  8.3819e-02,\n",
      "         1.7339e-01, -1.5891e-02, -2.1988e-03,  1.2582e-02,  2.0374e-01,\n",
      "         1.5293e-02, -1.2125e-01,  1.8066e-01, -2.8012e-02,  8.5298e-02,\n",
      "        -1.1308e-01,  2.7320e-01,  2.5258e-02, -8.8448e-02,  1.9618e-01,\n",
      "         4.8639e-02, -9.2476e-03,  6.7800e-02,  9.2085e-02, -1.1441e-01,\n",
      "         5.9660e-02, -5.6994e-02,  2.6814e-01,  1.1946e-01,  2.9347e-02,\n",
      "         2.6254e-01,  5.9447e-02,  1.3827e-01,  5.1153e-02, -5.9081e-02,\n",
      "        -5.3996e-02,  1.3619e-01,  1.2323e-01,  1.8285e-01, -8.4436e-03,\n",
      "         1.4477e-01,  4.1536e-02, -1.0732e-01,  3.2855e-02,  2.0624e-01,\n",
      "        -1.0505e-01,  9.9968e-03,  1.6997e-01, -1.0132e-01,  7.3262e-02,\n",
      "         1.1771e-01, -5.6171e-02, -9.7614e-02, -9.3018e-02,  7.7950e-02,\n",
      "         8.8889e-02, -9.8612e-02,  2.5723e-02,  9.8365e-02,  4.7671e-02,\n",
      "         2.1980e-01, -1.5436e-01, -1.0643e-01,  4.0180e-02,  1.1196e-01,\n",
      "         1.6786e-01,  1.0621e-01,  2.3366e-01, -4.0035e-02,  1.2793e-01,\n",
      "         3.3726e-02,  4.1785e-02, -5.1227e-02,  7.1775e-02,  2.0989e-01,\n",
      "         1.3254e-01,  1.6535e-01,  2.1443e-01, -1.2260e-01,  2.1879e-01,\n",
      "         1.2227e-01,  1.1674e-01,  7.1581e-03,  1.8211e-01,  1.1956e-01,\n",
      "         2.4998e-02,  1.9623e-01, -1.5321e-02,  1.0718e-01, -7.8355e-02,\n",
      "        -1.1326e-01,  1.9297e-01,  1.2302e-01,  2.1488e-02,  1.8375e-01,\n",
      "        -7.0644e-02,  2.0471e-01,  3.0901e-03, -1.4418e-02,  1.3463e-01,\n",
      "         1.1034e-01,  6.4821e-02,  2.3115e-01,  2.0275e-01,  1.3634e-01,\n",
      "        -1.3591e-01,  1.6902e-02, -1.9240e-02,  1.1929e-01,  1.3207e-01,\n",
      "         2.0507e-01,  4.3778e-03, -4.0236e-02, -4.2740e-04,  2.6730e-01,\n",
      "        -2.2275e-01, -6.4235e-02, -9.8890e-02,  2.9866e-02,  2.2385e-01,\n",
      "         1.7711e-01,  2.0513e-01, -4.7634e-02, -1.0972e-01, -1.9416e-02,\n",
      "         7.4810e-02,  7.7781e-02,  1.5393e-02,  1.4977e-01,  7.3896e-02,\n",
      "         2.9498e-02,  1.4788e-01, -4.6658e-02,  1.6507e-02, -1.4274e-02,\n",
      "         1.6919e-01,  7.9606e-02,  1.3096e-01,  1.0997e-01,  9.3153e-02,\n",
      "        -2.1021e-03,  1.4450e-01,  6.0856e-02, -1.0615e-02,  2.4149e-02,\n",
      "        -4.2761e-02,  2.6228e-02, -1.1105e-01,  1.4887e-01, -1.2350e-02,\n",
      "         1.2003e-01,  2.3322e-01,  4.1488e-02, -1.1564e-02, -3.2250e-02,\n",
      "         1.1118e-01, -1.0945e-01, -7.6545e-03, -6.3192e-02,  1.7922e-01,\n",
      "         1.8046e-01,  7.7163e-02, -3.8353e-02,  2.1646e-01,  1.4877e-01,\n",
      "         1.8486e-01,  1.6874e-01, -1.0730e-01,  1.0086e-01, -8.8698e-02,\n",
      "         5.3817e-03,  9.7886e-02, -6.4851e-02,  2.6151e-01,  4.5403e-02,\n",
      "        -2.0648e-02,  2.1013e-01, -3.7825e-02, -5.4148e-02,  1.6665e-02,\n",
      "         3.7667e-02, -1.2040e-02,  3.7119e-02,  8.5423e-02,  1.4835e-01,\n",
      "         1.8971e-01, -3.2630e-02,  9.5849e-02,  2.5131e-01,  4.1384e-02,\n",
      "        -8.5663e-02,  1.5133e-01, -3.2198e-03,  5.7627e-02,  2.5137e-01,\n",
      "         8.8389e-02, -9.0132e-02,  6.6890e-02,  3.0833e-02,  1.2972e-01,\n",
      "         2.1958e-01,  1.2693e-01,  1.7336e-01, -1.3838e-01,  1.7328e-01,\n",
      "        -9.3433e-02, -8.9950e-03,  8.1280e-02,  2.0431e-01,  1.2210e-01,\n",
      "        -4.3468e-03, -3.9147e-02,  3.5477e-02,  7.5938e-02,  1.8368e-01,\n",
      "         2.0307e-01,  8.4911e-02, -6.0621e-02,  4.1936e-03, -6.6686e-02,\n",
      "         4.7311e-02,  2.0628e-02,  1.4621e-01,  1.6897e-01,  1.6376e-01,\n",
      "         1.4580e-01,  5.2465e-02, -4.7107e-02,  6.4156e-05,  1.0928e-01,\n",
      "         2.1441e-01,  1.9604e-01,  1.2788e-01, -1.1484e-01,  9.2929e-02])\n",
      "tensor([0.8370, 1.0221, 0.9643, 0.9487, 0.9680, 0.9880, 1.0300, 0.9946, 1.0491,\n",
      "        1.0613, 0.9966, 0.9778, 1.0537, 1.0010, 1.0088, 0.9859, 1.0182, 0.9610,\n",
      "        0.9706, 0.9879, 0.9871, 0.8480, 0.9949, 0.9483, 0.9744, 0.9835, 1.0292,\n",
      "        1.0012, 0.9129, 0.9844, 1.0035, 0.9612, 0.9120, 1.0149, 0.9712, 1.0041,\n",
      "        0.9834, 0.9493, 1.0498, 1.0433, 1.0328, 1.0107, 0.9573, 0.9878, 0.9903,\n",
      "        0.9961, 0.9495, 0.9479, 1.0765, 1.0338, 0.8552, 0.9552, 0.8884, 1.0010,\n",
      "        1.0111, 1.0366, 0.9958, 0.9753, 0.9013, 0.9925, 0.9529, 0.9425, 1.0064,\n",
      "        0.9120, 0.9254, 0.9822, 0.8394, 0.9850, 0.9944, 0.9843, 0.9361, 0.9779,\n",
      "        1.0303, 0.9631, 1.0454, 0.9669, 0.9724, 1.0070, 0.9705, 0.9247, 0.9423,\n",
      "        0.9700, 0.9599, 0.9972, 1.0038, 0.9821, 1.0182, 0.9316, 1.0535, 1.0187,\n",
      "        0.9785, 0.9937, 1.0310, 0.9272, 0.9466, 0.9002, 0.9571, 1.0134, 1.0091,\n",
      "        0.9566, 0.8773, 0.9298, 0.9477, 1.0468, 0.9303, 1.0157, 0.9693, 0.9573,\n",
      "        0.9196, 1.0130, 0.9548, 0.9565, 0.9654, 1.0298, 0.9356, 1.0103, 1.0068,\n",
      "        0.9468, 0.9871, 0.9526, 0.9386, 0.9482, 1.0074, 0.9868, 0.9948, 1.0155,\n",
      "        0.9523, 0.8772, 0.9884, 0.9778, 0.8733, 1.0624, 0.8389, 0.8882, 1.0002,\n",
      "        0.9853, 0.8586, 1.0254, 0.9911, 0.9320, 1.0054, 0.9765, 1.0595, 0.9842,\n",
      "        1.0129, 1.0574, 1.0000, 0.9989, 0.9136, 0.9450, 0.9892, 0.9939, 0.9437,\n",
      "        0.9699, 1.0203, 1.0223, 0.9352, 0.8951, 0.9947, 0.9286, 0.9288, 1.0160,\n",
      "        0.9936, 0.9106, 1.0284, 0.9070, 0.9832, 0.9564, 0.9573, 0.9880, 0.9783,\n",
      "        0.9561, 0.9438, 0.9883, 0.9353, 0.9880, 0.9083, 0.9769, 0.9582, 0.9529,\n",
      "        1.0698, 0.8368, 0.9761, 1.0341, 0.9798, 0.9696, 0.9683, 0.9386, 0.9465,\n",
      "        1.0129, 0.9554, 0.9825, 1.0318, 0.9247, 1.0344, 0.9937, 0.9700, 0.9778,\n",
      "        1.0553, 0.9864, 0.9859, 1.0122, 0.9990, 1.0022, 0.9684, 1.0514, 1.0284,\n",
      "        0.9689, 0.9975, 0.9975, 0.9609, 0.9656, 0.9820, 1.0384, 0.9788, 1.0250,\n",
      "        0.8833, 1.0267, 1.0498, 1.0383, 0.9076, 1.0305, 0.8974, 0.9997, 0.9006,\n",
      "        1.0337, 0.9680, 0.9258, 0.9348, 1.0909, 0.9921, 0.9691, 0.9979, 1.0362,\n",
      "        1.0264, 1.0361, 0.9368, 1.0192, 0.9917, 0.9943, 0.9959, 0.9517, 0.9784,\n",
      "        0.9831, 1.0035, 0.9686, 1.0070, 0.9539, 0.9805, 0.9559, 0.9421, 1.0040,\n",
      "        0.9912, 1.0161, 0.9428, 0.9832, 1.0089, 0.9156, 0.9662, 0.9420, 0.8753,\n",
      "        0.9870, 0.9779, 1.0154, 1.0317, 1.0312, 1.0223, 0.9640, 1.0440, 0.9761,\n",
      "        0.9412, 0.9771, 1.0514, 0.9157, 0.9665, 0.9501, 0.9356, 1.0660, 1.0329,\n",
      "        0.9822, 1.0183, 0.9916, 0.9992, 0.9586, 0.9702, 0.9340, 0.9576, 0.9409,\n",
      "        1.0127, 0.9395, 0.9584, 1.0333, 0.9963, 0.9300, 0.9801, 1.0262, 1.0208,\n",
      "        0.9722, 0.9517, 0.9605, 1.0541, 0.9659, 1.0307, 1.0707, 0.9970, 1.0347,\n",
      "        1.0109, 1.0004, 0.9633, 1.0177, 0.9524, 0.9063, 0.9568, 0.9308, 0.9855,\n",
      "        1.0098, 0.9938, 1.0740, 0.8708, 1.0050, 0.9169, 1.0769, 0.9522, 0.9060,\n",
      "        0.9898, 0.9358, 0.8765, 1.0051, 1.0079, 0.9404, 1.0156, 0.9816, 1.0031,\n",
      "        1.0247, 0.9829, 1.0289, 0.9706, 0.9765, 1.0295, 0.9969, 1.0025, 0.9270,\n",
      "        0.9036, 1.0194, 0.8235, 1.0202, 1.0172, 0.9887, 0.9781, 1.0222])\n",
      "tensor([-8.1144e-03, -1.1477e-01,  6.5374e-02,  7.1216e-02,  1.6664e-01,\n",
      "        -1.9901e-02, -5.4041e-02,  1.2363e-01, -2.1770e-03,  1.3605e-01,\n",
      "        -6.4105e-02, -5.7969e-02, -1.2041e-01, -1.2723e-01, -1.4060e-01,\n",
      "        -1.1969e-01,  2.2015e-01, -1.3179e-03, -7.3500e-02,  8.6607e-02,\n",
      "        -1.4935e-02,  1.0440e-01,  8.7954e-03,  1.3460e-02,  1.0356e-02,\n",
      "        -4.8980e-02,  6.7917e-02, -6.1129e-02, -2.0193e-02,  1.1643e-01,\n",
      "        -4.1386e-02, -8.3423e-02,  2.2341e-03,  1.7840e-01,  5.0502e-02,\n",
      "        -4.3699e-02, -1.3264e-01, -4.2652e-02, -8.1347e-02, -6.8727e-02,\n",
      "        -1.6505e-02,  1.8421e-03,  4.6652e-02,  4.0345e-02,  2.5943e-02,\n",
      "        -5.1128e-02,  1.4282e-01,  3.2128e-02, -2.1327e-02, -1.3249e-01,\n",
      "        -1.7046e-02,  9.7437e-02,  1.1447e-01,  5.9549e-02,  1.6295e-01,\n",
      "         3.8790e-02,  8.5921e-02,  6.9810e-02,  6.6768e-02, -3.2995e-02,\n",
      "         9.4957e-02,  8.5988e-03, -6.4181e-02, -4.5814e-02, -8.1845e-03,\n",
      "        -1.3149e-01, -2.7017e-02,  4.3474e-02, -1.0657e-01, -1.0830e-02,\n",
      "         1.1168e-01, -1.8270e-02,  1.8009e-01, -1.2698e-02, -2.2515e-02,\n",
      "         5.3589e-02, -7.4970e-02,  1.9552e-02,  5.2082e-02,  2.2937e-03,\n",
      "        -3.2120e-02,  1.7009e-01,  6.4640e-02, -1.4250e-01, -4.7977e-02,\n",
      "         9.5050e-02, -4.1076e-02,  4.3931e-02,  4.1493e-02, -7.0248e-04,\n",
      "         1.0054e-01,  3.7532e-02, -6.1912e-03,  3.3785e-02,  3.4195e-02,\n",
      "         1.0011e-01, -9.3150e-04, -1.9278e-01, -9.2620e-02, -6.6880e-02,\n",
      "        -3.4881e-02,  7.4292e-02,  9.4718e-02, -4.3925e-03, -1.1759e-02,\n",
      "        -9.3252e-02,  2.4573e-02,  1.1865e-03, -7.2230e-02, -7.3656e-02,\n",
      "         1.5216e-01,  9.8712e-02,  2.9949e-02,  6.4871e-03, -6.1234e-02,\n",
      "        -6.3716e-04, -1.8832e-01,  1.6440e-01, -3.4098e-02, -7.9614e-02,\n",
      "        -3.2163e-02, -2.8197e-02, -5.4475e-02,  7.7480e-02,  1.3228e-01,\n",
      "        -4.7472e-02,  8.4632e-02,  2.5547e-02, -3.4490e-02, -8.1728e-02,\n",
      "         9.1207e-02,  5.8275e-03,  1.2863e-01, -1.3331e-02, -3.6641e-02,\n",
      "        -5.8843e-02,  5.8967e-02, -1.0698e-01,  1.3907e-01, -1.3259e-02,\n",
      "        -8.7982e-02, -7.4879e-02,  6.6379e-02, -2.1053e-02,  1.4107e-01,\n",
      "        -1.0160e-01, -1.1111e-01, -4.2767e-02, -1.4831e-01,  5.4159e-02,\n",
      "        -1.4913e-01, -2.3089e-02,  1.5194e-01,  1.5491e-02, -1.4185e-01,\n",
      "         5.8096e-02,  2.0699e-03,  3.6854e-02,  5.0500e-02, -4.6747e-02,\n",
      "        -5.9488e-03,  1.0648e-01, -1.2815e-01, -8.4211e-04,  3.8928e-02,\n",
      "        -2.0866e-02, -8.0412e-03,  5.5991e-02,  9.1247e-02, -1.3911e-01,\n",
      "         1.3721e-01, -5.6909e-02, -9.6634e-02, -1.4635e-01,  7.3759e-02,\n",
      "         1.4711e-01, -5.7070e-02, -5.9861e-02,  2.1037e-02, -6.1670e-02,\n",
      "        -4.8901e-02, -1.9954e-03,  1.9451e-01, -1.3784e-01,  1.2642e-01,\n",
      "        -1.4795e-01,  9.9879e-02,  3.6984e-02, -3.1923e-02, -1.3582e-01,\n",
      "         5.4003e-02, -7.6928e-03, -2.9329e-03,  1.9424e-01, -2.5528e-04,\n",
      "         7.3750e-02,  4.3357e-02,  6.3562e-02, -1.4393e-01, -5.7903e-02,\n",
      "         3.2249e-02, -1.8477e-02, -1.0983e-01,  1.7166e-01,  1.0049e-01,\n",
      "        -9.0256e-02,  1.1341e-01,  4.2288e-02, -1.0401e-03, -1.6779e-01,\n",
      "         8.2802e-02, -5.3941e-02,  1.8284e-03, -5.8344e-04,  8.3532e-02,\n",
      "        -1.7525e-02, -2.3756e-02, -8.2716e-02,  6.0895e-02, -1.6640e-01,\n",
      "         3.3623e-02,  6.4700e-02,  5.0722e-02,  8.0817e-02,  2.2480e-01,\n",
      "        -1.4670e-01, -1.3324e-01,  1.6592e-02,  4.8687e-02, -5.3927e-02,\n",
      "        -1.4498e-01, -8.2600e-02, -1.4261e-01, -1.1942e-02, -1.3534e-02,\n",
      "         3.3677e-03,  3.1670e-02,  2.5212e-02, -4.5288e-02, -2.2336e-02,\n",
      "        -1.0292e-01, -4.2005e-02,  5.0229e-02, -6.1796e-02,  1.3958e-01,\n",
      "        -1.1141e-02, -6.2033e-03,  1.4374e-01, -2.1762e-02, -1.0884e-01,\n",
      "        -5.9575e-02, -5.5757e-02, -1.5575e-01, -5.6297e-02,  2.5913e-01,\n",
      "        -7.1701e-02,  2.5687e-03,  5.9178e-02, -1.1603e-01, -3.7085e-02,\n",
      "        -1.0919e-02, -1.8227e-01, -1.3923e-01,  1.5664e-01, -2.7265e-02,\n",
      "         1.3327e-01, -5.2999e-02,  8.1670e-02, -9.2690e-02, -5.9331e-02,\n",
      "         1.6527e-02, -1.0694e-01, -1.0637e-02,  4.3608e-02,  1.3251e-01,\n",
      "         1.0316e-01,  2.2908e-02, -7.3523e-02,  5.8124e-02,  2.8313e-02,\n",
      "        -6.1745e-02,  9.9176e-02, -1.7280e-02,  4.8946e-02, -5.0848e-02,\n",
      "         1.1215e-01,  3.3671e-03, -1.1047e-01,  1.3350e-01,  7.9876e-02,\n",
      "        -3.9340e-02, -4.9876e-02, -6.2516e-02, -1.2915e-02,  5.9618e-02,\n",
      "         1.4237e-02, -4.4857e-02, -9.1821e-02,  2.4345e-02,  7.4726e-02,\n",
      "         1.2336e-01,  1.0910e-01,  2.3629e-01,  6.1586e-02,  6.3471e-02,\n",
      "        -1.6998e-01,  1.8545e-02,  4.5022e-02,  1.8300e-01,  7.2371e-02,\n",
      "         1.3217e-01,  8.1778e-03,  1.0253e-02, -2.4598e-02, -4.7790e-02,\n",
      "        -1.2665e-01, -6.5223e-03, -2.6463e-02,  3.2004e-02, -6.0030e-02,\n",
      "        -5.6529e-02, -6.7958e-02,  6.9051e-02, -5.2029e-02, -2.0657e-02,\n",
      "        -8.7977e-02,  4.0982e-02, -2.0531e-03, -1.2463e-01,  3.6412e-02,\n",
      "        -8.6987e-03,  4.6096e-02,  7.2024e-02, -2.1125e-01,  8.7709e-02,\n",
      "         3.5188e-02,  4.7298e-02,  2.2774e-02, -3.1049e-02,  1.9253e-02,\n",
      "        -3.1815e-02,  9.9070e-03,  3.2314e-02, -9.8031e-02,  4.4015e-02,\n",
      "        -3.9436e-02, -5.3085e-02, -1.6634e-01,  1.6482e-02,  1.0628e-01])\n",
      "tensor([[ 0.0045,  0.0479, -0.0243,  ...,  0.0017,  0.0420,  0.0303],\n",
      "        [-0.0112,  0.0099, -0.0159,  ..., -0.0154, -0.0031, -0.0407],\n",
      "        [ 0.0504, -0.0389, -0.0315,  ...,  0.0269,  0.0071, -0.0259],\n",
      "        ...,\n",
      "        [ 0.0177, -0.0305, -0.0268,  ...,  0.0076,  0.0512,  0.0038],\n",
      "        [ 0.0047,  0.0543, -0.0521,  ...,  0.0069, -0.0438, -0.0285],\n",
      "        [ 0.0054,  0.0565,  0.0435,  ..., -0.0210, -0.0063, -0.0416]])\n",
      "tensor([-0.0304, -0.0259,  0.0006, -0.0254,  0.0673,  0.0076, -0.0397, -0.0381,\n",
      "        -0.0411, -0.0570, -0.0126, -0.0166, -0.0312, -0.0345,  0.0069,  0.0278,\n",
      "        -0.0293,  0.0541,  0.1054,  0.0705,  0.0199, -0.0928,  0.0654, -0.0828,\n",
      "        -0.0079, -0.0337,  0.0607, -0.0004, -0.0502,  0.1061, -0.0520,  0.0047,\n",
      "         0.0089, -0.1322,  0.0213, -0.0380,  0.0107, -0.0041,  0.0212,  0.0564,\n",
      "        -0.0140, -0.0122, -0.0468, -0.0085,  0.0847, -0.0289, -0.0222, -0.0288,\n",
      "         0.0344,  0.0006, -0.0755, -0.1015,  0.0648, -0.0095, -0.0099, -0.0080,\n",
      "         0.0709,  0.0134, -0.0177, -0.0768, -0.0337, -0.0227,  0.0568,  0.0330,\n",
      "        -0.0115, -0.0334, -0.1446,  0.0177,  0.0119, -0.1012,  0.0380, -0.0203,\n",
      "        -0.0245, -0.0384, -0.0106, -0.0129,  0.0492, -0.0038,  0.0255,  0.0551,\n",
      "         0.0090, -0.0741,  0.0491, -0.0539, -0.0135, -0.0647, -0.0437, -0.0484,\n",
      "        -0.1294, -0.0757,  0.0880, -0.0575, -0.0074,  0.0407,  0.0468, -0.1713,\n",
      "        -0.0152,  0.0428,  0.0776, -0.0802,  0.0363,  0.0770, -0.0689, -0.0245,\n",
      "         0.0263, -0.0031,  0.0788,  0.0051,  0.0207, -0.0369, -0.0171, -0.0236,\n",
      "        -0.1416, -0.0010, -0.0200, -0.0266, -0.0494, -0.0361,  0.0471, -0.0189,\n",
      "        -0.0166, -0.0037, -0.0313, -0.0034,  0.0139, -0.0441,  0.0146, -0.0140,\n",
      "         0.0315,  0.0461, -0.1807,  0.0696,  0.0514, -0.0909, -0.0622, -0.0036,\n",
      "         0.0152,  0.0432, -0.0044, -0.0188,  0.0016, -0.0570,  0.1194,  0.0533,\n",
      "        -0.0242, -0.0587,  0.0413, -0.0508,  0.0362,  0.0680,  0.0425,  0.0300,\n",
      "        -0.0651, -0.0587,  0.0446, -0.0082, -0.0307,  0.0430,  0.0897, -0.0247,\n",
      "        -0.0077, -0.0530,  0.0051, -0.0199, -0.0196,  0.0013, -0.0278,  0.0409,\n",
      "         0.0101, -0.0332,  0.0453, -0.0542, -0.0219, -0.0277, -0.0403,  0.0150,\n",
      "        -0.0187, -0.0579, -0.0675,  0.0321,  0.0252,  0.0177, -0.0123,  0.0534,\n",
      "        -0.0099,  0.0033,  0.0732,  0.0472, -0.0346, -0.0547,  0.0227, -0.0831,\n",
      "         0.0696, -0.0329,  0.0606,  0.0225, -0.1579,  0.0851,  0.0176, -0.0045,\n",
      "        -0.0773,  0.1072,  0.0544,  0.0157, -0.1035,  0.0164,  0.0237, -0.0281,\n",
      "        -0.0105,  0.0016, -0.0124,  0.0711,  0.0130, -0.1629,  0.0423, -0.0298,\n",
      "        -0.0368, -0.0352,  0.0448,  0.0215,  0.0625, -0.1029,  0.0150,  0.0519,\n",
      "        -0.0206,  0.0098,  0.0134,  0.0355, -0.0206,  0.1163, -0.0632,  0.0625,\n",
      "         0.0359, -0.1378, -0.0287, -0.0469,  0.0124, -0.1485, -0.0760,  0.0556,\n",
      "         0.0716, -0.1722,  0.0267,  0.0544,  0.0016, -0.0019, -0.1193,  0.0520,\n",
      "        -0.0083, -0.0526,  0.0921, -0.0146,  0.0465, -0.1075, -0.0407, -0.0494,\n",
      "        -0.0080,  0.1083, -0.0139,  0.0290,  0.0757, -0.0482, -0.0794, -0.0409,\n",
      "        -0.0278,  0.1029, -0.0326, -0.0264, -0.0257, -0.0650, -0.0816, -0.0036,\n",
      "        -0.0316,  0.0143, -0.0356,  0.0149, -0.0155,  0.0578,  0.0381,  0.0025,\n",
      "         0.0231, -0.0380,  0.0594,  0.0226, -0.0200,  0.0804,  0.0841, -0.0577,\n",
      "         0.0182, -0.0517, -0.1953, -0.0243, -0.0247, -0.0274,  0.0359, -0.0899,\n",
      "         0.0156,  0.0212, -0.0534, -0.0315,  0.0624, -0.0055, -0.0245,  0.0303,\n",
      "        -0.0021, -0.0571, -0.0627,  0.0491,  0.1401,  0.1133, -0.0540, -0.0852,\n",
      "        -0.0402,  0.0331,  0.0440,  0.0845,  0.0642, -0.0145, -0.0297, -0.2073,\n",
      "        -0.1083,  0.0754, -0.0226,  0.0336, -0.0243, -0.1141, -0.0795,  0.0166,\n",
      "        -0.0037, -0.0360,  0.0333,  0.0233,  0.0533, -0.0403, -0.1543,  0.0134,\n",
      "         0.0880, -0.0506,  0.0095,  0.0206,  0.0316, -0.0759, -0.0027, -0.0014,\n",
      "         0.0044,  0.0700, -0.0142, -0.0792,  0.0037,  0.0897])\n",
      "tensor([0.9773, 1.0180, 0.9657, 0.9664, 0.9859, 0.9889, 1.0059, 0.9501, 1.0717,\n",
      "        1.0873, 1.0021, 0.9841, 0.9734, 0.9902, 0.9558, 1.0329, 1.0050, 1.0458,\n",
      "        0.9666, 0.9482, 0.9712, 1.1008, 0.9727, 1.0203, 0.9933, 0.9694, 0.9899,\n",
      "        1.0129, 1.0232, 1.0106, 0.9734, 0.9549, 1.0045, 1.0593, 0.9628, 0.9459,\n",
      "        0.9828, 0.9327, 1.0186, 1.0187, 0.9979, 0.9824, 1.0711, 1.0706, 0.9905,\n",
      "        0.9849, 0.9892, 0.9855, 0.9690, 0.9776, 1.0665, 0.9744, 1.0045, 0.9832,\n",
      "        0.9740, 0.9855, 0.9908, 1.0356, 0.9873, 1.0128, 0.9729, 1.0878, 0.9827,\n",
      "        0.9961, 0.9564, 0.9539, 1.0524, 1.0281, 1.0108, 1.0142, 0.9549, 0.9774,\n",
      "        1.0707, 0.9920, 0.9589, 0.9830, 1.0264, 0.9766, 0.9733, 0.9637, 1.0279,\n",
      "        1.0677, 0.9805, 1.0235, 0.9811, 1.0182, 0.9820, 1.0378, 1.1031, 1.0191,\n",
      "        0.9674, 1.1976, 0.9978, 0.9481, 1.0194, 1.0284, 0.9988, 0.9349, 0.9895,\n",
      "        1.0412, 0.9863, 0.9674, 1.0434, 0.9988, 0.9690, 0.9823, 1.0015, 0.9412,\n",
      "        1.0693, 1.0450, 1.0368, 1.0766, 1.0858, 0.9559, 0.9082, 0.9808, 1.0013,\n",
      "        0.9810, 0.9779, 0.9855, 0.9828, 1.1215, 0.9613, 1.0408, 1.1043, 0.9883,\n",
      "        1.0107, 0.9640, 0.9663, 0.9802, 1.0189, 0.9814, 0.9523, 1.0413, 0.9916,\n",
      "        0.9903, 1.0234, 0.9914, 0.9556, 0.9892, 1.1197, 1.0289, 0.9727, 0.9704,\n",
      "        0.9506, 0.9940, 1.0009, 0.9988, 0.9642, 1.0177, 0.9516, 0.9872, 1.0066,\n",
      "        0.9606, 0.9954, 0.9653, 0.9158, 1.1389, 0.9857, 0.9738, 0.9574, 0.9989,\n",
      "        1.0022, 1.0289, 1.0337, 1.0204, 0.9695, 0.9774, 0.9992, 0.9685, 1.0588,\n",
      "        1.0037, 0.9411, 1.0685, 1.0302, 1.0028, 0.9778, 1.0043, 0.9845, 0.9650,\n",
      "        0.9603, 1.0447, 1.0437, 1.0170, 0.9762, 0.9627, 0.9966, 0.9692, 1.0182,\n",
      "        0.9715, 0.9788, 0.9902, 1.0042, 0.9594, 0.9882, 1.0183, 0.9993, 0.9718,\n",
      "        0.9785, 0.9869, 1.0187, 0.9740, 1.0059, 0.9994, 1.0186, 0.9648, 0.9907,\n",
      "        0.9893, 0.9657, 0.9990, 0.9323, 0.9639, 1.0256, 1.0827, 1.0057, 1.0061,\n",
      "        0.9818, 0.9609, 0.9498, 1.0053, 0.9558, 1.0565, 0.9810, 0.9907, 0.9615,\n",
      "        0.9580, 1.0378, 0.9673, 0.9524, 0.9887, 1.0312, 0.9869, 0.9338, 1.1124,\n",
      "        0.9954, 0.9752, 1.0069, 1.0399, 0.9764, 0.9713, 1.0072, 1.0681, 1.0491,\n",
      "        1.0006, 0.9871, 0.9931, 0.9556, 1.0069, 0.9974, 1.0354, 1.0055, 1.0101,\n",
      "        0.9754, 1.0314, 1.0016, 0.9906, 0.9716, 0.9668, 1.0110, 0.9092, 0.9737,\n",
      "        0.9893, 1.0221, 0.9898, 1.0187, 0.9942, 1.0067, 0.9789, 0.9605, 0.9899,\n",
      "        1.0691, 0.9645, 1.0108, 0.9953, 0.9998, 0.9396, 0.9452, 0.9772, 0.9839,\n",
      "        0.9492, 1.0158, 0.9458, 0.9996, 0.9598, 0.9885, 0.9549, 1.0054, 1.0739,\n",
      "        0.9731, 1.0789, 1.1329, 1.0086, 1.0475, 1.0289, 1.0332, 1.0420, 0.9626,\n",
      "        0.9424, 1.0043, 0.9748, 0.9579, 1.0684, 1.0307, 0.9588, 0.9748, 1.0065,\n",
      "        0.9850, 0.9859, 1.0342, 0.9817, 0.9908, 0.9846, 0.9733, 0.9588, 0.9485,\n",
      "        1.0645, 1.0141, 1.0070, 1.1046, 1.1741, 1.0385, 0.9683, 1.0114, 0.9335,\n",
      "        0.9741, 1.1568, 1.1207, 1.0231, 1.0103, 0.9802, 0.9571, 0.9520, 0.9869,\n",
      "        0.9984, 1.0452, 1.0117, 0.9749, 1.0114, 0.9913, 0.9860, 0.9722, 0.9980,\n",
      "        0.9742, 0.9794, 0.9306, 0.9517, 0.9469, 1.0021, 0.9977, 0.9707])\n",
      "tensor([-0.0981, -0.1447,  0.0858,  0.0857,  0.0792,  0.0315,  0.0168, -0.0729,\n",
      "         0.0654,  0.0756,  0.0943, -0.0968, -0.1231, -0.1121,  0.0367, -0.1001,\n",
      "        -0.0402, -0.1235, -0.0498, -0.0215,  0.0777,  0.0414,  0.0203,  0.0377,\n",
      "        -0.1197, -0.0743,  0.1209, -0.0150, -0.0553,  0.0143, -0.0307, -0.0098,\n",
      "         0.0031, -0.1200, -0.0469,  0.0359, -0.0814,  0.0627, -0.0880, -0.0736,\n",
      "        -0.0101, -0.0163,  0.0216,  0.0166,  0.0747,  0.0865,  0.1388,  0.0492,\n",
      "         0.0340,  0.1141, -0.0075,  0.0336,  0.0557,  0.0406, -0.1004, -0.0900,\n",
      "         0.0335,  0.0148, -0.0056, -0.0401, -0.0708,  0.0655, -0.0283, -0.0146,\n",
      "        -0.0911,  0.0502, -0.0892,  0.1004,  0.0131, -0.1103,  0.1092, -0.0285,\n",
      "         0.0258,  0.0412, -0.0049,  0.0454, -0.0017,  0.1613,  0.0095,  0.1778,\n",
      "         0.0621, -0.0085, -0.0204, -0.0685, -0.0605, -0.0300, -0.0391,  0.1249,\n",
      "        -0.0720,  0.0903,  0.0437, -0.0250,  0.0491, -0.0487,  0.0571, -0.0659,\n",
      "         0.0130, -0.0342,  0.0984,  0.0754,  0.0509,  0.1435, -0.0024, -0.0186,\n",
      "         0.0188,  0.0220, -0.0937, -0.0261,  0.0018, -0.0124,  0.0376, -0.0957,\n",
      "        -0.1117,  0.0366, -0.0006, -0.0930,  0.0086, -0.0678,  0.1132,  0.0272,\n",
      "         0.0050, -0.0173, -0.1866,  0.0477, -0.0935, -0.0240,  0.0280, -0.1194,\n",
      "        -0.0565, -0.0578, -0.0674, -0.0688, -0.0259,  0.0385, -0.0942,  0.0284,\n",
      "        -0.0206,  0.1064,  0.0614, -0.0139, -0.0218, -0.1134,  0.0802,  0.0083,\n",
      "         0.0271, -0.1470, -0.0353, -0.0268,  0.0242,  0.0214,  0.0421,  0.1293,\n",
      "        -0.0404, -0.0633, -0.0012, -0.0991,  0.0874, -0.0036,  0.0077, -0.0232,\n",
      "        -0.0234, -0.0165,  0.1568, -0.0514,  0.0205, -0.0121, -0.0654, -0.0052,\n",
      "        -0.0491, -0.0748,  0.0240,  0.0500, -0.0049,  0.0648,  0.0817, -0.0026,\n",
      "         0.1139, -0.1146,  0.0170, -0.0393,  0.0365, -0.0167,  0.0531, -0.0074,\n",
      "        -0.0772,  0.0809,  0.0567,  0.0528, -0.0310,  0.0361,  0.1002, -0.1192,\n",
      "        -0.0128,  0.0864,  0.0826, -0.0320,  0.0506, -0.0253, -0.0090, -0.0159,\n",
      "         0.0648, -0.0650, -0.0275, -0.0258, -0.0523, -0.0038, -0.0532,  0.0810,\n",
      "         0.0442, -0.0270,  0.0093,  0.0249,  0.1049,  0.0393, -0.0028, -0.0350,\n",
      "        -0.0285,  0.0526,  0.0231, -0.0878,  0.0239,  0.0573,  0.0138,  0.0188,\n",
      "         0.0466,  0.0260, -0.0127, -0.0833,  0.1594,  0.0759, -0.0604,  0.0546,\n",
      "        -0.0071, -0.0754,  0.0630, -0.0357, -0.0226, -0.2310,  0.0098,  0.0182,\n",
      "        -0.0724,  0.0173,  0.1451, -0.0251,  0.0810,  0.0097, -0.1290, -0.0591,\n",
      "        -0.0549,  0.0751, -0.0862, -0.0156, -0.0534, -0.1199, -0.0837, -0.1032,\n",
      "         0.0306, -0.0107, -0.0436,  0.0070,  0.0044, -0.0763, -0.0839,  0.0097,\n",
      "        -0.0509, -0.0051, -0.0104, -0.0435,  0.1566, -0.1259,  0.1162,  0.0427,\n",
      "        -0.0356,  0.0227,  0.0845, -0.0675, -0.0741,  0.0307,  0.0206,  0.0084,\n",
      "         0.0643,  0.0195,  0.0107, -0.0696,  0.0410,  0.0042,  0.0275, -0.0082,\n",
      "         0.0689,  0.0087,  0.1199,  0.0123,  0.0680,  0.0649,  0.0720, -0.0175,\n",
      "         0.0771, -0.0680, -0.0118, -0.0700,  0.0816, -0.0166,  0.0826,  0.1277,\n",
      "         0.0515, -0.0849,  0.0226,  0.0588,  0.0013, -0.1070, -0.0513, -0.0154,\n",
      "        -0.0392,  0.0598,  0.0029,  0.0473, -0.0660, -0.0715,  0.0610,  0.0209,\n",
      "         0.0140, -0.0459, -0.0520,  0.0216,  0.0028, -0.0537, -0.0282,  0.0597,\n",
      "        -0.0679, -0.1188,  0.0381,  0.0701, -0.0548, -0.0148,  0.0219, -0.0056,\n",
      "         0.0664,  0.0441, -0.0045,  0.0527, -0.0439,  0.0737,  0.1422,  0.0320,\n",
      "         0.0540,  0.0893,  0.0403, -0.0629,  0.0502,  0.0888])\n",
      "tensor([[ 0.0206,  0.0586, -0.0106,  ..., -0.0037,  0.0276, -0.0502],\n",
      "        [ 0.0392, -0.0088,  0.0330,  ...,  0.0184, -0.0493,  0.0568],\n",
      "        [-0.0090, -0.0361, -0.0015,  ...,  0.0018, -0.0065,  0.0037],\n",
      "        ...,\n",
      "        [-0.0088,  0.0149,  0.0138,  ..., -0.0069,  0.0211,  0.0133],\n",
      "        [-0.0255,  0.0366, -0.0025,  ..., -0.0355, -0.0220,  0.0022],\n",
      "        [ 0.0318,  0.0662,  0.0542,  ...,  0.0263,  0.0183, -0.0109]])\n",
      "tensor([-0.0720, -0.0885,  0.0625, -0.0260,  0.0721, -0.0023, -0.0389,  0.0767,\n",
      "        -0.0258, -0.1227,  0.0468,  0.0079,  0.0777, -0.0407,  0.0593,  0.0539,\n",
      "         0.0205,  0.0290,  0.0422,  0.0405,  0.0446, -0.0914,  0.0093, -0.0645,\n",
      "        -0.0303,  0.0303,  0.0347,  0.0379,  0.0383,  0.0005, -0.0035,  0.0052,\n",
      "         0.0606, -0.0305, -0.0146,  0.0429,  0.0107, -0.0187,  0.0583,  0.0173,\n",
      "         0.0677, -0.0616,  0.0253, -0.0033,  0.0542,  0.0097,  0.0112,  0.0363,\n",
      "         0.0560, -0.0436,  0.1094, -0.0219,  0.0424,  0.0415,  0.0027,  0.0186,\n",
      "         0.0473,  0.0023, -0.0708,  0.0295, -0.0069,  0.0356,  0.0562, -0.0656,\n",
      "         0.0390,  0.0706, -0.1649,  0.0204,  0.0958, -0.0100,  0.0053,  0.0141,\n",
      "         0.0155, -0.0022, -0.0050,  0.1083,  0.0767,  0.0387,  0.0132,  0.0727,\n",
      "         0.1003,  0.0316,  0.0484,  0.0101,  0.0230, -0.0057,  0.0682,  0.0148,\n",
      "        -0.0892, -0.0353,  0.0422,  0.0310, -0.0262,  0.0361,  0.0023, -0.1123,\n",
      "        -0.1262, -0.0662, -0.0110, -0.0543,  0.0741,  0.0337,  0.0665,  0.0021,\n",
      "        -0.0411,  0.0445,  0.0647,  0.0333, -0.0271, -0.1226, -0.0169, -0.0555,\n",
      "         0.0055, -0.0108, -0.0274, -0.0330, -0.0263,  0.0460,  0.0926,  0.0037,\n",
      "        -0.0746, -0.0133,  0.0051, -0.0338, -0.0204,  0.0627,  0.0134, -0.0173,\n",
      "         0.0462,  0.0211, -0.1683, -0.0380, -0.0011, -0.1388, -0.0297,  0.0363,\n",
      "         0.0161,  0.0037,  0.0330, -0.0626,  0.0347,  0.0126,  0.0425,  0.0228,\n",
      "         0.0024,  0.0116,  0.0527,  0.0236, -0.0331,  0.0776,  0.0648,  0.0632,\n",
      "         0.0218,  0.0173,  0.0761,  0.0127,  0.0490,  0.0602,  0.0217,  0.0063,\n",
      "        -0.0204,  0.0963, -0.0152, -0.0132,  0.0216,  0.0017,  0.0326,  0.0787,\n",
      "         0.0386,  0.0067, -0.0080, -0.0184,  0.0623,  0.0043, -0.0607, -0.0383,\n",
      "        -0.0195, -0.1301, -0.0003,  0.0522,  0.0050,  0.0864,  0.0999,  0.0511,\n",
      "         0.0364, -0.0083,  0.0826,  0.0396,  0.0424,  0.0276, -0.0024, -0.0824,\n",
      "         0.0698,  0.0045,  0.0694,  0.0929, -0.1128,  0.0569, -0.0332,  0.0006,\n",
      "        -0.0434,  0.0202,  0.0575,  0.0257, -0.0956, -0.0036, -0.0017,  0.0144,\n",
      "        -0.0522, -0.0140,  0.0454,  0.0170,  0.0542, -0.1030,  0.0767, -0.0700,\n",
      "        -0.0798, -0.0221, -0.0162, -0.0140,  0.0166, -0.1165, -0.0437,  0.0488,\n",
      "         0.0213,  0.0554, -0.0431,  0.0579,  0.0465,  0.0321,  0.0322,  0.0257,\n",
      "        -0.0191, -0.0721,  0.0538, -0.0756,  0.0200,  0.0329, -0.0714,  0.0236,\n",
      "         0.0283, -0.1400, -0.0463,  0.0041,  0.0066, -0.0171, -0.0407,  0.0704,\n",
      "         0.0813,  0.0251,  0.0022,  0.0231,  0.0393, -0.0236,  0.0775, -0.0562,\n",
      "         0.0427, -0.0113,  0.0104,  0.0560, -0.0443, -0.0455, -0.0931, -0.0176,\n",
      "        -0.0755,  0.1408,  0.0372, -0.0503, -0.0040, -0.0410,  0.0679, -0.0018,\n",
      "         0.0277, -0.0299, -0.0869,  0.0617,  0.0132,  0.0652,  0.0316,  0.0191,\n",
      "         0.0769, -0.0066,  0.0884, -0.0073, -0.0923, -0.0182,  0.0424,  0.0037,\n",
      "        -0.0120,  0.0510, -0.0211, -0.0378,  0.1332, -0.0468,  0.0524,  0.0493,\n",
      "        -0.0325,  0.0047,  0.0095,  0.0044,  0.0990, -0.0559, -0.0379,  0.0937,\n",
      "         0.0312, -0.0159,  0.0361,  0.0325,  0.1214,  0.0470, -0.0960,  0.0297,\n",
      "         0.0068,  0.0501, -0.0023,  0.0809,  0.0420,  0.0040, -0.0105,  0.0095,\n",
      "        -0.0206, -0.0619, -0.0602,  0.0799, -0.0731, -0.0937, -0.1228, -0.0057,\n",
      "        -0.0017,  0.0359,  0.0469,  0.0217,  0.0471,  0.0480,  0.0280, -0.0177,\n",
      "         0.0769,  0.0271,  0.0708,  0.0151,  0.0058,  0.0381, -0.0405,  0.0244,\n",
      "         0.0114,  0.1012,  0.0775, -0.0390,  0.0427,  0.1021])\n",
      "tensor([0.9961, 0.9584, 0.9426, 0.9500, 0.9654, 0.9326, 0.9693, 0.9571, 1.0326,\n",
      "        1.0008, 0.9414, 0.9597, 0.9726, 0.9570, 0.9361, 0.9946, 0.9409, 0.9289,\n",
      "        0.9575, 0.9475, 0.9542, 1.0505, 0.9575, 0.9725, 0.9631, 0.9650, 0.9311,\n",
      "        0.9729, 0.9574, 0.9538, 0.9619, 0.9862, 0.9742, 0.9685, 0.9466, 0.9448,\n",
      "        0.9627, 1.0173, 0.9651, 0.9649, 0.9549, 0.9689, 1.0485, 1.0501, 0.9455,\n",
      "        0.9671, 0.9883, 0.9359, 0.9414, 1.0024, 0.9736, 0.9211, 0.9498, 0.9460,\n",
      "        0.9549, 0.9440, 0.9352, 0.9972, 0.9706, 0.9764, 0.9477, 0.9768, 0.9382,\n",
      "        1.0597, 0.9656, 0.9437, 1.0058, 0.9800, 0.9392, 0.9844, 0.9473, 0.9609,\n",
      "        0.9557, 0.9668, 0.9589, 0.9656, 0.9699, 0.9720, 0.9476, 0.9293, 0.9494,\n",
      "        0.9957, 0.9568, 0.9883, 0.9945, 0.9470, 0.9572, 1.0071, 1.0400, 0.9659,\n",
      "        0.9459, 1.0267, 0.9769, 0.9457, 0.9499, 1.0073, 1.0144, 0.9699, 0.9541,\n",
      "        1.0645, 0.9565, 0.9775, 0.9354, 0.9681, 1.0138, 0.9370, 0.9666, 0.9526,\n",
      "        1.0948, 1.1175, 1.0283, 1.0012, 1.0328, 0.9434, 0.9504, 0.9669, 0.9906,\n",
      "        0.9699, 0.9294, 0.9728, 0.9584, 1.0057, 0.9492, 0.9797, 1.0070, 0.9496,\n",
      "        0.9728, 0.9578, 0.9453, 0.9598, 1.0352, 0.9408, 0.9566, 0.9612, 0.9955,\n",
      "        0.9683, 0.9528, 0.9340, 0.9494, 1.0311, 1.0197, 0.9610, 0.9530, 0.9629,\n",
      "        0.9547, 1.0039, 0.9956, 0.9528, 0.9487, 0.9574, 0.9480, 0.9440, 0.9479,\n",
      "        0.9605, 0.9781, 0.9411, 0.9374, 1.0678, 0.9337, 0.9386, 0.9323, 0.9647,\n",
      "        0.9652, 0.9995, 0.9330, 0.9550, 0.9483, 0.9587, 0.9702, 0.9618, 0.9714,\n",
      "        1.0259, 0.9614, 1.0171, 0.9871, 0.9653, 0.9343, 0.9761, 0.9656, 0.9384,\n",
      "        0.9531, 1.0183, 0.9639, 0.9621, 0.9725, 0.9151, 0.9494, 0.9403, 0.9404,\n",
      "        0.9963, 0.9673, 0.9601, 0.9609, 0.9369, 0.9661, 0.9636, 1.0350, 0.9416,\n",
      "        0.9626, 0.9570, 0.9681, 0.9482, 0.9673, 0.9595, 0.9817, 1.0039, 0.9683,\n",
      "        0.9901, 0.9777, 0.9663, 0.9413, 0.9686, 0.9010, 1.0026, 0.9611, 0.9661,\n",
      "        0.9653, 0.9400, 0.9407, 0.9717, 0.9264, 0.9965, 0.9436, 0.9374, 0.9206,\n",
      "        0.9180, 0.9930, 0.9620, 0.9190, 0.9621, 0.9978, 0.9543, 0.9716, 1.0587,\n",
      "        0.9357, 1.0004, 0.9297, 0.9591, 0.9870, 0.9477, 0.9598, 1.0270, 1.0004,\n",
      "        1.0188, 0.9497, 0.9463, 0.9714, 1.0221, 0.9971, 0.9334, 0.9290, 0.9624,\n",
      "        0.9527, 0.9739, 0.9642, 0.9659, 0.9688, 0.8866, 0.9741, 0.9200, 0.9545,\n",
      "        0.9719, 1.0034, 0.9612, 0.9598, 0.9589, 0.9446, 0.9985, 0.9667, 0.9904,\n",
      "        0.9732, 0.9476, 0.9652, 0.9209, 0.9693, 0.9834, 0.9082, 0.9768, 0.9288,\n",
      "        0.9520, 0.9773, 0.9791, 0.9521, 0.9873, 0.9785, 0.9132, 0.9402, 0.9927,\n",
      "        0.9502, 1.0130, 0.9530, 0.9596, 0.9704, 0.9623, 0.9619, 0.9532, 0.9428,\n",
      "        0.9142, 0.9603, 0.9439, 0.9632, 0.9913, 0.9740, 0.9680, 0.9555, 0.9783,\n",
      "        0.9540, 0.9325, 0.9536, 0.9366, 0.9504, 0.9495, 0.9548, 0.9590, 1.0076,\n",
      "        0.9690, 0.9622, 0.9678, 0.9899, 0.9737, 0.9648, 0.9095, 0.9605, 0.9262,\n",
      "        1.0008, 1.0936, 1.0966, 0.9631, 1.0013, 0.9533, 0.9690, 0.9210, 0.9362,\n",
      "        0.9558, 0.9406, 1.0009, 0.9723, 0.9568, 0.9492, 0.9617, 0.9689, 0.9516,\n",
      "        0.9673, 0.9513, 0.9387, 0.9292, 0.9580, 0.9734, 0.9472, 0.9582])\n",
      "tensor([ 7.1255e-02, -1.1446e-01, -1.4952e-01, -4.9643e-02,  1.1153e-01,\n",
      "        -1.0721e-01,  1.6778e-01,  1.9671e-02,  1.3573e-01, -6.6729e-04,\n",
      "        -1.8647e-01,  1.6062e-01,  5.7368e-02,  1.0469e-01,  1.5631e-01,\n",
      "        -1.1661e-01, -1.1810e-01,  6.6659e-02, -2.0056e-02, -1.4072e-01,\n",
      "         5.6093e-02,  7.6967e-02,  8.6200e-02, -1.4530e-01, -1.3944e-01,\n",
      "        -7.2337e-02, -7.7419e-02, -6.2910e-02, -5.2494e-02,  1.3175e-02,\n",
      "         1.2075e-01, -1.0314e-01,  3.7735e-02, -2.0240e-02, -1.0003e-01,\n",
      "         1.5289e-01, -1.1382e-01, -4.4267e-03, -4.8755e-02,  3.1001e-02,\n",
      "        -1.0690e-01,  2.3532e-02, -1.5242e-01, -2.3668e-02, -1.1323e-01,\n",
      "        -2.4979e-03,  9.0862e-02, -1.3700e-01, -7.3049e-02,  1.0472e-01,\n",
      "        -3.1433e-02, -1.5827e-02,  1.3542e-01, -1.7294e-01,  1.3904e-01,\n",
      "        -1.4445e-01, -1.9507e-01,  1.5866e-01, -8.8607e-02,  1.6912e-01,\n",
      "         7.4109e-02,  1.4530e-01, -7.7246e-02,  9.5019e-02,  1.2795e-01,\n",
      "         2.7948e-02,  1.0764e-01, -9.3208e-02,  1.0894e-01, -1.0231e-02,\n",
      "        -1.7440e-01,  1.5083e-02, -1.6680e-01, -8.5034e-02, -3.8688e-02,\n",
      "        -7.4587e-02,  3.2319e-02, -4.4447e-02, -1.2976e-01, -1.0644e-01,\n",
      "        -4.1961e-02,  5.1871e-02,  1.1935e-01, -4.3845e-02, -4.0445e-02,\n",
      "        -9.8009e-03, -1.6025e-01,  5.4008e-02,  1.3999e-01,  9.2516e-02,\n",
      "         1.3982e-02, -4.9031e-02,  1.1082e-01,  9.0290e-02, -3.0474e-02,\n",
      "         1.1164e-01, -7.7280e-02,  7.0085e-02,  1.9428e-02,  5.5313e-02,\n",
      "         1.1106e-01, -1.1883e-02,  3.7335e-02, -7.9301e-02,  1.0811e-01,\n",
      "        -1.1222e-01,  1.5074e-01, -3.5795e-02,  2.7488e-02, -3.5600e-03,\n",
      "         8.4681e-02,  3.7762e-02, -9.7633e-03, -1.8905e-01, -7.1461e-02,\n",
      "         1.2992e-01, -1.3973e-01, -4.4679e-02, -1.0386e-01,  9.7433e-02,\n",
      "         7.8750e-02,  8.2856e-02, -1.1721e-01, -4.1345e-02,  9.3564e-02,\n",
      "        -9.2854e-02,  1.1935e-01, -1.1652e-01,  1.6174e-02,  1.2212e-01,\n",
      "         8.6132e-02, -1.3363e-01,  8.2934e-02, -9.2710e-02, -3.3534e-02,\n",
      "         8.3959e-02,  1.3878e-01, -1.5862e-01,  9.1869e-03,  5.9080e-02,\n",
      "         7.9278e-02,  1.7799e-01,  8.4116e-02, -1.3343e-01,  9.9810e-02,\n",
      "        -9.6545e-02,  4.7383e-02, -8.6331e-02,  7.1847e-03,  1.6491e-01,\n",
      "         1.4662e-01,  1.2823e-01, -2.2107e-02,  7.9926e-02, -1.3234e-01,\n",
      "         1.6597e-01,  1.3737e-01, -3.7415e-02,  1.4595e-01,  5.1886e-02,\n",
      "        -5.1679e-02,  8.8925e-02, -1.1383e-01, -2.4260e-02, -1.0519e-01,\n",
      "         1.7529e-01, -3.5633e-02, -3.8340e-02, -1.1919e-01,  3.9863e-02,\n",
      "        -7.1174e-02,  8.5152e-02, -6.4063e-02, -1.0907e-01,  1.3946e-02,\n",
      "        -7.5489e-02, -1.2254e-01,  1.6496e-02, -1.3728e-02, -1.0907e-01,\n",
      "        -1.2434e-01,  1.2942e-02,  3.7925e-02,  1.0458e-01,  1.1242e-02,\n",
      "        -4.5544e-02, -9.1723e-02, -6.7543e-02,  6.1198e-02,  1.5548e-01,\n",
      "        -1.1915e-01,  2.7597e-02, -1.8035e-01,  1.2251e-01,  1.4531e-01,\n",
      "         4.5695e-02,  1.2519e-01,  1.6632e-01, -9.0415e-02, -9.5918e-02,\n",
      "        -8.9977e-02, -1.7291e-02, -9.7382e-02, -1.4566e-02, -7.2189e-02,\n",
      "         1.8011e-03,  1.3028e-01,  4.5420e-02,  2.5145e-02, -9.2173e-02,\n",
      "        -5.8469e-02,  9.2367e-02, -1.1986e-01, -1.3530e-01, -1.3963e-01,\n",
      "         1.2209e-01,  5.5936e-04, -5.0808e-02, -7.4634e-02,  4.9620e-02,\n",
      "        -1.1516e-01,  1.3946e-01, -1.3667e-01,  1.4245e-02,  1.7096e-01,\n",
      "         6.4940e-03, -1.3598e-01, -1.3759e-01,  1.3729e-01,  4.7029e-02,\n",
      "        -6.9926e-02,  1.2544e-01, -5.5896e-02,  1.0131e-01, -1.4268e-01,\n",
      "        -6.6309e-02, -7.4353e-02,  1.7377e-01, -4.7109e-02, -1.3729e-02,\n",
      "        -8.0726e-03,  9.5052e-02, -1.4615e-01, -5.8619e-02, -1.2865e-01,\n",
      "        -1.2545e-01,  7.6196e-02, -1.9686e-02,  1.4760e-01,  8.0157e-02,\n",
      "         9.4014e-02, -4.0117e-02,  1.2042e-01,  1.1177e-01,  1.3027e-01,\n",
      "        -3.0185e-02, -1.2567e-01, -1.3577e-01,  1.5464e-01, -1.4710e-01,\n",
      "         4.3994e-02, -9.9803e-02, -4.5403e-02, -1.1377e-01, -8.6547e-03,\n",
      "        -2.3723e-02,  1.1733e-01, -1.7608e-01, -9.1242e-02,  1.0616e-02,\n",
      "        -8.0084e-02, -1.1333e-01, -5.4316e-02, -1.0779e-01, -1.8977e-02,\n",
      "         4.6597e-02, -3.8798e-02,  4.7470e-05,  2.6071e-02, -2.3994e-02,\n",
      "         9.1402e-02,  1.9966e-02,  7.3941e-02,  5.2774e-02, -1.7478e-02,\n",
      "         1.2389e-01, -1.1391e-01,  2.6951e-02, -1.1606e-01, -1.3344e-01,\n",
      "        -1.4759e-01, -5.7651e-03, -1.4172e-01, -8.3470e-02, -8.9579e-04,\n",
      "         9.7065e-02, -7.3963e-02,  1.5741e-01, -1.3600e-01,  4.3365e-03,\n",
      "        -3.8324e-02,  9.2979e-02,  8.6552e-02,  4.5212e-02, -1.2754e-01,\n",
      "         1.2311e-01,  1.4091e-01, -1.7458e-01,  1.0042e-01,  4.4123e-02,\n",
      "         1.0499e-01, -1.0710e-01, -7.5058e-02,  5.3561e-02, -2.5272e-02,\n",
      "        -5.1344e-02, -9.7772e-02,  1.6128e-01, -9.1485e-02,  1.0397e-01,\n",
      "         1.2419e-02, -2.3559e-02, -8.6567e-02,  1.3798e-01,  8.0930e-02,\n",
      "        -4.8980e-02, -8.7553e-02, -1.5975e-01,  3.0054e-02, -3.2420e-02,\n",
      "         2.0201e-02,  7.8407e-02, -1.3206e-01, -6.7589e-03,  4.9661e-02,\n",
      "         1.3081e-01, -1.4031e-01, -1.8108e-01,  1.5774e-01, -1.2043e-01,\n",
      "        -7.0231e-02,  1.2344e-01,  1.4412e-01,  6.9671e-03, -9.3140e-02,\n",
      "        -1.1692e-01, -1.0187e-01,  1.2905e-01,  7.2723e-03,  1.6543e-01])\n",
      "tensor([[ 4.9389e-04, -3.6792e-02, -2.1432e-02,  ..., -1.9962e-02,\n",
      "         -5.2565e-03,  1.6962e-02],\n",
      "        [ 2.0479e-03,  1.6671e-03, -1.4008e-03,  ..., -3.2802e-02,\n",
      "         -3.2941e-03,  2.8445e-02],\n",
      "        [-6.1091e-02,  2.4868e-02, -1.1177e-02,  ..., -1.0235e-02,\n",
      "         -1.8755e-02, -2.2258e-04],\n",
      "        ...,\n",
      "        [ 2.3627e-02, -1.8557e-02, -3.2102e-02,  ...,  4.4563e-02,\n",
      "          2.9497e-02,  1.1738e-02],\n",
      "        [ 5.0182e-05,  5.9447e-03, -3.5349e-03,  ...,  5.9359e-03,\n",
      "          1.6808e-02,  1.7560e-02],\n",
      "        [ 5.9696e-03, -1.0979e-02, -1.9197e-02,  ...,  6.1531e-02,\n",
      "         -2.2316e-02,  3.5027e-02]])\n",
      "tensor([ 0.0116, -0.0288,  0.0308,  0.0226,  0.2309,  0.1195,  0.1605,  0.1157])\n",
      "tensor([[-0.0784, -0.1295, -0.5098,  0.0275],\n",
      "        [-0.2481,  0.1075, -0.2494,  0.0249],\n",
      "        [ 0.1772,  0.2915,  0.1700, -0.1111],\n",
      "        ...,\n",
      "        [ 0.4124,  0.3857, -0.4344, -0.0914],\n",
      "        [-0.3666, -0.3978,  0.3891, -0.0222],\n",
      "        [ 0.2643,  0.2642,  0.4051, -0.1835]])\n",
      "tensor([-4.3020e-02,  2.9969e-01,  6.5399e-02,  3.0189e-01, -5.0614e-01,\n",
      "         3.7838e-01, -4.2457e-01, -2.2316e-01,  1.9417e-01,  3.0755e-01,\n",
      "        -1.8473e-01,  4.2207e-01, -1.0232e-01, -1.4918e-01, -2.6085e-01,\n",
      "         3.2919e-01,  1.6166e-01, -1.4737e-01, -4.7426e-01, -4.7206e-01,\n",
      "         5.2078e-01,  1.3810e-01, -2.7125e-01,  1.5792e-01, -4.7280e-01,\n",
      "         7.3925e-02,  1.8158e-01, -1.4815e-02, -2.8621e-01, -2.0399e-01,\n",
      "         4.1990e-02, -1.1153e-01,  3.2641e-01, -4.2025e-01, -4.5760e-02,\n",
      "         4.0333e-01,  4.8967e-01, -6.3954e-02, -2.1781e-01,  3.8280e-01,\n",
      "        -2.6189e-01, -2.7963e-02,  3.6660e-01,  1.2413e-02,  1.3932e-01,\n",
      "         4.9994e-01,  3.8468e-01, -1.4283e-01,  1.2342e-01, -4.6008e-01,\n",
      "        -4.6035e-01, -8.6044e-02,  3.2241e-02, -2.3757e-01,  8.4951e-02,\n",
      "        -2.4551e-01,  2.3315e-01,  6.3135e-02,  2.4338e-01, -4.4695e-02,\n",
      "         2.6393e-01,  4.6519e-01, -4.8289e-01,  3.4122e-01,  1.7276e-01,\n",
      "        -3.0560e-01, -4.5741e-01, -4.6753e-01,  2.6667e-01,  1.4752e-01,\n",
      "        -2.4959e-01,  2.2586e-01, -4.6134e-01, -1.4954e-01,  5.1866e-01,\n",
      "        -4.8048e-01, -4.0899e-01, -1.7042e-01,  3.4021e-01,  4.9576e-01,\n",
      "        -4.2467e-01,  3.9106e-01, -2.9685e-01,  5.6869e-02,  1.3299e-01,\n",
      "         9.8934e-02,  1.5276e-01, -7.8478e-02,  4.5528e-01,  3.0151e-02,\n",
      "        -4.9500e-01,  3.0414e-01,  1.7387e-01,  4.5944e-04, -3.8290e-01,\n",
      "        -2.7455e-02, -1.4940e-01,  3.8179e-01, -2.5497e-01,  2.6123e-02,\n",
      "         4.3612e-01, -1.9063e-01,  1.9382e-01, -5.8208e-02,  9.2423e-02,\n",
      "        -2.5205e-01,  8.0242e-02, -5.3147e-01,  3.5583e-01,  1.3991e-01,\n",
      "         3.4884e-01,  8.5409e-02, -3.0843e-01, -1.1506e-01, -3.4391e-01,\n",
      "         7.8779e-02, -4.4042e-01,  9.7868e-02, -2.8637e-01, -3.7152e-01,\n",
      "         8.1405e-03, -3.3772e-01, -5.1432e-01,  4.0029e-01,  7.1581e-03,\n",
      "        -3.9896e-02, -4.4091e-01,  1.9275e-01, -2.0327e-01, -1.8298e-01,\n",
      "         2.1414e-01, -3.7660e-01, -2.8724e-01, -4.7778e-01,  4.4487e-01,\n",
      "        -2.1097e-01, -2.1568e-01,  3.8005e-01, -2.9934e-01, -4.7102e-01,\n",
      "        -6.9711e-02, -3.2850e-01,  4.2776e-01,  3.7263e-02,  1.4695e-01,\n",
      "         3.4278e-01,  1.4984e-01,  2.1059e-01, -4.0187e-01,  2.5999e-01,\n",
      "        -2.4620e-01, -1.1500e-02,  3.8363e-02, -1.5345e-01, -2.0955e-01,\n",
      "         1.5547e-01, -3.0834e-01,  4.8383e-01,  1.8081e-01, -2.6497e-01,\n",
      "         3.8297e-01, -1.1881e-01, -3.5884e-01, -2.1329e-01,  4.5147e-01,\n",
      "        -2.6230e-01, -1.8329e-01, -4.8954e-01,  1.1010e-01,  3.1031e-01,\n",
      "        -1.8755e-01,  2.0964e-02, -5.4057e-03, -2.2887e-01,  2.9438e-01,\n",
      "        -2.7214e-01, -4.5021e-01, -5.2709e-01,  4.9499e-01,  1.9709e-01,\n",
      "        -3.6606e-01, -3.4032e-01, -1.8129e-01,  3.2917e-01, -1.2291e-01,\n",
      "        -4.2586e-01,  3.9982e-01, -2.7707e-01, -2.9440e-01, -8.2126e-02,\n",
      "         6.0296e-02, -3.6475e-02,  4.0823e-01,  2.4409e-01,  2.4589e-01,\n",
      "        -4.0850e-02, -2.7215e-02, -1.2572e-01, -3.5818e-02,  2.9811e-01,\n",
      "        -2.6556e-01, -3.6270e-02,  1.4641e-01,  1.0953e-01, -5.8666e-02,\n",
      "         2.1830e-01,  1.0167e-02, -3.4519e-01, -1.9280e-01,  3.7310e-01,\n",
      "         3.3991e-01,  3.5430e-01, -9.8209e-02, -5.0136e-01, -1.4529e-01,\n",
      "        -3.2692e-01, -4.8623e-01,  5.1324e-01, -3.4279e-01,  4.4396e-01,\n",
      "         2.7882e-02, -3.1055e-01, -5.0080e-01, -3.7689e-01,  4.2322e-01,\n",
      "        -4.6641e-02, -3.9868e-01, -2.9844e-01, -2.3105e-01,  3.1161e-01,\n",
      "         2.6747e-02, -5.8259e-02, -5.8371e-01,  1.6868e-01, -5.0295e-01,\n",
      "        -2.1525e-01, -2.5489e-01, -2.8370e-01,  4.1358e-01, -4.8061e-02,\n",
      "         1.1933e-01, -3.3910e-01, -4.3503e-01, -9.6355e-02,  4.3248e-01,\n",
      "         5.4411e-02, -3.6087e-01,  5.8935e-02,  4.1195e-01, -4.6014e-02,\n",
      "        -4.4776e-02,  1.1352e-01, -1.9175e-01, -4.3912e-01,  2.4847e-01,\n",
      "        -2.0782e-01,  4.2239e-01, -2.4262e-01,  4.0668e-01, -4.0237e-01,\n",
      "         2.9072e-01, -3.3332e-01, -2.9129e-01, -4.9142e-01, -5.4206e-01,\n",
      "         1.7218e-01, -2.5421e-01,  4.9640e-01, -4.4749e-02,  3.0032e-02,\n",
      "        -4.6002e-01, -4.5387e-02,  3.4294e-01, -4.4748e-02,  7.7214e-02,\n",
      "        -4.2339e-01, -1.0649e-01,  1.8151e-01,  1.3043e-01,  7.7580e-02,\n",
      "        -1.0599e-03, -5.9093e-02,  2.3774e-01, -2.8147e-01, -1.4200e-01,\n",
      "        -2.7043e-01,  1.3340e-01,  2.2301e-01, -4.5934e-03, -2.1648e-01,\n",
      "        -4.1928e-01, -3.6548e-01,  2.8747e-01, -4.8238e-01,  1.1651e-02,\n",
      "         3.0597e-01, -2.9933e-01, -4.1778e-01, -2.3436e-01, -3.5503e-01,\n",
      "         1.1685e-01,  3.1811e-01, -3.5806e-01,  1.2905e-01,  1.7959e-02,\n",
      "        -1.4593e-01,  1.3884e-01,  2.4195e-01,  2.4333e-01,  1.8740e-01,\n",
      "        -1.0046e-01,  2.5516e-01, -2.2813e-01, -4.8857e-01, -1.8231e-01,\n",
      "        -5.0858e-01,  4.3496e-01, -2.3021e-01,  4.4912e-01,  4.6785e-01,\n",
      "        -3.0700e-01, -8.5895e-03,  2.1984e-01, -5.3838e-01, -2.6413e-01,\n",
      "        -2.5318e-02,  1.2573e-01,  2.3074e-01, -1.2955e-01, -4.4345e-01,\n",
      "         2.1200e-01, -1.9676e-01, -1.4202e-01,  1.8499e-01, -4.0162e-01,\n",
      "         4.1014e-02,  4.3653e-01, -3.8940e-01,  3.3421e-02, -8.5253e-02,\n",
      "         4.4427e-01,  4.4633e-01, -4.5393e-01,  3.7066e-01, -4.0457e-01,\n",
      "         3.7730e-01, -5.3893e-01,  2.4798e-01,  2.5763e-01, -2.3542e-01])\n",
      "tensor([1.0214, 0.9607, 0.9753, 0.9525, 0.9841, 1.0175, 0.9466, 1.0020, 0.9733,\n",
      "        0.9353, 0.9889, 0.9632, 0.9799, 0.9367, 0.9546, 0.9776, 0.9271, 1.0126,\n",
      "        0.9684, 0.9806, 0.9855, 0.9571, 0.9970, 0.9661, 0.9900, 0.9763, 0.9787,\n",
      "        0.9664, 1.0212, 0.9590, 0.9766, 1.0290, 0.9634, 1.0003, 0.9690, 1.0052,\n",
      "        0.9625, 0.9661, 1.0015, 0.9565, 0.9995, 0.9442, 1.0138, 1.0041, 0.9874,\n",
      "        0.9901, 0.9443, 0.9799, 0.9638, 0.9981, 0.9909, 0.9542, 0.9780, 0.9394,\n",
      "        0.9751, 1.0121, 0.9627, 1.0053, 0.9772, 0.9654, 0.9879, 0.9595, 0.9794,\n",
      "        0.9583, 0.9640, 0.9683, 0.9291, 0.9645, 0.9467, 0.9437, 1.0086, 0.9789,\n",
      "        0.9937, 0.9638, 0.9621, 0.9702, 0.9637, 0.9546, 0.9457, 0.9364, 0.9875,\n",
      "        0.9772, 1.0080, 0.9940, 0.9943, 0.9446, 0.9418, 0.9863, 0.9592, 0.9714,\n",
      "        1.0097, 0.9746, 1.0206, 0.9791, 0.9685, 0.9607, 1.0621, 0.9502, 0.9719,\n",
      "        0.9686, 0.9776, 0.9408, 0.9587, 0.9993, 0.9898, 0.9913, 1.0089, 0.9942,\n",
      "        0.9770, 0.9643, 1.0060, 0.9728, 0.9395, 0.9816, 0.9987, 0.9799, 1.0013,\n",
      "        0.9507, 0.9725, 0.9871, 0.9726, 0.9823, 0.9817, 0.9956, 0.9648, 0.9513,\n",
      "        0.9469, 1.0043, 1.0093, 0.9838, 0.9581, 0.9980, 0.9586, 0.9341, 0.9498,\n",
      "        0.9360, 0.9692, 0.9791, 0.9952, 0.8891, 0.9517, 1.0032, 0.9788, 1.0254,\n",
      "        0.9926, 0.9951, 0.9957, 0.9889, 0.9567, 0.9878, 0.9763, 0.9736, 0.9523,\n",
      "        1.0265, 0.9872, 0.9872, 0.9862, 1.0008, 0.9674, 0.9797, 0.9618, 0.9817,\n",
      "        1.0299, 0.9613, 0.9606, 0.9636, 1.0804, 0.9932, 0.9638, 0.9713, 1.0084,\n",
      "        0.9574, 0.9995, 0.9877, 0.9436, 0.9922, 0.9414, 0.9972, 0.9651, 1.0031,\n",
      "        0.9894, 0.9650, 0.9786, 0.9754, 0.9883, 1.0024, 0.9721, 0.9772, 0.9417,\n",
      "        0.9540, 0.9689, 0.9947, 0.9573, 0.9793, 0.9658, 0.9786, 0.9807, 1.0685,\n",
      "        0.9678, 0.9633, 0.9811, 0.9694, 0.9778, 0.9784, 0.9675, 0.9522, 0.9669,\n",
      "        0.9736, 0.9887, 0.9506, 0.9556, 1.0429, 0.9548, 0.9908, 0.9534, 0.9973,\n",
      "        0.9722, 0.9594, 1.0234, 0.9782, 0.9918, 1.0366, 0.9978, 1.0172, 0.9702,\n",
      "        0.9470, 1.0002, 1.0043, 1.0556, 0.9546, 0.9626, 0.9640, 1.0128, 0.9227,\n",
      "        1.0228, 0.9630, 1.0923, 0.9534, 0.9497, 0.9575, 0.9307, 0.9842, 0.9799,\n",
      "        0.9514, 0.9744, 0.9964, 0.9791, 0.9983, 0.9338, 1.0304, 0.9687, 0.9793,\n",
      "        0.9414, 0.9556, 0.9418, 0.9726, 1.0133, 0.9682, 0.9624, 0.9522, 0.9750,\n",
      "        0.9746, 0.9742, 0.9715, 0.9995, 0.9534, 0.9812, 0.9298, 0.9679, 0.9761,\n",
      "        0.9820, 0.9611, 0.9784, 1.0509, 0.9581, 0.9741, 0.9699, 1.0246, 1.0269,\n",
      "        0.9768, 1.0561, 1.0022, 0.9554, 0.9633, 1.0148, 1.0124, 0.9731, 0.9418,\n",
      "        0.9586, 1.0183, 0.9640, 1.0010, 0.9368, 1.0142, 1.0028, 0.9431, 0.9629,\n",
      "        0.9711, 0.9746, 0.9797, 0.9707, 0.9861, 0.9514, 0.9577, 0.9402, 0.9643,\n",
      "        0.9719, 0.9409, 1.0413, 0.9679, 1.0423, 0.9732, 0.9561, 0.9585, 0.9716,\n",
      "        0.9739, 0.9695, 0.9349, 0.9455, 0.9541, 0.9518, 0.9774, 1.0202, 0.9810,\n",
      "        1.0103, 0.9516, 0.9575, 0.9936, 0.9593, 0.9706, 0.9716, 1.0004, 0.9593,\n",
      "        0.9749, 0.9647, 0.9730, 1.0134, 0.9926, 0.9746, 0.9837, 0.9848, 0.9700,\n",
      "        1.0456, 0.9505, 0.9845, 0.9519, 1.0104, 0.9886, 0.9549, 0.9849])\n",
      "tensor([ 0.0488,  0.0820, -0.0549,  0.0379,  0.0119,  0.0141,  0.0049,  0.0967,\n",
      "        -0.0088, -0.0090,  0.0291, -0.0280, -0.0598,  0.0181,  0.0076,  0.0065,\n",
      "         0.0115,  0.0235, -0.0380,  0.0255,  0.0322, -0.0392,  0.0023, -0.0052,\n",
      "        -0.0989,  0.0308, -0.0584,  0.0343,  0.0648, -0.0091, -0.0136,  0.0784,\n",
      "         0.0263,  0.0371, -0.0014,  0.0035, -0.0264,  0.1138,  0.0549, -0.0071,\n",
      "        -0.0208, -0.0527, -0.0504, -0.0629,  0.0162, -0.0363, -0.0358, -0.0645,\n",
      "        -0.0849, -0.0016,  0.0156, -0.0902, -0.0423,  0.0186, -0.0459, -0.0027,\n",
      "         0.0036,  0.0683,  0.0496,  0.0838, -0.0061, -0.0594, -0.0665,  0.0081,\n",
      "        -0.0146, -0.0643,  0.0135, -0.0214,  0.0075, -0.0309,  0.0130,  0.0389,\n",
      "        -0.0064, -0.0578, -0.0212,  0.0116, -0.0498, -0.0069, -0.0468, -0.0036,\n",
      "         0.0356, -0.0161, -0.0862,  0.0184, -0.0019, -0.0308,  0.0051,  0.0064,\n",
      "         0.0146, -0.0334,  0.0065, -0.0598, -0.0285,  0.0496, -0.0619, -0.0031,\n",
      "         0.0921,  0.0216,  0.0147,  0.0402, -0.0502,  0.0119, -0.1240,  0.0120,\n",
      "         0.0310,  0.0257,  0.0450,  0.0808, -0.0893, -0.0384,  0.0248, -0.0243,\n",
      "         0.0896, -0.0400, -0.0874,  0.0193, -0.0502,  0.0280, -0.0704,  0.0060,\n",
      "        -0.0207, -0.0131,  0.0021,  0.0303, -0.0267,  0.0089, -0.0189,  0.0200,\n",
      "        -0.0105,  0.0243,  0.0221, -0.0040,  0.0567, -0.0263, -0.0798,  0.0232,\n",
      "        -0.0419, -0.0252,  0.0264,  0.0596, -0.0134,  0.0443, -0.0569, -0.0400,\n",
      "         0.0345, -0.0321,  0.0265,  0.0032,  0.0462,  0.0026,  0.0058,  0.0778,\n",
      "        -0.0107,  0.0237, -0.0246,  0.0677,  0.0334,  0.0023,  0.0329, -0.0039,\n",
      "        -0.0657, -0.0281, -0.0512,  0.0586,  0.0116, -0.0163,  0.0583,  0.0248,\n",
      "         0.0117, -0.0200,  0.0103,  0.0567, -0.0736, -0.0940, -0.0574,  0.0160,\n",
      "         0.0685, -0.0544, -0.0161, -0.0147, -0.0137,  0.0357, -0.0145, -0.0185,\n",
      "         0.0126,  0.0170,  0.0355, -0.0348,  0.0333, -0.0147, -0.0524, -0.0258,\n",
      "        -0.0217,  0.0374, -0.0029, -0.0369,  0.0358, -0.0432,  0.0047, -0.0268,\n",
      "         0.0187,  0.0189,  0.0775, -0.0161,  0.0373,  0.0035, -0.0651, -0.0031,\n",
      "        -0.0560,  0.0141, -0.0172, -0.0387, -0.0049,  0.0447, -0.0283,  0.0310,\n",
      "        -0.0122, -0.0771,  0.0084,  0.0383, -0.0182,  0.0588,  0.0323, -0.0089,\n",
      "         0.0117, -0.0462, -0.0441, -0.0307,  0.0336,  0.0416, -0.0540, -0.0496,\n",
      "         0.0024, -0.1044, -0.0312, -0.0071,  0.0705, -0.0173, -0.0912,  0.0395,\n",
      "        -0.0239,  0.0047,  0.0379, -0.0210, -0.0298,  0.0107,  0.0150,  0.0258,\n",
      "        -0.0217,  0.0667, -0.0590, -0.0578, -0.0206, -0.0086, -0.0740,  0.0654,\n",
      "         0.0261, -0.0151, -0.0536,  0.0036, -0.0478,  0.0096, -0.0363, -0.0140,\n",
      "        -0.0173,  0.0389, -0.0813, -0.0603,  0.0012, -0.0014, -0.0011,  0.0354,\n",
      "         0.0588, -0.0531,  0.0156, -0.0762,  0.0138,  0.0003, -0.0225,  0.0383,\n",
      "        -0.0350,  0.0076, -0.0648, -0.0609, -0.0326,  0.0076, -0.0064,  0.0059,\n",
      "        -0.0252,  0.0428, -0.0310,  0.0339, -0.0116, -0.0207,  0.0082, -0.0336,\n",
      "        -0.0006, -0.0714,  0.0014, -0.0133,  0.0509, -0.0076, -0.0505,  0.0008,\n",
      "        -0.0561, -0.0119,  0.0180, -0.0930, -0.0345, -0.0565,  0.0919,  0.0472,\n",
      "         0.1384, -0.0189,  0.0298,  0.0276,  0.0493,  0.0147, -0.0002, -0.0120,\n",
      "         0.0032, -0.0037,  0.0341,  0.0535,  0.0770,  0.0357, -0.0287, -0.0154,\n",
      "         0.0335, -0.0668, -0.0227, -0.0123, -0.0855, -0.0028, -0.0627,  0.0157,\n",
      "        -0.0378, -0.0165, -0.0730, -0.0157, -0.0699,  0.0549,  0.0308,  0.0397,\n",
      "        -0.0565,  0.0091,  0.0140,  0.0361,  0.0060,  0.0498])\n",
      "tensor([[-0.0562, -0.0275,  0.0060,  ..., -0.0115, -0.0477, -0.0365],\n",
      "        [-0.0033,  0.0109, -0.0192,  ..., -0.0086, -0.0638, -0.0599],\n",
      "        [-0.0561,  0.0195, -0.0375,  ..., -0.0382,  0.0477, -0.0713],\n",
      "        ...,\n",
      "        [-0.0341,  0.0589,  0.0352,  ...,  0.0022, -0.0411, -0.0056],\n",
      "        [-0.0303, -0.0055, -0.0358,  ...,  0.0133, -0.0170,  0.0268],\n",
      "        [ 0.0500,  0.0515, -0.0328,  ...,  0.0040, -0.0572,  0.0202]])\n",
      "tensor([-0.0516, -0.0315, -0.0649, -0.0264, -0.0465, -0.0282, -0.0249,  0.0140,\n",
      "        -0.0140, -0.0606,  0.0795, -0.0463, -0.0802, -0.0683,  0.0423, -0.0379,\n",
      "        -0.0756,  0.0067, -0.0238, -0.0600,  0.0647, -0.0417, -0.0580, -0.0487,\n",
      "        -0.0377, -0.0712, -0.0115,  0.0677, -0.1367, -0.0193, -0.0922, -0.0460,\n",
      "         0.0222,  0.0022, -0.0546, -0.0021,  0.0124,  0.0243, -0.1006,  0.0265,\n",
      "        -0.0838, -0.0336,  0.0300, -0.0539, -0.0034,  0.1055, -0.0186, -0.0067,\n",
      "         0.0198, -0.0454, -0.0604,  0.0229, -0.0157, -0.0006, -0.0288,  0.0174,\n",
      "         0.0269, -0.0319,  0.0072, -0.0128,  0.0296,  0.0067, -0.0252, -0.1206,\n",
      "        -0.0445, -0.0155, -0.0021,  0.0393,  0.0393, -0.0284, -0.0207,  0.0328,\n",
      "        -0.0869, -0.0853,  0.1081,  0.0111, -0.0234, -0.0162, -0.0535,  0.0835,\n",
      "         0.0227,  0.0159, -0.0214,  0.0144, -0.1333,  0.0442, -0.0564, -0.0527,\n",
      "        -0.0875,  0.0147, -0.0630, -0.0221, -0.0141,  0.0493, -0.0129, -0.0489,\n",
      "        -0.0315,  0.0431,  0.0095, -0.0986,  0.0444,  0.0235,  0.0093, -0.0177,\n",
      "        -0.0168, -0.0642,  0.0143, -0.0590,  0.0023,  0.0115, -0.0146,  0.0476,\n",
      "         0.0221, -0.1196, -0.0074, -0.0386, -0.0219,  0.0390, -0.0058,  0.0463,\n",
      "         0.0578,  0.0361,  0.0137,  0.0045, -0.0316, -0.0184,  0.0243,  0.0360,\n",
      "        -0.0412,  0.0102, -0.0116,  0.0214,  0.0013, -0.0484,  0.0185, -0.0100,\n",
      "         0.0407, -0.0302, -0.0698, -0.0775,  0.0424, -0.0132, -0.0401, -0.0349,\n",
      "        -0.1585, -0.0277,  0.0492, -0.0412, -0.0259, -0.0109, -0.0444, -0.0546,\n",
      "         0.0507, -0.0110, -0.0712,  0.0713, -0.0502,  0.0775, -0.0290, -0.0380,\n",
      "         0.0292, -0.1119, -0.1075, -0.0159, -0.0094, -0.1256, -0.0179, -0.0658,\n",
      "        -0.0102, -0.0295,  0.0303, -0.0316, -0.0083, -0.0454,  0.0132, -0.0017,\n",
      "        -0.0682, -0.0135,  0.0481, -0.0999, -0.0119, -0.0396,  0.0280,  0.0619,\n",
      "        -0.0382, -0.0210,  0.0075, -0.0248, -0.0703,  0.0410, -0.0458, -0.0060,\n",
      "        -0.0332, -0.0511, -0.0547, -0.0614,  0.0732, -0.0325,  0.0287,  0.0206,\n",
      "         0.0304, -0.0706, -0.0056, -0.0141, -0.0373,  0.0520, -0.0478, -0.0722,\n",
      "         0.0770,  0.0381, -0.0056,  0.0513, -0.0307, -0.0395, -0.0078, -0.0432,\n",
      "         0.0168, -0.0488,  0.0091,  0.0526,  0.0755, -0.0087, -0.0094, -0.1160,\n",
      "         0.0433, -0.0192, -0.0290, -0.0046,  0.0399,  0.0195,  0.0206,  0.0225,\n",
      "        -0.1350, -0.0784, -0.0151, -0.0293, -0.0325, -0.0198, -0.0338, -0.0058,\n",
      "        -0.0611,  0.0136, -0.0412, -0.1146, -0.0347,  0.0399,  0.0269, -0.0095,\n",
      "        -0.0064, -0.0064,  0.0095,  0.0391, -0.0406,  0.0294,  0.0096, -0.0533,\n",
      "        -0.0717, -0.0263,  0.0889,  0.0132, -0.0124, -0.0304, -0.0049,  0.0533,\n",
      "         0.0185, -0.0531,  0.0072,  0.0628, -0.0334, -0.0475, -0.0007,  0.0092,\n",
      "         0.0100, -0.1176, -0.0268,  0.0273, -0.0303, -0.0633, -0.0578, -0.0502,\n",
      "         0.0209,  0.0257,  0.0897, -0.0270, -0.0587,  0.0162, -0.0280, -0.0796,\n",
      "         0.0118, -0.0998,  0.0527,  0.0140, -0.0566, -0.1184,  0.0262,  0.0704,\n",
      "        -0.0224, -0.0155, -0.0184, -0.0867,  0.0138,  0.0345, -0.0886, -0.0243,\n",
      "        -0.0185, -0.0134,  0.0279,  0.0372, -0.0233, -0.0243, -0.0835,  0.0070,\n",
      "        -0.0879, -0.0186, -0.0254, -0.0918, -0.0111,  0.0395, -0.0692, -0.0192,\n",
      "        -0.0111, -0.0070,  0.0169, -0.0404, -0.0346, -0.0487,  0.0467, -0.0058,\n",
      "         0.0258,  0.0350,  0.0144, -0.0068, -0.0341, -0.0500, -0.0047, -0.0787,\n",
      "        -0.0293, -0.0772, -0.0164,  0.0194, -0.0194,  0.0057,  0.0038,  0.0138,\n",
      "        -0.0567, -0.0607, -0.0023, -0.0083, -0.0300,  0.0390])\n",
      "tensor([1.0421, 1.0052, 0.9821, 1.0109, 1.0011, 1.0182, 0.9673, 1.0031, 1.0448,\n",
      "        1.0042, 0.9768, 1.0079, 0.9980, 0.9977, 1.0166, 0.9862, 0.9788, 1.0313,\n",
      "        0.9901, 1.0279, 0.9840, 0.9668, 0.9685, 0.9738, 1.0242, 1.0028, 0.9881,\n",
      "        0.9920, 0.9912, 1.0130, 1.0404, 1.0210, 1.0019, 1.0073, 1.0333, 0.9885,\n",
      "        0.9964, 1.0199, 0.9895, 0.9538, 1.0097, 1.0626, 1.0214, 0.9877, 1.0074,\n",
      "        1.0198, 0.9500, 1.0195, 0.9594, 1.0381, 1.0440, 1.0199, 1.0195, 1.0008,\n",
      "        1.0116, 0.9543, 0.9907, 1.0012, 1.0003, 0.9826, 1.0133, 1.0091, 1.0398,\n",
      "        1.0366, 0.9840, 1.0357, 0.9990, 1.0268, 1.0155, 1.0042, 0.9763, 1.0158,\n",
      "        0.9877, 0.9888, 1.0160, 0.9973, 1.0046, 1.0354, 1.0204, 0.9468, 1.0313,\n",
      "        1.0227, 0.9981, 0.9776, 1.0895, 1.0115, 1.0001, 0.9868, 0.9902, 1.0011,\n",
      "        1.0465, 0.9968, 0.9801, 0.9933, 1.0131, 1.0490, 1.0446, 0.9746, 1.0454,\n",
      "        0.9952, 0.9932, 0.9972, 0.9942, 0.9809, 0.9904, 0.9857, 0.9930, 1.0312,\n",
      "        0.9825, 0.9870, 0.9534, 0.9576, 1.0338, 1.0042, 0.9712, 1.0389, 0.9895,\n",
      "        1.0234, 1.0247, 1.0169, 0.9827, 1.0188, 0.9663, 1.0121, 1.0220, 1.0139,\n",
      "        1.0064, 1.0251, 0.9865, 0.9819, 0.9872, 0.9999, 0.9970, 1.0669, 0.9892,\n",
      "        0.9882, 1.0282, 0.9871, 1.0112, 1.0374, 1.0138, 1.0172, 1.0148, 0.9546,\n",
      "        1.0293, 0.9937, 0.9643, 0.9802, 0.9792, 1.0203, 1.0069, 0.9592, 1.0038,\n",
      "        1.0281, 0.9906, 1.0092, 1.0229, 1.0044, 0.9852, 0.9992, 1.0271, 1.0139,\n",
      "        1.0485, 0.9785, 0.9797, 1.0496, 0.9701, 1.0131, 1.0059, 1.0013, 1.0112,\n",
      "        1.0231, 1.0297, 1.0077, 1.0097, 1.0927, 1.0705, 1.0244, 0.9862, 0.9695,\n",
      "        0.9905, 0.9753, 1.0094, 0.9623, 0.9782, 0.9994, 1.0348, 0.9868, 1.0093,\n",
      "        0.9958, 0.9881, 1.0126, 0.9821, 1.0298, 1.0068, 1.0041, 0.9519, 0.9651,\n",
      "        0.9660, 0.9731, 0.9855, 0.9911, 1.0130, 1.0235, 1.0284, 0.9930, 0.9959,\n",
      "        0.9971, 0.9505, 0.9900, 0.9990, 0.9766, 1.0389, 0.9969, 0.9763, 1.0360,\n",
      "        1.0168, 1.0222, 1.0021, 0.9618, 1.0065, 0.9793, 1.0168, 1.0096, 1.0105,\n",
      "        1.0069, 1.0019, 0.9796, 0.9995, 0.9798, 0.9835, 0.9857, 1.0191, 1.0066,\n",
      "        0.9913, 0.9869, 1.0015, 0.9966, 0.9836, 0.9932, 0.9971, 1.0423, 1.0455,\n",
      "        1.0071, 0.9449, 1.0022, 0.9723, 1.0068, 0.9856, 1.0601, 0.9691, 1.0021,\n",
      "        0.9626, 1.0200, 0.9809, 1.0581, 1.0350, 1.0231, 1.0058, 0.9835, 1.0340,\n",
      "        1.0331, 0.9997, 0.9998, 0.9977, 0.9904, 0.9929, 0.9577, 1.0225, 1.0397,\n",
      "        1.0755, 0.9925, 0.9765, 0.9841, 1.0426, 1.0421, 1.0265, 1.0267, 1.0135,\n",
      "        1.0038, 0.9826, 1.0029, 0.9843, 1.0085, 1.0392, 1.0236, 0.9665, 0.9861,\n",
      "        0.9772, 1.0345, 1.0119, 1.0195, 1.0142, 1.0125, 1.0071, 0.9839, 0.9707,\n",
      "        1.0563, 1.0329, 0.9912, 0.9655, 1.0086, 1.0114, 0.9801, 0.9540, 1.0059,\n",
      "        0.9840, 0.9769, 1.0116, 1.0123, 1.0375, 0.9744, 1.0247, 0.9986, 0.9987,\n",
      "        1.0158, 0.9761, 1.0329, 1.0465, 0.9888, 1.0308, 1.0301, 1.0077, 1.0303,\n",
      "        0.9967, 1.0198, 1.0119, 1.0182, 0.9968, 0.9613, 0.9739, 1.0142, 1.0130,\n",
      "        1.0615, 1.0537, 1.0306, 1.0320, 0.9998, 0.9781, 1.0428, 0.9837, 0.9831,\n",
      "        1.0055, 0.9791, 1.0217, 0.9556, 0.9823, 1.0007, 0.9994, 1.0041])\n",
      "tensor([ 2.6530e-02,  3.4068e-02,  6.7312e-02, -7.8475e-03, -1.3262e-02,\n",
      "         7.5315e-03,  1.1240e-02, -4.1953e-02,  4.3788e-03,  1.3003e-02,\n",
      "        -1.0826e-02, -3.8767e-02,  2.1830e-02,  2.0539e-02,  4.0463e-03,\n",
      "         2.3981e-02, -4.3788e-02, -9.6494e-03,  4.1471e-02, -3.5621e-04,\n",
      "         1.8546e-02, -6.3270e-02, -3.5969e-03,  1.1481e-02, -3.9631e-03,\n",
      "        -6.5629e-03,  9.8632e-02, -1.2366e-02, -4.4768e-03,  1.6067e-02,\n",
      "        -2.1741e-02, -8.0580e-03, -4.1869e-02, -2.9693e-02,  3.8821e-02,\n",
      "        -9.4130e-03, -4.1922e-02,  2.9888e-03,  1.4397e-02, -7.6406e-04,\n",
      "         2.3460e-02, -3.8164e-02,  4.5126e-02,  5.8815e-02,  6.8374e-02,\n",
      "         3.8053e-02,  1.4067e-02,  8.3054e-02, -6.1149e-02, -4.5795e-02,\n",
      "        -2.5191e-02,  1.8380e-02,  7.3665e-02,  1.2341e-02,  1.0799e-02,\n",
      "        -7.4914e-02, -3.9902e-02, -7.8940e-03, -1.2031e-03,  3.0925e-02,\n",
      "         2.3278e-02,  4.8276e-02, -4.7751e-02, -3.0060e-02, -5.1525e-02,\n",
      "        -2.1637e-02,  3.5585e-02,  5.4899e-02,  2.7492e-02,  5.9021e-02,\n",
      "         9.9745e-02,  2.2124e-02,  7.6397e-04, -6.2784e-02,  4.6928e-03,\n",
      "         1.7939e-02, -5.6119e-02,  7.1678e-02, -1.4697e-02,  3.8676e-02,\n",
      "         8.9099e-02, -2.7013e-02,  4.9152e-02, -1.8754e-02, -5.1652e-02,\n",
      "        -5.6167e-02, -1.3397e-03,  1.1871e-02, -5.2695e-02,  1.6686e-02,\n",
      "        -2.6515e-02, -1.9629e-02, -3.1140e-02, -1.8567e-02, -5.4428e-02,\n",
      "        -1.7093e-02,  2.2931e-02,  1.7468e-02,  1.0947e-02, -1.4821e-02,\n",
      "         4.6458e-02, -2.8857e-02, -9.8483e-03, -2.4354e-02,  4.0958e-03,\n",
      "         1.1553e-02,  1.4093e-02,  1.8364e-02, -1.9876e-03,  1.5568e-02,\n",
      "        -5.4005e-02,  3.2357e-03, -2.3236e-02,  5.6477e-03, -1.0799e-02,\n",
      "        -8.8480e-03, -3.9217e-02, -8.9828e-03,  3.4407e-02,  6.3522e-03,\n",
      "        -1.4279e-02,  2.3888e-02,  2.6430e-02,  3.4631e-02,  5.9434e-02,\n",
      "         5.6107e-03, -3.7069e-02, -9.6610e-03,  4.2594e-02,  2.5945e-02,\n",
      "         6.9011e-03, -2.0582e-02, -8.9410e-03, -5.3910e-02,  3.9308e-02,\n",
      "         4.4552e-02, -2.9592e-02, -6.2558e-02,  1.3149e-02,  5.5392e-03,\n",
      "         1.4186e-02, -1.9986e-02,  8.8822e-03, -1.4202e-02,  2.7615e-02,\n",
      "         5.3317e-02,  2.4163e-02, -2.8994e-03,  9.8716e-03,  6.1870e-02,\n",
      "         5.0399e-02, -1.7055e-02,  1.5262e-02, -5.9504e-02,  1.0424e-02,\n",
      "        -5.2957e-02,  2.7312e-02,  2.4682e-02, -9.2089e-03,  1.4456e-02,\n",
      "         5.5120e-03, -7.7923e-03, -3.3280e-02, -3.1693e-02,  3.6217e-02,\n",
      "         1.9619e-02,  4.4898e-02, -3.6008e-02,  1.1219e-02, -1.7697e-02,\n",
      "         2.2847e-02,  1.5782e-02,  6.2070e-02, -2.2819e-02,  8.4239e-02,\n",
      "         7.4501e-03, -9.7937e-03, -6.3666e-02,  4.5607e-02, -3.1805e-02,\n",
      "         3.6856e-02,  3.9972e-02, -4.2071e-02, -4.5021e-03, -3.1917e-02,\n",
      "         2.2301e-02,  2.9831e-02, -2.4223e-02,  4.2356e-02,  4.3691e-03,\n",
      "        -2.2190e-02,  2.5498e-02,  4.9704e-05,  4.6759e-02,  4.6778e-02,\n",
      "        -3.7739e-02, -1.9008e-02, -1.3249e-02, -5.3888e-03, -5.6318e-02,\n",
      "        -1.7213e-02,  2.5543e-02, -3.2097e-02,  5.9015e-02,  3.4878e-02,\n",
      "         4.6962e-02,  7.8576e-02, -9.5014e-03,  1.6976e-02, -9.1342e-02,\n",
      "        -1.4488e-02,  3.2907e-02,  7.1920e-02,  3.9064e-02,  8.3003e-03,\n",
      "         1.2628e-02, -3.6837e-02,  3.9729e-02,  3.3719e-02,  2.0454e-02,\n",
      "         2.8438e-02,  9.0228e-03, -1.4908e-02,  6.6780e-02,  1.2661e-02,\n",
      "         5.1994e-02, -1.4851e-02,  3.0051e-02,  3.6721e-02,  5.2340e-03,\n",
      "         3.0619e-03,  3.0778e-02, -9.4560e-03,  3.2280e-02, -1.1014e-02,\n",
      "         4.3687e-02, -6.7893e-02, -4.6850e-02,  9.7631e-03,  3.2313e-02,\n",
      "         2.8892e-02, -1.3917e-02, -3.4229e-02,  1.6975e-02, -1.3078e-02,\n",
      "        -3.7331e-02,  1.0147e-02, -4.0304e-02, -5.5163e-03, -3.6798e-02,\n",
      "         3.0228e-02,  1.9561e-02, -4.3691e-03, -3.7808e-02, -7.8656e-03,\n",
      "         9.1757e-02,  3.0811e-02, -1.4044e-02,  4.7375e-02,  4.7435e-02,\n",
      "        -4.1955e-02, -2.9351e-02,  1.0494e-02,  3.7287e-02, -2.3301e-02,\n",
      "        -2.1342e-02,  2.9134e-02, -1.6506e-02,  3.6097e-02,  3.2266e-02,\n",
      "         2.9259e-02, -4.7643e-02, -5.4631e-03, -1.9915e-02, -8.0284e-02,\n",
      "         4.2786e-02,  3.2800e-02, -5.5490e-03,  2.5245e-02,  1.3271e-02,\n",
      "        -2.0215e-02,  2.7012e-02,  5.7934e-02,  1.6542e-02, -1.8728e-02,\n",
      "        -2.2956e-02, -3.0397e-02, -4.5016e-03,  5.1769e-02, -3.7549e-02,\n",
      "         6.8749e-03,  4.1289e-03,  3.3011e-02, -5.8532e-02,  5.0159e-02,\n",
      "         3.2656e-02,  2.1113e-03, -8.2517e-03,  2.4149e-02,  3.8592e-02,\n",
      "        -4.5529e-02, -3.7461e-02,  5.1672e-02,  1.5865e-02,  2.1098e-02,\n",
      "         9.4689e-03,  2.8948e-02, -3.2434e-02,  1.9499e-02, -1.7465e-02,\n",
      "         6.4700e-02,  6.2926e-02, -5.3374e-02,  6.8129e-03,  5.6141e-02,\n",
      "         1.6101e-02, -3.6139e-02,  2.8665e-02,  3.5079e-02, -7.9447e-03,\n",
      "        -1.3293e-02,  7.3510e-03, -1.2716e-02,  6.3565e-02, -1.6406e-02,\n",
      "        -5.9021e-02,  7.5282e-03, -1.8560e-02,  8.6926e-02, -9.3193e-03,\n",
      "        -3.4289e-02, -2.4119e-02, -4.7480e-02,  4.7163e-03, -3.2394e-02,\n",
      "         1.8527e-02,  3.9744e-02,  3.7574e-02, -2.8846e-02,  7.7723e-02,\n",
      "         1.2077e-02, -1.2148e-02, -3.3115e-02,  3.1379e-02,  9.3003e-03,\n",
      "        -1.2808e-04, -3.7130e-02,  4.0527e-02, -3.4974e-02,  5.0961e-02])\n",
      "tensor([[-0.0680, -0.0349, -0.0519,  ...,  0.0206,  0.0345, -0.0268],\n",
      "        [ 0.0047, -0.0663, -0.0292,  ..., -0.0101, -0.0019,  0.0266],\n",
      "        [ 0.0143,  0.0309, -0.0437,  ...,  0.0046,  0.0637,  0.0335],\n",
      "        ...,\n",
      "        [ 0.0597, -0.0180,  0.0300,  ..., -0.0700,  0.0120, -0.0122],\n",
      "        [-0.0315, -0.0946,  0.0342,  ...,  0.0589, -0.0048, -0.0078],\n",
      "        [ 0.0026, -0.0551,  0.0204,  ..., -0.0432, -0.0185, -0.0374]])\n",
      "tensor([-0.1055, -0.0142, -0.0393,  0.0444, -0.0327, -0.0736,  0.0404,  0.0006,\n",
      "        -0.0120, -0.0433,  0.0433, -0.0873,  0.0098, -0.0172,  0.0238,  0.0351,\n",
      "        -0.0554,  0.0007,  0.0221, -0.0263,  0.0825,  0.0188, -0.0299, -0.0494,\n",
      "        -0.0481, -0.0058, -0.0290, -0.0067, -0.0858,  0.0847, -0.0294,  0.0431,\n",
      "         0.0653, -0.0078,  0.0702,  0.0192, -0.0056,  0.0226, -0.0197,  0.0203,\n",
      "        -0.0706,  0.0192,  0.0412, -0.0388,  0.0244,  0.0077, -0.0041,  0.0260,\n",
      "         0.0444, -0.0028, -0.0072,  0.0027, -0.0439, -0.0287,  0.0158, -0.0058,\n",
      "         0.0410,  0.0288,  0.0214, -0.0343, -0.0290, -0.0196,  0.0147, -0.0677,\n",
      "        -0.0884, -0.0366,  0.0171, -0.0307,  0.0060, -0.0103, -0.0016, -0.0442,\n",
      "        -0.0925, -0.0045,  0.0720, -0.0186, -0.0189, -0.0284, -0.0600,  0.0052,\n",
      "        -0.0461,  0.0585, -0.0529,  0.0008,  0.0269, -0.0658, -0.0359,  0.0241,\n",
      "         0.0103, -0.0448, -0.0299, -0.0399,  0.0312,  0.0670, -0.0133, -0.0372,\n",
      "         0.0604,  0.0157,  0.0628,  0.0110, -0.0048, -0.0053, -0.0391, -0.0380,\n",
      "        -0.0891,  0.0016, -0.0404,  0.0066,  0.0463, -0.0500, -0.0026,  0.0100,\n",
      "        -0.0095, -0.0106, -0.0084, -0.0128,  0.0305, -0.0434,  0.0403,  0.0264,\n",
      "         0.0672,  0.0486,  0.0070, -0.0218,  0.0331,  0.0556, -0.0398, -0.0167,\n",
      "         0.0311, -0.0303, -0.0097, -0.0624, -0.0065,  0.0167,  0.0568, -0.0315,\n",
      "        -0.0321, -0.1150,  0.0399, -0.0150,  0.0113, -0.0092, -0.0132, -0.0478,\n",
      "        -0.1763,  0.0009,  0.0977,  0.0017,  0.0432, -0.0249, -0.0431, -0.0084,\n",
      "        -0.0065,  0.0039,  0.0545, -0.0258,  0.0111,  0.0406,  0.0111, -0.0100,\n",
      "         0.0041, -0.0345, -0.0063, -0.1012, -0.0153, -0.0805, -0.0614,  0.0287,\n",
      "        -0.0741, -0.0514,  0.0869,  0.0093,  0.0411,  0.0040, -0.0192, -0.0256,\n",
      "         0.0723,  0.0023,  0.0191, -0.0661,  0.0339, -0.0070, -0.0060,  0.0082,\n",
      "         0.0317,  0.0561, -0.0061,  0.0309, -0.0371, -0.0516, -0.0030, -0.0294,\n",
      "        -0.0451, -0.0686, -0.0615, -0.1006,  0.0965, -0.0179,  0.0126,  0.0063,\n",
      "         0.0412, -0.0626, -0.0437, -0.0226, -0.0665,  0.0180, -0.0498,  0.0086,\n",
      "         0.0561,  0.0168, -0.0678,  0.0538,  0.0212,  0.0275,  0.0150, -0.0136,\n",
      "         0.0471,  0.0281, -0.0290,  0.0136,  0.0512,  0.0289, -0.0465, -0.0798,\n",
      "        -0.0129,  0.0411, -0.0499,  0.0238,  0.0515, -0.0375,  0.0591, -0.0040,\n",
      "        -0.0931,  0.0242, -0.0879,  0.0112,  0.0210, -0.0221, -0.0094, -0.0397,\n",
      "        -0.0430, -0.0786, -0.0291, -0.0040, -0.0663,  0.0125, -0.0236, -0.0347,\n",
      "        -0.0112, -0.0275,  0.0040, -0.0528, -0.0341, -0.0186, -0.0188,  0.0525,\n",
      "        -0.0095, -0.0579,  0.0095,  0.0653,  0.0087, -0.0051,  0.0278,  0.0508,\n",
      "        -0.0061,  0.0438, -0.0568,  0.0160, -0.0082, -0.0027,  0.0080,  0.0138,\n",
      "         0.0377, -0.0665, -0.0346, -0.0241,  0.0690,  0.0299, -0.0091, -0.0560,\n",
      "         0.0597,  0.0254,  0.0548, -0.0487, -0.0418, -0.0264, -0.0036, -0.0265,\n",
      "        -0.0823, -0.1047, -0.0287,  0.0706, -0.1070, -0.1340, -0.0259,  0.0291,\n",
      "        -0.0178,  0.0379, -0.0066, -0.0564, -0.0215, -0.0454, -0.0660, -0.0810,\n",
      "        -0.0612, -0.0351,  0.0312, -0.0427,  0.0196,  0.0258, -0.0330, -0.0069,\n",
      "        -0.0731, -0.0620,  0.0282, -0.0913, -0.0217, -0.0255, -0.0352,  0.0288,\n",
      "        -0.0027, -0.0114, -0.0426,  0.0135, -0.0418, -0.0348, -0.0058,  0.0331,\n",
      "         0.0378,  0.0609,  0.0622, -0.0040,  0.0065, -0.0312, -0.0251, -0.0017,\n",
      "        -0.0376,  0.0140, -0.0206,  0.0005, -0.0452,  0.0248, -0.0772, -0.0353,\n",
      "        -0.0640, -0.0321, -0.0169,  0.0729, -0.0877, -0.0501])\n",
      "tensor([1.1148, 1.0141, 1.0548, 1.0368, 1.0481, 1.0464, 1.0362, 1.0098, 1.0570,\n",
      "        1.0138, 1.0650, 1.0548, 1.0176, 1.0360, 0.9849, 1.0148, 1.0273, 1.0450,\n",
      "        0.9993, 0.9943, 1.0344, 1.0194, 1.0069, 1.0280, 1.0707, 1.0314, 0.9807,\n",
      "        1.0301, 1.0656, 1.0639, 1.0158, 1.0774, 0.9911, 1.0202, 1.0284, 1.0395,\n",
      "        1.0048, 1.0222, 0.9598, 1.0272, 1.0131, 1.0464, 1.0313, 1.0447, 1.0433,\n",
      "        1.0491, 1.0265, 1.0357, 1.0277, 1.0640, 1.1031, 1.0382, 1.0608, 1.0049,\n",
      "        1.0169, 1.0651, 1.0599, 1.0296, 1.0190, 1.0565, 1.0975, 1.0964, 1.0636,\n",
      "        1.0858, 1.1103, 1.0148, 1.1150, 1.0316, 1.0196, 1.0764, 1.0368, 1.0305,\n",
      "        1.0579, 1.0245, 1.0122, 1.0240, 1.0243, 1.0361, 1.0408, 1.0258, 1.0534,\n",
      "        1.0300, 1.0150, 1.0148, 1.1104, 1.0179, 1.0375, 1.1150, 1.0061, 1.0883,\n",
      "        1.0451, 1.0324, 1.0150, 1.0291, 1.0310, 0.9939, 1.0330, 1.0334, 1.0532,\n",
      "        1.0646, 1.0297, 1.0111, 1.0311, 1.1973, 1.0490, 1.0353, 1.0394, 1.0500,\n",
      "        1.0635, 1.0529, 1.0230, 1.0270, 0.9999, 1.0281, 1.0255, 1.0577, 0.9895,\n",
      "        1.0642, 1.0232, 1.0373, 1.0520, 1.0139, 1.0136, 1.0102, 1.0114, 1.0849,\n",
      "        1.0295, 1.0333, 1.0479, 1.0028, 1.0530, 1.0175, 1.0257, 1.0313, 1.0125,\n",
      "        1.0514, 1.0123, 1.0544, 1.0061, 1.0032, 1.0078, 1.0259, 1.0279, 1.0048,\n",
      "        1.1384, 1.0247, 1.1074, 1.0146, 1.0376, 1.0450, 1.0196, 1.0425, 1.0546,\n",
      "        1.0394, 1.0445, 1.0280, 1.0564, 1.0031, 1.0220, 1.0195, 1.0217, 1.0132,\n",
      "        1.0571, 1.0498, 1.0699, 1.0769, 1.0432, 1.0593, 0.9973, 1.0127, 1.0188,\n",
      "        1.0346, 1.0429, 1.0588, 1.0302, 1.0309, 1.0700, 1.0541, 1.0049, 1.1042,\n",
      "        1.0160, 1.0060, 1.0411, 0.9783, 1.0621, 0.9909, 1.0407, 1.0125, 1.1026,\n",
      "        1.0127, 1.0452, 1.0576, 1.0514, 1.0759, 1.1319, 1.0630, 1.0454, 0.9996,\n",
      "        1.0311, 1.0308, 1.0389, 1.0083, 1.0693, 1.0669, 1.0640, 1.0365, 1.1174,\n",
      "        1.0213, 1.0392, 1.0146, 1.0710, 1.0647, 1.0396, 1.0135, 1.0627, 1.0278,\n",
      "        1.0304, 1.0123, 1.0725, 1.0405, 1.0650, 1.0202, 1.0154, 1.0154, 1.0354,\n",
      "        1.0536, 1.0213, 1.0656, 1.0390, 1.0398, 1.0160, 0.9966, 1.0843, 1.0373,\n",
      "        1.0001, 1.0423, 1.0084, 1.0398, 1.0356, 1.0320, 1.0907, 1.0578, 1.0450,\n",
      "        1.0264, 1.0476, 1.0479, 1.0325, 1.0899, 1.0582, 1.0416, 1.0448, 1.0274,\n",
      "        1.0658, 0.9916, 1.0130, 1.0361, 1.0178, 1.0288, 1.0943, 1.0254, 1.0932,\n",
      "        1.0225, 0.9969, 1.0483, 1.0138, 1.0475, 1.0560, 1.0308, 1.0149, 1.0659,\n",
      "        1.0496, 1.0327, 1.0585, 1.0088, 1.0533, 1.0587, 1.0017, 1.0372, 1.0104,\n",
      "        1.0476, 1.0089, 1.0262, 1.0588, 1.0031, 1.0393, 1.0153, 1.0527, 1.0350,\n",
      "        1.0230, 1.1048, 1.0438, 1.0562, 1.0787, 1.0798, 1.0069, 1.0465, 1.0197,\n",
      "        1.0574, 1.0887, 1.0507, 1.0307, 1.0410, 1.0302, 1.0299, 1.0315, 1.0135,\n",
      "        1.0214, 1.0707, 1.0321, 1.0357, 1.0057, 1.0579, 1.0603, 1.0529, 1.0457,\n",
      "        1.0758, 1.0392, 1.0133, 1.0939, 1.0209, 0.9829, 1.0161, 1.0406, 1.0188,\n",
      "        1.0195, 1.0696, 1.0549, 1.0186, 1.0516, 1.0240, 1.0055, 1.0768, 1.0526,\n",
      "        1.0950, 1.0771, 1.0412, 1.0531, 1.0068, 1.0706, 1.0415, 1.0456, 1.0440,\n",
      "        1.0662, 1.0423, 1.0919, 1.0246, 1.0229, 1.0328, 1.0970, 1.0104])\n",
      "tensor([-0.0502,  0.1835, -0.1844, -0.0763,  0.0981, -0.0632,  0.1781,  0.1799,\n",
      "        -0.1615, -0.0070,  0.0180, -0.1221,  0.0532, -0.0642,  0.1442, -0.0105,\n",
      "        -0.0110, -0.1797,  0.0989,  0.0290,  0.0524, -0.1219, -0.0814, -0.0964,\n",
      "         0.0850,  0.1046,  0.0888,  0.0730,  0.2475,  0.0987, -0.0807,  0.0227,\n",
      "         0.2099,  0.1751,  0.1787, -0.0726,  0.2360, -0.1719, -0.0662,  0.0993,\n",
      "        -0.1662,  0.1792,  0.0687, -0.0914,  0.2015,  0.1067, -0.1048,  0.2747,\n",
      "         0.0885, -0.2359, -0.1621,  0.0642, -0.0750,  0.0571,  0.1149, -0.1690,\n",
      "         0.1581,  0.0500,  0.1722, -0.1559,  0.1978,  0.1538,  0.2045, -0.2411,\n",
      "         0.1083,  0.1640, -0.1631, -0.0725,  0.1616,  0.0133, -0.0311, -0.2404,\n",
      "         0.0999, -0.1359, -0.1695, -0.1385, -0.0917,  0.1369,  0.0765,  0.1796,\n",
      "         0.1789,  0.1468, -0.2053,  0.0925, -0.0215,  0.1086,  0.2229,  0.0214,\n",
      "        -0.1603,  0.2229,  0.1009, -0.1305, -0.0197, -0.1939, -0.0919, -0.1292,\n",
      "         0.0940,  0.1249, -0.0296,  0.1658,  0.1623,  0.0304,  0.1712, -0.1425,\n",
      "         0.2158,  0.1802,  0.2118,  0.2391, -0.1955,  0.1230,  0.0807,  0.0138,\n",
      "        -0.0447, -0.1215,  0.0992, -0.1799, -0.1511, -0.0713,  0.1787,  0.2354,\n",
      "        -0.0908, -0.0950, -0.0093,  0.1304, -0.1023, -0.1671,  0.1482,  0.2177,\n",
      "        -0.0456, -0.1250,  0.0822, -0.0919,  0.1335,  0.2406, -0.1098, -0.0949,\n",
      "        -0.2020, -0.1000,  0.1127, -0.0588, -0.1748,  0.1471, -0.1005, -0.1136,\n",
      "         0.0628,  0.0628,  0.1542, -0.1733, -0.0977,  0.2574, -0.1552, -0.1288,\n",
      "         0.1105,  0.0325,  0.2301, -0.1985,  0.0388,  0.1362, -0.0735, -0.1593,\n",
      "        -0.1916,  0.1985, -0.1225, -0.1455, -0.1777,  0.2084, -0.0750, -0.2712,\n",
      "        -0.0989, -0.0199, -0.1780,  0.0529,  0.1424,  0.0915, -0.1351, -0.0340,\n",
      "         0.2285, -0.1627,  0.2559,  0.1475, -0.0866, -0.0639,  0.1266, -0.0215,\n",
      "        -0.1581, -0.0855, -0.1540, -0.1085,  0.2112,  0.1174, -0.0925,  0.0609,\n",
      "         0.2068, -0.2392, -0.0464, -0.1811, -0.0253, -0.0691,  0.1281, -0.0803,\n",
      "         0.0856, -0.0878,  0.1700, -0.1894,  0.1141,  0.2125, -0.1014,  0.1147,\n",
      "         0.0724, -0.1748,  0.1498, -0.2617, -0.0550, -0.0813, -0.1159, -0.1020,\n",
      "         0.0562, -0.1539,  0.1956,  0.1433, -0.1581,  0.0814,  0.0280, -0.1372,\n",
      "         0.1417, -0.1184,  0.0162,  0.1014, -0.0249,  0.1090,  0.1286,  0.1625,\n",
      "         0.0682, -0.1908,  0.1283, -0.1346,  0.0377,  0.1623,  0.2513, -0.1629,\n",
      "        -0.0419,  0.1360, -0.2449, -0.1193, -0.1957, -0.2435, -0.1803, -0.1047,\n",
      "        -0.1436, -0.1185, -0.2189, -0.0587, -0.1312, -0.1207, -0.2030,  0.0891,\n",
      "        -0.1623, -0.0724, -0.1750,  0.2263, -0.0869, -0.0677,  0.0577, -0.2483,\n",
      "         0.1628,  0.1870,  0.2058, -0.1071, -0.1557,  0.2590,  0.2499,  0.1801,\n",
      "        -0.1378,  0.1214, -0.2091, -0.1011, -0.1090, -0.1650, -0.0997,  0.2204,\n",
      "        -0.1191,  0.1421,  0.2736, -0.1255, -0.1790,  0.0421, -0.2486, -0.0122,\n",
      "         0.0617,  0.0741, -0.2152, -0.1700,  0.1184, -0.1648, -0.0906,  0.0261,\n",
      "        -0.0988, -0.0908,  0.0077,  0.1079, -0.1607, -0.1200, -0.0441, -0.1713,\n",
      "         0.0992,  0.1517, -0.0167,  0.1583,  0.0858,  0.1436, -0.0345,  0.1662,\n",
      "        -0.1596,  0.0313,  0.1974, -0.1423, -0.1691, -0.1880,  0.1543,  0.1643,\n",
      "         0.1695, -0.2335,  0.1707,  0.1607, -0.1587, -0.0932,  0.1273,  0.0040,\n",
      "        -0.0253, -0.0389, -0.0725,  0.1756, -0.0616, -0.1428, -0.0922, -0.1161,\n",
      "        -0.0915, -0.1616, -0.1734, -0.2097,  0.0257,  0.1436, -0.0120,  0.1366,\n",
      "         0.1910,  0.0631, -0.2381,  0.1449,  0.1477,  0.2067])\n",
      "tensor([[-0.0038,  0.0329, -0.0995,  ...,  0.0798, -0.0322, -0.0546],\n",
      "        [-0.0104,  0.0485,  0.0151,  ..., -0.0214,  0.0907, -0.0470],\n",
      "        [ 0.0438, -0.0056,  0.0693,  ..., -0.0544, -0.0832,  0.0021],\n",
      "        ...,\n",
      "        [-0.0098, -0.0338,  0.0007,  ...,  0.0295, -0.0061,  0.0332],\n",
      "        [-0.1034, -0.1140, -0.0630,  ..., -0.1009,  0.1711, -0.0071],\n",
      "        [ 0.1734,  0.0847,  0.0628,  ...,  0.0281, -0.1722,  0.0327]])\n",
      "tensor([ 0.0382,  0.0118, -0.1258,  0.1912, -0.1298,  0.0823, -0.0080, -0.1503,\n",
      "        -0.1260, -0.2725,  0.2707,  0.0453, -0.0321,  0.0530, -0.0065,  0.0183,\n",
      "         0.0470,  0.0210,  0.0005])\n"
     ]
    }
   ],
   "source": [
    "for p in net.model.parameters():\n",
    "    print(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7bef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
