{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58155dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986ac1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "#Working with CPU for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d795ad",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8befdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets in UCI\n",
    "def load_UCI(dset_name, splits=10, seed=0, separate_targets=True, save_dir='data/'):\n",
    "    mkdir(save_dir)\n",
    "\n",
    "    if dset_name == 'wine':\n",
    "        if not os.path.isfile(save_dir+'winequality-red.csv'):\n",
    "            urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "                               filename=save_dir+'winequality-red.csv')\n",
    "        data = pd.read_csv(save_dir+'winequality-red.csv', header=1, delimiter=';').values\n",
    "        y_idx = [-1]\n",
    "\n",
    "    elif dset_name == 'default_credit':\n",
    "        if not os.path.isfile(save_dir + 'default of credit card clients.xls'):\n",
    "            urllib.request.urlretrieve(\n",
    "                \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\",\n",
    "                filename=save_dir + 'default of credit card clients.xls')\n",
    "        data = pd.read_excel(save_dir + 'default of credit card clients.xls', header=[0, 1], index_col=0, # delimiter=\"\\s+\"\n",
    "                             ).values\n",
    "        y_idx = [-1]  # OK\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception('Dataset name doesnt match any known datasets.')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    data = data[np.random.permutation(np.arange(len(data)))]\n",
    "\n",
    "    kf = KFold(n_splits=splits)\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "\n",
    "        # Not sure what separate targets is\n",
    "        if separate_targets:\n",
    "            x_idx = list(range(data.shape[1]))\n",
    "            for e in y_idx:\n",
    "                x_idx.remove(x_idx[e])\n",
    "\n",
    "            x_idx = np.array(x_idx)\n",
    "            y_idx = np.array(y_idx)\n",
    "            x_train, y_train = data[train_index, :], data[train_index, :]\n",
    "            x_train, y_train = x_train[:, x_idx], y_train[:, y_idx]\n",
    "            x_test, y_test = data[test_index, :], data[test_index, :]\n",
    "            x_test, y_test = x_test[:, x_idx], y_test[:, y_idx]\n",
    "\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "            y_means, y_stds = y_train.mean(axis=0), y_train.std(axis=0)\n",
    "\n",
    "            y_stds[y_stds < 1e-10] = 1\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            y_train = ((y_train - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "            y_test = ((y_test - y_means) / y_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds\n",
    "\n",
    "        else:\n",
    "            x_train, x_test = data[train_index, :], data[test_index, :]\n",
    "            x_means, x_stds = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "\n",
    "            x_stds[x_stds < 1e-10] = 1\n",
    "\n",
    "            x_train = ((x_train - x_means) / x_stds).astype(np.float32)\n",
    "            x_test = ((x_test - x_means) / x_stds).astype(np.float32)\n",
    "\n",
    "            return x_train, x_test, x_means, x_stds\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path, mode=0o777)\n",
    "\n",
    "# Not sure why this is needed\n",
    "def unnormalise_cat_vars(x, x_means, x_stds, input_dim_vec):\n",
    "    input_dim_vec = np.array(input_dim_vec)\n",
    "    unnorm_x = np.multiply(x, x_stds) + x_means\n",
    "\n",
    "    fixed_unnorm = unnorm_x.round()\n",
    "    fixed_unnorm -= fixed_unnorm.min(axis=0).reshape([1, fixed_unnorm.shape[1]])  # this sets all mins to 0\n",
    "    for idx, dims in enumerate(input_dim_vec):\n",
    "        if dims > 1:\n",
    "            vec = fixed_unnorm[:, idx]\n",
    "            vec[vec > dims - 1] = dims - 1\n",
    "            fixed_unnorm[:, idx] = vec\n",
    "\n",
    "    x[:, input_dim_vec > 1] = fixed_unnorm[:, input_dim_vec > 1]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b1d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit (27000, 24) (3000, 24)\n",
      "[1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "default_credit\n"
     ]
    }
   ],
   "source": [
    "names = ['wine', 'default_credit', 'compas', 'lsat']\n",
    "widths = [300, 300, 300, 300] # [200, 200, 200, 200]\n",
    "depths = [3, 3, 3, 3] # We go deeper because we are using residual models\n",
    "latent_dims = [6, 8, 4, 4]\n",
    "\n",
    "\"\"\"\n",
    "x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds = \\\n",
    "    load_UCI(dset_name='wine', splits=10, seed=42, separate_targets=True, save_dir='../data/')\n",
    "print('Wine', x_train.shape, x_test.shape)\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, x_means, x_stds  = \\\n",
    "    load_UCI(dset_name='default_credit', splits=10, seed=42, separate_targets=False, save_dir='../data/')\n",
    "print('Credit', x_train.shape, x_test.shape)\n",
    "print([1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2])\n",
    "\n",
    "x_train = unnormalise_cat_vars(x_train, x_means, x_stds, input_dim_vec)\n",
    "x_test = unnormalise_cat_vars(x_test, x_means, x_stds, input_dim_vec)\n",
    "# target unnormalisation\n",
    "y_train = unnormalise_cat_vars(y_train, y_means, y_stds, [2])\n",
    "y_test = unnormalise_cat_vars(y_test, y_means, y_stds, [2])\n",
    "\n",
    "dname = 'default_credit'\n",
    "print(dname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353217a",
   "metadata": {},
   "source": [
    "## Recognition (Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### for default_credit ###\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2]\n",
    "print(sum(input_dim_vec))\n",
    "width = 350\n",
    "depth = 3\n",
    "latent_dim = 8\n",
    "\n",
    "inputs = keras.Input(shape=(sum(input_dim_vec),))\n",
    "input = layers.Dense(width)(inputs)\n",
    "\n",
    "for i in range(depth-1):\n",
    "    \n",
    "    x = layers.LeakyReLU()(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(width, kernel_initializer=tf.keras.initializers.Zeros())(x)\n",
    "    \n",
    "    x = x + input\n",
    "    \n",
    "    input = x\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "outputs = layers.Dense(latent_dim*2,kernel_initializer=tf.keras.initializers.Zeros())(x)\n",
    "\n",
    "encoder = keras.Model(inputs=inputs, outputs=outputs, name=\"encoder_model\")\n",
    "\n",
    "# encoder.summary()\n",
    "\n",
    "# keras.utils.plot_model(encoder, \"encoder.png\")\n",
    "keras.utils.plot_model(encoder, \"encoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea345bb8",
   "metadata": {},
   "source": [
    "## Prior network (Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3438dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### for default_credit ###\n",
    "input_dim_vec = [1, 2, 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1 ,1 ,1 ,1, 2]\n",
    "width = 350\n",
    "depth = 3\n",
    "latent_dim = 8\n",
    "\n",
    "inputs = keras.Input(shape=(sum(input_dim_vec)*2,))\n",
    "input = layers.Dense(width)(inputs)\n",
    "\n",
    "for i in range(depth-1):\n",
    "    \n",
    "    x = layers.LeakyReLU()(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(width, kernel_initializer=tf.keras.initializers.Zeros())(x)\n",
    "    \n",
    "    x = x + input\n",
    "    \n",
    "    input = x\n",
    "\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "outputs = layers.Dense(latent_dim*2,kernel_initializer=tf.keras.initializers.Zeros())(x)\n",
    "\n",
    "encoder = keras.Model(inputs=inputs, outputs=outputs, name=\"encoder_model\")\n",
    "\n",
    "# encoder.summary()\n",
    "\n",
    "# keras.utils.plot_model(encoder, \"encoder.png\")\n",
    "keras.utils.plot_model(encoder, \"encoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54449180",
   "metadata": {},
   "source": [
    "## Generator (Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a568e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wine', 'default_credit', 'compas', 'lsat']\n",
    "widths = [350, 350, 350, 350] # Bigger than VAE because the task of modelling all conditionals is more complex\n",
    "depths = [3, 3, 3, 3] # We go deeper because we are using residual models\n",
    "latent_dims = [6, 8, 4, 4]\n",
    "under_latent_dims = [6, 8, 4, 4] # following the original paper we set dim(u) = dim(z) with d>r [r is true manifold dim]\n",
    "under_latent_dims2 = [4, 6, 3, 3] # following the original paper we set dim(u) = dim(z) with d>r [r is true manifold dim]\n",
    "\n",
    "dname = 'wine'\n",
    "print(dname)\n",
    "\n",
    "x_train, x_test, x_means, x_stds = \\\n",
    "load_UCI(dset_name=dname, splits=10, seed=42, separate_targets=False, save_dir='../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf73fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix input dimensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
